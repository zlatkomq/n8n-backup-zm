{
  "active": true,
  "connections": {
    "RFP PDF Upload Form": {
      "main": [
        []
      ]
    },
    "Extract Text from PDF": {
      "main": [
        [
          {
            "node": "Prepare RFP Context",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare RFP Context": {
      "main": [
        [
          {
            "node": "Text Cleanup",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Text Cleanup": {
      "main": [
        [
          {
            "node": "TechStack",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Chunking": {
      "main": [
        [
          {
            "node": "Document Extraction1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Add Chunk Index": {
      "main": [
        []
      ]
    },
    "Clean and Combine Chunks": {
      "main": [
        []
      ]
    },
    "Format Data": {
      "main": [
        [
          {
            "node": "Effort Estimator",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Scope & Requirements Extractor": {
      "main": [
        [
          {
            "node": "Prepare for frontend1",
            "type": "main",
            "index": 0
          },
          {
            "node": "Format Data",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Calculator": {
      "ai_tool": [
        [
          {
            "node": "Effort Estimator",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Effort Estimator": {
      "main": [
        [
          {
            "node": "Prepare for frontend2",
            "type": "main",
            "index": 0
          },
          {
            "node": "Team Composition Agent",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Team Composition Agent": {
      "main": [
        [
          {
            "node": "Format Json",
            "type": "main",
            "index": 0
          },
          {
            "node": "Development Plan",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Format Json": {
      "main": [
        [
          {
            "node": "Prepare for frontend3",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Total Effort": {
      "main": [
        [
          {
            "node": "Prepare for frontend5",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Development Plan": {
      "main": [
        [
          {
            "node": "Prepare for frontend4",
            "type": "main",
            "index": 0
          },
          {
            "node": "Prepare for frontend6",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Structured Output Parser": {
      "ai_outputParser": [
        [
          {
            "node": "Effort Estimator",
            "type": "ai_outputParser",
            "index": 0
          }
        ]
      ]
    },
    "Anthropic Chat Model": {
      "ai_languageModel": [
        [
          {
            "node": "Effort Estimator",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Anthropic Chat Model1": {
      "ai_languageModel": [
        []
      ]
    },
    "Anthropic Chat Model2": {
      "ai_languageModel": [
        [
          {
            "node": "Document Extraction1",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Anthropic Chat Model3": {
      "ai_languageModel": [
        [
          {
            "node": "Team Composition Agent",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Anthropic Chat Model4": {
      "ai_languageModel": [
        [
          {
            "node": "Development Plan",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Calculator1": {
      "ai_tool": [
        [
          {
            "node": "Development Plan",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Anthropic Chat Model5": {
      "ai_languageModel": [
        [
          {
            "node": "Reporter",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Reporter": {
      "main": [
        [
          {
            "node": "Prepare for frontend7",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Anthropic Chat Model6": {
      "ai_languageModel": [
        [
          {
            "node": "Extract - Sonnet",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Structured Output Parser1": {
      "ai_outputParser": [
        [
          {
            "node": "Extract - Sonnet",
            "type": "ai_outputParser",
            "index": 0
          }
        ]
      ]
    },
    "When clicking ‘Test workflow’": {
      "main": [
        []
      ]
    },
    "final_report1": {
      "main": [
        []
      ]
    },
    "file_upload1": {
      "main": [
        [
          {
            "node": "Wait",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Wait": {
      "main": [
        [
          {
            "node": "document_preparation1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Wait1": {
      "main": [
        [
          {
            "node": "data_extraction1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "data_extraction1": {
      "main": [
        [
          {
            "node": "Wait2",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Wait2": {
      "main": [
        [
          {
            "node": "scope_analysis1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "scope_analysis1": {
      "main": [
        [
          {
            "node": "Wait3",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Wait3": {
      "main": [
        [
          {
            "node": "effort_estimation1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "effort_estimation1": {
      "main": [
        [
          {
            "node": "Wait4",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Wait4": {
      "main": [
        [
          {
            "node": "team_composition1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "team_composition1": {
      "main": [
        [
          {
            "node": "Wait5",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Wait5": {
      "main": [
        [
          {
            "node": "development_plan1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "development_plan1": {
      "main": [
        [
          {
            "node": "Wait6",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Wait6": {
      "main": [
        [
          {
            "node": "final_report1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "document_preparation1": {
      "main": [
        [
          {
            "node": "Wait1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Code1": {
      "main": [
        [
          {
            "node": "data_extraction",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare for frontend": {
      "main": [
        [
          {
            "node": "delivery_context",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare for frontend1": {
      "main": [
        [
          {
            "node": "scope_analysis",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Structured Output Parser2": {
      "ai_outputParser": [
        []
      ]
    },
    "Prepare for frontend2": {
      "main": [
        [
          {
            "node": "effort_estimation",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare for frontend3": {
      "main": [
        [
          {
            "node": "team_composition",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare for frontend4": {
      "main": [
        [
          {
            "node": "development_plan",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Structured Output Parser3": {
      "ai_outputParser": [
        [
          {
            "node": "Development Plan",
            "type": "ai_outputParser",
            "index": 0
          }
        ]
      ]
    },
    "Prepare for frontend5": {
      "main": [
        [
          {
            "node": "Prepare for Gantt",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare for frontend6": {
      "main": [
        [
          {
            "node": "Total Effort",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare for frontend7": {
      "main": [
        [
          {
            "node": "final_report",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare for Gantt": {
      "main": [
        [
          {
            "node": "Reporter",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "RFP Upload": {
      "main": [
        [
          {
            "node": "Extract Text from PDF",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Send PDF to Email": {
      "main": [
        [
          {
            "node": "Code",
            "type": "main",
            "index": 0
          },
          {
            "node": "Merge",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Gmail": {
      "main": [
        []
      ]
    },
    "Code": {
      "main": [
        [
          {
            "node": "Merge",
            "type": "main",
            "index": 1
          }
        ]
      ]
    },
    "Merge": {
      "main": [
        [
          {
            "node": "Gmail",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Structured Output Parser4": {
      "ai_outputParser": [
        [
          {
            "node": "TechStack",
            "type": "ai_outputParser",
            "index": 0
          }
        ]
      ]
    },
    "Anthropic Chat Model7": {
      "ai_languageModel": [
        [
          {
            "node": "TechStack",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "TechStack": {
      "main": [
        [
          {
            "node": "Delivery Context",
            "type": "main",
            "index": 0
          },
          {
            "node": "Prepare for frontend8",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Anthropic Chat Model8": {
      "ai_languageModel": [
        [
          {
            "node": "Delivery Context",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Structured Output Parser5": {
      "ai_outputParser": [
        [
          {
            "node": "Delivery Context",
            "type": "ai_outputParser",
            "index": 0
          }
        ]
      ]
    },
    "Delivery Context": {
      "main": [
        [
          {
            "node": "Prepare for frontend",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Code2": {
      "main": [
        []
      ]
    },
    "Google Gemini Chat Model": {
      "ai_languageModel": [
        [
          {
            "node": "Preprocess Gemini",
            "type": "ai_languageModel",
            "index": 0
          },
          {
            "node": "Preprocess Exclude",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Structured Output Parser7": {
      "ai_outputParser": [
        []
      ]
    },
    "Preprocess Gemini": {
      "main": [
        [
          {
            "node": "Markdown to JSON1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare for frontend9": {
      "main": [
        [
          {
            "node": "document_preparation",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Markdown to JSON": {
      "main": [
        [
          {
            "node": "Clean and Combine Chunks1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Generate HTML": {
      "main": [
        [
          {
            "node": "RFP HTML - Changes",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare for frontend10": {
      "main": [
        [
          {
            "node": "document_preparation3",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Markdown to JSON1": {
      "main": [
        [
          {
            "node": "Generate HTML1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Generate HTML1": {
      "main": [
        [
          {
            "node": "RFP HTML - Changes1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Clean and Combine Chunks1": {
      "main": [
        [
          {
            "node": "Generate HTML",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Extract - Sonnet": {
      "main": [
        [
          {
            "node": "Markdown to JSON1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Chunking - Gemini": {
      "main": [
        [
          {
            "node": "Basic LLM Chain2",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Google Gemini Chat Model1": {
      "ai_languageModel": [
        [
          {
            "node": "Preprocess Gemini -reverse",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Preprocess Gemini -reverse": {
      "main": [
        [
          {
            "node": "remove '''json",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Code3": {
      "main": [
        []
      ]
    },
    "remove '''json": {
      "main": [
        [
          {
            "node": "Code3",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Chat Model": {
      "ai_languageModel": [
        []
      ]
    },
    "Google Gemini Chat Model2": {
      "ai_languageModel": [
        [
          {
            "node": "Scope & Requirements Extractor",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Prepare for frontend8": {
      "main": [
        [
          {
            "node": "tech_stack1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "delivery_context": {
      "main": [
        []
      ]
    },
    "Basic LLM Chain": {
      "main": [
        [
          {
            "node": "Code4",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Chat Model1": {
      "ai_languageModel": [
        [
          {
            "node": "Basic LLM Chain",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Basic LLM Chain1": {
      "main": [
        [
          {
            "node": "remove '''json1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Chat Model2": {
      "ai_languageModel": [
        [
          {
            "node": "Basic LLM Chain1",
            "type": "ai_languageModel",
            "index": 0
          },
          {
            "node": "Basic LLM Chain2",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "remove '''json1": {
      "main": [
        [
          {
            "node": "Code5",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Preprocess Exclude": {
      "main": [
        [
          {
            "node": "Markdown to JSON1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "RFP Upload1": {
      "main": [
        [
          {
            "node": "file_upload1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "createdAt": "2025-03-31T16:18:56.271Z",
  "id": "cHtp8Fd5t5HO71iG",
  "isArchived": false,
  "meta": {
    "templateCredsSetupCompleted": true
  },
  "name": "Estimation Tool Public",
  "nodes": [
    {
      "parameters": {
        "formTitle": "RFP Analyzer",
        "formDescription": "Upload your RFP document to extract features, create a backlog, and estimate development time",
        "formFields": {
          "values": [
            {
              "fieldLabel": "RFP Document (PDF)",
              "fieldType": "file",
              "acceptFileTypes": ".pdf",
              "requiredField": true
            }
          ]
        },
        "options": {}
      },
      "id": "013d584a-3315-484b-910e-7770a7ede089",
      "name": "RFP PDF Upload Form",
      "type": "n8n-nodes-base.formTrigger",
      "position": [
        -1600,
        1920
      ],
      "typeVersion": 2.2,
      "webhookId": "d9fa7da6-8639-44cf-951c-8f1e63fa048e",
      "disabled": true
    },
    {
      "parameters": {
        "operation": "pdf",
        "binaryPropertyName": "=file",
        "options": {}
      },
      "id": "982ec328-0301-4c11-8de9-ae419abd7677",
      "name": "Extract Text from PDF",
      "type": "n8n-nodes-base.extractFromFile",
      "position": [
        -1380,
        2330
      ],
      "typeVersion": 1
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "62eb33b1-52f2-4a1e-b0e8-9a5e7a96ccbf",
              "name": "rfpText",
              "type": "string",
              "value": "={{ $json.text }}"
            }
          ]
        },
        "options": {}
      },
      "id": "a75a337d-a8c1-4339-963a-4dfe8af5d285",
      "name": "Prepare RFP Context",
      "type": "n8n-nodes-base.set",
      "position": [
        -1160,
        2330
      ],
      "typeVersion": 3.4
    },
    {
      "parameters": {
        "jsCode": "// This function handles cleaning and formatting of RFP text for LLM processing\nfunction cleanRfpText(text) {\n  if (!text || typeof text !== 'string') {\n    throw new Error('Invalid input: Expected text string');\n  }\n\n  let cleanedText = text;\n\n  try {\n    // 1. Fix common OCR issues and formatting problems\n    cleanedText = cleanedText\n      // Fix broken line breaks from PDF extraction\n      .replace(/(\\w+)-\\s*\\n\\s*(\\w+)/g, '$1$2')\n      \n      // Normalize whitespace (multiple spaces, tabs)\n      .replace(/[ \\t]+/g, ' ')\n      \n      // Fix paragraph breaks (ensure consistent double line breaks)\n      .replace(/\\n{3,}/g, '\\n\\n')\n      \n      // Fix bullet points and numbered lists\n      .replace(/•\\s*/g, '• ')\n      .replace(/(\\d+)[\\.\\)]\\s*/g, '$1. ')\n      \n      // Clean up page numbers and headers/footers\n      .replace(/Page \\d+ of \\d+/gi, '')\n      .replace(/^\\s*\\d+\\s*$\\n/gm, '')\n      \n      // Fix common OCR errors\n      .replace(/\\bI\\s+I\\b/g, 'II')\n      .replace(/\\b1\\s+I\\b/g, 'II')\n      .replace(/\\bO\\b/g, '0')\n      .replace(/\\b0\\b/g, 'O') // CAUTION: Only uncomment if truly needed for your RFPs\n      \n      // Remove form field markers often found in PDFs\n      .replace(/□|☐|■|☑|☒/g, '')\n      \n      // Fix broken section headers\n      .replace(/(\\d+)[\\.\\s]+([A-Z][a-z]+)\\s*\\n/g, '$1. $2\\n')\n      \n      // Normalize URLs\n      .replace(/(?:https?:\\/\\/)(?:www\\.)?([a-zA-Z0-9-]+(?:\\.[a-zA-Z0-9-]+)+)(?:\\/[^\\s]*)?/g, 'https://$1')\n      \n      // Fix broken table structures\n      .replace(/\\|\\s*\\|/g, '|')\n      .replace(/\\|\\s*\\n\\s*\\|/g, '|\\n|')\n      \n      // Standardize quotation marks\n      .replace(/[\"\"]/g, '\"')\n      .replace(/['']/g, \"'\");\n    \n    // 2. Handle structured content like sections and tables\n    // Find and standardize section headings\n    cleanedText = cleanedText.replace(/^(\\d+\\.?\\d*\\.?\\d*)\\s+([A-Z][A-Za-z\\s]+)$/gm, \n                                     '## $1 $2');\n    \n    // 3. Special handling for common RFP components\n\n    \n    \n    // Format requirements sections\n    cleanedText = cleanedText.replace(/Requirements?:?\\s*\\n/gi, '### Requirements:\\n');\n    \n    // Format deliverables sections\n    cleanedText = cleanedText.replace(/Deliverables?:?\\s*\\n/gi, '### Deliverables:\\n');\n    \n    // Format timeline/schedule sections\n    cleanedText = cleanedText.replace(/(?:Timeline|Schedule):?\\s*\\n/gi, '### Timeline:\\n');\n    \n    // 4. Final cleanup\n    // Remove redundant spaces at line beginnings/endings\n    cleanedText = cleanedText.replace(/^\\s+|\\s+$/gm, '');\n    \n    // Ensure consistent heading formatting for sections\n    cleanedText = cleanedText.replace(/^([A-Z][A-Z\\s]+):\\s*$/gm, '## $1');\n    \n    // Remove PDF artifacts like Form field [____] often used for signatures\n    cleanedText = cleanedText.replace(/\\[_{2,}\\]/g, '[SIGNATURE FIELD]');\n    \n    // Replace multiple spaces between sentences\n    cleanedText = cleanedText.replace(/\\.\\s{2,}/g, '. ');\n    \n    // Normalize line endings\n    cleanedText = cleanedText.replace(/\\r\\n/g, '\\n');\n\n    // Add this to your cleanRfpText function before the final cleanup section\n\n  // Remove table of contents ellipses patterns\n    cleanedText = cleanedText.replace(/\\.{2,}\\s*\\d+$/gm, '');\n\n// Remove lines that are just ellipses\n    cleanedText = cleanedText.replace(/^\\.{3,}$/gm, '');\n\n// Clean up lines with text followed by ellipses and page numbers\ncleanedText = cleanedText.replace(/^(.*?)\\.{2,}\\s*\\d+$/gm, '$1');\n\n    // Remove lines that are mostly or entirely periods/dots\ncleanedText = cleanedText.replace(/^[.\\s]*$\\n?/gm, '');\n\n// For lines with extreme repetition of periods (like in TOC formatting)\ncleanedText = cleanedText.replace(/\\.{10,}/g, '');\n\n// Clean up lines where text is followed by many periods\ncleanedText = cleanedText.replace(/^(.*?)\\s*\\.{5,}\\s*(\\d+)?$/gm, '$1');\n    \n    // 5. Sanity check to ensure we haven't broken the text\n    if (cleanedText.length < 0.5 * text.length) {\n      console.log('Warning: Cleaning reduced text length by more than 50%. Using original with basic cleaning.');\n      return text.replace(/\\s+/g, ' ').trim();\n    }\n    \n    return cleanedText.trim();\n  } catch (error) {\n    console.error('Error during RFP text cleaning:', error);\n    // Return original text with basic cleaning if something goes wrong\n    return text.replace(/\\s+/g, ' ').trim();\n  }\n}\n\n// Main function for n8n processing\nconst rfpText = $input.first()?.json?.rfpText;\n\nif (!rfpText) {\n  return {\n    json: {\n      error: 'No RFP text found in input',\n      expectedInput: 'json.rfpText'\n    }\n  };\n}\n\ntry {\n  const cleanedRfpText = cleanRfpText(rfpText);\n  \n  return {\n    json: {\n      cleanedRfpText,\n      originalLength: rfpText.length,\n      cleanedLength: cleanedRfpText.length,\n      reductionPercentage: ((rfpText.length - cleanedRfpText.length) / rfpText.length * 100).toFixed(2) + '%'\n    }\n  };\n} catch (error) {\n  return {\n    json: {\n      error: error.message,\n      errorDetails: error.toString(),\n      partialResult: rfpText.replace(/\\s+/g, ' ').trim()\n    }\n  };\n}"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -940,
        2330
      ],
      "id": "df80563a-5e15-40ee-bec6-4b9749c37e4d",
      "name": "Text Cleanup"
    },
    {
      "parameters": {
        "jsCode": "const text = $('Extract - Sonnet').first().json.output.markdown; // replace with the correct input field if different\nconst maxChars = 10000; // GPT-4o-safe chunk size (~1500 tokens)\nconst overlapChars = 600; // optional overlap to preserve context\n\nfunction smartChunker(text, maxLen, overlap = 0) {\n  const chunks = [];\n  const paragraphs = text.split(/\\n{2,}/); // split on double newlines (semantic breaks)\n  let buffer = \"\";\n\n  for (const para of paragraphs) {\n    const paragraph = para.trim();\n    if (!paragraph) continue;\n\n    if ((buffer + \"\\n\\n\" + paragraph).length <= maxLen) {\n      buffer += (buffer ? \"\\n\\n\" : \"\") + paragraph;\n    } else {\n      if (buffer) {\n        chunks.push(buffer.trim());\n      }\n      // paragraph might still be too large — break it into sentences\n      if (paragraph.length > maxLen) {\n        const sentences = paragraph.split(/(?<=[.?!])\\s+/);\n        let sentenceBuffer = \"\";\n        for (const sentence of sentences) {\n          if ((sentenceBuffer + \" \" + sentence).length <= maxLen) {\n            sentenceBuffer += (sentenceBuffer ? \" \" : \"\") + sentence;\n          } else {\n            if (sentenceBuffer) chunks.push(sentenceBuffer.trim());\n            sentenceBuffer = sentence;\n          }\n        }\n        if (sentenceBuffer) chunks.push(sentenceBuffer.trim());\n        buffer = \"\";\n      } else {\n        chunks.push(paragraph);\n        buffer = \"\";\n      }\n    }\n  }\n\n  if (buffer) chunks.push(buffer.trim());\n\n  // Apply overlap if needed\n  const overlappedChunks = [];\n  for (let i = 0; i < chunks.length; i++) {\n    let chunk = chunks[i];\n    if (i > 0 && overlap > 0) {\n      const prevChunk = chunks[i - 1];\n      const overlapText = prevChunk.slice(-overlap);\n      chunk = overlapText + \"\\n\\n\" + chunk;\n    }\n    overlappedChunks.push({ chunk, index: i + 1 });\n  }\n\n  return overlappedChunks;\n}\n\nconst finalChunks = smartChunker(text, maxChars, overlapChars);\n\n// Output each chunk as its own item in the workflow\nreturn finalChunks.map(c => ({\n  json: {\n    chunk_index: c.index,\n    chunk_text: c.chunk\n  }\n}));\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1600,
        0
      ],
      "id": "e1e89e09-5859-4c49-a271-ba007c7b9f36",
      "name": "Chunking",
      "disabled": true
    },
    {
      "parameters": {
        "jsCode": "// Loop over input items and add a new field called 'myNewField' to the JSON of each one\nvar number = 0;\nfor (const item of $input.all()) {\n  item.json.chunkIndex = number++;\n}\n\nreturn $input.all();"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1600,
        620
      ],
      "id": "773da2a5-5361-4bfb-b3ee-16240611e983",
      "name": "Add Chunk Index",
      "disabled": true
    },
    {
      "parameters": {
        "jsCode": "for (const item of $input.all()) {\n  chunkIndex++;\n  console.log(`⏳ Processing chunk ${chunkIndex}`);\n\n  let raw = item.json.output || item.json.chunk_text || \"\";\n  console.log(`✂️ Raw length: ${raw.length}`);\n\n  const cleanRaw = tryToFixMalformedJson(raw);\n\n  let parsed;\n  try {\n    parsed = JSON.parse(cleanRaw);\n    console.log(`✅ Parsed chunk ${chunkIndex}, ${parsed.length} items`);\n  } catch (e) {\n    console.error(`❌ Failed chunk ${chunkIndex}:`, e.message);\n    throw new Error(`❌ JSON parse failed in chunk ${chunkIndex}: ${e.message}`);\n  }\n\n  for (const req of parsed) {\n    if (req && req.description) {\n      output.push({\n        json: {\n          chunkIndex,\n          ...req\n        }\n      });\n    }\n  }\n}\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1600,
        1400
      ],
      "id": "22a34424-7503-4389-8796-60c67c146fba",
      "name": "Clean and Combine Chunks"
    },
    {
      "parameters": {
        "jsCode": "const input = $input.first().json.output; // grab the full array from \"output\"\n\nconst grouped = {\n  FR: [],\n  NFR: [],\n  TC: [],\n  BC: []\n};\n\nfor (const { category, description } of input) {\n  if (grouped[category]) {\n    grouped[category].push(`- ${description}`);\n  }\n}\n\nlet formattedText = `## Project Features (Grouped)\\n`;\n\nfor (const cat of ['FR', 'NFR', 'TC', 'BC']) {\n  if (grouped[cat].length > 0) {\n    const label = {\n      FR: \"Functional Requirements\",\n      NFR: \"Non-functional Requirements\",\n      TC: \"Technical Constraints\",\n      BC: \"Business Constraints\"\n    }[cat];\n\n    formattedText += `\\n### ${label}\\n${grouped[cat].join('\\n')}\\n`;\n  }\n}\n\nreturn [\n  {\n    json: {\n      formattedFeatures: formattedText\n    }\n  }\n];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        472,
        2630
      ],
      "id": "555b0744-8bb6-4ff0-a183-d2e7b60efcee",
      "name": "Format Data"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=You will receive a complete list of structured project requirements, written in Markdown. Your task is to extract all meaningful features and expectations and assign them to one of the following categories:\n\n- Functional Requirement (FR): What the system must do.\n- Non-functional Requirement (NFR): How the system must behave (e.g. performance, usability, security).\n- Technical Constraint (TC): Technology or architecture constraints (e.g. on-premise hosting, DB selection).\n- Business Constraint (BC): Policy, contract, or staffing constraints (e.g. SLA terms, staffing location).\n\nInstructions:\n- You must assign every feature to one of the four categories.\n- If a feature could belong to multiple categories, choose the most specific and relevant one.\n- Do not skip, combine, or summarize any features.\n- Do not refer to “the document” or mention formatting.\n- Do not include commentary, labels, headings, or markdown blocks.\n\nReturn only the result as a clean JSON array, using this structure:\n[\n  features: {\n    \"category\": \"FR | NFR | TC | BC\",\n    \"description\": \"Clear and specific requirement\"\n  },\n  ...\n]\n\n--- BEGIN REQUIREMENTS ---\n{{ $json.cleanedRfpText }}\n--- END REQUIREMENTS ---\n",
        "options": {
          "systemMessage": "You are highly disciplined, consistent, and precise. Your output must be reliable for automation and estimation.\n\nYou are a Scope and Requirements Analysis Agent specializing in software project proposals. You analyze complete, structured RFP scope content and extract key requirements, goals, and constraints.\n\nYou always:\n- Identify and tag requirements using one of four categories:\n  - Functional Requirement (FR)\n  - Non-functional Requirement (NFR)\n  - Technical Constraint (TC)\n  - Business Constraint (BC)\n- Preserve every relevant feature without omission, duplication, or interpretation\n- Ensure clean, accurate, and structured output that downstream systems can use directly\n\nYou are highly disciplined, consistent, and precise. Your output must be delivered as a valid JSON array and must be reliable for automation and effort estimation.\n"
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.8,
      "position": [
        100,
        2480
      ],
      "id": "e605d8ec-7891-4c4e-9af3-2b5fb3af3396",
      "name": "Scope & Requirements Extractor"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=Below is a grouped list of features and requirements extracted from a software project RFP.\n\nYour tasks:\n1. Estimate the number of 2-week sprints needed to implement this project.\n2. Return a range: `min_sprints` to `max_sprints`.\n3. Explain your reasoning — highlight areas of likely complexity or unknowns and return it in 'note'.\n4. Write the risks that you see.\n\nKey delivery assumptions:\n- Development will be performed using **AI-assisted tooling**, including AI pair programming, code generation, and automated testing.\n- Assume a typical cross-functional team (backend, frontend, mobile, QA, PM, etc.).\n- The team is experienced, cross-functional, and capable of delivering 13-16 story points per sprint.\n- Use a **narrow range** between min and max where there are no big unknowns.\n- If there are big unknowns and risks, explain them and explain how they are affecting the max range.\n- Do NOT include wide buffers or overly cautious estimates.\n- Do NOT create a detailed plan or estimate per feature.\n- Base your estimate on realistic, high-velocity agile delivery.\n- Focus on giving a well-informed effort range based on scope size and density.\n\n\n--- BEGIN FEATURES ---\n{{ $json.formattedFeatures }}\n--- END FEATURES ---\n",
        "hasOutputParser": true,
        "options": {
          "systemMessage": "You are a highly disciplined and accurate software effort estimation agent. You evaluate project requirements and return precise sprint estimates for delivery using agile practices. Your estimates should reflect AI-augmented engineering workflows.\n"
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.8,
      "position": [
        720,
        2640
      ],
      "id": "651fbb91-facd-4711-8f57-09c484e582ff",
      "name": "Effort Estimator"
    },
    {
      "parameters": {},
      "type": "@n8n/n8n-nodes-langchain.toolCalculator",
      "typeVersion": 1,
      "position": [
        812,
        2850
      ],
      "id": "7e017f4e-3f09-4b66-8380-b192c944b3b2",
      "name": "Calculator"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=A software development project has been scoped and effort has been estimated at between {{ $json.output.min_sprints }} and {{ $json.output.max_sprints }} sprints (2-week sprints). Below is a grouped list of the project’s functional, non-functional, technical, and business requirements.\n\nYour task:\n1. Recommend the team composition required to deliver this project efficiently.\n2. For each role, specify:\n   - `\"role\"`: Role title\n   - `\"count\"`: Approximate number of people\n   - `\"justification\"`: Why this role is needed\n3. Consider all relevant delivery work: development, testing, infrastructure, security, compliance, deployment, and training.\n\n**Format**: Return only a JSON array like this (no explanation or headers):\n```json\n[\n  {\n    \"role\": \"Backend Developer\",\n    \"count\": 2,\n    \"justification\": \"Handles core APIs, database integration, and logic-heavy modules like translation memory and OCR.\"\n  },\n  ...\n]\n--- BEGIN REQUIREMENTS --- {{ $('Format Data').item.json.formattedFeatures }} --- END REQUIREMENTS ---",
        "options": {
          "systemMessage": "You are a software delivery strategist and agile team architect. You design cross-functional delivery teams for software projects based on project scope and delivery timeline.\n\nYou always return precise, justified team structures in clean JSON format, without commentary or summaries.\n"
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.8,
      "position": [
        1180,
        2720
      ],
      "id": "dd1c8452-9257-402f-a5b5-e3998aa1dad1",
      "name": "Team Composition Agent"
    },
    {
      "parameters": {
        "jsCode": "const raw = $input.first().json.output || \"\";\n\n// Remove code fences (e.g., ```json ... ```)\nconst clean = raw.replace(/^```json\\s*|\\s*```$/g, '').trim();\n\nlet team;\ntry {\n  team = JSON.parse(clean);\n} catch (err) {\n  throw new Error(\"Failed to parse team composition JSON: \" + err.message);\n}\n\n// Wrap the whole array under the \"team\" key and return as a single item\nreturn [\n  {\n    json: {\n      team\n    }\n  }\n];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1618,
        2580
      ],
      "id": "7cbc530d-9043-4e36-8029-1e909499163d",
      "name": "Format Json"
    },
    {
      "parameters": {
        "jsCode": "// Get the stringified team JSON from the first input item\nconst raw =  $('Team Composition Agent').first().json.output || \"\";\n\nlet team;\ntry {\n  team = JSON.parse(raw); // parse the JSON string\n} catch (err) {\n  throw new Error(\"Failed to parse team JSON: \" + err.message);\n}\n\n// Get sprint range from another node\nconst minSprints = $('Effort Estimator').first().json.output.min_sprints ?? 0;\nconst maxSprints = $('Effort Estimator').first().json.output.max_sprints ?? 0;\n\n// Calculate totals\nconst totalTeamSize = team.reduce((sum, member) => sum + Number(member.count || 0), 0);\nconst daysPerSprintPerPerson = 10;\nconst personDaysPerSprint = totalTeamSize * daysPerSprintPerPerson;\nconst minPersonDays = minSprints * personDaysPerSprint;\nconst maxPersonDays = maxSprints * personDaysPerSprint;\nconst avgSprints = (minSprints + maxSprints) / 2;\nconst avgEffort = (minPersonDays + maxPersonDays) / 2;\nconst fteEstimate = avgEffort / (avgSprints * 10); // 10 days per person per sprint\n\n// Prepare summary for report\nconst teamSummary = team.map(member => ({\n  role: member.role,\n  count: Number(member.count)\n}));\n\nreturn [\n  {\n    json: {\n      effort: {\n      total_team_size: totalTeamSize,\n      days_per_sprint_per_person: daysPerSprintPerPerson,\n      person_days_per_sprint: personDaysPerSprint,\n      estimated_effort: {\n        min_sprints: minSprints,\n        max_sprints: maxSprints,\n        min_person_days: minPersonDays,\n        max_person_days: maxPersonDays,\n        fte_estimate: fteEstimate\n      }\n      },\n      team_summary: teamSummary\n    }\n  }\n];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        2168,
        3030
      ],
      "id": "a48ec15d-fc56-4327-8304-be8914cc5c43",
      "name": "Total Effort"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=We have a software development project with the following scope and estimated effort:\n\n- Estimated duration: {{ $('Effort Estimator').item.json.output.min_sprints }} to {{ $('Effort Estimator').item.json.output.max_sprints }} sprints (2-week sprints)\n- Below is a grouped list of functional, non-functional, technical, and business requirements.\n\nYour task:\n1. Create a high-level **sprint-based development plan** that aligns with the estimated duration.\n2. Organize the plan into **semantically labeled phases** based on common delivery flow, such as:\n   - \"Planning and Foundation\"\n   - \"Core Development\"\n   - \"Feature Completion and Polishing\"\n   - \"Finalization and Handover\"\n3. For each phase, include:\n   - A `\"name\"` (semantic label as described)\n   - A `\"sprints\"` object with `\"start\"` and `\"end\"` sprint numbers\n   - A list of `\"items\"` representing deliverables, feature groups, or technical milestones\n\n4. Also provide a `\"cross_cutting\"` section with grouped items under:\n   - `\"infrastructure\"`\n   - `\"security\"`\n   - `\"testing\"`\n   - `\"documentation\"`\n   - `\"deployment\"`\n\nYou must not re-estimate effort. Use the sprint range provided.\n\nReturn your response as a single valid JSON object using this structure:\n{\n  \"phases\": [\n    {\n      \"name\": \"Planning and Foundation\",\n      \"sprints\": { \"start\": 1, \"end\": 2 },\n      \"items\": [\n        \"Set up environments and CI/CD pipeline\",\n        \"Define architecture and technical frameworks\",\n        \"Implement user authentication and role system\"\n      ]\n    },\n    {\n      \"name\": \"Core Development\",\n      \"sprints\": { \"start\": 3, \"end\": 6 },\n      \"items\": [\n        \"Develop mission system and rewards engine\",\n        \"Integrate forest visualization and topic feed\"\n      ]\n    }\n    // ...more phases\n  ],\n  \"cross_cutting\": {\n    \"infrastructure\": [ \"CI/CD setup\", \"VPN access configuration\" ],\n    \"security\": [ \"Access control\", \"Penetration testing\" ],\n    \"testing\": [ \"Unit testing\", \"UAT\" ],\n    \"documentation\": [ \"API documentation\", \"User guides\" ],\n    \"deployment\": [ \"Staging environment\", \"Production rollout\" ]\n  }\n}\n\nDo not return markdown, bullet points, or code fences. Only output valid JSON.\n--- BEGIN REQUIREMENTS ---\n{{ $('Format Data').first().json.formattedFeatures }}\n--- END REQUIREMENTS ---\n",
        "hasOutputParser": true,
        "options": {
          "systemMessage": "You are a senior technical project planner and agile delivery strategist. You design high-level sprint-based development plans for software projects based on known scope and estimated duration.\n\nYou always:\n- Organize the plan into clear sprint phases\n- Include key delivery activities per phase\n- Address cross-cutting themes like infrastructure, testing, and security\n- Avoid repeating or re-estimating effort\n"
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.8,
      "position": [
        1540,
        2930
      ],
      "id": "725d2801-a750-462b-9d60-637ff01cc7ee",
      "name": "Development Plan"
    },
    {
      "parameters": {
        "jsonSchemaExample": "{\n\t\"min_sprints\": 0,\n\t\"max_sprints\": 0,\n    \"note\":\"\"\n}"
      },
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "typeVersion": 1.2,
      "position": [
        932,
        2850
      ],
      "id": "09d89d9d-05db-41f9-a0f8-8c7617ac47a2",
      "name": "Structured Output Parser"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "claude-3-7-sonnet-20250219",
          "mode": "list",
          "cachedResultName": "Claude 3.7 Sonnet"
        },
        "options": {
          "temperature": 0.3,
          "thinking": false
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatAnthropic",
      "typeVersion": 1.3,
      "position": [
        692,
        2850
      ],
      "id": "66db6b31-b2de-489a-a2b7-16c80e502549",
      "name": "Anthropic Chat Model",
      "credentials": {
        "anthropicApi": {
          "id": "qzCm5Ds2qD9ZY1W5",
          "name": "Anthropic account"
        }
      }
    },
    {
      "parameters": {
        "operation": "append",
        "documentId": {
          "__rl": true,
          "value": "1DyuEkvoNn_yfnAWTVKvnE9UhMnjv-HjHzoaZSWpu-cE",
          "mode": "list",
          "cachedResultName": "AI Estimations",
          "cachedResultUrl": "https://docs.google.com/spreadsheets/d/1DyuEkvoNn_yfnAWTVKvnE9UhMnjv-HjHzoaZSWpu-cE/edit?usp=drivesdk"
        },
        "sheetName": {
          "__rl": true,
          "value": "gid=0",
          "mode": "list",
          "cachedResultName": "Claude 3.7",
          "cachedResultUrl": "https://docs.google.com/spreadsheets/d/1DyuEkvoNn_yfnAWTVKvnE9UhMnjv-HjHzoaZSWpu-cE/edit#gid=0"
        },
        "columns": {
          "mappingMode": "defineBelow",
          "value": {
            "Min": "={{ $json.output.min_sprints }}",
            "Max": "={{ $json.output.max_sprints }}",
            "Note": "={{ $json.output.note }}",
            "Time": "={{$now}}",
            "File": "={{ $('RFP PDF Upload Form').first().json[\"RFP Document (PDF)\"][0].filename }}"
          },
          "matchingColumns": [
            "Estimation"
          ],
          "schema": [
            {
              "id": "File",
              "displayName": "File",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "type": "string",
              "canBeUsedToMatch": true,
              "removed": false
            },
            {
              "id": "Min",
              "displayName": "Min",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "type": "string",
              "canBeUsedToMatch": true,
              "removed": false
            },
            {
              "id": "Max",
              "displayName": "Max",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "type": "string",
              "canBeUsedToMatch": true,
              "removed": false
            },
            {
              "id": "Note",
              "displayName": "Note",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "type": "string",
              "canBeUsedToMatch": true,
              "removed": false
            },
            {
              "id": "Time",
              "displayName": "Time",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "type": "string",
              "canBeUsedToMatch": true,
              "removed": false
            }
          ],
          "attemptToConvertTypes": false,
          "convertFieldsToString": false
        },
        "options": {}
      },
      "type": "n8n-nodes-base.googleSheets",
      "typeVersion": 4.5,
      "position": [
        -1600,
        1660
      ],
      "id": "84be46cb-6400-4821-a559-a57e298d2066",
      "name": "Claude 3.7",
      "credentials": {
        "googleSheetsOAuth2Api": {
          "id": "FtlTep04mtONOydH",
          "name": "Google Sheets account"
        }
      }
    },
    {
      "parameters": {
        "operation": "append",
        "documentId": {
          "__rl": true,
          "value": "1DyuEkvoNn_yfnAWTVKvnE9UhMnjv-HjHzoaZSWpu-cE",
          "mode": "list",
          "cachedResultName": "AI Estimations",
          "cachedResultUrl": "https://docs.google.com/spreadsheets/d/1DyuEkvoNn_yfnAWTVKvnE9UhMnjv-HjHzoaZSWpu-cE/edit?usp=drivesdk"
        },
        "sheetName": {
          "__rl": true,
          "value": 249221196,
          "mode": "list",
          "cachedResultName": "GPT4o",
          "cachedResultUrl": "https://docs.google.com/spreadsheets/d/1DyuEkvoNn_yfnAWTVKvnE9UhMnjv-HjHzoaZSWpu-cE/edit#gid=249221196"
        },
        "columns": {
          "mappingMode": "defineBelow",
          "value": {
            "Min": "={{ $json.output.min_sprints }}",
            "Max": "={{ $json.output.max_sprints }}",
            "Note": "={{ $json.output.note }}",
            "Time": "={{$now}}",
            "File": "={{ $('RFP PDF Upload Form').first().json[\"RFP Document (PDF)\"][0].filename }}"
          },
          "matchingColumns": [
            "Estimation"
          ],
          "schema": [
            {
              "id": "File",
              "displayName": "File",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "type": "string",
              "canBeUsedToMatch": true,
              "removed": false
            },
            {
              "id": "Min",
              "displayName": "Min",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "type": "string",
              "canBeUsedToMatch": true,
              "removed": false
            },
            {
              "id": "Max",
              "displayName": "Max",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "type": "string",
              "canBeUsedToMatch": true,
              "removed": false
            },
            {
              "id": "Note",
              "displayName": "Note",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "type": "string",
              "canBeUsedToMatch": true,
              "removed": false
            },
            {
              "id": "Time",
              "displayName": "Time",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "type": "string",
              "canBeUsedToMatch": true,
              "removed": false
            }
          ],
          "attemptToConvertTypes": false,
          "convertFieldsToString": false
        },
        "options": {}
      },
      "type": "n8n-nodes-base.googleSheets",
      "typeVersion": 4.5,
      "position": [
        -1600,
        1140
      ],
      "id": "96d5e095-3671-4cba-9a56-525eb5127ec1",
      "name": "GPT4o",
      "credentials": {
        "googleSheetsOAuth2Api": {
          "id": "FtlTep04mtONOydH",
          "name": "Google Sheets account"
        }
      }
    },
    {
      "parameters": {
        "operation": "append",
        "documentId": {
          "__rl": true,
          "value": "1DyuEkvoNn_yfnAWTVKvnE9UhMnjv-HjHzoaZSWpu-cE",
          "mode": "list",
          "cachedResultName": "AI Estimations",
          "cachedResultUrl": "https://docs.google.com/spreadsheets/d/1DyuEkvoNn_yfnAWTVKvnE9UhMnjv-HjHzoaZSWpu-cE/edit?usp=drivesdk"
        },
        "sheetName": {
          "__rl": true,
          "value": 94145736,
          "mode": "list",
          "cachedResultName": "GPT 4o mini",
          "cachedResultUrl": "https://docs.google.com/spreadsheets/d/1DyuEkvoNn_yfnAWTVKvnE9UhMnjv-HjHzoaZSWpu-cE/edit#gid=94145736"
        },
        "columns": {
          "mappingMode": "defineBelow",
          "value": {
            "Min": "={{ $json.output.min_sprints }}",
            "Max": "={{ $json.output.max_sprints }}",
            "Note": "={{ $json.output.note }}",
            "Time": "={{$now}}",
            "File": "={{ $('RFP PDF Upload Form').first().json[\"RFP Document (PDF)\"][0].filename }}"
          },
          "matchingColumns": [
            "Estimation"
          ],
          "schema": [
            {
              "id": "File",
              "displayName": "File",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "type": "string",
              "canBeUsedToMatch": true,
              "removed": false
            },
            {
              "id": "Min",
              "displayName": "Min",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "type": "string",
              "canBeUsedToMatch": true,
              "removed": false
            },
            {
              "id": "Max",
              "displayName": "Max",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "type": "string",
              "canBeUsedToMatch": true,
              "removed": false
            },
            {
              "id": "Note",
              "displayName": "Note",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "type": "string",
              "canBeUsedToMatch": true,
              "removed": false
            },
            {
              "id": "Time",
              "displayName": "Time",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "type": "string",
              "canBeUsedToMatch": true,
              "removed": false
            }
          ],
          "attemptToConvertTypes": false,
          "convertFieldsToString": false
        },
        "options": {}
      },
      "type": "n8n-nodes-base.googleSheets",
      "typeVersion": 4.5,
      "position": [
        -1600,
        -620
      ],
      "id": "1822ad25-bb13-49b2-a6f4-acabbcdc7164",
      "name": "GPT4o - mini",
      "credentials": {
        "googleSheetsOAuth2Api": {
          "id": "FtlTep04mtONOydH",
          "name": "Google Sheets account"
        }
      }
    },
    {
      "parameters": {
        "operation": "append",
        "documentId": {
          "__rl": true,
          "value": "1mDakVXLu1hkomSMS-oZtVX588sZaEY2vFjVCWVhH0hI",
          "mode": "list",
          "cachedResultName": "AI Estimation Tool  Public - Scope",
          "cachedResultUrl": "https://docs.google.com/spreadsheets/d/1mDakVXLu1hkomSMS-oZtVX588sZaEY2vFjVCWVhH0hI/edit?usp=drivesdk"
        },
        "sheetName": {
          "__rl": true,
          "value": "gid=0",
          "mode": "list",
          "cachedResultName": "Claude 3.7",
          "cachedResultUrl": "https://docs.google.com/spreadsheets/d/1mDakVXLu1hkomSMS-oZtVX588sZaEY2vFjVCWVhH0hI/edit#gid=0"
        },
        "columns": {
          "mappingMode": "defineBelow",
          "value": {
            "Output": "={{ $json.formattedFeatures }}"
          },
          "matchingColumns": [
            "Output"
          ],
          "schema": [
            {
              "id": "Output",
              "displayName": "Output",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "type": "string",
              "canBeUsedToMatch": true,
              "removed": false
            }
          ],
          "attemptToConvertTypes": false,
          "convertFieldsToString": false
        },
        "options": {}
      },
      "type": "n8n-nodes-base.googleSheets",
      "typeVersion": 4.5,
      "position": [
        -1600,
        -360
      ],
      "id": "a602fb43-a836-4bf6-8dc0-9431e5ebc72c",
      "name": "GPT4o1",
      "credentials": {
        "googleSheetsOAuth2Api": {
          "id": "FtlTep04mtONOydH",
          "name": "Google Sheets account"
        }
      }
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "claude-3-7-sonnet-20250219",
          "mode": "list",
          "cachedResultName": "Claude 3.7 Sonnet"
        },
        "options": {
          "maxTokensToSample": 8096,
          "temperature": 0.3,
          "thinking": false
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatAnthropic",
      "typeVersion": 1.3,
      "position": [
        -100,
        2980
      ],
      "id": "759734c2-711e-488e-8f37-ac6ec071b55f",
      "name": "Anthropic Chat Model1",
      "credentials": {
        "anthropicApi": {
          "id": "qzCm5Ds2qD9ZY1W5",
          "name": "Anthropic account"
        }
      }
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "claude-3-7-sonnet-20250219",
          "mode": "list",
          "cachedResultName": "Claude 3.7 Sonnet"
        },
        "options": {
          "thinking": false
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatAnthropic",
      "typeVersion": 1.3,
      "position": [
        -1292,
        120
      ],
      "id": "54aeb252-cbe1-4fc9-af5a-eb431172e12c",
      "name": "Anthropic Chat Model2",
      "credentials": {
        "anthropicApi": {
          "id": "qzCm5Ds2qD9ZY1W5",
          "name": "Anthropic account"
        }
      },
      "disabled": true
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "mode": "list",
          "value": "claude-3-7-sonnet-20250219",
          "cachedResultName": "Claude 3.7 Sonnet"
        },
        "options": {
          "temperature": 0.3
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatAnthropic",
      "typeVersion": 1.3,
      "position": [
        1220,
        3000
      ],
      "id": "e4aa4353-3ea3-459b-aec6-ea8d195b9835",
      "name": "Anthropic Chat Model3",
      "credentials": {
        "anthropicApi": {
          "id": "qzCm5Ds2qD9ZY1W5",
          "name": "Anthropic account"
        }
      }
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "mode": "list",
          "value": "claude-3-7-sonnet-20250219",
          "cachedResultName": "Claude 3.7 Sonnet"
        },
        "options": {
          "temperature": 0.3
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatAnthropic",
      "typeVersion": 1.3,
      "position": [
        1500,
        3160
      ],
      "id": "6f5a4c8b-372f-45ae-9489-2f5a5e8e0296",
      "name": "Anthropic Chat Model4",
      "credentials": {
        "anthropicApi": {
          "id": "qzCm5Ds2qD9ZY1W5",
          "name": "Anthropic account"
        }
      }
    },
    {
      "parameters": {},
      "type": "@n8n/n8n-nodes-langchain.toolCalculator",
      "typeVersion": 1,
      "position": [
        1628,
        3150
      ],
      "id": "64f0ad2d-8152-4ed5-8405-23f7f7a825cc",
      "name": "Calculator1"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "mode": "list",
          "value": "claude-3-7-sonnet-20250219",
          "cachedResultName": "Claude 3.7 Sonnet"
        },
        "options": {
          "temperature": 0.5
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatAnthropic",
      "typeVersion": 1.3,
      "position": [
        2840,
        3220
      ],
      "id": "2de43aea-5245-493e-b734-9b0a1ff6898a",
      "name": "Anthropic Chat Model5",
      "credentials": {
        "anthropicApi": {
          "id": "qzCm5Ds2qD9ZY1W5",
          "name": "Anthropic account"
        }
      }
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=Generate a high-level project delivery summary based on the following structured inputs. This will be usefull for clients that want to see effort needed to complete the project in rfp.\n\n\nYour output should be a business-readable project summary. Include:\n\n### 1. Project Scope and Requirements\n{{ $('Format Data').first().json.formattedFeatures }}\n\n### 2. Effort Estimate - Make this part structured and clearly visible in table and make it bold.\n- Duration: {{ $('Effort Estimator').item.json.output.min_sprints }} to {{ $('Effort Estimator').item.json.output.max_sprints }} sprints (2-week sprints)\n\n### 3. Team Composition - Make this part structured and clearly visible in table.\n{{ $('Total Effort').first().json.team_summary.map(r => `- ${r.role}: ${r.count}`).join('\\n') }}\n\n### 4. Notes about reasons for the effort estimation\n{{ $('Effort Estimator').item.json.output.note }}\n\n### 5. Development Plan\n{{ $('Development Plan').item.json.output.phases.map(p => `#### Phase: ${p.name} (Sprints ${p.sprints.start}–${p.sprints.end})\\n${p.items.map(i => `- ${i}`).join('\\n')}`).join('\\n\\n') }}\n\n### 7. Additional data, write in a sentence.\n{{ $('Total Effort').item.json.effort.estimated_effort.min_person_days }} to \n{{ $('Total Effort').item.json.effort.estimated_effort.max_person_days }}\n{{ $('Prepare for frontend5').item.json.total_effort }}\n\n\nDo not return JSON. Return Markdown. Make this markdown friendly for html conversion later on. Make all titles and subtitle clearly formaerd in markdown. Make all tables and section clearly separated with some vertical padding. Clearly separate different tables. Do not include raw feature lists. Write as if explaining to a potential client.",
        "options": {
          "systemMessage": "You are a technical project reporting assistant. You generate clear, professional summaries of software projects based on structured input. Your reports are intended for stakeholders, clients, and delivery managers.\n\nYou write in concise, business-appropriate language. You highlight key scope elements, the estimated effort, the proposed team, and the planned delivery phases. You do not repeat raw data or code."
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.8,
      "position": [
        2820,
        3040
      ],
      "id": "614355d3-547e-4e1b-9240-08b4bc78b487",
      "name": "Reporter"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "claude-3-7-sonnet-20250219",
          "mode": "list",
          "cachedResultName": "Claude 3.7 Sonnet"
        },
        "options": {
          "maxTokensToSample": 9096,
          "thinking": true,
          "thinkingBudget": 2048
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatAnthropic",
      "typeVersion": 1.3,
      "position": [
        -2740,
        2420
      ],
      "id": "ccd5882b-1051-49a1-8216-4d1ed62b24cf",
      "name": "Anthropic Chat Model6",
      "credentials": {
        "anthropicApi": {
          "id": "qzCm5Ds2qD9ZY1W5",
          "name": "Anthropic account"
        }
      }
    },
    {
      "parameters": {
        "jsonSchemaExample": "{\n  \"markdown\": \"The preserved content with original structure\",\n  \"metrics\": {\n    \"originalCharCount\": \"\",\n    \"filteredCharCount\": \"\",\n    \"reductionPercentage\": \"\",\n    \"excluded_content\": []\n  }\n}"
      },
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "typeVersion": 1.2,
      "position": [
        -2580,
        2400
      ],
      "id": "96af213a-51f5-4bf0-a23b-28612f4c53d7",
      "name": "Structured Output Parser1"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://sse-estimation-tool.onrender.com/progress",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"step\": \"file_upload\",\n  \"title\": \"Step 1: File Uploaded\",\n  \"output\": \"{{ $('Extract Text from PDF').item.json.info.Title }}\"\n}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -1600,
        2580
      ],
      "id": "4234a49d-e954-4f11-836a-20801142dacc",
      "name": "file_upload"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://sse-estimation-tool.onrender.com/progress",
        "sendBody": true,
        "contentType": "raw",
        "rawContentType": "application/json",
        "body": "={{ $json.body }}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -1380,
        360
      ],
      "id": "e5be889a-7375-4318-9f58-9faa2cb9e780",
      "name": "data_extraction",
      "disabled": true
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://sse-estimation-tool.onrender.com/progress",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"step\": \"scope_analysis\",\n  \"title\": \"Scope Analysis\",\n  \"output\": {{ $json.features }},\n  \"sessionId\": \"{{ $('RFP Upload').item.json.body.sessionId }}\"\n}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        800,
        2340
      ],
      "id": "92f45121-14d5-481e-98ce-4939e9f4b9d0",
      "name": "scope_analysis"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://sse-estimation-tool.onrender.com/progress",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"step\": \"effort_estimation\",\n  \"title\": \"Effort Estimation\",\n  \"output\": {{ $json.effort }},\n  \"sessionId\": \"{{ $('RFP Upload').item.json.body.sessionId }}\"\n}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        1620,
        2340
      ],
      "id": "edd5faa7-db94-40e5-b367-e4fb0fd53e52",
      "name": "effort_estimation"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://sse-estimation-tool.onrender.com/progress",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"step\": \"development_plan\",\n  \"title\": \"Development Plan\",\n  \"output\": {{ $json.development_plan }},\n  \"sessionId\": \"{{ $('RFP Upload').item.json.body.sessionId }}\"\n}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        2168,
        2830
      ],
      "id": "99651b3b-d855-4e5c-8246-c08a37585094",
      "name": "development_plan"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://sse-estimation-tool.onrender.com/progress",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"step\": \"final_report\",\n  \"title\": \"Final Report\",\n  \"output\": {{ $json.final_report }},\n  \"sessionId\": \"{{ $('RFP Upload').item.json.body.sessionId }}\"\n}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        3424,
        3030
      ],
      "id": "66552ada-2239-4d19-99a7-9c1990171c19",
      "name": "final_report"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://sse-estimation-tool.onrender.com/progress",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"step\": \"team_composition\",\n  \"title\": \"Team Composition\",\n  \"output\": {{ $json.team }},\n  \"sessionId\": \"{{ $('RFP Upload').item.json.body.sessionId }}\"\n}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        2168,
        2580
      ],
      "id": "b74abc0f-733c-4775-bd1c-ead8464b35eb",
      "name": "team_composition"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://sse-estimation-tool.onrender.com/progress",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"step\": \"file_upload\",\n  \"title\": \"Step 1: File Uploaded\",\n  \"output\": \"Only scope\",\n  \"sessionId\": \"{{ $json.body.sessionId }}\"\n}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -1460,
        -1040
      ],
      "id": "3d4b5313-4e2e-4221-b934-afdb8cc31ca1",
      "name": "file_upload1"
    },
    {
      "parameters": {},
      "type": "n8n-nodes-base.manualTrigger",
      "typeVersion": 1,
      "position": [
        -1620,
        -1320
      ],
      "id": "94da90b9-095a-440b-ad07-9d7fef551d0b",
      "name": "When clicking ‘Test workflow’"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://sse-estimation-tool.onrender.com/progress",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"step\": \"data_extraction\",\n  \"title\": \"Step 3: Data Extracted\",\n  \"output\": \"Data Extracted\",\n  \"sessionId\": \"{{ $('RFP Upload1').item.json.body.sessionId }}\"\n}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -580,
        -1040
      ],
      "id": "7b5df551-5a03-4ca8-af33-fb82ae309a19",
      "name": "data_extraction1"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://sse-estimation-tool.onrender.com/progress",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"step\": \"scope_analysis\",\n  \"title\": \"Step 4: Scope Analysis\",\n  \"output\": \"Scope Analysed\",\n  \"sessionId\": \"{{ $('RFP Upload1').item.json.body.sessionId }}\"\n}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -140,
        -1040
      ],
      "id": "d6c4f23c-6494-47c0-908c-23b7b44f8ba1",
      "name": "scope_analysis1"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://sse-estimation-tool.onrender.com/progress",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"step\": \"effort_estimation\",\n  \"title\": \"Step 5: Effort Estimation\",\n  \"output\": \"Effort Estimation\",\n  \"sessionId\": \"{{ $('RFP Upload1').item.json.body.sessionId }}\"\n}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        300,
        -1040
      ],
      "id": "7312f2bb-879d-431c-841c-1d721cedce5d",
      "name": "effort_estimation1"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://sse-estimation-tool.onrender.com/progress",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"step\": \"team_composition\",\n  \"title\": \"Step 6: Team Composition\",\n  \"output\": \"Team Composition\",\n  \"sessionId\": \"{{ $('RFP Upload1').item.json.body.sessionId }}\"\n}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        740,
        -1040
      ],
      "id": "dbe001d7-8fa0-401f-ba0c-39b0e760ff5a",
      "name": "team_composition1"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://sse-estimation-tool.onrender.com/progress",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"step\": \"development_plan\",\n  \"title\": \"Step 7: Development Plan\",\n  \"output\": \"Development Plan\",\n  \"sessionId\": \"{{ $('RFP Upload1').item.json.body.sessionId }}\"\n}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        1180,
        -1040
      ],
      "id": "fc910b95-3164-4487-9c98-b7b5469bc908",
      "name": "development_plan1"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://sse-estimation-tool.onrender.com/progress",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"step\": \"final_report\",\n  \"title\": \"Step 8: Final Report\",\n  \"output\": \"Final Report\",\n  \"sessionId\": \"{{ $('RFP Upload1').item.json.body.sessionId }}\"\n}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        1620,
        -1040
      ],
      "id": "131c9457-a264-4a66-9c63-b25db4466302",
      "name": "final_report1"
    },
    {
      "parameters": {
        "amount": 3
      },
      "type": "n8n-nodes-base.wait",
      "typeVersion": 1.1,
      "position": [
        -1240,
        -1040
      ],
      "id": "6b111888-6bde-4745-a169-b3ec3281b192",
      "name": "Wait",
      "webhookId": "dde90e75-f027-4bde-91cd-450d25d5dd42"
    },
    {
      "parameters": {
        "amount": 3
      },
      "type": "n8n-nodes-base.wait",
      "typeVersion": 1.1,
      "position": [
        -800,
        -1040
      ],
      "id": "579e2192-1406-4d78-b429-41db9b013e41",
      "name": "Wait1",
      "webhookId": "dde90e75-f027-4bde-91cd-450d25d5dd42"
    },
    {
      "parameters": {
        "amount": 3
      },
      "type": "n8n-nodes-base.wait",
      "typeVersion": 1.1,
      "position": [
        -360,
        -1040
      ],
      "id": "5af2dcc6-034f-44b4-a422-df3909e3123e",
      "name": "Wait2",
      "webhookId": "dde90e75-f027-4bde-91cd-450d25d5dd42"
    },
    {
      "parameters": {
        "amount": 3
      },
      "type": "n8n-nodes-base.wait",
      "typeVersion": 1.1,
      "position": [
        80,
        -1040
      ],
      "id": "aa9d9894-b5cf-4085-932c-250dc032bf90",
      "name": "Wait3",
      "webhookId": "dde90e75-f027-4bde-91cd-450d25d5dd42"
    },
    {
      "parameters": {
        "amount": 3
      },
      "type": "n8n-nodes-base.wait",
      "typeVersion": 1.1,
      "position": [
        520,
        -1040
      ],
      "id": "173bca79-b263-4835-a665-c0c0efed7398",
      "name": "Wait4",
      "webhookId": "dde90e75-f027-4bde-91cd-450d25d5dd42"
    },
    {
      "parameters": {
        "amount": 3
      },
      "type": "n8n-nodes-base.wait",
      "typeVersion": 1.1,
      "position": [
        960,
        -1040
      ],
      "id": "1896e47f-6bb7-48e6-8bca-71ac3e5b84e0",
      "name": "Wait5",
      "webhookId": "dde90e75-f027-4bde-91cd-450d25d5dd42"
    },
    {
      "parameters": {
        "amount": 3
      },
      "type": "n8n-nodes-base.wait",
      "typeVersion": 1.1,
      "position": [
        1400,
        -1040
      ],
      "id": "546f1c11-bb96-4141-ade2-603b4136c5ec",
      "name": "Wait6",
      "webhookId": "dde90e75-f027-4bde-91cd-450d25d5dd42"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://sse-estimation-tool.onrender.com/progress",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"step\": \"document_preparation\",\n  \"title\": \"Step 2: Document Preparation\",\n  \"output\": \"Document Preparation\",\n  \"sessionId\": \"{{ $('RFP Upload1').item.json.body.sessionId }}\"\n}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -1020,
        -1040
      ],
      "id": "2a0dda0b-e906-4859-8378-0d2ed4dbcf2b",
      "name": "document_preparation1"
    },
    {
      "parameters": {
        "jsCode": "const input = $input.first().json;\n\nconst payload = {\n  step: \"data_extraction\",\n  title: \"Data Extracted!\",\n  sessionId: $('RFP Upload').first().json.body.sessionId || \"no-session\",\n  output: $('Extract - Sonnet').first().json.output.markdown.toString() ?? ''\n};\n\nreturn [\n  {\n    json: {\n      body: JSON.stringify(payload)\n    }\n  }\n];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1600,
        360
      ],
      "id": "386477e5-dc1b-4c36-baba-34d75a7a3bed",
      "name": "Code1",
      "disabled": true
    },
    {
      "parameters": {
        "jsCode": "\nconst outputs = $input.all().map(item => item.json.output);\n\nconst delivery_context = outputs.find(o => o.delivery_context)?.delivery_context ?? {};\n\nconst payload = {\n  step: \"delivery_context\",\n  title: \"Delivery Context\",\n  sessionId: $('RFP Upload').first().json.body.sessionId || \"no-session\",\n  delivery_context: JSON.stringify(delivery_context ?? {})\n};\n\nreturn [\n  {\n    json: {\n      body: JSON.stringify(payload)\n    }\n  }\n];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        280,
        2060
      ],
      "id": "baa47934-b1bd-4135-9205-6fa52f4cd13c",
      "name": "Prepare for frontend"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=You will receive raw RFP text. Your task is to extract only the parts that describe the software project scope, system requirements, goals, features, and deliverables — even if the structure is inconsistent or if the scope is implied.\n\nYour task:\nExtract only the sections that clearly describe the software project scope. These may include:\n- Functional or non-functional requirements\n- System features and technical specifications\n- Deployment or integration constraints\n- Business or operational obligations\n- Any descriptions of system functionality or software features\n- Project goals and what the software is expected to achieve\n- Expected integrations, platforms, components, modules, or user types\n- Anything that relates to what the vendor is being asked to build or deliver\n\nDo NOT include:\n- High level project overview\n- Legal terms or disclaimers\n- Submission instructions or deadlines\n- Evaluation or scoring criteria\n- Company background or vendor qualification rules\n- Cover letters or general introductions\n\nIf section headers are not clear, scan for paragraphs that mention:\n- Project objectives\n- Business goals\n- Functional requirements\n- Technical needs\n- Scope, modules, or integrations\n\nFormat your output in clean Markdown:\n- Use ## for section headers\n- Use ### for subheaders\n- Use bullet points (-) or numbered lists where applicable\n- Preserve any tables or structured formatting (use triple backticks for tables)\n\nYou must extract directly from the input.\n\nYou may include goal- or feature-related content even if it's not in list format, as long as it's clearly scope-related.\n\nDo not include code fences or extra formatting around your JSON.\n\n--- RFP TEXT START ---\n{{ $json.cleanedRfpText }}\n--- RFP TEXT END ---",
        "hasOutputParser": true,
        "options": {
          "systemMessage": "You are a strict RFP filtering agent that extracts only scope-relevant sections from raw proposal documents.\n\nYou must:\n- Detect and preserve all sections related to system features, scope, delivery, architecture, or business constraints\n- Remove any administrative, legal, or vendor selection content\n- Format all retained content as Markdown using a clear, structured layout\n- Wrap your result in a valid JSON object under the key \"output\"\n\nYou may include goal- or feature-related content even if it's not in list format, as long as it's clearly scope-related. Your goal is to pass through only what is needed for further technical analysis and estimation.\n\n"
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.8,
      "position": [
        -1600,
        880
      ],
      "id": "9ffed311-e797-4907-9704-8110b3c71a17",
      "name": "Only Scope1",
      "disabled": true
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=You are processing a single **CHUNK** from a larger RFP document. It may contain incomplete paragraphs or duplicated lines due to overlap. Your job is to convert this into clean, structured Markdown that reflects the **original document structure** as faithfully as possible.\n\nYour output must:\n- Extract **ALL visible content** without omitting anything\n- Preserve the original hierarchy (section headers, subheaders, bullet lists, numbered items)\n- Format everything in **Markdown**, using:\n  - `##` for section headers\n  - `###` for subheaders\n  - `-` or numbered lists where applicable\n  - Triple backticks for tables or fixed-width formatting\n- Maintain bullet/numbering structure and indentation if meaningful\n- Do NOT summarize, paraphrase, or interpret content\n- Do NOT add context or fill in missing sections\n- Do NOT label the chunk or return anything other than the Markdown content\n\nIf metadata is included (e.g., project name, submission deadline, issuing organization), extract and format it at the top of the output.\n\nIf the chunk contains mentions of requirements, timelines, evaluation, or vendor criteria — preserve them exactly as written. You may insert Markdown comments like:\n`<!-- possible requirement -->` or `<!-- possible evaluation criteria -->` above the relevant lines.\nReturn a clean JSON array only. Do not include markdown code blocks like ```json.\n--- CHUNK START ---\n{{ $json.chunk_text }}\n--- CHUNK END ---",
        "options": {
          "systemMessage": "You are a Document Extraction Specialist for software-related RFPs. You process small chunks of these documents and transform them into structured, machine-readable content.\n\nYou always:\n- Extract exactly what is visible in the chunk\n- Preserve the RFP’s original structure and formatting\n- Output Markdown without commentary\n- Avoid summarization, inference, or hallucination\n",
          "returnIntermediateSteps": false
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.8,
      "position": [
        -1380,
        -100
      ],
      "id": "b67d7a03-3ff9-4d5f-b246-c9cb3170c5dd",
      "name": "Document Extraction1",
      "disabled": true
    },
    {
      "parameters": {
        "jsCode": "const input = $input.first().json;\nreturn [\n  {\n    json: {\n      features: JSON.stringify(input.output)\n    }\n  }\n];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        472,
        2330
      ],
      "id": "e09cfcf5-3348-4a91-8470-bd5c0278927b",
      "name": "Prepare for frontend1"
    },
    {
      "parameters": {
        "schemaType": "manual",
        "inputSchema": "{\n  \"features\": \n\t\t[\n  {\n    \"category\": \"FR | NFR | TC | BC\",\n    \"description\": \"Clear and specific requirement\"\n  }\n]\n}"
      },
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "typeVersion": 1.2,
      "position": [
        240,
        2700
      ],
      "id": "4dd6d469-11c7-4015-a2b1-2c83738f7a36",
      "name": "Structured Output Parser2"
    },
    {
      "parameters": {
        "jsCode": "const input = $input.first().json;\nreturn [\n  {\n    json: {\n      effort: JSON.stringify(input.output)\n    }\n  }\n];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1180,
        2340
      ],
      "id": "c37ab706-0f99-4bb4-bf49-07def961971d",
      "name": "Prepare for frontend2"
    },
    {
      "parameters": {
        "jsCode": "const input = $input.first().json.team;\nreturn [\n  {\n    json: {\n      team: JSON.stringify(input)\n    }\n  }\n];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1948,
        2580
      ],
      "id": "5e115dec-cd82-4bb6-9b39-90e28788c689",
      "name": "Prepare for frontend3"
    },
    {
      "parameters": {
        "jsCode": "const input = $input.first().json;\nreturn [\n  {\n    json: {\n      development_plan: JSON.stringify(input.output)\n    }\n  }\n];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1948,
        2830
      ],
      "id": "9b71d17d-b128-4e6d-9fdd-392d916b449e",
      "name": "Prepare for frontend4"
    },
    {
      "parameters": {
        "jsonSchemaExample": "{\n  \"phases\": [\n  {\n    \"name\": \"Planning and Foundation\",\n      \"sprints\": { \"start\": 1, \"end\": 2 },\n      \"items\": [\n        \"Set up environments and CI/CD pipeline\",\n        \"Define architecture and technical frameworks\",\n        \"Implement user authentication and role system\"\n      ]\n  }\n],\n  \"cross_cutting\": {\n    \"infrastructure\": [ \"CI/CD setup\", \"VPN access configuration\" ],\n    \"security\": [ \"Access control\", \"Penetration testing\" ],\n    \"testing\": [ \"Unit testing\", \"UAT\" ],\n    \"documentation\": [ \"API documentation\", \"User guides\" ],\n    \"deployment\": [ \"Staging environment\", \"Production rollout\" ]\n  }\n}"
      },
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "typeVersion": 1.2,
      "position": [
        1748,
        3150
      ],
      "id": "3a3ca00b-0751-4621-b587-690d77da2783",
      "name": "Structured Output Parser3"
    },
    {
      "parameters": {
        "jsCode": "const input = $input.first().json.effort;\nreturn [\n  {\n    json: {\n      total_effort: JSON.stringify(input)\n    }\n  }\n];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        2388,
        3030
      ],
      "id": "e69993a4-033d-4149-91a3-294e875bb5b4",
      "name": "Prepare for frontend5"
    },
    {
      "parameters": {
        "jsCode": "const input = $input.first().json.output.cross_cutting;\nreturn [\n  {\n    json: {\n      cross_cutting: JSON.stringify(input)\n    }\n  }\n];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1948,
        3030
      ],
      "id": "0e8a0cab-1e5d-46d9-b8e0-073ae82f9c71",
      "name": "Prepare for frontend6"
    },
    {
      "parameters": {
        "jsCode": "const input = $input.first().json.output;\n\nreturn [\n  {\n    json: {\n      final_report: JSON.stringify(input)\n    }\n  }\n];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        3204,
        3030
      ],
      "id": "23bdb12f-e396-4d7f-b379-f7a4f847df0d",
      "name": "Prepare for frontend7"
    },
    {
      "parameters": {
        "jsCode": "// Config: you can change this\nconst projectStartDate = new Date('2024-05-01'); // project start date\nconst sprintLengthInDays = 14;\n\n// Get input\nconst input = $('Development Plan').first().json.output; // assumes { phases: [...] }\nconst phases = input.phases ?? [];\n\nfunction sprintToDate(sprintNum) {\n  const date = new Date(projectStartDate);\n  date.setDate(date.getDate() + (sprintNum - 1) * sprintLengthInDays);\n  return date.toISOString().split('T')[0]; // YYYY-MM-DD\n}\n\nconst gantt = [];\n\nphases.forEach((phase, index) => {\n  const startSprint = phase.sprints.start;\n  const endSprint = phase.sprints.end;\n\n  const task = {\n    id: `phase-${index + 1}`,\n    name: phase.name,\n    start: sprintToDate(startSprint),\n    end: sprintToDate(endSprint + 1), // end = end of sprint range\n    progress: 0,\n    custom_class: \"gantt-phase\"\n  };\n\n  gantt.push(task);\n});\n\nreturn [\n  {\n    json: {\n      gantt\n    }\n  }\n];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        2608,
        3030
      ],
      "id": "8ccac593-29ab-4d98-b6e2-5c64a3ab9117",
      "name": "Prepare for Gantt"
    },
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "sendToEmail",
        "options": {}
      },
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 2,
      "position": [
        -1880,
        3440
      ],
      "id": "7ddc40c8-93ac-41e8-b762-81dac9a78ceb",
      "name": "Send PDF to Email",
      "webhookId": "663a2e7d-35dd-4241-8890-97393732bb42",
      "disabled": true
    },
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "rfp-upload",
        "options": {}
      },
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 2,
      "position": [
        -1600,
        2330
      ],
      "id": "c8a03561-02d7-4322-9f75-643e1bb4c2e6",
      "name": "RFP Upload",
      "webhookId": "663a2e7d-35dd-4241-8890-97393732bb42",
      "disabled": true
    },
    {
      "parameters": {
        "sendTo": "={{ $json.email }}",
        "subject": "=Your Q AI RFP Analysis Report is Ready for {{ $json.fileName }}",
        "message": "=<!DOCTYPE html>\n<html>\n  <head>\n    <meta charset=\"UTF-8\" />\n    <title>Q AI RFP Analysis Report</title>\n  </head>\n  <body style=\"font-family: Arial, sans-serif; background-color: #f5f5f5; padding: 20px; margin: 0;\">\n    <table width=\"100%\" cellpadding=\"0\" cellspacing=\"0\" border=\"0\" style=\"max-width: 600px; margin: auto; background-color: #ffffff; border-radius: 8px; overflow: hidden;\">\n      <tr>\n        <td style=\"padding: 30px 40px;\">\n          <h2 style=\"color: #333333;\">Dear {{ $json.name }},</h2>\n          <p style=\"font-size: 16px; color: #555555; line-height: 1.6;\">\n            Thank you for using the <strong>Q AI RFP Analysis Tool</strong>.\n          </p>\n          <p style=\"font-size: 16px; color: #555555; line-height: 1.6;\">\n            Attached to this email, you will find the informative analysis report generated based on the RFP you uploaded.\n            The report includes insights related to estimated effort, key requirements, potential risks, and other relevant aspects of the document.\n          </p>\n          <p style=\"font-size: 16px; color: #555555; line-height: 1.6;\">\n            We hope this helps you streamline your decision-making process and improve planning efficiency.\n          </p>\n          <p style=\"font-size: 16px; color: #555555; line-height: 1.6;\">\n            If you have any questions or would like further support, feel free to reach out.\n          </p>\n          <p style=\"font-size: 16px; color: #333333; margin-top: 30px;\">\n            Best regards,<br/>\n            <strong>AI Team at Q Agency</strong>\n          </p>\n        </td>\n      </tr>\n      <tr>\n        <td style=\"background-color: #eeeeee; padding: 20px; text-align: center; font-size: 12px; color: #888888;\">\n          © 2025 Q Agency. All rights reserved.\n        </td>\n      </tr>\n    </table>\n  </body>\n</html>",
        "options": {
          "appendAttribution": false,
          "attachmentsUi": {
            "attachmentsBinary": [
              {
                "property": "file"
              }
            ]
          },
          "bccList": "zlatko.matokanovic@q.agency"
        }
      },
      "type": "n8n-nodes-base.gmail",
      "typeVersion": 2.1,
      "position": [
        -1160,
        3440
      ],
      "id": "8259a032-7368-43d0-b18b-6578b3f0a9e1",
      "name": "Gmail",
      "webhookId": "e71d01f0-8d29-4bad-8b6a-25062a67369e",
      "credentials": {
        "gmailOAuth2": {
          "id": "AnMIdKkQ5ToxkLrh",
          "name": "Gmail account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "function extractNameFromEmail(email) {\n  if (!email || typeof email !== 'string') return '';\n\n  const localPart = email.split('@')[0];\n\n  // Replace separators with spaces\n  const raw = localPart.replace(/[\\._\\-]+/g, ' ').trim();\n\n  // Split and capitalize\n  const nameParts = raw\n    .split(' ')\n    .filter(Boolean)\n    .map(w => w.charAt(0).toUpperCase() + w.slice(1).toLowerCase());\n\n  return nameParts.join(' ');\n}\n\nconst input = $input.first().json;\n\nconst email = input.body?.email || '';\nconst sessionId = input.body?.sessionId || '';\nconst name = extractNameFromEmail(email);\nconst fileName = $input.first().json.body.originalFilename\n\n\nreturn [\n  {\n    json: {\n      email,\n      name,\n      sessionId,\n      fileName,\n      binary: input.binary\n    }\n  }\n];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1640,
        3560
      ],
      "id": "f34feaa6-2abc-480b-95bb-e9ed003fcd6e",
      "name": "Code"
    },
    {
      "parameters": {
        "mode": "combine",
        "combineBy": "combineAll",
        "options": {}
      },
      "type": "n8n-nodes-base.merge",
      "typeVersion": 3,
      "position": [
        -1420,
        3440
      ],
      "id": "97bf9093-212e-46e8-975d-2c7f40b39fa3",
      "name": "Merge"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=You will receive the full raw extracted text from a Request for Proposal (RFP). This text may include both relevant and irrelevant content, such as system descriptions, legal disclaimers, vendor instructions, evaluation criteria, and platform details.\n\nYour task is to extract and return a structured JSON object describing the **technology stack and architectural context** required for the project.\n\nYou must analyze both:\n- **Explicit mentions** of tools, platforms, languages, frameworks, hosting models, or integrations\n- **Implicit needs** based on described user workflows, system goals, feature types, and delivery expectations\n\n---\n\n### Output Structure:\nReturn your result as a valid JSON object using the key `\"tech_stack\"`, with this exact structure:\n\njson\n{\n  \"platforms\": [\"web\", \"mobile\", \"admin\", \"desktop\"],\n  \"web_stack\": [\"React\", \"Vue\", \"Angular\"],\n  \"design\": [\"Shadcn\", \"Material UI\", \"Custom\"],\n  \"mobile_stack\": [\"Flutter\", \"Swift\", \"Kotlin\"],\n  \"backend_stack\": [\"Node.js\", \"Java\", \"Python\"],\n  \"ai_needed\": true or false,\n  \"database\": \"PostgreSQL\",\n  \"deployment\": \"cloud\",\n  \"integrations\": [\"OAuth\", \"SAML\", \"third-party APIs\"],\n  \"stack_model\": \"fullstack\" or \"separated\",\n  \"rationale\": \"Why this tech stack is appropriate for this project\"\n}\n\n### Definitions:\n\"platforms\": Which types of interfaces the system will include (e.g. public site, admin portal, mobile app)\n\"web_stack\": Frontend framework(s) required or inferred (e.g. React, Vue)\n\"design\": Design system or UI layer used (if not explicitly mentioned, infer from context)\n\"mobile_stack\": Tools used for mobile development\n\"backend_stack\": Server-side tech, frameworks, or APIs used\n\"ai_needed\": Set to true if the RFP involves building or integrating AI/ML functionality\n\"database\": Main data storage system (relational or NoSQL)\n\"deployment\": Hosting or infrastructure model (cloud, on-prem, hybrid)\n\"integrations\": Any third-party APIs, internal systems, payment gateways, or SSO requirements\n\"stack_model\":\n\"fullstack\" → The same dev team can handle both frontend and backend using aligned technologies\n\"separated\" → Distinct technologies or teams are likely needed\n\"rationale\": Short explanation of how and why you selected the technologies and design above\n\n### Fallback Logic:\nIf the RFP does not explicitly specify technologies, apply these reasonable defaults:\n\n\"platforms\": [\"web\"]\n\"web_stack\": [\"React\", \"Next.js\"]\n\"backend_stack\": [\"PHP\"]\n\"mobile_stack\": [\"Flutter\"]\n\"design\": [\"Shadcn\"] — if the project is admin-heavy, lacks branding, or doesn’t mention visual complexity\n\"database\": Use a common relational DB (e.g., PostgreSQL)\n\"deployment\": \"AWS\" (cloud hosting is preferred unless stated otherwise)\n\"integrations\": Infer from context or leave as an empty array if unclear\n\"stack_model\": Choose \"fullstack\" only if the stack is unified and executable by one team; otherwise \"separated\"\n\"rationale\": If RFP gave you nothing to work with, give your best educated rationale guess.\n\n### You must exclude:\nLegal disclaimers or proposal formatting rules\nVendor eligibility requirements or scoring instructions\nBackground about the issuing organization\nAny markdown, code blocks, or commentary\n\nDo not include markdown code fences like ```json or any headings\n\nReturn only the final JSON object under the key \"tech_stack\".\n\n--- BEGIN RFP TEXT --- {{ $json.cleanedRfpText }} --- END RFP TEXT ---\n",
        "hasOutputParser": true,
        "options": {
          "systemMessage": "You are a Technical Stack Analysis Agent. Your job is to analyze the full text of a Request for Proposal (RFP) and return a structured JSON object describing the technology stack and delivery model required for the project.\n\nYou always:\n- Extract platforms (web, mobile, desktop, admin)\n- Infer frontend and backend technologies\n- Identify mobile frameworks, design system expectations, and deployment models\n- Determine whether AI development or integration is needed\n- Use fallback values if the RFP does not state preferences explicitly\n- Return a clear rationale explaining your reasoning based on the RFP content\n\nYou skip irrelevant content, including:\n- Vendor qualification requirements\n- Proposal submission rules, deadlines, or evaluation criteria\n- Company background, legal disclaimers, or general marketing language\n\nYour output must be a valid JSON object using the key `\"tech_stack\"` and follow this structure:\n\njson\n{\n  \"platforms\": [\"web\", \"mobile\", \"admin\", \"desktop\"],\n  \"web_stack\": [\"React\", \"Vue\", \"Angular\"],\n  \"design\": [\"Shadcn\", \"Material UI\", \"Custom\"],\n  \"mobile_stack\": [\"Flutter\", \"Swift\", \"Kotlin\"],\n  \"backend_stack\": [\"Node.js\", \"Java\", \"Python\"],\n  \"ai_needed\": true or false,\n  \"database\": \"PostgreSQL\",\n  \"deployment\": \"cloud\",\n  \"integrations\": [\"OAuth\", \"SAML\", \"third-party APIs\"],\n  \"stack_model\": \"fullstack\" or \"separated\",\n  \"rationale\": \"Why this stack was selected\"\n}\nFallback logic:\n\nIf no platform is mentioned, default to \"web\"\nIf frontend or backend tools are missing, infer from scope or use defaults (React, PHP)\nIf design system is not mentioned and the system appears admin-heavy or minimal UI, use [\"Shadcn\"]\nIf unclear, assume deployment: \"AWS\" and database: \"PostgreSQL\"\n\nNever include markdown, code fences, or extra commentary — only the final structured JSON."
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.8,
      "position": [
        -680,
        2060
      ],
      "id": "0ca43c4b-a018-4c1e-ae7c-bd0713433f8c",
      "name": "TechStack"
    },
    {
      "parameters": {
        "jsonSchemaExample": "{\n  \"tech_stack\":{\n  \"platforms\": [\"web\", \"mobile\", \"admin\"],\n  \"stack_model\": \"\",\n  \"web_stack\": [\"React\", \"Tailwind CSS\"],\n  \"ai_needed\": true,\n  \"design\": [\"Shadcn\", \"Material UI\", \"Custom\"],\n  \"mobile_stack\": [\"Flutter\"],\n  \"backend_stack\": [\"Node.js\", \"Express\", \"TypeScript\"],\n  \"database\": \"PostgreSQL\",\n  \"deployment\": \"cloud\",\n  \"integrations\": [\"OAuth 2.0\", \"Stripe\", \"Google Maps API\", \"Slack\"],\n  \"rationale\": \"\"\n}\n}"
      },
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "typeVersion": 1.2,
      "position": [
        -520,
        2340
      ],
      "id": "b8d40384-325b-4b4b-8edb-37542c1ac418",
      "name": "Structured Output Parser4"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "claude-3-7-sonnet-20250219",
          "mode": "list",
          "cachedResultName": "Claude 3.7 Sonnet"
        },
        "options": {
          "thinking": true
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatAnthropic",
      "typeVersion": 1.3,
      "position": [
        -680,
        2340
      ],
      "id": "c7c9bbac-4694-462f-aca1-94d6484f97fc",
      "name": "Anthropic Chat Model7",
      "credentials": {
        "anthropicApi": {
          "id": "qzCm5Ds2qD9ZY1W5",
          "name": "Anthropic account"
        }
      }
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=You will receive full extracted text from a Request for Proposal (RFP).\n\nYour task is to extract and return a structured summary of delivery context. This includes compliance expectations, localization needs, user roles, project classification, and timing constraints.\n\nReturn your output as a valid JSON object under the key `\"delivery_context\"` using this structure:\n\n{\n  \"regulatory_requirements\": [\"GDPR\", \"HIPAA\", \"SOC 2\", \"NDA\", \"Saudi Hosting Requirement\"],\n  \"localization\": [\"en\", \"ar\"],\n  \"user_types\": [\"admin\", \"customer\", \"vendor\"],\n  \"project_type\": \"greenfield\" | \"modernization\" | \"migration\",\n  \"delivery_model\": \"mvp\" | \"phased delivery\" | \"big bang\",\n  \"security_needs\": [\"SSO\", \"RBAC\", \"Audit Logs\", \"Encryption\", \"Firewall\"],\n  \"timeline_pressure\": \"tight\" | \"normal\" | \"flexible\"\n}\n\n### 🧠 Inference Guidelines:\n- Infer `\"regulatory_requirements\"` from any mention of privacy laws, hosting rules, data sovereignty, or compliance frameworks (e.g. GDPR, SOC 2, HIPAA)\n- Set `\"localization\"` from any mention of language support or region-specific user experience (e.g. Arabic + English)\n- Extract `\"user_types\"` from roles like buyer, seller, admin, manager, agent, etc.\n- Use `\"project_type\"`:\n  - `\"greenfield\"` for new builds\n  - `\"modernization\"` for rebuilds or design updates\n  - `\"migration\"` if moving from legacy platforms\n- Use `\"delivery_model\"`:\n  - `\"mvp\"` if early launch or fast go-to-market is emphasized\n  - `\"phased delivery\"` if delivery is planned in stages or releases\n  - `\"big bang\"` if it implies full delivery all at once\n- Use `\"timeline_pressure\"`:\n  - `\"tight\"` if deadlines are aggressive\n  - `\"normal\"` if timelines are standard or unspecified\n  - `\"flexible\"` if RFP says timing is negotiable\n\nUse fallback values only if no signal is found. All fields must be present in the JSON response.\n\nDo not include markdown formatting, code fences, or commentary.\n\n--- BEGIN RFP TEXT ---\n{{ $('Text Cleanup').item.json.cleanedRfpText }}\n--- END RFP TEXT ---\n",
        "hasOutputParser": true,
        "options": {
          "systemMessage": "You are a Delivery Context Analysis Agent. Your task is to process full Request for Proposal (RFP) documents and extract structured delivery-related metadata that will influence how the project is estimated, staffed, and executed.\n\nYou focus on identifying implicit or explicit delivery context, regulatory considerations, and project structure — not functional requirements or feature descriptions.\n\nYou always:\n- Detect key delivery expectations such as project type, delivery model, regulatory needs, localization, security requirements, timeline pressure, and user roles\n- Extract both explicitly stated and strongly implied information\n- Apply fallback values only when the RFP provides no clear signals\n- Return your output as a valid JSON object using the `\"delivery_context\"` key\n- Use short, accurate field values with no formatting outside the JSON object\n\nYou never include:\n- Feature-level requirements\n- Legal disclaimers or submission instructions\n- Marketing or background content about the issuing entity\n- Markdown, code blocks, or commentary\n\nYou return only a clean, flat JSON object under the key `\"delivery_context\"`.\n"
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.8,
      "position": [
        -260,
        2060
      ],
      "id": "0c76deb6-59fc-4470-bce4-8dc55ac97580",
      "name": "Delivery Context"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "claude-3-7-sonnet-20250219",
          "mode": "list",
          "cachedResultName": "Claude 3.7 Sonnet"
        },
        "options": {
          "thinking": true
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatAnthropic",
      "typeVersion": 1.3,
      "position": [
        -260,
        2340
      ],
      "id": "01144f64-1cb6-47fb-b65e-e848c43185fb",
      "name": "Anthropic Chat Model8",
      "credentials": {
        "anthropicApi": {
          "id": "qzCm5Ds2qD9ZY1W5",
          "name": "Anthropic account"
        }
      }
    },
    {
      "parameters": {
        "jsonSchemaExample": "{\n  \"delivery_context\":{\n  \"regulatory_requirements\": [\"GDPR\", \"HIPAA\", \"SOC 2\", \"NDA\", \"Saudi Hosting Requirement\"],\n  \"localization\": [\"en\", \"ar\"],\n  \"user_types\": [\"admin\", \"customer\", \"vendor\"],\n  \"project_type\": \"greenfield\", \n  \"delivery_model\": \"phased delivery\",\n  \"security_needs\": [\"SSO\", \"RBAC\", \"Audit Logs\", \"Encryption\", \"Firewall\"],\n  \"timeline_pressure\": \"tight\"\n}\n}"
      },
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "typeVersion": 1.2,
      "position": [
        -100,
        2340
      ],
      "id": "cbe527cf-f0fc-4074-aae3-e00cfe386b9d",
      "name": "Structured Output Parser5"
    },
    {
      "parameters": {
        "jsCode": "const outputs = $input.all().map(item => item.json.output);\n\nconst markdown = outputs.find(o => o.markdown)?.markdown ?? '';\nconst tech_stack = outputs.find(o => o.tech_stack)?.tech_stack ?? {};\nconst delivery_context = outputs.find(o => o.delivery_context)?.delivery_context ?? {};\n\nreturn [\n  {\n    json: {\n      markdown,\n      tech_stack,\n      delivery_context\n    }\n  }\n];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -220,
        2700
      ],
      "id": "616d5895-713e-41c9-90d4-464585efed4b",
      "name": "Code2"
    },
    {
      "parameters": {
        "modelName": "models/gemini-2.0-flash",
        "options": {
          "maxOutputTokens": 30000,
          "temperature": 0.5
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "typeVersion": 1,
      "position": [
        -1120,
        1660
      ],
      "id": "e58de90d-a0fa-4fa8-ad71-42a7476067b8",
      "name": "Google Gemini Chat Model",
      "credentials": {
        "googlePalmApi": {
          "id": "405i02YoCznHTji7",
          "name": "Google Gemini(PaLM) Api account"
        }
      }
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=Analyze the following document text and extract the scope based on your instructions:\n{{ $json.cleanedRfpText }}",
        "options": {
          "systemMessage": "You are an AI assistant specialized in analyzing Request for Proposal (RFP) documents or similar requests, even if they lack clear structure. Your objective is to identify and extract ONLY the information defining the project's core scope of work.\n\nFocus on extracting:\n- RFP Objectives\n- Project Goals & Objectives (Purpose, problems, outcomes)\n- Required Work & Functionality (Tasks, services, features, specs)\n- Deliverables (Outputs, products, results)\n- Relevant Background/Context (Why requirements exist)\n- Key Assumptions & Constraints (Conditions, limitations, boundaries)\n\nExplicitly ignore and exclude text related to:\n\n* **RFP Process & Submission Procedures:**\n    * Instructions on how, when, or where to submit responses\n    * Deadlines, timelines for the bidding process\n    * Contact persons/Administrative contact information for procurement\n    * Required proposal formats (page limits, font requirements, etc.)\n    * Bidder Question forms/Q&A sections\n    * Qualifying rounds, pre-bid meetings\n    * Invitation to Bid\n\n* **Evaluation & Selection:**\n    * Evaluation criteria, scoring methodology\n    * Selection process descriptions\n\n* **Commercial Terms & Pricing:**\n    * Pricing instructions, requests for cost breakdowns (e.g., Cost breakdown sheet)\n    * Payment schedules, budget information\n    * Bid bonds, financial guarantees\n    * Pricing tables\n\n* **Legal, Contractual & Compliance:**\n    * Standard Terms and Conditions (T&Cs), references to separate T&C documents/agreements\n    * Legal disclaimers, liability statements, certification requirements\n    * Confidentiality statements regarding the bidding process\n    * Procurement rules\n\n* **Bidder/Vendor Qualifications:**\n    * Requirements for the responding company's experience, finances, team structure, certifications\n    * Vendor eligibility criteria\n    * Instructions for providing references\n\n* **Document Structure & Boilerplate:**\n    * Table of Contents (ToC) / Section lists\n    * Boilerplate marketing language, cover letters\n    * General company history or background about the issuing organization unrelated to the project's specific context\n    * References to specific forms provided for the bidder to fill out (e.g., Form of Proposal, Acknowledgement Form)\n    * Watermarks, headers, footers, signatures (unless part of a specific deliverable requirement)\n    * References to attachments or separate documents unless their *content* describes scope.\n\n* **Ambiguous Terms (Exclude unless clearly part of scope):**\n    * General mentions of \"Materials\" or \"Reference Documents\" without context defining them as deliverables or essential scope information.\n\n\n\n\nPresent the extracted scope information clearly.\n\nWhen in doubt, preserve the content.\nPreserve the original structure and wording as closely as possible\n- Do not summarize or fabricate content\n\n- Do not include markdown fences like ```json or explanatory commentary\n\nReturn a JSON object with the following structure:\njson\n{\n  \"markdown\": \"The preserved content with original structure maintained\",\n  \"metrics\": {\n    \"originalCharCount\": <number of characters in original text>,\n    \"filteredCharCount\": <number of characters in filtered text>,\n    \"reductionPercentage\": <percentage of text removed>,\n    \"excluded_content\": <content that was excluded>\n  }\n}"
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.8,
      "position": [
        -700,
        1480
      ],
      "id": "333e7742-cb0d-4911-9884-5726eb305100",
      "name": "Preprocess Gemini",
      "onError": "continueRegularOutput"
    },
    {
      "parameters": {
        "jsonSchemaExample": "{\n  \"markdown\": \"The preserved content with original structure\",\n  \"metrics\": {\n    \"originalCharCount\": \"\",\n    \"filteredCharCount\": \"\",\n    \"reductionPercentage\": \"\",\n    \"excluded_content\": \"\"\n  }\n}"
      },
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "typeVersion": 1.2,
      "position": [
        -460,
        1780
      ],
      "id": "5fc7565e-4fe1-4949-9928-ff9f9c3dcc09",
      "name": "Structured Output Parser7"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://sse-estimation-tool.onrender.com/progress",
        "sendBody": true,
        "contentType": "raw",
        "rawContentType": "application/json",
        "body": "={{ $json.body }}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        360,
        1340
      ],
      "id": "aeef325e-489f-47dd-a363-9d9a4ee48b79",
      "name": "document_preparation"
    },
    {
      "parameters": {
        "jsCode": "\nconst outputs = $input.all().map(item => item.json);\n\nconst markdown = outputs.find(o => o.markdown)?.markdown ?? '';\nconst tech_stack = outputs.find(o => o.tech_stack)?.tech_stack ?? {};\nconst delivery_context = outputs.find(o => o.delivery_context)?.delivery_context ?? {};\n\nconst payload = {\n  step: \"document_preparation\",\n  title: \"Document Preparation Test\",\n  sessionId: $('RFP Upload').first().json.body.sessionId || \"no-session\",\n  output: markdown.toString() ?? '',\n  tech_stack: JSON.stringify(tech_stack ?? {}),\n  delivery_context: JSON.stringify(delivery_context ?? {})\n};\n\nreturn [\n  {\n    json: {\n      body: JSON.stringify(payload)\n    }\n  }\n];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        140,
        1340
      ],
      "id": "1924a520-24ba-498a-9c41-b67fa0646117",
      "name": "Prepare for frontend9"
    },
    {
      "parameters": {
        "jsCode": "const cleanedOutputs = [];\n\nfor (const item of $input.all()) {\n  let raw = item.json.output;\n\n  if (typeof raw === 'string') {\n    // Remove code fences (e.g., ```json ... ```)\n    raw = raw.replace(/^```json\\s*|\\s*```$/g, '').trim();\n\n    try {\n      const parsed = JSON.parse(raw);\n      cleanedOutputs.push({ json: parsed });\n    } catch (err) {\n      throw new Error(\"Failed to parse JSON from markdown-wrapped string: \" + err.message);\n    }\n  } else if (typeof raw === 'object') {\n    cleanedOutputs.push({ json: raw }); // already parsed\n  } else {\n    throw new Error(\"Unexpected format in item.output\");\n  }\n}\n\nreturn cleanedOutputs;"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -80,
        1280
      ],
      "id": "8f6c7dfa-1856-45ef-b6d5-44c94deebce4",
      "name": "Markdown to JSON"
    },
    {
      "parameters": {
        "jsCode": "// Function for n8n processing\nfunction processRfpWithExcludedContent(items) {\n  try {\n    // Check if we have the necessary data\n    if (!Array.isArray(items) || items.length === 0) {\n      throw new Error('No input items provided');\n    }\n    \n    const item = items[0];\n    \n    // Get the RFP data from the input - use $node reference\n    let originalRfpText = '';\n    try {\n      // Try to get from Text Cleanup node\n      originalRfpText = $node[\"Text Cleanup\"]?.json?.cleanedRfpText || '';\n    } catch (error) {\n      console.log(\"Text Cleanup node not found or accessible\");\n    }\n    \n    // If still empty, try to get from the current input\n    if (!originalRfpText) {\n      originalRfpText = item.json?.originalRfpText || item.json?.cleanedRfpText || '';\n    }\n    \n    let filteredRfp = null;\n    \n    // Find the filtered RFP data with new structure adaptation\n    if (Array.isArray(item.json) && item.json[0] && typeof item.json[0] === 'object' && \n        (item.json[0].markdown !== undefined || item.json[0].metrics !== undefined)) {\n      // Handle the case where input is the array format [{ markdown: {}, metrics: { excluded_content: [] }}]\n      filteredRfp = item.json[0];\n    } else if (item.json.haikuResponse && typeof item.json.haikuResponse === 'object') {\n      filteredRfp = item.json.haikuResponse;\n    } else if (item.json.filteredRfp && typeof item.json.filteredRfp === 'object') {\n      filteredRfp = item.json.filteredRfp;\n    } else if (item.json.markdown !== undefined) {\n      // Handle case where the input is already the filtered data\n      filteredRfp = item.json;\n    } else {\n      throw new Error('Could not find filtered RFP data in input');\n    }\n    \n    // Create visualization\n    let result = null;\n    \n    if (originalRfpText) {\n      // If we have the original text, create interleaved visualization\n      result = createRfpVisualization(originalRfpText, filteredRfp);\n    } else {\n      // If we don't have the original text, use the alternative approach\n      const filteredText = typeof filteredRfp.markdown === 'object'\n        ? JSON.stringify(filteredRfp.markdown, null, 2)\n        : filteredRfp.markdown;\n      \n      const html = buildFromExcludedList(\n        filteredText, \n        (filteredRfp.metrics || {}).excluded_content || []\n      );\n      \n      result = {\n        success: true,\n        html: html,\n        metrics: filteredRfp.metrics || {}\n      };\n    }\n    \n    // Return the result as an object with json property\n    return {\n      json: {\n        rfpVisualization: result.html,\n        visualizationMetrics: result.metrics\n      }\n    };\n  } catch (error) {\n    // Return error as an object with json property\n    return {\n      json: {\n        error: error.message,\n        errorDetails: error.toString()\n      }\n    };\n  }\n}\n\n// Make sure we're returning something from the main function\n// N8N requires an object with a json property\nreturn processRfpWithExcludedContent($input.all());"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        560,
        1280
      ],
      "id": "d5361f67-254d-461a-915c-0657beb2e566",
      "name": "Generate HTML"
    },
    {
      "parameters": {
        "html": "{{ $json.rfpVisualization }}"
      },
      "type": "n8n-nodes-base.html",
      "typeVersion": 1.2,
      "position": [
        840,
        1260
      ],
      "id": "221de0f5-f510-4f82-bafc-a0d402a1baa1",
      "name": "RFP HTML - Changes"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://sse-estimation-tool.onrender.com/progress",
        "sendBody": true,
        "contentType": "raw",
        "rawContentType": "application/json",
        "body": "={{ $json.body }}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        1400,
        1860
      ],
      "id": "e9969d8a-d787-477e-b94a-d127bf1ecb0a",
      "name": "document_preparation3"
    },
    {
      "parameters": {
        "jsCode": "\nconst outputs = $input.all().map(item => item.json);\n\nconst markdown = outputs.find(o => o.markdown)?.markdown ?? '';\nconst tech_stack = outputs.find(o => o.tech_stack)?.tech_stack ?? {};\nconst delivery_context = outputs.find(o => o.delivery_context)?.delivery_context ?? {};\n\nconst payload = {\n  step: \"document_preparation\",\n  title: \"Document Preparation Test\",\n  sessionId: $('RFP Upload').first().json.body.sessionId || \"no-session\",\n  output: markdown.toString() ?? '',\n  tech_stack: JSON.stringify(tech_stack ?? {}),\n  delivery_context: JSON.stringify(delivery_context ?? {})\n};\n\nreturn [\n  {\n    json: {\n      body: JSON.stringify(payload)\n    }\n  }\n];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1180,
        1860
      ],
      "id": "66419c14-53a2-4561-92c8-c293ba1877e8",
      "name": "Prepare for frontend10"
    },
    {
      "parameters": {
        "jsCode": "const cleanedOutputs = [];\n\nfor (const item of $input.all()) {\n  let raw = item.json.output;\n\n  if (typeof raw === 'string') {\n    // Remove code fences (e.g., ```json ... ```)\n    raw = raw.replace(/^```json\\s*|\\s*```$/g, '').trim();\n\n    try {\n      const parsed = JSON.parse(raw);\n      cleanedOutputs.push({ json: parsed });\n    } catch (err) {\n      throw new Error(\"Failed to parse JSON from markdown-wrapped string: \" + err.message);\n    }\n  } else if (typeof raw === 'object') {\n    cleanedOutputs.push({ json: raw }); // already parsed\n  } else {\n    throw new Error(\"Unexpected format in item.output\");\n  }\n}\n\nreturn cleanedOutputs;"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        200,
        1580
      ],
      "id": "aa1c8e95-7e84-401d-b626-02026ae8e196",
      "name": "Markdown to JSON1"
    },
    {
      "parameters": {
        "jsCode": "// Function to create HTML visualization of an RFP with excluded content in red\n// Adapted to work with specific data structure from Haiku pre-filtering\nfunction createRfpVisualization(originalRfpText, filteredRfp) {\n  try {\n    // Get the filtered text and metrics from the input\n    const filteredText = filteredRfp.markdown;\n    const metrics = filteredRfp.metrics;\n    const excludedContent = filteredRfp.metrics.excluded_content || [];\n    \n    // Convert JSON string newlines to actual newlines if needed\n    if (typeof originalRfpText === 'string' && originalRfpText.includes('\\\\n')) {\n      originalRfpText = originalRfpText.replace(/\\\\n/g, '\\n');\n    }\n    \n    // Generate HTML with interleaved content\n    const html = generateHtmlFromExcluded(originalRfpText, filteredText, excludedContent, metrics);\n\n    return {\n      success: true,\n      html: html,\n      metrics: metrics\n    };\n  } catch (error) {\n    return {\n      success: false,\n      error: error.message,\n      details: error.toString()\n    };\n  }\n}\n\n// Generate HTML document with interleaved included and excluded content\nfunction generateHtmlFromExcluded(originalText, filteredText, excludedContent, metrics) {\n  // Add debugging\n  console.log('Original text length:', originalText.length);\n  console.log('First 100 chars of original:', originalText.substring(0, 100));\n  console.log('Excluded sections count:', excludedContent.length);\n  \n  // First, create a map to track positions of excluded content in the original text\n  const exclusionMap = createExclusionMap(originalText, excludedContent);\n  console.log('Exclusion map entries found:', exclusionMap.length);\n  \n  // Build HTML content by interleaving filtered and excluded content\n  let contentHtml = '';\n  \n  // Check if we should use simplified approach if mapping failed\n  if (exclusionMap.length === 0 && excludedContent.length > 0) {\n    console.log('Using simplified content approach due to mapping issues');\n    contentHtml = buildSimplifiedContent(filteredText, excludedContent);\n  } else {\n    contentHtml = buildInterlevedContent(originalText, filteredText, exclusionMap);\n  }\n  \n  // Create the full HTML document\n  return `<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <title>RFP with Excluded Content in Red</title>\n    <style>\n        body {\n            font-family: Arial, sans-serif;\n            line-height: 1.6;\n            max-width: 900px;\n            margin: 0 auto;\n            padding: 20px;\n        }\n        .excluded {\n            color: red;\n        }\n        h1, h2, h3 {\n            margin-top: 1.5em;\n            margin-bottom: 0.5em;\n        }\n        .summary {\n            background-color: #f5f5f5;\n            padding: 15px;\n            border-radius: 5px;\n            margin-bottom: 30px;\n        }\n        pre {\n            white-space: pre-wrap;\n            margin: 0;\n            padding: 0;\n            font-family: 'Courier New', Courier, monospace;\n            font-size: 14px;\n            overflow-x: auto;\n        }\n        .legend {\n            display: flex;\n            margin-bottom: 15px;\n        }\n        .legend-item {\n            margin-right: 20px;\n            display: flex;\n            align-items: center;\n        }\n        .color-box {\n            width: 20px;\n            height: 20px;\n            margin-right: 5px;\n            border: 1px solid #ccc;\n        }\n        .color-box.included {\n            background-color: black;\n        }\n        .color-box.excluded {\n            background-color: red;\n        }\n        .controls {\n            position: fixed;\n            bottom: 20px;\n            right: 20px;\n            background: #fff;\n            padding: 10px;\n            border-radius: 5px;\n            box-shadow: 0 0 10px rgba(0,0,0,0.1);\n            z-index: 1000;\n        }\n        .toggle-btn {\n            padding: 8px 12px;\n            background: #007bff;\n            color: white;\n            border: none;\n            border-radius: 4px;\n            cursor: pointer;\n        }\n        .toggle-btn:hover {\n            background: #0069d9;\n        }\n        .hidden-excluded .excluded {\n            display: none;\n        }\n    </style>\n</head>\n<body>\n    <div class=\"summary\">\n        <h1>RFP Content Analysis</h1>\n        <p>This document shows the complete RFP with preserved content in normal text and excluded content in <span class=\"excluded\">red</span>.</p>\n        <div class=\"legend\">\n            <div class=\"legend-item\">\n                <div class=\"color-box included\"></div>\n                <span>Included Content</span>\n            </div>\n            <div class=\"legend-item\">\n                <div class=\"color-box excluded\"></div>\n                <span>Excluded Content</span>\n            </div>\n        </div>\n        <p><strong>Original Length:</strong> ${metrics.originalCharCount} characters</p>\n        <p><strong>Filtered Length:</strong> ${metrics.filteredCharCount} characters</p>\n        <p><strong>Reduction:</strong> ${metrics.reductionPercentage}%</p>\n        <p><strong>Excluded Sections:</strong> ${excludedContent.length}</p>\n    </div>\n\n    <div class=\"controls\">\n        <button class=\"toggle-btn\" onclick=\"toggleExcluded()\">Toggle Excluded Content</button>\n    </div>\n\n    <div id=\"rfp-content\">\n        ${contentHtml}\n    </div>\n\n    <script>\n        function toggleExcluded() {\n            document.body.classList.toggle('hidden-excluded');\n        }\n    </script>\n</body>\n</html>`;\n}\n\n// New simplified content approach as a fallback\nfunction buildSimplifiedContent(filteredText, excludedContentList) {\n  // Just show filtered content followed by excluded sections\n  let html = `<h2>Included Content</h2><pre>${handleContentForDisplay(filteredText)}</pre>`;\n  \n  html += '<h2 class=\"excluded\">Excluded Content</h2>';\n  for (const section of excludedContentList) {\n    html += `<pre class=\"excluded\">${handleContentForDisplay(section)}</pre>`;\n  }\n  \n  return html;\n}\n\n// Helper function to create a mapping of excluded content positions\nfunction createExclusionMap(originalText, excludedContent) {\n  const exclusionMap = [];\n  \n  // For each excluded section, find its position in the original text\n  for (const section of excludedContent) {\n    // Clean up the section to improve matching\n    const cleanSection = section.trim();\n    if (!cleanSection) continue;\n    \n    const position = originalText.indexOf(cleanSection);\n    if (position !== -1) {\n      exclusionMap.push({\n        content: section,\n        position: position,\n        length: section.length,\n        end: position + section.length\n      });\n    } else {\n      console.log(`Couldn't find excluded section in original text: ${cleanSection.substring(0, 50)}...`);\n    }\n  }\n  \n  // Sort by position\n  exclusionMap.sort((a, b) => a.position - b.position);\n  \n  return exclusionMap;\n}\n\n// Build interleaved content with included and excluded sections\nfunction buildInterlevedContent(originalText, filteredText, exclusionMap) {\n  let html = '';\n  let currentPosition = 0;\n  \n  // Special case: if there's no exclusion map or it's empty,\n  // just return the original text as included content\n  if (!exclusionMap || exclusionMap.length === 0) {\n    return `<pre>${handleContentForDisplay(originalText)}</pre>`;\n  }\n  \n  // Handle case where the filtered text contains all content (no exclusions)\n  if (originalText === filteredText) {\n    return `<pre>${handleContentForDisplay(originalText)}</pre>`;\n  }\n  \n  // Go through original text, marking sections as included or excluded\n  for (const exclusion of exclusionMap) {\n    // If there's content before this exclusion, it's included\n    if (exclusion.position > currentPosition) {\n      const includedContent = originalText.substring(currentPosition, exclusion.position);\n      html += `<pre>${handleContentForDisplay(includedContent)}</pre>`;\n    }\n    \n    // This section is excluded\n    html += `<pre class=\"excluded\">${handleContentForDisplay(exclusion.content)}</pre>`;\n    \n    // Move current position\n    currentPosition = exclusion.end;\n  }\n  \n  // Add any remaining content after the last exclusion\n  if (currentPosition < originalText.length) {\n    const remainingContent = originalText.substring(currentPosition);\n    html += `<pre>${handleContentForDisplay(remainingContent)}</pre>`;\n  }\n  \n  return html;\n}\n\n// Alternative build method when original text is not available\nfunction buildFromExcludedList(filteredText, excludedContentList) {\n  let html = `<pre>${handleContentForDisplay(filteredText)}</pre>`;\n  \n  // Add all excluded content sections at the end\n  if (excludedContentList && excludedContentList.length > 0) {\n    html += '<h2 class=\"excluded\">Excluded Content</h2>';\n    \n    for (let i = 0; i < excludedContentList.length; i++) {\n      html += `<pre class=\"excluded\">${handleContentForDisplay(excludedContentList[i])}</pre>`;\n    }\n  }\n  \n  return html;\n}\n\n// Improved helper function to handle content for display\nfunction handleContentForDisplay(text) {\n  if (!text) return '';\n  \n  // Check if text already contains HTML entities\n  const alreadyEscaped = \n    text.includes('&amp;') || \n    text.includes('&lt;') || \n    text.includes('&gt;');\n  \n  if (alreadyEscaped) {\n    // If already escaped, only handle newlines\n    return text.replace(/\\n/g, '<br>');\n  }\n  \n  // Regular escaping plus newline handling\n  return text\n    .replace(/&/g, '&amp;')\n    .replace(/</g, '&lt;')\n    .replace(/>/g, '&gt;')\n    .replace(/\"/g, '&quot;')\n    .replace(/'/g, '&#039;')\n    .replace(/\\n/g, '<br>');\n}\n\n// Function for n8n processing\nfunction processRfpWithExcludedContent(items) {\n  try {\n    // Check if we have the necessary data\n    if (!Array.isArray(items) || items.length === 0) {\n      throw new Error('No input items provided');\n    }\n    \n    const item = items[0];\n    \n    // Get the RFP data from the input - use $node reference\n    let originalRfpText = '';\n    try {\n      // Try to get from Text Cleanup node\n      originalRfpText = $node[\"Text Cleanup\"]?.json?.cleanedRfpText || '';\n    } catch (error) {\n      console.log(\"Text Cleanup node not found or accessible\");\n    }\n    \n    // If still empty, try to get from the current input\n    if (!originalRfpText) {\n      originalRfpText = item.json?.originalRfpText || item.json?.cleanedRfpText || '';\n    }\n    \n    let filteredRfp = null;\n    \n    // Find the filtered RFP data\n    if (item.json.haikuResponse && typeof item.json.haikuResponse === 'object') {\n      filteredRfp = item.json.haikuResponse;\n    } else if (item.json.filteredRfp && typeof item.json.filteredRfp === 'object') {\n      filteredRfp = item.json.filteredRfp;\n    } else if (item.json.markdown !== undefined) {\n      // Handle case where the input is already the filtered data\n      filteredRfp = item.json;\n    } else {\n      throw new Error('Could not find filtered RFP data in input');\n    }\n    \n    // Create visualization\n    let result = null;\n    \n    if (originalRfpText) {\n      // If we have the original text, create interleaved visualization\n      result = createRfpVisualization(originalRfpText, filteredRfp);\n    } else {\n      // If we don't have the original text, use the alternative approach\n      const html = buildFromExcludedList(\n        filteredRfp.markdown, \n        filteredRfp.metrics.excluded_content\n      );\n      \n      result = {\n        success: true,\n        html: html,\n        metrics: filteredRfp.metrics\n      };\n    }\n    \n    // Return the result\n    return {\n      json: {\n        ...item.json,\n        rfpVisualization: result.html,\n        visualizationMetrics: result.metrics\n      }\n    };\n  } catch (error) {\n    return {\n      json: {\n        error: error.message,\n        errorDetails: error.toString()\n      }\n    };\n  }\n}\n\n// Return the function result for N8N\nreturn processRfpWithExcludedContent($input.all());"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1180,
        1620
      ],
      "id": "a93793f4-2419-48dc-877c-154159b047c4",
      "name": "Generate HTML1"
    },
    {
      "parameters": {
        "html": "{{ $json.rfpVisualization }}"
      },
      "type": "n8n-nodes-base.html",
      "typeVersion": 1.2,
      "position": [
        1420,
        1620
      ],
      "id": "10203a7d-6498-482b-b003-06288b31b8ef",
      "name": "RFP HTML - Changes1"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=Analyze the following document text and extract the scope based on your instructions:\n{{ $json.chunk_text }}",
        "options": {
          "systemMessage": "You are an AI assistant specialized in analyzing Request for Proposal (RFP) documents or similar requests, even if they lack clear structure. Your objective is to identify and extract ONLY the information defining the project's core scope of work.\n\nFocus on extracting:\n- RFP Objectives\n- Project Goals & Objectives (Purpose, problems, outcomes)\n- Required Work & Functionality (Tasks, services, features, specs)\n- Deliverables (Outputs, products, results)\n- Relevant Background/Context (Why requirements exist)\n- Key Assumptions & Constraints (Conditions, limitations, boundaries)\n\nExplicitly ignore and exclude text related to:\n\n* **RFP Process & Submission Procedures:**\n    * Instructions on how, when, or where to submit responses\n    * Deadlines, timelines for the bidding process\n    * Contact persons/Administrative contact information for procurement\n    * Required proposal formats (page limits, font requirements, etc.)\n    * Bidder Question forms/Q&A sections\n    * Qualifying rounds, pre-bid meetings\n    * Invitation to Bid\n\n* **Evaluation & Selection:**\n    * Evaluation criteria, scoring methodology\n    * Selection process descriptions\n\n* **Commercial Terms & Pricing:**\n    * Pricing instructions, requests for cost breakdowns (e.g., Cost breakdown sheet)\n    * Payment schedules, budget information\n    * Bid bonds, financial guarantees\n    * Pricing tables\n\n* **Legal, Contractual & Compliance:**\n    * Standard Terms and Conditions (T&Cs), references to separate T&C documents/agreements\n    * Legal disclaimers, liability statements, certification requirements\n    * Confidentiality statements regarding the bidding process\n    * Procurement rules\n\n* **Bidder/Vendor Qualifications:**\n    * Requirements for the responding company's experience, finances, team structure, certifications\n    * Vendor eligibility criteria\n    * Instructions for providing references\n\n* **Document Structure & Boilerplate:**\n    * Table of Contents (ToC) / Section lists\n    * Boilerplate marketing language, cover letters\n    * General company history or background about the issuing organization unrelated to the project's specific context\n    * References to specific forms provided for the bidder to fill out (e.g., Form of Proposal, Acknowledgement Form)\n    * Watermarks, headers, footers, signatures (unless part of a specific deliverable requirement)\n    * References to attachments or separate documents unless their *content* describes scope.\n\n* **Ambiguous Terms (Exclude unless clearly part of scope):**\n    * General mentions of \"Materials\" or \"Reference Documents\" without context defining them as deliverables or essential scope information.\n\n\n\n\nPresent the extracted scope information clearly.\n\nWhen in doubt, preserve the content.\nPreserve the original structure and wording as closely as possible\n- Do not summarize or fabricate content\n\n- Do not include markdown fences like ```json or explanatory commentary\n\nReturn a JSON object with the following structure:\njson\n{\n  \"markdown\": \"The preserved content with original structure maintained\",\n  \"metrics\": {\n    \"originalCharCount\": <number of characters in original text>,\n    \"filteredCharCount\": <number of characters in filtered text>,\n    \"reductionPercentage\": <percentage of text removed>,\n    \"excluded_content\": <content that was excluded>\n  }\n}"
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.8,
      "position": [
        1320,
        940
      ],
      "id": "7c0937d5-f279-4c4a-939f-42a1bc4b4f8b",
      "name": "Preprocess Gemini1",
      "disabled": true,
      "onError": "continueRegularOutput"
    },
    {
      "parameters": {
        "jsCode": "/**\n * Combines multiple text chunks into a single document in the correct order\n * @param {Array} chunks - Array of text chunks to be combined\n * @param {Object} options - Optional configuration settings\n * @returns {String} Combined text document\n */\nfunction combineTextChunks(chunks, options = {}) {\n  // Default options\n  const defaultOptions = {\n    separator: '\\n\\n', // Separator between chunks\n    trimChunks: true,  // Whether to trim whitespace from each chunk\n    removeEmptyChunks: true, // Whether to remove empty chunks\n    addPageNumbers: false, // Whether to add page numbers\n    pageNumberFormat: 'Page {pageNum}', // Format for page numbers\n    maxChunkLength: null, // Optional max length for each chunk\n    preserveLineBreaks: true // Whether to preserve original line breaks\n  };\n  \n  // Merge provided options with defaults\n  const config = { ...defaultOptions, ...options };\n  \n  // Validate input\n  if (!Array.isArray(chunks)) {\n    throw new Error('Input must be an array of text chunks');\n  }\n  \n  // Process chunks according to options\n  let processedChunks = [...chunks];\n  \n  // Remove empty chunks if configured\n  if (config.removeEmptyChunks) {\n    processedChunks = processedChunks.filter(chunk => {\n      return chunk && (typeof chunk === 'string' ? chunk.trim() !== '' : true);\n    });\n  }\n  \n  // Process each chunk\n  processedChunks = processedChunks.map((chunk, index) => {\n    // Skip non-string chunks\n    if (typeof chunk !== 'string') {\n      console.warn(`Chunk at index ${index} is not a string. Converting to string.`);\n      return String(chunk);\n    }\n    \n    // Trim if configured\n    let processedChunk = config.trimChunks ? chunk.trim() : chunk;\n    \n    // Apply maximum chunk length if specified\n    if (config.maxChunkLength && processedChunk.length > config.maxChunkLength) {\n      processedChunk = processedChunk.substring(0, config.maxChunkLength) + '...';\n    }\n    \n    // Add page numbers if configured\n    if (config.addPageNumbers) {\n      const pageNumber = config.pageNumberFormat.replace('{pageNum}', index + 1);\n      processedChunk += `\\n${pageNumber}`;\n    }\n    \n    return processedChunk;\n  });\n  \n  // Join chunks with the specified separator\n  let combinedText = processedChunks.join(config.separator);\n  \n  // Handle line breaks\n  if (!config.preserveLineBreaks) {\n    combinedText = combinedText.replace(/\\n+/g, ' ').replace(/\\s+/g, ' ');\n  }\n  \n  return combinedText;\n}\n\n/**\n * Process RFP chunks in N8N workflow\n * @param {Array} items - Input items from previous nodes\n * @returns {Object} Result object with combined text\n */\nfunction processRfpChunks(items) {\n  try {\n    // Check if we have the necessary data\n    if (!Array.isArray(items) || items.length === 0) {\n      throw new Error('No input items provided');\n    }\n    \n    const item = items[0];\n    \n    // Determine where the chunks are in the input data\n    let chunks = [];\n    \n    if (Array.isArray(item.json)) {\n      // If the input is an array, use it directly\n      chunks = item.json.map(chunk => {\n        // If chunks are objects with a 'text' or 'content' property, extract that\n        if (typeof chunk === 'object') {\n          return chunk.text || chunk.content || chunk.markdown || JSON.stringify(chunk);\n        }\n        return chunk;\n      });\n    } else if (item.json.chunks && Array.isArray(item.json.chunks)) {\n      // If chunks are in a 'chunks' property\n      chunks = item.json.chunks;\n    } else if (item.json.sections && Array.isArray(item.json.sections)) {\n      // If chunks are in a 'sections' property\n      chunks = item.json.sections;\n    } else if (item.binary && item.binary.data) {\n      // If the input is binary data, try to convert it to text\n      const textData = Buffer.from(item.binary.data, 'base64').toString('utf8');\n      chunks = [textData];\n    } else {\n      // If we can't find chunks, use the entire item.json as a single chunk\n      chunks = [JSON.stringify(item.json)];\n    }\n    \n    // Combine the chunks\n    const combinedText = combineTextChunks(chunks, {\n      separator: '\\n\\n',\n      trimChunks: true,\n      removeEmptyChunks: true\n    });\n    \n    // Return the combined text\n    return {\n      json: {\n        combinedText,\n        chunkCount: chunks.length,\n        totalLength: combinedText.length\n      }\n    };\n  } catch (error) {\n    // Return error as an object with json property\n    return {\n      json: {\n        error: error.message,\n        errorDetails: error.toString()\n      }\n    };\n  }\n}\n\n// Return the processed result for N8N\nreturn processRfpChunks($input.all());"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        200,
        1060
      ],
      "id": "e86b2724-7f82-4ce5-aa93-57d0fd5d2bbe",
      "name": "Clean and Combine Chunks1"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=Analyze this RFP document to extract ONLY content defining the core scope of work. Take time to think through each section's relevance to implementation rather than administration.\n\n## INCLUDE (scope-related):\n- Project objectives and business goals\n- Required functionality, features, and capabilities\n- Technical specifications and standards\n- Deliverables and expected outcomes\n- Essential background explaining requirements\n- Constraints and limitations affecting implementation\n- Integration requirements with existing systems\n\n## EXCLUDE (administrative):\n- Submission instructions and deadlines\n- Evaluation criteria and vendor selection process\n- Pricing instructions and budget formats\n- Legal terms, conditions, and compliance requirements\n- Bidder qualification requirements\n- Document formatting instructions\n- Contact information for RFP administrators\n\n### Formatting Instructions:\n- Use clean Markdown formatting:\n  - `##` for section headers\n  - `###` for subheaders\n  - `-` for bullet points\n  - Triple backticks for fixed-format text or tables\n- Preserve the original structure and wording as closely as possible\n- Do not summarize or fabricate content\n- Do not include markdown fences like ```json or explanatory commentary\n\nWhen uncertain about content, evaluate its direct relevance to what must be built or delivered rather than how to respond to the RFP. Use your reasoning to make defensible judgments in borderline cases.\n\nReturn a JSON object with:\n{\n  \"markdown\": \"<preserved scope content with original structure>\",\n  \"metrics\": {\n    \"originalCharCount\": <characters in original text>,\n    \"filteredCharCount\": <characters in filtered text>,\n    \"reductionPercentage\": <percentage of text removed>,\n    \"excluded_content\": [<array of sections that were excluded, including the whole text of that sections>]\n  }\n}\n\n--- BEGIN RFP TEXT --- {{ $json.cleanedRfpText }} --- END RFP TEXT ---",
        "hasOutputParser": true,
        "options": {
          "systemMessage": "You are an RFP Scope Extraction Agent with advanced analytical capabilities. Your purpose is to carefully analyze Request for Proposal (RFP) documents to extract only content related to the core scope of work.\n\nUse your reasoning abilities to:\n1. First understand the overall structure and purpose of the document\n2. Identify sections containing scope information versus administrative content\n3. Make nuanced judgments about borderline content by considering its relevance to implementation\n4. Trace your decision-making about what to include or exclude\n5. Maintain comprehensive tracking of excluded content for later reference\n\nYour analysis must be thorough and precise, preserving the exact wording and structure of scope-related content while systematically filtering out administrative details.\n\nYour output is always a JSON object with:\n- \"markdown\": The preserved scope content with original structure maintained\n- \"metrics\": Complete statistics and tracking of the filtering process"
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.8,
      "position": [
        -2760,
        2200
      ],
      "id": "ebd3fa95-885f-4643-9e17-ab4249bcbbce",
      "name": "Extract - Sonnet"
    },
    {
      "parameters": {
        "jsCode": "// Enhanced RFP chunking function for Gemini Flash 2.0\nconst text = $input.first().json.cleanedRfpText; // replace with your input field if different\nconst maxChars = 10000; // Size safe for Gemini Flash 2.0\nconst overlapChars = 600; // Context overlap between chunks\n\nfunction rfpSmartChunker(text, maxLen, overlap = 0) {\n  const chunks = [];\n  \n  // First try to split on section headers (which are common in RFPs)\n  // This regex matches common RFP section patterns like \"1.1\", \"Section A:\", \"## Heading\", etc.\n  const sectionPattern = /(?:\\n|\\r\\n)(?:(?:\\d+\\.[\\d\\.]*\\s+[A-Z]|[A-Z]+\\.\\s+|Section\\s+[A-Z0-9]+:|\\#{1,3}\\s+\\d+\\.|\\#{1,3}\\s+[A-Z])[\\w\\s]+)(?:\\n|\\r\\n)/g;\n  \n  // Get all section positions\n  const sectionMatches = [...text.matchAll(sectionPattern)];\n  const sectionPositions = sectionMatches.map(match => ({ \n    pos: match.index, \n    text: match[0].trim(),\n    isHeading: true \n  }));\n  \n  // Add document start and end as positions\n  sectionPositions.unshift({ pos: 0, text: \"\", isHeading: false });\n  sectionPositions.push({ pos: text.length, text: \"\", isHeading: false });\n  \n  // If no sections found or very few, fall back to paragraph splitting\n  if (sectionPositions.length < 3) {\n    return fallbackParagraphChunker(text, maxLen, overlap);\n  }\n  \n  // Create chunks from sections while respecting max length\n  let buffer = \"\";\n  let currentSection = \"\";\n  \n  for (let i = 0; i < sectionPositions.length - 1; i++) {\n    const sectionStart = sectionPositions[i].pos;\n    const sectionEnd = sectionPositions[i+1].pos;\n    const section = text.substring(sectionStart, sectionEnd);\n    \n    // Track current section header for context\n    if (sectionPositions[i].isHeading) {\n      currentSection = sectionPositions[i].text;\n    }\n    \n    if ((buffer + section).length <= maxLen) {\n      buffer += section;\n    } else {\n      // If buffer is not empty, push it as a chunk\n      if (buffer) {\n        chunks.push(buffer.trim());\n      }\n      \n      // If section is too large, need to split it further\n      if (section.length > maxLen) {\n        // Try to split by paragraphs first\n        const paragraphs = section.split(/\\n{2,}/);\n        let paraBuffer = \"\";\n        let addedContext = false;\n        \n        for (const para of paragraphs) {\n          const paragraph = para.trim();\n          if (!paragraph) continue;\n          \n          // Add current section context to first paragraph in split\n          const contextualPara = !addedContext && currentSection \n            ? `[Context: ${currentSection}]\\n${paragraph}` \n            : paragraph;\n          \n          if ((paraBuffer + (paraBuffer ? \"\\n\\n\" : \"\") + contextualPara).length <= maxLen) {\n            paraBuffer += (paraBuffer ? \"\\n\\n\" : \"\") + contextualPara;\n            if (!addedContext) addedContext = true;\n          } else {\n            if (paraBuffer) chunks.push(paraBuffer.trim());\n            \n            // If single paragraph still exceeds max length, split by sentences\n            if (contextualPara.length > maxLen) {\n              splitBySentences(contextualPara, maxLen, chunks);\n            } else {\n              paraBuffer = contextualPara;\n            }\n          }\n        }\n        \n        if (paraBuffer) chunks.push(paraBuffer.trim());\n      } else {\n        chunks.push(section.trim());\n      }\n      \n      buffer = \"\";\n    }\n  }\n  \n  if (buffer) chunks.push(buffer.trim());\n  \n  // Apply overlap if needed\n  return applyOverlap(chunks, overlap);\n}\n\n// Helper function to split text by sentences\nfunction splitBySentences(text, maxLen, chunks) {\n  const sentences = text.split(/(?<=[.?!])\\s+/);\n  let sentenceBuffer = \"\";\n  \n  for (const sentence of sentences) {\n    if (!sentence.trim()) continue;\n    \n    if ((sentenceBuffer + (sentenceBuffer ? \" \" : \"\") + sentence).length <= maxLen) {\n      sentenceBuffer += (sentenceBuffer ? \" \" : \"\") + sentence;\n    } else {\n      if (sentenceBuffer) chunks.push(sentenceBuffer.trim());\n      \n      // If sentence is still too long, split by character\n      if (sentence.length > maxLen) {\n        let i = 0;\n        while (i < sentence.length) {\n          chunks.push(sentence.substr(i, maxLen).trim());\n          i += maxLen;\n        }\n      } else {\n        sentenceBuffer = sentence;\n      }\n    }\n  }\n  \n  if (sentenceBuffer) chunks.push(sentenceBuffer.trim());\n}\n\n// Fallback chunker using paragraphs when no sections are found\nfunction fallbackParagraphChunker(text, maxLen, overlap) {\n  const chunks = [];\n  const paragraphs = text.split(/\\n{2,}/);\n  let buffer = \"\";\n  \n  for (const para of paragraphs) {\n    const paragraph = para.trim();\n    if (!paragraph) continue;\n    \n    if ((buffer + \"\\n\\n\" + paragraph).length <= maxLen) {\n      buffer += (buffer ? \"\\n\\n\" : \"\") + paragraph;\n    } else {\n      if (buffer) chunks.push(buffer.trim());\n      \n      if (paragraph.length > maxLen) {\n        splitBySentences(paragraph, maxLen, chunks);\n      } else {\n        buffer = paragraph;\n      }\n    }\n  }\n  \n  if (buffer) chunks.push(buffer.trim());\n  \n  return applyOverlap(chunks, overlap);\n}\n\n// Helper function to apply overlap between chunks\nfunction applyOverlap(chunks, overlap) {\n  if (overlap <= 0 || chunks.length <= 1) {\n    return chunks.map((chunk, i) => ({ \n      chunk, \n      index: i + 1,\n      total: chunks.length\n    }));\n  }\n  \n  const overlappedChunks = [];\n  \n  for (let i = 0; i < chunks.length; i++) {\n    let chunk = chunks[i];\n    \n    // Add overlap from previous chunk\n    if (i > 0 && overlap > 0) {\n      const prevChunk = chunks[i - 1];\n      const overlapText = prevChunk.slice(-overlap);\n      chunk = `[CONTINUED FROM PREVIOUS CHUNK]\\n${overlapText}\\n\\n${chunk}`;\n    }\n    \n    // Add notice if there's more content\n    if (i < chunks.length - 1) {\n      chunk = `${chunk}\\n\\n[CONTINUES IN NEXT CHUNK]`;\n    }\n    \n    overlappedChunks.push({ \n      chunk, \n      index: i + 1,\n      total: chunks.length\n    });\n  }\n  \n  return overlappedChunks;\n}\n\nconst finalChunks = rfpSmartChunker(text, maxChars, overlapChars);\n\n// Output each chunk as its own item in the workflow\nreturn finalChunks.map(c => ({\n  json: {\n    chunk_index: c.index,\n    chunk_total: c.total,\n    chunk_text: c.chunk\n  }\n}));"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -820,
        1160
      ],
      "id": "fc2d4729-c3bf-4891-8a33-f6431ac775a2",
      "name": "Chunking - Gemini"
    },
    {
      "parameters": {
        "modelName": "models/gemini-2.0-flash",
        "options": {
          "maxOutputTokens": 4096,
          "temperature": 0
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "typeVersion": 1,
      "position": [
        -280,
        860
      ],
      "id": "39bea481-11ab-40fe-b621-21bb50cd09d4",
      "name": "Google Gemini Chat Model1",
      "credentials": {
        "googlePalmApi": {
          "id": "405i02YoCznHTji7",
          "name": "Google Gemini(PaLM) Api account"
        }
      }
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=Analyze the following RFP text chunk. Identify and list all unambiguous non-scope markers (section headers or the first ~10-15 words of relevant paragraphs) according to your instructions. Return ONLY a valid JSON array containing these markers.\n\nRFP Text Chunk:\n{{ $json.chunk_text }}",
        "options": {
          "systemMessage": "You are an AI assistant specialized in analyzing Request for Proposal (RFP) document chunks. Your objective is to identify specific markers (section headers or the beginning of paragraphs) that clearly indicate **NON-SCOPE** content based on predefined categories.\n\n**Your Task:**\nAnalyze the provided text chunk and identify all markers that unambiguously belong to the following NON-SCOPE categories:\n\n* **RFP Process & Submission Procedures:** Instructions on how/when/where to submit, deadlines, timelines, contact persons, proposal formats, Q&A sections, qualifying rounds, invitation to bid, etc.\n* **Evaluation & Selection:** Evaluation criteria, scoring methodology, selection process descriptions.\n* **Commercial Terms & Pricing:** Pricing instructions, cost breakdowns, payment schedules, budgets, bid bonds, pricing tables, licensing models.\n* **Legal, Contractual & Compliance:** Standard T&Cs, legal disclaimers, liability statements, certifications, confidentiality (about bidding), procurement rules.\n* **Bidder/Vendor Qualifications:** Requirements for the bidding company (experience, finances, team), eligibility criteria, instructions for references.\n* **Document Structure & Boilerplate:** Table of Contents, section lists, boilerplate marketing/cover letters, general company background unrelated to the project context, references to forms (Form of Proposal, Acknowledgement), watermarks, headers/footers, signatures, references to attachments/appendices (unless the *content* description is scope).\n\n**What Constitutes a \"Marker\":**\n1.  The **exact, full text** of a section header (e.g., \"2.4 Submission Instructions\", \"## Vendor Qualifications\", \"Section 6: LEGAL AND CONTRACTUAL REQUIREMENTS\").\n2.  If a paragraph clearly starts a non-scope topic but lacks a distinct header, use the **first approximately 10-15 words** of that paragraph as the marker (e.g., \"All communications regarding this RFP must be directed solely to...\", \"Pricing must remain valid for a minimum of...\", \"VMTA shall retain full and exclusive ownership of...\").\n\n**IMPORTANT Instructions:**\n* **ONLY identify markers for the NON-SCOPE categories listed above.**\n* **DO NOT identify markers for SCOPE-RELATED content**, such as: Project/RFP Objectives, Goals, Required Work/Functionality, Features, Specifications, Deliverables, Relevant Background/Context, Assumptions, Constraints, Technical Requirements, Scope of Work sections.\n* **DO NOT include the full text** of the sections or paragraphs, only the marker (header or starting words).\n* Be precise. Only list markers that clearly fall into the non-scope categories.\n* Aim to identify *all* clear non-scope markers within the chunk.\n* **Output ONLY a valid JSON array of strings.** Each string in the array should be one identified non-scope marker.\n* Do not include any explanations, commentary, apologies, or conversational text before or after the JSON array.\n* If no non-scope markers are found in the chunk, return an empty JSON array: [].\n\n**Example Output Format:**\n\n[\n  \"2.1. RFP Timeline & Key Dates\",\n  \"2.2. Primary Point of Contact\",\n  \"All inquiries and communications related to this RFP must be directed exclusively to:\",\n  \"5.1. Pricing Model & Detailed Breakdown\",\n  \"Appendix A: VMTA Standard Terms & Conditions\"\n]"
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.8,
      "position": [
        -280,
        660
      ],
      "id": "d3899d5a-6c76-4a88-b7f1-5e9542970d0a",
      "name": "Preprocess Gemini -reverse",
      "onError": "continueRegularOutput"
    },
    {
      "parameters": {
        "jsCode": "const input = $input.first().json;\n\nconst rawText =   $('Chunking - Gemini').first().json.chunk_text || '';\nconst markers = Array.isArray(input.markers) ? input.markers : [];\n\nif (!rawText) throw new Error(\"Missing RFP chunk text.\");\nif (!Array.isArray(markers)) throw new Error(\"Invalid or missing markers list.\");\n\n// Normalize marker phrases for comparison\nconst normalize = str =>\n  str\n    .replace(/[#*]+/g, '')\n    .replace(/^\\d+(\\.\\d+)*\\s*/, '')       // remove numbered prefixes\n    .replace(/[^\\w\\s]/g, '')              // remove punctuation\n    .replace(/\\s+/g, ' ')                 // normalize whitespace\n    .trim()\n    .toLowerCase();\n\nconst normalizedMarkers = markers.map(normalize);\n\n// Line-based filtering\nconst allLines = rawText.split(/\\r?\\n/); // safe for Windows + Unix\nconst scopeLines = [];\nconst excludedLines = [];\nconst matchedLines = [];\n\nfor (const line of allLines) {\n  const normalizedLine = normalize(line);\n\n  const isExcluded = normalizedMarkers.some(marker =>\n    normalizedLine.startsWith(marker) || normalizedLine.includes(marker)\n  );\n\n  if (isExcluded) {\n    excludedLines.push(line);\n    matchedLines.push(normalizedLine);\n  } else {\n    scopeLines.push(line);\n  }\n}\n\nconst scopeText = scopeLines.join('\\n').trim();\nconst excludedText = excludedLines.join('\\n').trim();\n\nconst originalCharCount = rawText.length;\nconst filteredCharCount = scopeText.length;\nconst reductionPercentage = originalCharCount > 0\n  ? parseFloat((((originalCharCount - filteredCharCount) / originalCharCount) * 100).toFixed(2))\n  : 0;\n\nreturn [\n  {\n    json: {\n      scope_text: scopeText,\n      excluded_text: excludedText,\n      metrics: {\n        originalCharCount,\n        filteredCharCount,\n        reductionPercentage,\n        removedLineCount: excludedLines.length\n      },\n      debug: {\n        normalizedMarkers,\n        matchedLines\n      }\n    }\n  }\n];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        500,
        680
      ],
      "id": "33e18f4a-bc40-4157-8c61-b2b01bb5e07b",
      "name": "Code3"
    },
    {
      "parameters": {
        "jsCode": "// n8n Code Node Script: Parse JSON Array from Markdown Code Fence\n\n// Purpose: Extracts a JSON array from a string that is wrapped\n//          in markdown code fences like ```json ... ```.\n\nconst results = [];\nconst inputItems = $input.all(); // Get all input items\n\nfor (const item of inputItems) {\n  try {\n    // --- Get Input ---\n    // Adjust 'output' if the field containing the string is named differently\n    const rawStringOutput = item.json.output;\n\n    // --- Input Validation ---\n    if (typeof rawStringOutput !== 'string') {\n       // If the input is somehow already the array we want, just use it\n       if (Array.isArray(rawStringOutput)) {\n           console.warn(`Input for item index ${item.index} seems already parsed. Using as is.`);\n           results.push({ json: { markers: rawStringOutput } }); // Pass through directly\n           continue; // Move to the next item\n       } else {\n            // Otherwise, if it's not a string and not an array, it's an unexpected format\n            throw new Error(`Input 'output' is not a string for item index ${item.index}. Found type: ${typeof rawStringOutput}`);\n       }\n    }\n\n    // --- Processing ---\n\n    // 1. Remove the markdown code fences (```json ... ```)\n    // This regex handles potential whitespace variance around the fences.\n    const jsonString = rawStringOutput.replace(/^```json\\s*|\\s*```$/g, '').trim();\n\n    // 2. Parse the resulting string into a JavaScript object/array\n    const parsedData = JSON.parse(jsonString);\n\n    // --- Output Validation (Ensure it's an array) ---\n    if (!Array.isArray(parsedData)) {\n       throw new Error(`Parsed data is not an array for item index ${item.index}. Parsed type: ${typeof parsedData}`);\n    }\n\n    // --- Prepare Output Item ---\n    // Place the successfully parsed array into the output item's json property\n    // under a key named 'markers' (or choose a name you prefer).\n    results.push({\n      json: {\n        markers: parsedData\n        // You could optionally include the original raw string for debugging:\n        // raw_llm_output_string: rawStringOutput\n      }\n    });\n\n  } catch (error) {\n    console.error(`Error processing item index ${item.index}:`, error);\n    // Output an item indicating the error for easier debugging in n8n\n    results.push({\n      json: {\n        error: `Failed to parse JSON marker array: ${error.message}`,\n        itemIndex: item.index,\n        inputValue: item.json.output // Include the problematic input\n      }\n    });\n  }\n}\n\n// Return the array of processed items (or error items)\nreturn results;"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        160,
        660
      ],
      "id": "c09694ee-d90c-4277-a028-b91a184ece22",
      "name": "remove '''json"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "o3-mini",
          "mode": "list",
          "cachedResultName": "o3-mini"
        },
        "options": {
          "responseFormat": "json_object"
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        60,
        2980
      ],
      "id": "41c91e73-910b-45c3-a33a-a9b26101eeb5",
      "name": "OpenAI Chat Model",
      "credentials": {
        "openAiApi": {
          "id": "M8xqWvEC6mH6LNuk",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "modelName": "models/gemini-2.0-flash",
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "typeVersion": 1,
      "position": [
        40,
        2720
      ],
      "id": "6ad16dd9-0873-4dd8-ad44-87641754cfc8",
      "name": "Google Gemini Chat Model2",
      "credentials": {
        "googlePalmApi": {
          "id": "405i02YoCznHTji7",
          "name": "Google Gemini(PaLM) Api account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "\nconst outputs = $input.all().map(item => item.json.output);\n\n//const markdown = outputs.find(o => o.markdown)?.markdown ?? '';\nconst tech_stack = outputs.find(o => o.tech_stack)?.tech_stack ?? {};\n\nconst payload = {\n  step: \"project_info\",\n  title: \"Project Info\",\n  sessionId: $('RFP Upload').first().json.body.sessionId || \"no-session\",\n  tech_stack: JSON.stringify(tech_stack ?? {}),\n};\n\nreturn [\n  {\n    json: {\n      body: JSON.stringify(payload)\n    }\n  }\n];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -280,
        1880
      ],
      "id": "7353b635-006c-4e05-9793-48cb2fadd39b",
      "name": "Prepare for frontend8"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://sse-estimation-tool.onrender.com/progress",
        "sendBody": true,
        "contentType": "raw",
        "rawContentType": "application/json",
        "body": "={{ $json.body }}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -40,
        1880
      ],
      "id": "aa6b0e57-86f4-4992-974e-ecde457b4c13",
      "name": "tech_stack1"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://sse-estimation-tool.onrender.com/progress",
        "sendBody": true,
        "contentType": "raw",
        "rawContentType": "application/json",
        "body": "={{ $json.body }}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        520,
        2060
      ],
      "id": "521d0778-ae91-45f7-9284-df67f323bafb",
      "name": "delivery_context"
    },
    {
      "parameters": {
        "workflowId": {
          "__rl": true,
          "value": "Wq7yr65wS1pYHWUW",
          "mode": "list",
          "cachedResultName": "Clean RFP"
        },
        "workflowInputs": {
          "mappingMode": "defineBelow",
          "value": {
            "rfpText": "={{ $json.rfpText }}"
          },
          "matchingColumns": [],
          "schema": [
            {
              "id": "rfpText",
              "displayName": "rfpText",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "canBeUsedToMatch": true,
              "type": "string",
              "removed": false
            }
          ],
          "attemptToConvertTypes": false,
          "convertFieldsToString": true
        },
        "options": {
          "waitForSubWorkflow": false
        }
      },
      "type": "n8n-nodes-base.executeWorkflow",
      "typeVersion": 1.2,
      "position": [
        -480,
        1100
      ],
      "id": "0cb9cb9c-c19f-4940-a1fc-3a2a38825abc",
      "name": "Clean RFP"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=You will receive an RFP document in plain text.\n\nYour job is to return a JSON array containing the exact section titles or header lines that represent **non-scope** content. These are sections related to:\n\n- Submission deadlines\n- Evaluation/scoring criteria\n- Contact or company information\n- Proposal formatting\n- Legal terms or disclaimers\n- Budget/pricing instructions\n- Vendor qualifications\n\nExclude anything related to:\n- Functional or technical features\n- Deliverables\n- System architecture\n- Business goals\n- Platform or system requirements\n\n### Format:\nReturn your result as a **JSON array** of strings (no markdown or commentary):\n\n```json\n[\n  \"Evaluation Criteria\",\n  \"Proposal Submission\",\n  \"Terms and Conditions\",\n  \"Contact Information\",\n  \"Pricing Instructions\"\n]\n\n {{ $json.cleanedRfpText }}",
        "messages": {
          "messageValues": [
            {
              "message": "You are a filtering assistant. Your job is to identify which section titles in an RFP document are clearly unrelated to the scope of the actual software project.  These include submission rules, evaluation criteria, pricing instructions, vendor qualifications, legal disclaimers, and company background. Do not include anything that describes features, technical requirements, or delivery scope."
            }
          ]
        }
      },
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "typeVersion": 1.5,
      "position": [
        -1100,
        3220
      ],
      "id": "586ae22c-c561-458a-925d-cb0586e514ec",
      "name": "Basic LLM Chain"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "mode": "list",
          "value": "gpt-4o-mini"
        },
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        -880,
        3440
      ],
      "id": "3cc2eddd-978f-4c58-aa40-7473d101f714",
      "name": "OpenAI Chat Model1",
      "credentials": {
        "openAiApi": {
          "id": "M8xqWvEC6mH6LNuk",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "yes, create the prompt for gpt4o. user and prompt. this is the prompt i created for gemini: // n8n Code Node Script: Filter Scope Text, Collect Excluded Text, and Calculate Metrics\n\n// Purpose: Takes original RFP chunk text and non-scope markers. Filters the text\n//          and outputs the scope_text, excluded_text, original character count,\n//          scope character count, and reduction percentage.\n\n// --- Configuration ---\n// Adjust input expressions as needed based on your workflow structure.\n\nconst results = [];\nconst inputItems = $input.all();\n\nfor (const item of inputItems) {\n  let originalChunkText = ''; // Keep variable accessible in finally/catch\n  try {\n    // --- Get Inputs (ADJUST THESE EXPRESSIONS) ---\n    originalChunkText = item.json.chunk_text; // Assumes original text is here\n    let nonScopeMarkersRaw = item.json.markers;   // Assumes LLM marker list is here\n\n    // --- Input Validation ---\n    if (typeof originalChunkText !== 'string') {\n      throw new Error(`Invalid or missing originalChunkText for item index ${item.index}. Check input mapping.`);\n    }\n\n    // Ensure nonScopeMarkersRaw is treated as an array (handle null/undefined as empty)\n    if (!Array.isArray(nonScopeMarkersRaw)) {\n        if (nonScopeMarkersRaw == null) {\n            console.warn(`Warning: Non-scope markers list is null/undefined for item index ${item.index}. Assuming no non-scope content identified.`);\n            nonScopeMarkersRaw = [];\n        } else {\n            throw new Error(`Invalid nonScopeMarkers format for item index ${item.index}. Expected array, got ${typeof nonScopeMarkersRaw}. Check LLM output node.`);\n        }\n    }\n\n    // --- Processing ---\n    const nonScopeMarkerSet = new Set(\n        nonScopeMarkersRaw\n            .map(marker => typeof marker === 'string' ? marker.trim() : '')\n            .filter(marker => marker.length > 0)\n    );\n\n    const scopeSegments = [];\n    const excludedSegments = [];\n    let scopeText = '';       // Initialize scopeText\n    let excludedText = '';    // Initialize excludedText\n\n    // Handle empty marker set - entire chunk is scope\n    if (nonScopeMarkerSet.size === 0) {\n        scopeText = originalChunkText;\n        excludedText = \"\"; // No text was excluded\n    } else {\n        // Proceed with filtering only if there are markers\n        const segments = originalChunkText.split(/(\\n\\s*\\n)/);\n        let currentSegmentIsScope = true;\n\n        for (let i = 0; i < segments.length; i++) {\n            const segment = segments[i];\n            const trimmedSegment = segment.trim();\n\n            if (!trimmedSegment) {\n                if (currentSegmentIsScope && scopeSegments.length > 0) {\n                     if (!scopeSegments[scopeSegments.length-1]?.match(/^\\n\\s*\\n$/)) {\n                        scopeSegments.push(segment);\n                     }\n                }\n                continue;\n            }\n\n            let isNonScope = false;\n            for (const marker of nonScopeMarkerSet) {\n                if (trimmedSegment.startsWith(marker)) {\n                    isNonScope = true;\n                    break;\n                }\n            }\n\n            if (isNonScope) {\n                excludedSegments.push(segment);\n                currentSegmentIsScope = false;\n            } else {\n                scopeSegments.push(segment);\n                currentSegmentIsScope = true;\n\n                 if (i + 1 < segments.length) {\n                    const nextSeparator = segments[i+1];\n                     if (nextSeparator?.match(/^\\n\\s*\\n$/)) {\n                        const nextTextSegment = segments[i+2]?.trim();\n                        let nextSegmentIsNonScope = false;\n                        if (nextTextSegment) {\n                            for (const marker of nonScopeMarkerSet) {\n                               if (nextTextSegment.startsWith(marker)) {\n                                   nextSegmentIsNonScope = true;\n                                   break;\n                               }\n                           }\n                        } else {\n                             nextSegmentIsNonScope = true;\n                        }\n\n                        if (!nextSegmentIsNonScope) {\n                             if (!scopeSegments[scopeSegments.length-1]?.match(/^\\n\\s*\\n$/)) {\n                                 scopeSegments.push(nextSeparator);\n                             }\n                        }\n                        i++;\n                     }\n                 }\n            }\n        }\n        // Join the segments back together\n        scopeText = scopeSegments.join('').trim();\n        excludedText = excludedSegments.join('\\n\\n').trim();\n    }\n\n\n    // --- Calculate Metrics ---\n    const originalCharCount = originalChunkText.length;\n    const scopeCharCount = scopeText.length;\n    let reductionPercentage = 0;\n\n    if (originalCharCount > 0) {\n      // Calculate percentage and round to 2 decimal places\n      reductionPercentage = parseFloat((((originalCharCount - scopeCharCount) / originalCharCount) * 100).toFixed(2));\n    }\n\n    // --- Prepare Output Item ---\n    results.push({\n      json: {\n        scope_text: scopeText,\n        excluded_text: excludedText,\n        metrics: { // Add metrics object\n            originalCharCount: originalCharCount,\n            scopeCharCount: scopeCharCount,\n            reductionPercentage: reductionPercentage // Percentage value\n        }\n        // Optional for debugging:\n        // original_chunk: originalChunkText,\n        // non_scope_markers_identified: Array.from(nonScopeMarkerSet)\n      }\n    });\n\n  } catch (error) {\n    console.error(`Error processing item index ${item.index}:`, error);\n    // Add error information and original text to the output item for easier debugging\n    results.push({\n        json: {\n            error: error.message,\n            stack: error.stack,\n            itemIndex: item.index,\n            original_chunk_on_error: originalChunkText // Include original text if error occurred\n        }\n    });\n  }\n}\n\nreturn results;"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -680,
        3220
      ],
      "id": "24035750-8bb8-4868-b888-48951443c43c",
      "name": "Code4"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=Analyze the following RFP text chunk and identify all section headers or paragraph starts that represent clearly **non-scope** content as described in your instructions.\n\nReturn only a valid JSON array of strings.\n\n--- BEGIN RFP TEXT CHUNK ---\n{{ $json.chunk_text }}\n--- END RFP TEXT CHUNK ---",
        "messages": {
          "messageValues": [
            {
              "message": "You are an AI assistant trained to process RFP (Request for Proposal) document chunks and identify section markers that indicate **non-scope** content.  Your job is to extract only **titles or paragraph beginnings** that clearly belong to any of the following categories:  ---  **Categories of NON-SCOPE content to detect:** - **Submission Instructions** (how to submit, deadlines, proposal format, points of contact) - **Evaluation Criteria** (scoring, weighting, selection processes) - **Pricing & Commercial Terms** (budgets, cost tables, payment terms, bid bonds) - **Legal & Compliance** (terms and conditions, disclaimers, contracts, procurement rules) - **Vendor Requirements** (bidder qualifications, reference requirements, eligibility) - **Document Structure** (table of contents, signature pages, cover letters, watermark notices, references to appendices, or generic company background)  ---  **What counts as a \"marker\":** - A full section header, e.g., `\"2.4 Submission Instructions\"` or `\"## Terms and Conditions\"` - If no header, the **first 10–15 words** of a paragraph that clearly starts non-scope content, e.g.:   - `\"All communications must be directed to...\"`   - `\"Pricing shall remain valid for a period of...\"`   - `\"The bidder must demonstrate prior experience with...\"`  ---  **IMPORTANT:** - ❌ Do NOT mark anything related to actual system requirements, project goals, scope of work, features, specs, deliverables, or technical context. - ✅ Only return clear non-scope indicators as defined above.  ---  **Output Format:** - Return only a **JSON array of strings**, one per identified marker. - If no non-scope markers are found, return an empty array: `[]` - Do NOT include any explanation, markdown, formatting, or comments."
            }
          ]
        }
      },
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "typeVersion": 1.5,
      "position": [
        -500,
        360
      ],
      "id": "63c2e127-d509-44c0-8cab-b16676e1c669",
      "name": "Basic LLM Chain1"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "gpt-4o-mini",
          "mode": "list",
          "cachedResultName": "gpt-4o-mini"
        },
        "options": {
          "temperature": 0
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        -860,
        400
      ],
      "id": "d05f9036-ace3-4214-be9c-f22dfdc6322c",
      "name": "OpenAI Chat Model2",
      "credentials": {
        "openAiApi": {
          "id": "M8xqWvEC6mH6LNuk",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// n8n Code Node Script: Filter Scope Text, Collect Excluded Text, and Calculate Metrics\n\n// Purpose: Takes original RFP chunk text and non-scope markers. Filters the text\n//          and outputs the scope_text, excluded_text, original character count,\n//          scope character count, and reduction percentage.\n\n// --- Configuration ---\n// Adjust input expressions as needed based on your workflow structure.\n\nconst results = [];\nconst inputItems = $input.all();\n\nfor (const item of inputItems) {\n  let originalChunkText = ''; // Keep variable accessible in finally/catch\n  try {\n    // --- Get Inputs (ADJUST THESE EXPRESSIONS) ---\n    originalChunkText = $('Chunking - Gemini').first().json.chunk_text; // Assumes original text is here\n    let nonScopeMarkersRaw = $input.first().json.markers;   // Assumes LLM marker list is here\n\n    // --- Input Validation ---\n    if (typeof originalChunkText !== 'string') {\n      throw new Error(`Invalid or missing originalChunkText for item index ${item.index}. Check input mapping.`);\n    }\n\n    // Ensure nonScopeMarkersRaw is treated as an array (handle null/undefined as empty)\n    if (!Array.isArray(nonScopeMarkersRaw)) {\n        if (nonScopeMarkersRaw == null) {\n            console.warn(`Warning: Non-scope markers list is null/undefined for item index ${item.index}. Assuming no non-scope content identified.`);\n            nonScopeMarkersRaw = [];\n        } else {\n            throw new Error(`Invalid nonScopeMarkers format for item index ${item.index}. Expected array, got ${typeof nonScopeMarkersRaw}. Check LLM output node.`);\n        }\n    }\n\n    // --- Processing ---\n    const nonScopeMarkerSet = new Set(\n        nonScopeMarkersRaw\n            .map(marker => typeof marker === 'string' ? marker.trim() : '')\n            .filter(marker => marker.length > 0)\n    );\n\n    const scopeSegments = [];\n    const excludedSegments = [];\n    let scopeText = '';       // Initialize scopeText\n    let excludedText = '';    // Initialize excludedText\n\n    // Handle empty marker set - entire chunk is scope\n    if (nonScopeMarkerSet.size === 0) {\n        scopeText = originalChunkText;\n        excludedText = \"\"; // No text was excluded\n    } else {\n        // Proceed with filtering only if there are markers\n        const segments = originalChunkText.split(/(\\n\\s*\\n)/);\n        let currentSegmentIsScope = true;\n\n        for (let i = 0; i < segments.length; i++) {\n            const segment = segments[i];\n            const trimmedSegment = segment.trim();\n\n            if (!trimmedSegment) {\n                if (currentSegmentIsScope && scopeSegments.length > 0) {\n                     if (!scopeSegments[scopeSegments.length-1]?.match(/^\\n\\s*\\n$/)) {\n                        scopeSegments.push(segment);\n                     }\n                }\n                continue;\n            }\n\n            let isNonScope = false;\n            for (const marker of nonScopeMarkerSet) {\n                if (trimmedSegment.startsWith(marker)) {\n                    isNonScope = true;\n                    break;\n                }\n            }\n\n            if (isNonScope) {\n                excludedSegments.push(segment);\n                currentSegmentIsScope = false;\n            } else {\n                scopeSegments.push(segment);\n                currentSegmentIsScope = true;\n\n                 if (i + 1 < segments.length) {\n                    const nextSeparator = segments[i+1];\n                     if (nextSeparator?.match(/^\\n\\s*\\n$/)) {\n                        const nextTextSegment = segments[i+2]?.trim();\n                        let nextSegmentIsNonScope = false;\n                        if (nextTextSegment) {\n                            for (const marker of nonScopeMarkerSet) {\n                               if (nextTextSegment.startsWith(marker)) {\n                                   nextSegmentIsNonScope = true;\n                                   break;\n                               }\n                           }\n                        } else {\n                             nextSegmentIsNonScope = true;\n                        }\n\n                        if (!nextSegmentIsNonScope) {\n                             if (!scopeSegments[scopeSegments.length-1]?.match(/^\\n\\s*\\n$/)) {\n                                 scopeSegments.push(nextSeparator);\n                             }\n                        }\n                        i++;\n                     }\n                 }\n            }\n        }\n        // Join the segments back together\n        scopeText = scopeSegments.join('').trim();\n        excludedText = excludedSegments.join('\\n\\n').trim();\n    }\n\n\n    // --- Calculate Metrics ---\n    const originalCharCount = originalChunkText.length;\n    const scopeCharCount = scopeText.length;\n    let reductionPercentage = 0;\n\n    if (originalCharCount > 0) {\n      // Calculate percentage and round to 2 decimal places\n      reductionPercentage = parseFloat((((originalCharCount - scopeCharCount) / originalCharCount) * 100).toFixed(2));\n    }\n\n    // --- Prepare Output Item ---\n    results.push({\n      json: {\n        scope_text: scopeText,\n        excluded_text: excludedText,\n        metrics: { // Add metrics object\n            originalCharCount: originalCharCount,\n            scopeCharCount: scopeCharCount,\n            reductionPercentage: reductionPercentage // Percentage value\n        }\n        // Optional for debugging:\n        // original_chunk: originalChunkText,\n        // non_scope_markers_identified: Array.from(nonScopeMarkerSet)\n      }\n    });\n\n  } catch (error) {\n    console.error(`Error processing item index ${item.index}:`, error);\n    // Add error information and original text to the output item for easier debugging\n    results.push({\n        json: {\n            error: error.message,\n            stack: error.stack,\n            itemIndex: item.index,\n            original_chunk_on_error: originalChunkText // Include original text if error occurred\n        }\n    });\n  }\n}\n\nreturn results;"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        340,
        420
      ],
      "id": "e797ea51-4382-427c-9446-ab00edcd409a",
      "name": "Code5"
    },
    {
      "parameters": {
        "jsCode": "// n8n Code Node Script: Parse JSON Array from Markdown Code Fence\n\n// Purpose: Extracts a JSON array from a string that is wrapped\n//          in markdown code fences like ```json ... ```.\n\nconst results = [];\nconst inputItems = $input.all(); // Get all input items\n\nfor (const item of inputItems) {\n  try {\n    // --- Get Input ---\n    // Adjust 'output' if the field containing the string is named differently\n    const rawStringOutput = item.json.text;\n\n    // --- Input Validation ---\n    if (typeof rawStringOutput !== 'string') {\n       // If the input is somehow already the array we want, just use it\n       if (Array.isArray(rawStringOutput)) {\n           console.warn(`Input for item index ${item.index} seems already parsed. Using as is.`);\n           results.push({ json: { markers: rawStringOutput } }); // Pass through directly\n           continue; // Move to the next item\n       } else {\n            // Otherwise, if it's not a string and not an array, it's an unexpected format\n            throw new Error(`Input 'output' is not a string for item index ${item.index}. Found type: ${typeof rawStringOutput}`);\n       }\n    }\n\n    // --- Processing ---\n\n    // 1. Remove the markdown code fences (```json ... ```)\n    // This regex handles potential whitespace variance around the fences.\n    const jsonString = rawStringOutput.replace(/^```json\\s*|\\s*```$/g, '').trim();\n\n    // 2. Parse the resulting string into a JavaScript object/array\n    const parsedData = JSON.parse(jsonString);\n\n    // --- Output Validation (Ensure it's an array) ---\n    if (!Array.isArray(parsedData)) {\n       throw new Error(`Parsed data is not an array for item index ${item.index}. Parsed type: ${typeof parsedData}`);\n    }\n\n    // --- Prepare Output Item ---\n    // Place the successfully parsed array into the output item's json property\n    // under a key named 'markers' (or choose a name you prefer).\n    results.push({\n      json: {\n        markers: parsedData\n        // You could optionally include the original raw string for debugging:\n        // raw_llm_output_string: rawStringOutput\n      }\n    });\n\n  } catch (error) {\n    console.error(`Error processing item index ${item.index}:`, error);\n    // Output an item indicating the error for easier debugging in n8n\n    results.push({\n      json: {\n        error: `Failed to parse JSON marker array: ${error.message}`,\n        itemIndex: item.index,\n        inputValue: item.json.output // Include the problematic input\n      }\n    });\n  }\n}\n\n// Return the array of processed items (or error items)\nreturn results;"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        120,
        420
      ],
      "id": "c136c968-4996-4f0f-ab81-63c766ce7a91",
      "name": "remove '''json1"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=Analyze the following RFP text.\n\nReturn only the **section titles** (headings), in the order they appear, that represent major organizational parts of the document.\n\nDo NOT include full paragraphs or body content.\nDo NOT include sub-features or numbered bullets.\n\nFormat: Single Array with all section titles inside.\nReturn only a valid JSON array like:\n\n[\n  \"Introduction\",\n  \"Scope of Work\",\n  \"Project Requirements\",\n  \"Integration Overview\",\n  \"Evaluation Criteria\"\n]\n\n--- BEGIN RFP TEXT ---\n{{ $json.chunk_text }}\n--- END RFP TEXT ---\n",
        "messages": {
          "messageValues": [
            {
              "message": "You are a section-heading extraction agent for RFP documents.  Your task is to identify and return a clean list of **major section headers** that reflect the actual structure and organization of the document.  These should be meaningful, high-level sections — not bullet points, list items, or sub-features. Only include headings that reflect significant structure in the document, such as:  - Introduction - Scope of Work - Project Objectives - Functional Requirements - Evaluation Criteria - Proposal Submission  Ignore: - Bullet points or numbered features - Minor sub-bullets - Signatures, appendices, or footnotes  Return a clean JSON array of section titles, one string per section."
            }
          ]
        }
      },
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "typeVersion": 1.5,
      "position": [
        -560,
        100
      ],
      "id": "9bd45714-30a6-4f0a-8a04-ccbcf4d51fe4",
      "name": "Basic LLM Chain2"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=Analyze the following RFP text.\n\nReturn only the sections that clearly fall under administrative, legal, commercial, or process-related categories — NOT project requirements.\n\nFollow the instructions in your system prompt and return a valid JSON object.\n\n--- BEGIN RFP TEXT ---\n{{ $json.cleanedRfpText }}\n--- END RFP TEXT ---\n",
        "options": {
          "systemMessage": "You are an AI assistant trained to analyze RFP (Request for Proposal) documents and isolate all content that does NOT relate to the core scope of work.\n\nYour goal is to extract ONLY the parts of the document that are administrative, legal, pricing, evaluation, or vendor qualification content — anything that is NOT directly related to project implementation, features, functionality, or technical requirements.\n\n---\n\nYou must return a JSON object with two keys:\n- \"excluded_content\": the excluded content, in full, with original structure preserved\n- \"metrics\": character counts and reduction percentage\n\n---\n\n### ❌ You must extract and return ONLY content from these categories:\n\n1. **RFP Process & Submission Instructions**\n   - How/where/when to submit\n   - Deadlines, contact info, proposal formatting\n   - Q&A procedures, invitation to bid\n\n2. **Evaluation & Selection**\n   - Evaluation or scoring criteria\n   - Selection process explanations\n\n3. **Commercial Terms**\n   - Pricing instructions, cost sheets, payment schedules\n   - Bid bonds or financial guarantees\n\n4. **Legal & Compliance**\n   - Standard terms and conditions\n   - Disclaimers, liability, certification rules\n   - Confidentiality around bidding\n   - Procurement policies\n\n5. **Vendor Qualifications**\n   - Required experience, financials, references\n   - Team structure, eligibility rules\n\n6. **Document Structure / Boilerplate**\n   - Table of contents, cover letters, signatures, attachments\n   - General company background not tied to the project\n   - Mention of forms (Form of Proposal, Cost Breakdown, etc.)\n\n7. **Ambiguous items**\n   - Remove vague sections like “Reference Materials” unless clearly describing a deliverable or requirement\n\n---\n\n### ✅ DO NOT return:\n- Functional, technical, or feature requirements\n- Project goals or business objectives\n- Descriptions of system components or deliverables\n- Platform expectations or integration requirements\n- Any content essential to defining what will be built or delivered\n\n---\n\n### ⚙️ Output format:\n\nReturn a **JSON object** like this:\n\n{\n  \"excluded_content\": \"All removed content here, with original structure\",\n  \"metrics\": {\n    \"originalCharCount\": <original length>,\n    \"excludedCharCount\": <excluded text length>,\n    \"reductionPercentage\": <how much was removed as a %>\n  }\n}\n\n---\n\nDo not include Markdown fences, summaries, or commentary.\nPreserve the original structure and wording of the removed content.\nDo not fabricate or rephrase — return the exact sections as found in the document.\n"
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.8,
      "position": [
        -1100,
        1360
      ],
      "id": "630a9831-cbf5-4f20-8031-9fb8ec0525aa",
      "name": "Preprocess Exclude",
      "onError": "continueRegularOutput"
    },
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "rfp-upload",
        "options": {}
      },
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 2,
      "position": [
        -1940,
        -1040
      ],
      "id": "488a5a44-466b-465d-ab54-101cf98a816b",
      "name": "RFP Upload1",
      "webhookId": "663a2e7d-35dd-4241-8890-97393732bb42"
    }
  ],
  "pinData": {
    "Effort Estimator": [
      {
        "json": {
          "output": {
            "min_sprints": 8,
            "max_sprints": 12,
            "note": "This project represents a medium-to-large mobile/web application with social, content management, and gamification features. Key considerations:\n\n1. AI-assisted development will accelerate implementation of standard features like user profiles, content feeds, and basic CRUD operations.\n\n2. Areas of complexity that will require more time:\n   - Forest visualization system (likely requiring custom graphics/animations)\n   - Achievements and rewards system (complex business logic)\n   - Content management across multiple types (podcasts, videos, articles)\n   - Social features with commenting hierarchies\n   - Mission/challenge tracking with data collection\n\n3. Integration points that add uncertainty:\n   - Email system integration\n   - Social media platform connections\n   - Podcast integration\n   - Photo upload and storage\n\n4. The leaderboard and achievements systems suggest a gamification layer that will require careful implementation to ensure proper tracking and display.\n\nWith AI-assisted development, many standard components can be generated quickly, but the custom visualization, gamification logic, and multiple content types will still require significant effort. The range accounts for the complexity while recognizing the acceleration from AI tooling."
          }
        }
      }
    ],
    "Team Composition Agent": [
      {
        "json": {
          "output": "[\n  {\n    \"role\": \"Project Manager\",\n    \"count\": 1,\n    \"justification\": \"Required to coordinate the 8-12 sprint project, manage stakeholder expectations, and ensure timely delivery of all features.\"\n  },\n  {\n    \"role\": \"Frontend Developer\",\n    \"count\": 3,\n    \"justification\": \"Needed to implement numerous UI components including rewards screens, forest visualizations, social media sharing, content feeds, and interactive elements.\"\n  },\n  {\n    \"role\": \"Backend Developer\",\n    \"count\": 2,\n    \"justification\": \"Required for implementing API endpoints, database integration, notification systems, user authentication, and data processing for missions and achievements.\"\n  },\n  {\n    \"role\": \"UX/UI Designer\",\n    \"count\": 1,\n    \"justification\": \"Essential for designing user interfaces for multiple screens, ensuring consistent user experience across features like forests, rewards, missions, and profiles.\"\n  },\n  {\n    \"role\": \"QA Engineer\",\n    \"count\": 2,\n    \"justification\": \"Needed to test complex user flows, social interactions, and ensure cross-platform compatibility for all features.\"\n  },\n  {\n    \"role\": \"DevOps Engineer\",\n    \"count\": 1,\n    \"justification\": \"Required for setting up CI/CD pipelines, managing deployments, and ensuring infrastructure supports features like image uploads and social sharing.\"\n  },\n  {\n    \"role\": \"Mobile Developer\",\n    \"count\": 2,\n    \"justification\": \"Needed to implement mobile-specific functionality for photo uploads, notifications, and social sharing features.\"\n  },\n  {\n    \"role\": \"Database Engineer\",\n    \"count\": 1,\n    \"justification\": \"Required to design and optimize database schemas for user profiles, achievements, missions, content, and tracking user activities.\"\n  },\n  {\n    \"role\": \"Content Manager\",\n    \"count\": 1,\n    \"justification\": \"Needed to manage various content types including podcasts, videos, guides, and sustainability categories.\"\n  },\n  {\n    \"role\": \"Scrum Master\",\n    \"count\": 1,\n    \"justification\": \"Required to facilitate agile processes, remove impediments, and ensure efficient sprint execution over the 8-12 sprint timeline.\"\n  }\n]"
        }
      }
    ],
    "Development Plan": [
      {
        "json": {
          "output": {
            "phases": [
              {
                "name": "Planning and Foundation",
                "sprints": {
                  "start": 1,
                  "end": 3
                },
                "items": [
                  "Project setup and architecture definition",
                  "User authentication and profile system",
                  "Basic account management and profile editing",
                  "Environment configuration",
                  "Core data models and database schema",
                  "Basic UI framework and design system"
                ]
              },
              {
                "name": "Core Development",
                "sprints": {
                  "start": 4,
                  "end": 7
                },
                "items": [
                  "Personal forest visualization and growth tracking",
                  "Collective forest view implementation",
                  "Rewards system and redemption flow",
                  "Mission system core functionality",
                  "My feed section with content previews",
                  "Topics browsing and following capability",
                  "Mission joining with data collection",
                  "Notification system foundation"
                ]
              },
              {
                "name": "Feature Expansion",
                "sprints": {
                  "start": 8,
                  "end": 10
                },
                "items": [
                  "Social media sharing functionality",
                  "Challenge system and leaderboards",
                  "Content integration (podcasts, videos, events)",
                  "Learn section with commenting capabilities",
                  "Action options (donations, petitions, competitions)",
                  "Achievements system implementation",
                  "Social interaction features (likes, comments)",
                  "Email integration and notifications"
                ]
              },
              {
                "name": "Finalization and Optimization",
                "sprints": {
                  "start": 11,
                  "end": 12
                },
                "items": [
                  "Welcome back screen optimization",
                  "Reading history and activity tracking",
                  "Year-end summary functionality",
                  "Performance optimization",
                  "Final UI/UX refinements",
                  "Feature integration testing",
                  "Bug fixes and stability improvements",
                  "Prepare for production release"
                ]
              }
            ],
            "cross_cutting": {
              "infrastructure": [
                "CI/CD pipeline setup and maintenance",
                "Development, staging, and production environments",
                "Database infrastructure and scaling",
                "Cloud resources management",
                "Monitoring and logging systems"
              ],
              "security": [
                "User authentication and authorization",
                "Data encryption and protection",
                "Security testing and vulnerability scanning",
                "GDPR and data privacy compliance",
                "API security measures"
              ],
              "testing": [
                "Unit testing for all components",
                "Integration testing",
                "End-to-end testing",
                "Performance testing",
                "User acceptance testing",
                "Cross-browser and device compatibility testing"
              ],
              "documentation": [
                "API documentation",
                "Technical architecture documentation",
                "User guides and help content",
                "Developer onboarding documentation",
                "System diagrams and data flow documentation"
              ],
              "deployment": [
                "Deployment automation",
                "Feature flagging system",
                "Rollback procedures",
                "Database migration strategies",
                "Release notes preparation",
                "Phased rollout strategy"
              ]
            }
          }
        }
      }
    ]
  },
  "repo_name": "n8n-backup-zm",
  "repo_owner": "zlatkomq",
  "repo_path": "",
  "settings": {
    "executionOrder": "v1"
  },
  "shared": [
    {
      "updatedAt": "2025-03-31T16:18:56.271Z",
      "createdAt": "2025-03-31T16:18:56.271Z",
      "role": "workflow:owner",
      "workflowId": "cHtp8Fd5t5HO71iG",
      "projectId": "NM7VZoSXkcKo262s"
    }
  ],
  "staticData": null,
  "tags": [
    {
      "updatedAt": "2025-04-24T10:59:44.979Z",
      "createdAt": "2025-04-24T10:59:44.979Z",
      "id": "qEREEA2JvunvA9Nv",
      "name": "Estimation Tool"
    }
  ],
  "triggerCount": 1,
  "updatedAt": "2025-06-08T19:26:58.098Z",
  "versionId": "ca7a8a98-9fb3-4bc4-ae34-448510da3321"
}