{
  "active": false,
  "connections": {
    "When clicking ‘Test workflow’": {
      "main": [
        []
      ]
    },
    "Queries": {
      "main": [
        [
          {
            "node": "Embed Query - ollama",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Embed Query - ollama": {
      "main": [
        [
          {
            "node": "Wait",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Map Response": {
      "main": [
        [
          {
            "node": "Deduplicate and Best Score",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "PreparePrompts": {
      "main": [
        [
          {
            "node": "Get Platforms",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Claude 3.7": {
      "ai_languageModel": [
        []
      ]
    },
    "Platforms + Rationale": {
      "ai_outputParser": [
        [
          {
            "node": "Get Platforms",
            "type": "ai_outputParser",
            "index": 0
          }
        ]
      ]
    },
    "Merge Chunks": {
      "main": [
        [
          {
            "node": "Token Budgeting",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Deduplicate and Best Score": {
      "main": [
        [
          {
            "node": "Merge Chunks",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Token Budgeting": {
      "main": [
        [
          {
            "node": "Prepare Context3",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Chat Model1": {
      "ai_languageModel": [
        [
          {
            "node": "Get Platforms",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Prepare Context3": {
      "main": [
        [
          {
            "node": "PreparePrompts",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Queries2": {
      "main": [
        [
          {
            "node": "Embed Query - ollama2",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Embed Query - ollama2": {
      "main": [
        [
          {
            "node": "Wait1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Map Response2": {
      "main": [
        [
          {
            "node": "Deduplicate and Best Score6",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "PreparePrompts4": {
      "main": [
        [
          {
            "node": "Functional requirements",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Query - Full9": {
      "main": [
        [
          {
            "node": "Has Hits?1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Merge Chunks5": {
      "main": [
        [
          {
            "node": "Token Budgeting2",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Deduplicate and Best Score6": {
      "main": [
        [
          {
            "node": "Merge Chunks5",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Token Budgeting2": {
      "main": [
        [
          {
            "node": "Prepare Context4",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Chat Model3": {
      "ai_languageModel": [
        [
          {
            "node": "Functional requirements",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Prepare Context4": {
      "main": [
        [
          {
            "node": "PreparePrompts4",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Claude 3.": {
      "ai_languageModel": [
        []
      ]
    },
    "Functional requirements": {
      "main": [
        [
          {
            "node": "Functional Requirements Output",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Stop and Error1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Think": {
      "ai_tool": [
        [
          {
            "node": "Functional requirements",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Platforms Output": {
      "main": [
        [
          {
            "node": "Prepare for frontend8",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "GPT 4.1 Mini2": {
      "ai_languageModel": [
        []
      ]
    },
    "Code": {
      "main": [
        [
          {
            "node": "Team Composition",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Anthropic Chat Model": {
      "ai_languageModel": [
        [
          {
            "node": "Team Composition",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Functional Requirements Output": {
      "main": [
        [
          {
            "node": "Queries8",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Queries8": {
      "main": [
        [
          {
            "node": "Embed Query - ollama8",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Embed Query - ollama8": {
      "main": [
        [
          {
            "node": "Wait2",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "PreparePrompts7": {
      "main": [
        [
          {
            "node": "NonFunctional Requirements",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Query - Full11": {
      "main": [
        [
          {
            "node": "Has Hits?2",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Merge Chunks8": {
      "main": [
        [
          {
            "node": "Token Budgeting7",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Deduplicate and Best Score8": {
      "main": [
        [
          {
            "node": "Merge Chunks8",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Token Budgeting7": {
      "main": [
        [
          {
            "node": "Prepare Context6",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Chat Model": {
      "ai_languageModel": [
        []
      ]
    },
    "Prepare Context6": {
      "main": [
        [
          {
            "node": "PreparePrompts7",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Think1": {
      "ai_tool": [
        [
          {
            "node": "NonFunctional Requirements",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Map Response8": {
      "main": [
        [
          {
            "node": "Deduplicate and Best Score8",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "NonFunctional Requirements": {
      "main": [
        [
          {
            "node": "NonFunctional Requirements Output",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Stop and Error2",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "NonFunctional Requirements Output": {
      "main": [
        [
          {
            "node": "Combine Requirements",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Queries7": {
      "main": [
        [
          {
            "node": "Embed Query - ollama7",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Embed Query - ollama7": {
      "main": [
        [
          {
            "node": "Wait3",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Map Response3": {
      "main": [
        [
          {
            "node": "Deduplicate and Best Score7",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "PreparePrompts6": {
      "main": [
        [
          {
            "node": "Get Techstack",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Claude 3.8": {
      "ai_languageModel": [
        [
          {
            "node": "Get Techstack",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Platforms + Rationale2": {
      "ai_outputParser": [
        [
          {
            "node": "Get Techstack",
            "type": "ai_outputParser",
            "index": 0
          }
        ]
      ]
    },
    "Query - Full10": {
      "main": [
        [
          {
            "node": "Has Hits?3",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Merge Chunks7": {
      "main": [
        [
          {
            "node": "Token Budgeting5",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Deduplicate and Best Score7": {
      "main": [
        [
          {
            "node": "Merge Chunks7",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Token Budgeting5": {
      "main": [
        [
          {
            "node": "Prepare Context5",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare Context5": {
      "main": [
        [
          {
            "node": "PreparePrompts6",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Get Techstack": {
      "main": [
        [
          {
            "node": "Techstack Output",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Stop and Error4",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Chat Model5": {
      "ai_languageModel": [
        []
      ]
    },
    "Title + Desc + Section": {
      "ai_outputParser": [
        []
      ]
    },
    "Description": {
      "ai_outputParser": [
        [
          {
            "node": "Functional requirements",
            "type": "ai_outputParser",
            "index": 0
          }
        ]
      ]
    },
    "Full": {
      "ai_outputParser": [
        []
      ]
    },
    "Description + Category": {
      "ai_outputParser": [
        [
          {
            "node": "NonFunctional Requirements",
            "type": "ai_outputParser",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Chat Model6": {
      "ai_languageModel": [
        []
      ]
    },
    "Structured Output Parser": {
      "ai_outputParser": [
        [
          {
            "node": "Combine Requirements",
            "type": "ai_outputParser",
            "index": 0
          }
        ]
      ]
    },
    "Combine Requirements": {
      "main": [
        [
          {
            "node": "Combined Requirements Output",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Stop and Error3",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Combined Requirements Output": {
      "main": [
        [
          {
            "node": "Dependencies1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Dependencies1": {
      "main": [
        [
          {
            "node": "Prepare for frontend9",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Techstack Output": {
      "main": [
        [
          {
            "node": "Prepare for frontend10",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Team Composition1": {
      "ai_outputParser": [
        [
          {
            "node": "Team Composition",
            "type": "ai_outputParser",
            "index": 0
          }
        ]
      ]
    },
    "Team Composition": {
      "main": [
        [
          {
            "node": "Team Composition Output",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Stop and Error5",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Team Composition Output": {
      "main": [
        [
          {
            "node": "Prepare for frontend11",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Greenfield + Rationale": {
      "ai_outputParser": [
        [
          {
            "node": "Effort Estimation",
            "type": "ai_outputParser",
            "index": 0
          }
        ]
      ]
    },
    "GPT 4.1 Mini4": {
      "ai_languageModel": [
        []
      ]
    },
    "Code2": {
      "main": [
        [
          {
            "node": "Effort Estimation",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Calculator": {
      "ai_tool": [
        [
          {
            "node": "Effort Estimation",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Anthropic Chat Model2": {
      "ai_languageModel": [
        []
      ]
    },
    "Greenfield + Rationale3": {
      "ai_outputParser": [
        [
          {
            "node": "Development Plan",
            "type": "ai_outputParser",
            "index": 0
          }
        ]
      ]
    },
    "Code3": {
      "main": [
        [
          {
            "node": "Development Plan",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Anthropic Chat Model3": {
      "ai_languageModel": [
        [
          {
            "node": "Development Plan",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Calculator1": {
      "ai_tool": [
        [
          {
            "node": "Development Plan",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Effort Estimation": {
      "main": [
        [
          {
            "node": "Effort Estimate Output",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Stop and Error6",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Effort Estimate Output": {
      "main": [
        [
          {
            "node": "Prepare for frontend12",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Start RFP Analysis": {
      "main": [
        [
          {
            "node": "Call 'RFP Analysis Public - Ingestion'",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare for frontend8": {
      "main": [
        [
          {
            "node": "SSE - Platforms",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare for frontend9": {
      "main": [
        [
          {
            "node": "SSE - Requirements",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "SSE - Platforms": {
      "main": [
        [
          {
            "node": "Queries2",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "SSE - Requirements": {
      "main": [
        [
          {
            "node": "Queries7",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare for frontend10": {
      "main": [
        [
          {
            "node": "SSE - Techstack",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "SSE - Techstack": {
      "main": [
        [
          {
            "node": "Code",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare for frontend11": {
      "main": [
        [
          {
            "node": "SSE - Team Composition",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "SSE - Team Composition": {
      "main": [
        [
          {
            "node": "Code2",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare for frontend12": {
      "main": [
        [
          {
            "node": "SSE - Effort Estimation",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "SSE - Effort Estimation": {
      "main": [
        [
          {
            "node": "Code3",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare for frontend13": {
      "main": [
        [
          {
            "node": "SSE - Development Plan",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Development Plan": {
      "main": [
        [
          {
            "node": "Development Plan Output",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Stop and Error7",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Anthropic Chat Model5": {
      "ai_languageModel": [
        [
          {
            "node": "Reporter",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Reporter": {
      "main": [
        [
          {
            "node": "Prepare for frontend7",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Stop and Error8",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare for frontend7": {
      "main": [
        [
          {
            "node": "SSE - Final Report",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "SSE - Development Plan": {
      "main": [
        [
          {
            "node": "Prompt",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prompt": {
      "main": [
        [
          {
            "node": "Reporter",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Development Plan Output": {
      "main": [
        [
          {
            "node": "Prepare for frontend13",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Calculator2": {
      "ai_tool": [
        [
          {
            "node": "Reporter",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Think2": {
      "ai_tool": [
        [
          {
            "node": "Reporter",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "mock": {
      "main": [
        []
      ]
    },
    "Send PDF to Email": {
      "main": [
        [
          {
            "node": "Code6",
            "type": "main",
            "index": 0
          },
          {
            "node": "Merge",
            "type": "main",
            "index": 0
          },
          {
            "node": "Respond to Webhook",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Merge": {
      "main": [
        [
          {
            "node": "Gmail",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Code6": {
      "main": [
        [
          {
            "node": "Merge",
            "type": "main",
            "index": 1
          }
        ]
      ]
    },
    "Query - Full1": {
      "main": [
        [
          {
            "node": "Has Hits?",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Has Hits?": {
      "main": [
        [
          {
            "node": "Map Response",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Stop and Error",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Wait": {
      "main": [
        [
          {
            "node": "Query - Full1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Wait1": {
      "main": [
        [
          {
            "node": "Query - Full9",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Wait2": {
      "main": [
        [
          {
            "node": "Query - Full11",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Wait3": {
      "main": [
        [
          {
            "node": "Query - Full10",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Get Session ID and prepare file data": {
      "main": [
        [
          {
            "node": "Add Execution id",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Has Hits?1": {
      "main": [
        [
          {
            "node": "Map Response2",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Stop and Error1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Has Hits?2": {
      "main": [
        [
          {
            "node": "Map Response8",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Stop and Error2",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Has Hits?3": {
      "main": [
        [
          {
            "node": "Map Response3",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "PreparePrompts6",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "SSE - Final Report": {
      "main": [
        [
          {
            "node": "Delete tmp file",
            "type": "main",
            "index": 0
          },
          {
            "node": "Delete row(s)",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Get Platforms": {
      "main": [
        [
          {
            "node": "Platforms Output",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Chat Model4": {
      "ai_languageModel": [
        [
          {
            "node": "NonFunctional Requirements",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Chat Model7": {
      "ai_languageModel": [
        [
          {
            "node": "Combine Requirements",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Chat Model8": {
      "ai_languageModel": [
        [
          {
            "node": "Effort Estimation",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "vllm": {
      "ai_languageModel": [
        []
      ]
    },
    "RFP Upload": {
      "main": [
        []
      ]
    },
    "Download File": {
      "main": [
        [
          {
            "node": "Chunker Full",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Chunker Full": {
      "main": [
        [
          {
            "node": "Format Output1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "PreparePrompts - Metadata Enrichment": {
      "main": [
        [
          {
            "node": "Optimize Chunks - Metadata",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Remove TOC1": {
      "main": [
        [
          {
            "node": "Final Escaping1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Final Escaping1": {
      "main": [
        [
          {
            "node": "Only Big Chunks",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Format Output1": {
      "main": [
        [
          {
            "node": "Remove Search Documents prefix",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Topics": {
      "ai_outputParser": [
        [
          {
            "node": "Optimize Chunks - Metadata",
            "type": "ai_outputParser",
            "index": 0
          }
        ]
      ]
    },
    "Subchunking": {
      "ai_outputParser": [
        [
          {
            "node": "Optimize Chunks",
            "type": "ai_outputParser",
            "index": 0
          }
        ]
      ]
    },
    "Only Big Chunks": {
      "main": [
        [
          {
            "node": "PreparePrompts - subchunking",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Qwen": {
      "ai_languageModel": [
        [
          {
            "node": "Optimize Chunks - Metadata",
            "type": "ai_languageModel",
            "index": 1
          }
        ]
      ]
    },
    "PreparePrompts - subchunking": {
      "main": [
        [
          {
            "node": "Optimize Chunks",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Optimize Chunks": {
      "main": [
        [
          {
            "node": "Merge with original chunks",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Google Gemini - Free": {
      "ai_languageModel": [
        []
      ]
    },
    "Optimize Chunks - Metadata": {
      "main": [
        [
          {
            "node": "Add Metadata to Original",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Google Gemini - Payed": {
      "ai_languageModel": [
        [
          {
            "node": "Optimize Chunks - Metadata",
            "type": "ai_languageModel",
            "index": 0
          },
          {
            "node": "Topics",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Add Metadata to Original": {
      "main": [
        [
          {
            "node": "Prepare Embedding Text",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Insert or update rows in a table": {
      "main": [
        [
          {
            "node": "Prepare for frontend1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Embed Chunks1": {
      "main": [
        [
          {
            "node": "Embedding Isolated1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Embedding Isolated1": {
      "main": [
        [
          {
            "node": "Insert or update rows in a table",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare for frontend1": {
      "main": [
        [
          {
            "node": "SSE - Document Preparation1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Delete tmp file": {
      "main": [
        []
      ]
    },
    "SSE - Document Preparation1": {
      "main": [
        []
      ]
    },
    "Add Execution id": {
      "main": [
        [
          {
            "node": "Download File",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Google Gemini - Payed1": {
      "ai_languageModel": [
        [
          {
            "node": "Subchunking",
            "type": "ai_languageModel",
            "index": 0
          },
          {
            "node": "Optimize Chunks",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Qwen1": {
      "ai_languageModel": [
        []
      ]
    },
    "Merge with original chunks": {
      "main": [
        [
          {
            "node": "Add topic to Text",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Only subchunked": {
      "main": [
        []
      ]
    },
    "Add topic to Text": {
      "main": [
        [
          {
            "node": "PreparePrompts - Metadata Enrichment",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Remove Search Documents prefix": {
      "main": [
        [
          {
            "node": "Remove TOC1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare Embedding Text": {
      "main": [
        [
          {
            "node": "Embed Chunks1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare for frontend": {
      "main": [
        [
          {
            "node": "SSE - Document Preparation",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Call 'RFP Analysis Public - Ingestion'": {
      "main": [
        [
          {
            "node": "Prepare for frontend",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "createdAt": "2025-11-13T13:51:57.867Z",
  "id": "hppcM3kSB73vO8X2",
  "isArchived": false,
  "meta": {
    "templateCredsSetupCompleted": true
  },
  "name": "RFP Analysis Public - Supabase Backup",
  "nodes": [
    {
      "parameters": {},
      "id": "deca3640-44ba-47de-8cbe-c6c822607b1d",
      "name": "When clicking ‘Test workflow’",
      "type": "n8n-nodes-base.manualTrigger",
      "typeVersion": 1,
      "position": [
        -3936,
        1632
      ],
      "disabled": true
    },
    {
      "parameters": {
        "jsCode": "return [\n  {\n    json: {\n      platform: \"web\",\n      query: \"What web technologies or platforms are mentioned in the RFP?\",\n      keywords: \"web technology, technologies, platform, platforms, website, webapp, web application, HTML, CSS, JavaScript, TypeScript, React, Angular, Vue, Svelte, Next.js, Nuxt.js, PHP, Python, Django, Flask, Ruby, Rails, Node.js, Express, .NET, ASP.NET, Java, Spring, Laravel, Drupal, WordPress, CMS, frontend, backend, server-side, client-side, SaaS, PaaS, cloud hosting\",\n      phrase: \"web technology platform web application\",\n      rescore_query: \"web application OR React OR Angular OR Vue OR HTML OR CSS\"\n    }\n  },\n  {\n    json: {\n      platform: \"mobile\",\n      query: \"Is a mobile app required or mentioned in the RFP? Android, iOS or Flutter?\",\n      keywords: \"mobile app, application, Android, iOS, Flutter, React Native, Swift, Kotlin, cross-platform, smartphone, tablet, mobile device, iPhone, iPad, Play Store, App Store\",\n      phrase: \"mobile application mobile app\",\n      rescore_query: \"mobile app OR Android OR iOS OR Flutter OR React Native\"\n    }\n  },\n  {\n    json: {\n      platform: \"backend\",\n      query: \"Are there backend services or APIs involved in the RFP?\",\n      keywords: \"backend service, services, API, APIs, REST, RESTful, GraphQL, server, database, microservice, microservices, endpoint, endpoints, integration, integration layer, middleware, backend system, data storage, authentication, authorization, business logic\",\n      phrase: \"backend service API integration\",\n      rescore_query: \"REST API OR GraphQL OR microservice OR backend service\"\n    }\n  },\n  {\n    json: {\n      platform: \"admin\",\n      query: \"Does the RFP include an admin portal or dashboard?\",\n      keywords: \"admin portal, dashboard, administration, control panel, admin interface, management console, backend portal, admin dashboard, reporting, analytics, monitoring, configuration settings, user management\",\n      phrase: \"admin portal admin dashboard\",\n      rescore_query: \"admin portal OR admin dashboard OR management console\"\n    }\n  },\n  {\n    json: {\n      platform: \"desktop\",\n      query: \"Is desktop software or a desktop client part of the RFP scope?\",\n      keywords: \"desktop software, client application, Windows, MacOS, Linux, desktop app, Electron, desktop client, installable application, native desktop, cross-platform desktop, program, executable\",\n      phrase: \"desktop software desktop client\",\n      rescore_query: \"desktop app OR Electron OR native desktop\"\n    }\n  },\n  {\n    json: {\n      platform: \"kiosk\",\n      query: \"Are kiosk systems or interfaces required in the RFP?\",\n      keywords: \"kiosk system, systems, interface, interfaces, self-service terminal, touch screen, touchscreen, kiosk application, kiosk mode, interactive kiosk, public kiosk, digital kiosk, POS, point of sale\",\n      phrase: \"kiosk system kiosk interface\",\n      rescore_query: \"kiosk interface OR touchscreen OR point of sale\"\n    }\n  },\n  {\n    json: {\n      platform: \"system-architecture\",\n      query: \"Describe the overall system structure and functionality mentioned in the RFP.\",\n      keywords: \"system structure, architecture, functionality, components, modules, workflow, process, integration, overview, system design, system diagram, technical architecture, high-level design, system overview\",\n      phrase: \"system structure system functionality\",\n      rescore_query: \"system architecture OR technical architecture OR system design\"\n    }\n  },\n  {\n    json: {\n      platform: \"technical-components\",\n      query: \"What are the main technical or system components described in the RFP?\",\n      keywords: \"technical component, components, system element, elements, module, modules, subsystem, subsystems, architecture, infrastructure, technology stack, platform, integration, interface, API, backend, frontend, database, server, client\",\n      phrase: \"technical component system component\",\n      rescore_query: \"technical component OR system module OR technology stack\"\n    }\n  }\n];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -4064,
        3344
      ],
      "id": "668a212d-d599-4103-96bd-23399a18c554",
      "name": "Queries"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "http://192.168.20.70:11434/api/embed",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"model\": \"nomic-embed-text:latest\",\n  \"input\": [\"{{ $json.query }}\"]\n}",
        "options": {}
      },
      "id": "1ea4a72f-7084-4144-a8e8-db12de412dce",
      "name": "Embed Query - ollama",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -3888,
        3344
      ]
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "17f9e7d3-307e-4d60-92ef-e32285cbec29",
              "name": "_score",
              "value": "={{ $json._score }}",
              "type": "number"
            },
            {
              "id": "618f58cd-27c7-4ab4-8612-899f048afb6c",
              "name": "_id",
              "value": "={{ $json._id }}",
              "type": "string"
            },
            {
              "id": "a8cfb079-48c6-4ce2-a54c-251304107206",
              "name": "chunk_id",
              "value": "={{ $json._source.chunk_id }}",
              "type": "string"
            },
            {
              "id": "22e6e029-7ff1-4870-a1c2-d3b025a2748b",
              "name": "section_title",
              "value": "={{ $json._source.section_title }}",
              "type": "string"
            },
            {
              "id": "27e9a9ac-b6ed-4320-bb21-027f8659e7c5",
              "name": "text",
              "value": "={{ $json._source.text }}",
              "type": "string"
            },
            {
              "id": "6830a868-6492-405b-b8fb-1ae36ea184b2",
              "name": "metadata",
              "value": "={{ $json._source.metadata }}",
              "type": "object"
            },
            {
              "id": "e5dce93c-eb16-42be-8b42-47ca5cfacc52",
              "name": "platform",
              "value": "={{ $('Queries').item.json.platform }}",
              "type": "string"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        -3648,
        3360
      ],
      "id": "27fb001b-30cf-4417-8b44-7d6aa38a02d1",
      "name": "Map Response"
    },
    {
      "parameters": {
        "jsCode": "const contextForPrompt = $input.first().json.context;\nconst systemPrompt = \"You are a precise assistant that extracts structured insights from project documents, such as RFPs or technical scopes. Your primary goal is to identify platform requirements based on the content provided. Focus on what is clearly described, but use practical software development reasoning when appropriate: - If a frontend (web or mobile) is described in detail, and no backend is mentioned, assume a backend is required unless the RFP explicitly states otherwise.- If user-facing workflows imply system control or role management, you may reasonably infer that an admin interface is needed. Never invent features or platforms not supported by the text or standard architectural logic. If something is unclear or missing, say so clearly. Be structured, realistic, and accurate in all your conclusions.\";\n\n// 3. Define the user prompt\nconst userPrompt = `You are reviewing excerpts from an RFP document to determine which technology platforms are explicitly required.\n\\n\\n### excerpts:\\n\\n${contextForPrompt}\nInstructions:\n- Only list platforms that are clearly described or required in the text.\n- For each platform you list, provide a **short rationale** explaining what in the text led you to include it.\n- If no platforms are clearly required, say: \"No platform requirements explicitly stated.\"\n\nOnly identify platforms from the list below and use EXACTLY these enum values and text formats:\n- {\"enum\": \"WEB\", \"text\": \"Web application\"}\n- {\"enum\": \"MOBILE\", \"text\": \"Mobile app\"} (mention iOS/Android in rationale if stated)\n- {\"enum\": \"BACKEND_API\", \"text\": \"Backend/API services\"}\n- {\"enum\": \"ADMIN_PORTAL\", \"text\": \"Admin portal/dashboard\"}\n- {\"enum\": \"DESKTOP\", \"text\": \"Desktop application\"}\n- {\"enum\": \"IOT\", \"text\": \"IoT/Embedded system\"}\n- {\"enum\": \"KIOSK\", \"text\": \"Kiosk system\"}\n\n**Additional notes**:\n- If a web or mobile frontend is clearly described but no backend is mentioned, **assume a backend is needed** and include {\"enum\": \"BACKEND_API\", \"text\": \"Backend/API services\"} unless explicitly stated otherwise.\n- If the RFP includes user-facing features that typically require admin management (e.g., content moderation, approval workflows, user roles), you may infer that an **admin portal** is required even if not explicitly named - use {\"enum\": \"ADMIN_PORTAL\", \"text\": \"Admin portal/dashboard\"}.\n- Use Think tool to help you with reasoning.\n\nRemember: Base your answers strictly on the provided Context.  \nYou may make minimal inferences only when explicitly allowed in the instructions above (e.g., assuming a backend for a described frontend).  \nDo not invent platform requirements beyond that.\n\n**IMPORTANT: Format the rationale field using markdown markup for better readability:**\n- Use **bold text** for key points and important terms\n- Use ## headers for main sections\n- Use ### subheaders for subsections  \n- Use bullet points (- item) for lists\n- Use numbered lists (1. item) for sequential steps\n- Use \"code\" formatting for technical terms\n- Structure the rationale with clear sections and hierarchy\n`;\n\nreturn {\n  json: {\n    userPrompt,\n    systemPrompt: systemPrompt\n  }\n};"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -3504,
        3568
      ],
      "id": "e3248e62-543d-4a3f-94a7-b0aedfd377f5",
      "name": "PreparePrompts"
    },
    {
      "parameters": {
        "content": "## Inference PLATFORMS\nYou are reviewing excerpts \nfrom an RFP document \nto determine which technology \nplatforms are explicitly required.\n\nUse only the following categories:\n- Web applications\n- Mobile apps (mention iOS/Android if stated)\n- Backend/API services\n- Admin portals or dashboards\n- Desktop applications\n- Specialized systems (e.g., kiosks, IoT)\n\nFor each platform you identify, \nexplain briefly what in the text\n led you to that conclusion.\nOnly include platforms that are\n clearly required or described.\n\nIf nothing is clear, say \n“No platform requirements explicitly stated.”",
        "height": 860,
        "width": 2360
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        -4480,
        3152
      ],
      "id": "1384b7b8-54d4-4c77-9ac4-9029f50662f7",
      "name": "Sticky Note4"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "claude-sonnet-4-20250514",
          "mode": "list",
          "cachedResultName": "Claude Sonnet 4"
        },
        "options": {
          "temperature": 0.2,
          "thinking": false
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatAnthropic",
      "typeVersion": 1.3,
      "position": [
        -3552,
        3760
      ],
      "id": "2569617c-ecdc-482d-bc6b-377341a14c51",
      "name": "Claude 3.7",
      "credentials": {
        "anthropicApi": {
          "id": "qzCm5Ds2qD9ZY1W5",
          "name": "Anthropic account"
        }
      }
    },
    {
      "parameters": {
        "jsonSchemaExample": "{\n\t\"platforms\": [\n    {\n      \"enum\": \"ENUM_VALUE\",\n      \"text\": \"Platform text\"\n    }\n  ],\n  \"rationale\": \"Brief explanation for each platform identified\"\n}"
      },
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "typeVersion": 1.2,
      "position": [
        -3056,
        3760
      ],
      "id": "09ae1bbb-fa2e-42be-b8ef-ca786c68f323",
      "name": "Platforms + Rationale"
    },
    {
      "parameters": {
        "jsCode": "// n8n Function Node: Corrected Merge Split-Chunk Groups\n\nconst grouped = {};\n\n// 1. Group all items by the “true” chunk identifier\nfor (const item of $input.all()) {\n  const data = item.json;\n  // Use parent_chunk_id if it exists, else chunk_id\n  const parentId = data.metadata?.is_split_chunk\n    ? data.metadata.parent_chunk_id\n    : data.chunk_id;\n\n  if (!grouped[parentId]) grouped[parentId] = [];\n  grouped[parentId].push(data);\n}\n\nconst merged = [];\n\n// 2. For each group, produce exactly one merged record\nfor (const [parentId, parts] of Object.entries(grouped)) {\n  // Sort by the split_part if present (else leave order)\n  parts.sort((a, b) => \n    (a.metadata?.split_part ?? 0) - (b.metadata?.split_part ?? 0)\n  );\n\n  // Stitch text together\n  const text = parts.map(p => p.text).join(\"\\n\\n\");\n\n  // Merge platform_origins arrays from all parts (dedupe by platform)\n  const allOrigins = parts.flatMap(p => p.platform_origins || []);\n  const platform_origins = [];\n  for (const o of allOrigins) {\n    if (!platform_origins.some(existing => existing.platform === o.platform)) {\n      platform_origins.push(o);\n    }\n  }\n\n  // Pick the highest-scoring part to inherit section_title, filename, pages, and score\n  const bestPart = parts.reduce((best, p) => \n    p._score > best._score ? p : best\n  , parts[0]);\n\n  // Build the single merged record\n  const record = {\n    chunk_id: parentId,\n    _score: bestPart._score,\n    section_title: bestPart.section_title,\n    text,\n    metadata: {\n      ...bestPart.metadata,\n      is_split_chunk: false,\n      parent_chunk_id: undefined,\n      split_part: undefined,\n      total_parts: undefined\n    },\n    platform_origins\n  };\n\n  merged.push({ json: record });\n}\nmerged.sort((a, b) => b.json._score - a.json._score);\nreturn merged;\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -4064,
        3568
      ],
      "id": "f8d35d19-6fa8-4464-a40b-bbe3ba1649dc",
      "name": "Merge Chunks"
    },
    {
      "parameters": {
        "jsCode": "// n8n Function Node: Dedupe → Merge Origins → Filter → Sort → Fallback\n\nconst MIN_SCORE = 3.0;\nconst DESIRED_COUNT = 10;\n\n// Step 1: Deduplicate & merge platform origins, keep highest‐score record\nconst seen = {};\nfor (const item of $input.all()) {\n  const { chunk_id, platform, _score, ...rest } = item.json;\n  \n  if (!seen[chunk_id]) {\n    // First time seeing this chunk\n    seen[chunk_id] = {\n      chunk_id,\n      _score,\n      ...rest,\n      platform_origins: [{ platform, score: _score }],\n    };\n  } else {\n    // Merge new platform origin\n    const record = seen[chunk_id];\n    if (!record.platform_origins.some(p => p.platform === platform)) {\n      record.platform_origins.push({ platform, score: _score });\n    }\n    // If this hit has a higher score, overwrite core fields\n    if (_score > record._score) {\n      record._score = _score;\n      Object.assign(record, rest);\n    }\n  }\n}\n\n// Convert deduped map back to array of items\nlet deduped = Object.values(seen).map(r => ({ json: r }));\n\n// Step 2: Filter by score and sort descending\nlet filtered = deduped\n  .filter(item => item.json._score >= MIN_SCORE)\n  .sort((a, b) => b.json._score - a.json._score);\n\n// Step 3: Fallback if too few hits\nif (filtered.length < DESIRED_COUNT) {\n  // Return top DESIRED_COUNT from deduped (regardless of score)\n  filtered = deduped\n    .sort((a, b) => b.json._score - a.json._score)\n    .slice(0, DESIRED_COUNT);\n}\n\n// Step 4: Ensure we only return up to DESIRED_COUNT\nfiltered = filtered.slice(0, DESIRED_COUNT);\n\n// Return in n8n-compatible format\nreturn filtered;\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -3504,
        3360
      ],
      "id": "516518c3-b3c0-4f67-a246-293ca3f3497c",
      "name": "Deduplicate and Best Score"
    },
    {
      "parameters": {
        "jsCode": "// Configuration\nconst TOKEN_LIMIT = 5000;\nconst MIN_STRONG_SCORE = 7.0;\n\n// Rough token estimator (1 token ~ 4 characters)\nfunction estimateTokenCount(text) {\n  if (!text) return 0;\n  return Math.ceil(text.length / 4);\n}\n\n// Input already filtered and sorted!\nconst chunks = $input.all().map(item => item.json);\n\n// Build the final list\nconst selectedChunks = [];\nlet tokenCount = 0;\n\nfor (const chunk of chunks) {\n  const tokens = estimateTokenCount(chunk.text);\n\n  if ((tokenCount + tokens) <= TOKEN_LIMIT) {\n    selectedChunks.push(chunk);\n    tokenCount += tokens;\n  } else if (chunk._score >= MIN_STRONG_SCORE) {\n    // Allow overflow for very strong chunks\n    selectedChunks.push(chunk);\n    tokenCount += tokens;\n  } else {\n    break; // Stop adding\n  }\n}\n\n// Prepare output\nconst output = selectedChunks.map(chunk => ({ json: chunk }));\n\n// Add token usage metadata (attach to first item for simplicity)\nif (output.length > 0) {\n  output[0].json._token_summary = {\n    total_tokens_estimated: tokenCount,\n    total_chunks_selected: selectedChunks.length,\n  };\n}\n\nreturn output;\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -3888,
        3568
      ],
      "id": "e16331b1-7f96-4204-a185-75d737589e82",
      "name": "Token Budgeting"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "gpt-4.1-mini",
          "mode": "list",
          "cachedResultName": "gpt-4.1-mini"
        },
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        -3264,
        3760
      ],
      "id": "371d5378-e39a-4755-ab71-c2df8da462f2",
      "name": "OpenAI Chat Model1",
      "credentials": {
        "openAiApi": {
          "id": "M8xqWvEC6mH6LNuk",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "/**\n * Prepare ES chunks for Claude, without chunk‐length limiting.\n */\nfunction prepareSecurityRegulatoryContextForClaude(esResults) {\n  if (!Array.isArray(esResults)) {\n    throw new Error(\"Input must be an array of Elasticsearch results\");\n  }\n\n  // simple Markdown escaper\n  function mdEscape(str) {\n    return str.replace(/(`|\\*|_|~|>|\\[|\\])/g, \"\\\\$1\");\n  }\n\n  // normalize bullets and split into lines\n  function cleanText(raw) {\n    return raw\n      .replace(/^\\s*-\\s+/gm, \"\\n- \")\n      .replace(/^\\s*\\*\\s+/gm, \"\\n- \")\n      .replace(/[ \\t]+/g, \" \")\n      .replace(/\\. ([A-Z])/g, \".\\n$1\")\n      .replace(/\\n{3,}/g, \"\\n\\n\")\n      .trim();\n  }\n\n  const blocks = esResults.map(chunk => {\n    const { chunk_id, section_title, text = \"\", metadata = {}, _score, regScore, locScore } = chunk;\n\n    // Heading\n    const title = section_title\n      ? mdEscape(section_title)\n      : `Untitled Section (${chunk_id})`;\n\n    // Build YAML metadata\n    const pages = Array.isArray(metadata.page_numbers)\n      ? metadata.page_numbers.join(\", \")\n      : metadata.page_numbers || \"Unknown\";\n\n    const metaLines = [\n      `filename: ${metadata.filename || \"Unknown Document\"}`,\n      `pages: ${pages}`,\n      `score: ${_score.toFixed(2)}`,\n    ];\n    if (typeof regScore === \"number\") metaLines.push(`regScore: ${regScore.toFixed(2)}`);\n    if (typeof locScore === \"number\") metaLines.push(`locScore: ${locScore.toFixed(2)}`);\n    if (metadata.document_type) metaLines.push(`type: ${metadata.document_type}`);\n    if (metadata.languages) metaLines.push(`language: ${metadata.languages.join(\", \")}`);\n\n    const metaBlock = metaLines.join(\"\\n\");\n\n    // Clean and escape body\n    const body = mdEscape(cleanText(text));\n\n    return [\n      `### ${title}`,\n      \"```yaml\",\n      metaBlock,\n      \"```\",\n      \"\",\n      body\n    ].join(\"\\n\");\n  });\n\n  // Join with clear separators\n  return blocks.join(\"\\n\\n---\\n\\n\");\n}\n\n// Usage in n8n Function node:\nconst esResults = $input.all().map(i => i.json);\nconst contextForPrompt = prepareSecurityRegulatoryContextForClaude(esResults);\n\nreturn [{ json: { context: contextForPrompt } }];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -3680,
        3568
      ],
      "id": "b8e40c54-f6b3-4b4f-8edb-7397b76d013d",
      "name": "Prepare Context3"
    },
    {
      "parameters": {
        "jsCode": "return [\n{\n  json: {\n    query_type: \"feature_backlog\",\n    query:\n      \"Extract every user-facing feature, workflow, module, and use-case described in the RFP that will drive development effort.\",\n    /* Core verbs + backlog vocabulary (no compliance or legal terms) */\n    keywords: [\n      /* imperative verbs that usually start requirements */\n      \"shall\", \"must\", \"will\", \"should\", \"enable\", \"allow\", \"support\",\n\n      /* backlog & requirements terminology */\n      \"feature\", \"features\", \"functionality\", \"functional\", \"user story\",\n      \"user stories\", \"story\", \"stories\", \"epic\", \"use case\", \"use cases\",\n      \"acceptance criterion\", \"acceptance criteria\", \"requirement\",\n      \"requirements\", \"deliverable\", \"deliverables\",\n\n      /* common software capabilities */\n      \"dashboard\", \"report\", \"reporting\", \"search\", \"filter\", \"export\",\n      \"import\", \"authentication\", \"authorization\", \"login\", \"registration\",\n      \"profile\", \"notification\", \"messaging\", \"chat\", \"payment\", \"checkout\",\n      \"file upload\", \"download\", \"analytics\", \"admin panel\", \"cms\", \"api\",\n\n      /* workflow & domain phrases */\n      \"workflow\", \"process\", \"approval\", \"review\", \"comment\", \"feedback\",\n\n      /* MVP / release language */\n      \"MVP\", \"minimum viable product\", \"phase 1\", \"phase one\",\n      \"initial release\", \"pilot\", \"beta\"\n    ],\n\n    /* Phrase to give extra boost to clearly written requirements */\n    phrase: \"shall must will should feature user story use case\",\n\n    /* Tightest phrase for rescoring */\n    rescore_query: \"user story OR feature OR use case\",\n\n    description:\n      \"Surface all functional features and backlog items that drive development effort; ignore regulatory or contractual statements.\"\n  }\n}\n];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1728,
        3344
      ],
      "id": "06675de6-6b71-4abb-8e15-1cca4e0827ca",
      "name": "Queries2"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "http://192.168.20.70:11434/api/embed",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"model\": \"nomic-embed-text:latest\",\n  \"input\": [\"{{ $json.query }}\"]\n}",
        "options": {}
      },
      "id": "20d6dd73-49b8-490c-a171-72396d2751a7",
      "name": "Embed Query - ollama2",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -1504,
        3344
      ]
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "17f9e7d3-307e-4d60-92ef-e32285cbec29",
              "name": "_score",
              "value": "={{ $json._score }}",
              "type": "number"
            },
            {
              "id": "618f58cd-27c7-4ab4-8612-899f048afb6c",
              "name": "_id",
              "value": "={{ $json._id }}",
              "type": "string"
            },
            {
              "id": "a8cfb079-48c6-4ce2-a54c-251304107206",
              "name": "chunk_id",
              "value": "={{ $json._source.chunk_id }}",
              "type": "string"
            },
            {
              "id": "22e6e029-7ff1-4870-a1c2-d3b025a2748b",
              "name": "section_title",
              "value": "={{ $json._source.section_title }}",
              "type": "string"
            },
            {
              "id": "27e9a9ac-b6ed-4320-bb21-027f8659e7c5",
              "name": "text",
              "value": "={{ $json._source.text }}",
              "type": "string"
            },
            {
              "id": "6830a868-6492-405b-b8fb-1ae36ea184b2",
              "name": "metadata",
              "value": "={{ $json._source.metadata }}",
              "type": "object"
            },
            {
              "id": "e5dce93c-eb16-42be-8b42-47ca5cfacc52",
              "name": "platform",
              "value": "={{ $('Queries2').item.json.platform }}",
              "type": "string"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        -736,
        3344
      ],
      "id": "731cb2a3-ec3b-4038-9e0e-ee180bcdbae4",
      "name": "Map Response2"
    },
    {
      "parameters": {
        "jsCode": "// 2. Format the context\nconst contextForPrompt = $input.first().json.context;\nconst systemPrompt = \"You are a strict JSON extractor.The user will supply raw excerpts from a software RFP that describe project scope and backlog. Identify every distinct Functional Requirement (what the system must do). Do NOT invent, merge, or omit anything.Return **only** a valid JSON array—no headings, no markdown, no extra text.\";\n// 3. Define the user prompt\nconst userPrompt = `Below are excerpts from an RFP that describe the project scope, backlog items, and milestones.\n\n\\n\\n### excerpts:\\n\\n${contextForPrompt}\n\nYour task is to extract all meaningful features and expectations and assign them to one of the following categories:\n\n- Functional Requirement (FR): What the system must do.\n\nInstructions:\n- Do not skip, combine, or summarize any features.\n- Do not refer to “the document” or mention formatting.\n- Do not include commentary, labels, headings, or markdown blocks.\n- Sort results using section numbers, ascending.\n- Do not include documentation, \n`;\n\nreturn {\n  json: {\n    userPrompt,\n    systemPrompt: systemPrompt\n  }\n};\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -976,
        3568
      ],
      "id": "2a968bf1-677a-4332-84d9-795746b910c2",
      "name": "PreparePrompts4"
    },
    {
      "parameters": {
        "content": "## Inference Functional Requirements\n",
        "height": 860,
        "width": 1740,
        "color": 6
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        -1968,
        3152
      ],
      "id": "fc942bbd-d128-4340-b9ff-5c723e11ff6c",
      "name": "Sticky Note10"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "mode": "list",
          "value": "claude-3-7-sonnet-20250219",
          "cachedResultName": "Claude 3.7 Sonnet"
        },
        "options": {
          "thinking": true
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatAnthropic",
      "typeVersion": 1.3,
      "position": [
        -896,
        3760
      ],
      "id": "8a4fc14e-46d3-4e32-88bd-aabcc06bbf86",
      "name": "Claude 3.",
      "credentials": {
        "anthropicApi": {
          "id": "qzCm5Ds2qD9ZY1W5",
          "name": "Anthropic account"
        }
      }
    },
    {
      "parameters": {
        "operation": "getAll",
        "indexId": "={{ $('Start RFP Analysis').first().json.body.indexName }}",
        "limit": 30,
        "simple": false,
        "options": {
          "query": "={\n  \"size\": 30,\n  \"min_score\": 1.5,\n  \"_source\": [\n    \"chunk_id\",\"section_title\",\"text\",\n    \"metadata.filename\",\"metadata.page_numbers\",\n    \"metadata.parent_chunk_id\",\"metadata.is_split_chunk\",\n    \"metadata.split_part\",\"metadata.total_parts\"\n  ],\n  \"knn\": {\n    \"field\": \"embeddings\",\n    \"query_vector\":[ {{ $json.embeddings }} ],\n    \"k\": 60,\n    \"num_candidates\": 300\n  },\n  \"query\": {\n    \"bool\": {\n      \"should\": [\n        {\n          \"match_phrase\": {\n            \"text\": {\n              \"query\": \"shall must require\",\n              \"slop\":      2,\n              \"boost\":     2.0\n            }\n          }\n        },\n        {\n          \"multi_match\": {\n            \"query\": \"{{$('Queries2').item.json.keywords.join(' ') }}\",\n            \"fields\": [\"text^2\",\"section_title^3\"],\n            \"type\": \"most_fields\",\n            \"minimum_should_match\":   1,\n            \"boost\":                  1.2\n          }\n        },\n        {\n          \"terms_set\": {\n            \"text.keyword\": {\n              \"terms\": {{ JSON.stringify($('Queries2').item.json.keywords) }},\n              \"minimum_should_match_script\": {\n                \"source\": \"1\"\n              }\n            }\n          }\n        }\n      ],\n      \"minimum_should_match\": 1\n    }\n  },\n  \"rescore\": {\n    \"window_size\": 100,\n    \"query\": {\n      \"rescore_query\": {\n        \"match_phrase\": {\n          \"text\": {\n            \"query\": \"shall must require\",\n            \"slop\": 2\n          }\n        }\n      },\n      \"query_weight\":        0.5,\n      \"rescore_query_weight\":0.5\n    }\n  },\n  \"highlight\": {\n    \"type\": \"unified\",\n    \"fields\": { \"text\": {}, \"section_title\": {} }\n  }\n}\n"
        }
      },
      "type": "n8n-nodes-base.elasticsearch",
      "typeVersion": 1,
      "position": [
        -1088,
        3344
      ],
      "id": "12004dc8-f89c-4a03-90d0-d8d8e0b76ac0",
      "name": "Query - Full9",
      "alwaysOutputData": true,
      "credentials": {
        "elasticsearchApi": {
          "id": "wwaILZtoajWrVXwt",
          "name": "Elasticsearch account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// n8n Function Node: Corrected Merge Split-Chunk Groups\n\nconst grouped = {};\n\n// 1. Group all items by the “true” chunk identifier\nfor (const item of $input.all()) {\n  const data = item.json;\n  // Use parent_chunk_id if it exists, else chunk_id\n  const parentId = data.metadata?.is_split_chunk\n    ? data.metadata.parent_chunk_id\n    : data.chunk_id;\n\n  if (!grouped[parentId]) grouped[parentId] = [];\n  grouped[parentId].push(data);\n}\n\nconst merged = [];\n\n// 2. For each group, produce exactly one merged record\nfor (const [parentId, parts] of Object.entries(grouped)) {\n  // Sort by the split_part if present (else leave order)\n  parts.sort((a, b) => \n    (a.metadata?.split_part ?? 0) - (b.metadata?.split_part ?? 0)\n  );\n\n  // Stitch text together\n  const text = parts.map(p => p.text).join(\"\\n\\n\");\n\n  // Merge platform_origins arrays from all parts (dedupe by platform)\n  const allOrigins = parts.flatMap(p => p.platform_origins || []);\n  const platform_origins = [];\n  for (const o of allOrigins) {\n    if (!platform_origins.some(existing => existing.platform === o.platform)) {\n      platform_origins.push(o);\n    }\n  }\n\n  // Pick the highest-scoring part to inherit section_title, filename, pages, and score\n  const bestPart = parts.reduce((best, p) => \n    p._score > best._score ? p : best\n  , parts[0]);\n\n  // Build the single merged record\n  const record = {\n    chunk_id: parentId,\n    _score: bestPart._score,\n    section_title: bestPart.section_title,\n    text,\n    metadata: {\n      ...bestPart.metadata,\n      is_split_chunk: false,\n      parent_chunk_id: undefined,\n      split_part: undefined,\n      total_parts: undefined\n    },\n    platform_origins\n  };\n\n  merged.push({ json: record });\n}\nmerged.sort((a, b) => b.json._score - a.json._score);\nreturn merged;\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1536,
        3568
      ],
      "id": "ccb5f7ff-d6e4-4937-b66d-7679e53bc714",
      "name": "Merge Chunks5"
    },
    {
      "parameters": {
        "jsCode": "// n8n Function Node: Dedupe → Merge Origins → Filter → Sort → Fallback\n\nconst MIN_SCORE = 1.0;\nconst DESIRED_COUNT = 20;\n\n// Step 1: Deduplicate & merge platform origins, keep highest‐score record\nconst seen = {};\nfor (const item of $input.all()) {\n  const { chunk_id, platform, _score, ...rest } = item.json;\n  \n  if (!seen[chunk_id]) {\n    // First time seeing this chunk\n    seen[chunk_id] = {\n      chunk_id,\n      _score,\n      ...rest,\n      platform_origins: [{ platform, score: _score }],\n    };\n  } else {\n    // Merge new platform origin\n    const record = seen[chunk_id];\n    if (!record.platform_origins.some(p => p.platform === platform)) {\n      record.platform_origins.push({ platform, score: _score });\n    }\n    // If this hit has a higher score, overwrite core fields\n    if (_score > record._score) {\n      record._score = _score;\n      Object.assign(record, rest);\n    }\n  }\n}\n\n// Convert deduped map back to array of items\nlet deduped = Object.values(seen).map(r => ({ json: r }));\n\n// Step 2: Filter by score and sort descending\nlet filtered = deduped\n  .filter(item => item.json._score >= MIN_SCORE)\n  .sort((a, b) => b.json._score - a.json._score);\n\n// Step 3: Fallback if too few hits\nif (filtered.length < DESIRED_COUNT) {\n  // Return top DESIRED_COUNT from deduped (regardless of score)\n  filtered = deduped\n    .sort((a, b) => b.json._score - a.json._score)\n    .slice(0, DESIRED_COUNT);\n}\n\n// Step 4: Ensure we only return up to DESIRED_COUNT\nfiltered = filtered.slice(0, DESIRED_COUNT);\n\n// Return in n8n-compatible format\nreturn filtered;\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -560,
        3344
      ],
      "id": "ba2c13de-b362-471f-b3e0-9362d2e29b80",
      "name": "Deduplicate and Best Score6"
    },
    {
      "parameters": {
        "jsCode": "// Configuration\nconst TOKEN_LIMIT = 7000;\nconst MIN_STRONG_SCORE = 16.0;\n\n// Rough token estimator (1 token ~ 4 characters)\nfunction estimateTokenCount(text) {\n  if (!text) return 0;\n  return Math.ceil(text.length / 4);\n}\n\n// Input already filtered and sorted!\nconst chunks = $input.all().map(item => item.json);\n\n// Build the final list\nconst selectedChunks = [];\nlet tokenCount = 0;\n\nfor (const chunk of chunks) {\n  const tokens = estimateTokenCount(chunk.text);\n\n  if ((tokenCount + tokens) <= TOKEN_LIMIT) {\n    selectedChunks.push(chunk);\n    tokenCount += tokens;\n  } else if (chunk._score >= MIN_STRONG_SCORE) {\n    // Allow overflow for very strong chunks\n    selectedChunks.push(chunk);\n    tokenCount += tokens;\n  } else {\n    break; // Stop adding\n  }\n}\n\n// Prepare output\nconst output = selectedChunks.map(chunk => ({ json: chunk }));\n\n// Add token usage metadata (attach to first item for simplicity)\nif (output.length > 0) {\n  output[0].json._token_summary = {\n    total_tokens_estimated: tokenCount,\n    total_chunks_selected: selectedChunks.length,\n  };\n}\n\nreturn output;\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1360,
        3568
      ],
      "id": "4c410171-31a7-406f-86fd-34ccd06072a9",
      "name": "Token Budgeting2"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "gpt-4.1-mini",
          "mode": "list",
          "cachedResultName": "gpt-4.1-mini"
        },
        "options": {
          "temperature": 0.1
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        -768,
        3760
      ],
      "id": "df2b9b1c-02ed-4b0c-9543-49552c72500d",
      "name": "OpenAI Chat Model3",
      "credentials": {
        "openAiApi": {
          "id": "M8xqWvEC6mH6LNuk",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "/**\n * Prepare ES chunks for Claude, without chunk‐length limiting.\n */\nfunction prepareSecurityRegulatoryContextForClaude(esResults) {\n  if (!Array.isArray(esResults)) {\n    throw new Error(\"Input must be an array of Elasticsearch results\");\n  }\n\n  // simple Markdown escaper\n  function mdEscape(str) {\n    return str.replace(/(`|\\*|_|~|>|\\[|\\])/g, \"\\\\$1\");\n  }\n\n  // normalize bullets and split into lines\n  function cleanText(raw) {\n    return raw\n      .replace(/^\\s*-\\s+/gm, \"\\n- \")\n      .replace(/^\\s*\\*\\s+/gm, \"\\n- \")\n      .replace(/[ \\t]+/g, \" \")\n      .replace(/\\. ([A-Z])/g, \".\\n$1\")\n      .replace(/\\n{3,}/g, \"\\n\\n\")\n      .trim();\n  }\n\n  const blocks = esResults.map(chunk => {\n    const { chunk_id, section_title, text = \"\", metadata = {}, _score, regScore, locScore } = chunk;\n\n    // Heading\n    const title = section_title\n      ? mdEscape(section_title)\n      : `Untitled Section (${chunk_id})`;\n\n    // Build YAML metadata\n    const pages = Array.isArray(metadata.page_numbers)\n      ? metadata.page_numbers.join(\", \")\n      : metadata.page_numbers || \"Unknown\";\n\n    const metaLines = [\n      `filename: ${metadata.filename || \"Unknown Document\"}`,\n      `pages: ${pages}`,\n      `score: ${_score.toFixed(2)}`,\n    ];\n    if (typeof regScore === \"number\") metaLines.push(`regScore: ${regScore.toFixed(2)}`);\n    if (typeof locScore === \"number\") metaLines.push(`locScore: ${locScore.toFixed(2)}`);\n    if (metadata.document_type) metaLines.push(`type: ${metadata.document_type}`);\n    if (metadata.languages) metaLines.push(`language: ${metadata.languages.join(\", \")}`);\n\n    const metaBlock = metaLines.join(\"\\n\");\n\n    // Clean and escape body\n    const body = mdEscape(cleanText(text));\n\n    return [\n      `### ${title}`,\n      \"```yaml\",\n      metaBlock,\n      \"```\",\n      \"\",\n      body\n    ].join(\"\\n\");\n  });\n\n  // Join with clear separators\n  return blocks.join(\"\\n\\n---\\n\\n\");\n}\n\n// Usage in n8n Function node:\nconst esResults = $input.all().map(i => i.json);\nconst contextForPrompt = prepareSecurityRegulatoryContextForClaude(esResults);\n\nreturn [{ json: { context: contextForPrompt } }];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1168,
        3568
      ],
      "id": "a53409c6-2531-4fd5-8810-4a3aeb35240e",
      "name": "Prepare Context4"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ $json.userPrompt }}",
        "hasOutputParser": true,
        "options": {
          "systemMessage": "={{ $json.systemPrompt }}"
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.9,
      "position": [
        -736,
        3568
      ],
      "id": "034fc492-d90a-4301-949b-ef699e9827f6",
      "name": "Functional requirements",
      "onError": "continueErrorOutput"
    },
    {
      "parameters": {},
      "type": "@n8n/n8n-nodes-langchain.toolThink",
      "typeVersion": 1,
      "position": [
        -624,
        3760
      ],
      "id": "b12a418b-1f5c-4973-90cf-d77826e68163",
      "name": "Think"
    },
    {
      "parameters": {
        "jsCode": "/**\n * n8n Function node\n * Input  : first item from the previous “platform extraction” node\n *          {\n *            output: {\n *              platforms: [ ... ],\n *              rationale: \"...\"\n *            }\n *          }\n * Output : { detectedPlatformsSnippet: '### DETECTED_PLATFORMS …' }\n */\n\nconst { output } = $input.first().json;\n// --- Basic sanity check ----------------------------------------------------\nif (!output?.platforms || !Array.isArray(output.platforms)) {\n  throw new Error('Expected output.platforms array from previous step.');\n}\n\n// --- Build the snippet -----------------------------------------------------\nconst detectedPlatformsSnippet = [\n  '### DETECTED_PLATFORMS (authoritative, extracted in a prior step)',\n  JSON.stringify(\n    {\n      platforms: output.platforms,\n      rationale: output.rationale,\n    },\n    null,\n    2 // pretty-print indent\n  ),\n  '',\n  'You must treat the array in \"platforms\" as ground truth when selecting or defaulting technologies.',\n].join('\\n');\n\n// --- Return for the next node ---------------------------------------------\nreturn [\n  {\n    json: {\n      detectedPlatformsSnippet,\n    },\n  },\n];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -2784,
        3568
      ],
      "id": "da773514-75a1-4be6-a46a-3e2ada5b4b7a",
      "name": "Platforms Output"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "gpt-4.1",
          "mode": "list",
          "cachedResultName": "gpt-4.1"
        },
        "options": {
          "temperature": 0.1
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        -2000,
        4720
      ],
      "id": "d8f527eb-a8bf-4f24-a8e3-a94974641a61",
      "name": "GPT 4.1 Mini2",
      "credentials": {
        "openAiApi": {
          "id": "M8xqWvEC6mH6LNuk",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ $json.userPrompt }}",
        "hasOutputParser": true,
        "options": {
          "systemMessage": "={{ $json.systemPrompt }}"
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.9,
      "position": [
        -1680,
        4464
      ],
      "id": "be397ac5-60fa-4f5b-8c4b-d8cd220234e5",
      "name": "Team Composition",
      "onError": "continueErrorOutput"
    },
    {
      "parameters": {
        "jsCode": "/* n8n Function node\n   Builds the prompt for the “Team-Composition” LLM step.\n   ➜  Output JSON: { systemPrompt, userPrompt }\n*/\n\n// ---------------------------------------------------------------------------\n// 1. Collect fixed snippets prepared in earlier steps\n// ---------------------------------------------------------------------------\nconst {\n   detectedPlatformsSnippet,\n} = $('Dependencies1').first().json;\n\n// Optional extra RAG context (not mandatory)\nconst techstack = $('Techstack Output').first().json.detectedTechStackSnippet;\n\n// ---------------------------------------------------------------------------\n// 2. Static system prompt (sent once per LLM call)\n// ---------------------------------------------------------------------------\nconst systemPrompt =\n  'You are a senior delivery manager who produces concise team-composition plans ' +\n  'for software projects. Merge the fixed project constraints below with standard ' +\n  'Agile delivery practice. Output **only** a valid JSON object under the key \"team_plan\".';\n\n// ---------------------------------------------------------------------------\n// 3. Dynamic user prompt assembled from all snippets plus rules\n// ---------------------------------------------------------------------------\nconst userPrompt = `\nONLY output the JSON object—no other text.\n\n### CONTEXT_SNIPPETS\n\n${techstack}\n\n${detectedPlatformsSnippet}\n\n### TASK\nDefine the delivery roles needed to execute this project in line with the timeline and constraints.\nDo **not** estimate sprints, person-days, rates, or buffers—those will be calculated later.\nJust list each role, its seniority (e.g. Mid, Senior, Principal), and the average full-time-equivalent (FTE) allocation over the core delivery period.\n\n### DEFAULT & FALLBACK RULES\n\n-  Platform-driven roles:\n  • \"Web applications\" ⇒ Frontend Developer (React, Next.js)\n  • \"Mobile apps\" ⇒ Mobile Developer (Flutter by default; Swift/Kotlin if native)\n  • \"Admin portal\" ⇒ Frontend Developer with design system experience (Shadcn, Material UI)\n  • \"Backend/API services\" ⇒ Backend Developer (PHP Symfony, Node.js, or inferred)\n  • \"CMS\" or content-heavy site ⇒ CMS Developer or Content Specialist\n\nBy default add 1 Solution Arhitect at 30% -  depending on the complexity.\n\nBy default we have 1 project manager and 1 business analyst.\nIf the project is not too complex, use one Hybrid role (50% Project Manager and 50% Business Analyst) - Called: Product Manager.\n\n-  If compliance is \"Moderately Regulated\" or stricter:\n  • Add 1 QA Engineer minimum but in 30%\n  • Mention security-aware development practices in rationale\n  If compliance is \"Highly Regulated\":\n  add 1 QA at 50%\n\n-  If deployment seems classic (implicit or explicit):\n  • Add DevOps Engineer at 25% - if its complicated then add it at 50%\n\n-  If mobile apps required:\n  • Prefer Flutter unless RFP clearly prefers native (then Swift/Kotlin)\nIf Flutter, use 1 Flutter developer.\nIf iOS & Android, user 1 for each.\n\n-  If analytics, SEO, or tracking required:\n  • Include Analytics Specialist or Web Analyst at 30%\n\n-  If project includes “training”, “handover”, or “documentation”:\n  • Add Knowledge Transfer Lead or Documentation Specialist\n\n-  If delivery_model is “Full launch”:\n  • Treat it as a single delivery phase\n\n-  If MVP, phased delivery, or iterations mentioned:\n  • Scale team accordingly across delivery periods if needed\n\n-  If functional scope is large or complex (based on feature count or diversity):\n  • Increase number of developers or FTE allocation\n\n  -  If time line is tight:\n  • Increase number of developers or FTE allocation\n\n-  If 3rd party integrations like CRM, ERP, SSO, Stripe, etc. are required:\n  • Add some percentage to Solution Arhitect \n\n  If development aproach would be Heavily AI Generated code with Shadcn:\n  Don't add Designers. Add just one 100% NodeJS developer for development.\n  If Design is custom or if the project needs it, put 1 Designer at about 30%.\n\n  If the project needs AI, add 1 AI Engineer and, if data preparation is needed, add 1 Data Engineer.\n\n  If any requirement mentions login, authentication, payments, user roles, or GDPR, consider adding 10% to QA Engineer or Solution Architect FTE for security tasks.\n\n-  Rationale must:\n  • Start with **Extracted:**, **Inferred:**, or **Defaulted:**\n  • Be ≤ 200 words\n  • Mention platform/stack mapping to skills\n  • Justify any specialized roles added\n  **IMPORTANT: Format the rationale field using markdown markup for better readability:**\n- Use **bold text** for key points and important terms\n- Use ## headers for main sections\n- Use ### subheaders for subsections  \n- Use bullet points (- item) for lists\n- Use numbered lists (1. item) for sequential steps\n- Use \"code\" formatting for technical terms\n- Structure the rationale with clear sections and hierarchy\n\nONLY output the JSON object—no other text.\n`;\n\nreturn {\n  json: {\n    systemPrompt,\n    userPrompt,\n  },\n};\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1984,
        4464
      ],
      "id": "e7382f55-071a-4237-829e-2274e0da6fee",
      "name": "Code"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "claude-sonnet-4-20250514",
          "mode": "list",
          "cachedResultName": "Claude Sonnet 4"
        },
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatAnthropic",
      "typeVersion": 1.3,
      "position": [
        -1776,
        4752
      ],
      "id": "88ea8994-6753-430b-84a3-e51bd209b706",
      "name": "Anthropic Chat Model",
      "credentials": {
        "anthropicApi": {
          "id": "qzCm5Ds2qD9ZY1W5",
          "name": "Anthropic account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "/**\n * n8n Function node\n * Input (first item):\n * {\n *   \"output\": {\n *     \"features\": [\n *       { \"title\": \"...\", \"description\": \"...\", \"reference_section\": \"...\" },\n *       ...\n *     ]\n *   }\n * }\n *\n * Output:\n * { featureListSnippet: '### KEY_FEATURES …' }\n */\n\nconst feat = $input.first().json.output || {};\n\n// --- Basic validation ------------------------------------------------------\nif (!Array.isArray(feat.features) || feat.features.length === 0) {\n  throw new Error('Expected non-empty output.features array from previous step.');\n}\n\n// --- Build the snippet -----------------------------------------------------\nconst featureListSnippet = [\n  '### KEY_FEATURES (authoritative, extracted in a prior step)',\n  JSON.stringify(feat.features, null, 2), // pretty-printed JSON array\n  '',\n  'Treat this feature list as fixed functional scope for downstream sizing, sequencing, and cost estimation.',\n].join('\\n');\n\n// --- Return for downstream use --------------------------------------------\nreturn [\n  {\n    json: {\n      featureListSnippet,\n    },\n  },\n];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -128,
        3568
      ],
      "id": "209ada02-2e5c-4bf8-b370-5f4f712bdb88",
      "name": "Functional Requirements Output"
    },
    {
      "parameters": {
        "jsCode": "/**\n * n8n Function  ➜  “Build NFR query-pack”\n * Returns a single array item (same shape as your feature pack)\n */\nreturn [\n  {\n    json: {\n      query_type: \"non_functional_requirements\",\n      query:\n        \"Extract every non-functional requirement (performance, security, availability, scalability, accessibility, SEO, DevOps, monitoring, localization) described in the RFP that will influence architecture, DevOps, or QA effort.\",\n      /* NFR vocabulary */\n      keywords: [\n        /* performance & scale */\n        \"performance\", \"latency\", \"response time\", \"rps\", \"tps\",\n        \"load time\", \"web vitals\", \"core web vitals\", \"lighthouse\",\n        \"concurrency\", \"throughput\", \"scalability\", \"autoscale\",\n\n        /* availability & reliability */\n        \"uptime\", \"availability\", \"sla\", \"99.9%\", \"ha\", \"redundancy\",\n        \"failover\", \"disaster recovery\", \"rto\", \"rpo\",\n\n        /* security & privacy */\n        \"encryption\", \"tls\", \"ssl\", \"https\", \"owasp\", \"penetration test\",\n        \"vulnerability scan\", \"sso\", \"oauth\", \"saml\", \"jwt\", \"waf\",\n        \"access control\", \"role based access\", \"audit log\",\n\n        /* accessibility & seo */\n        \"wcag\", \"accessibility\", \"screen reader\", \"seo\", \"page speed\",\n        \"structured data\", \"sitemap.xml\",\n\n        /* DevOps & monitoring */\n        \"ci/cd\", \"pipeline\", \"deployment\", \"kubernetes\", \"docker\",\n        \"infrastructure as code\", \"terraform\", \"ansible\",\n        \"monitoring\", \"alerting\", \"logging\", \"grafana\", \"prometheus\",\n        \"observability\", \"sli\", \"slo\",\n\n        /* maintenance & support */\n        \"maintainability\", \"upgrade\", \"patching\", \"rollback\",\n        \"support window\", \"support hours\",\n\n          /* localisation & content scope */\n  \"localisation\", \"localization\", \"multilingual\", \"multi-language\",\n  \"translation\", \"i18n\", \"l10n\", \"languages\", \"locale\", \"page count\",\n  \"templates\", \"content migration\"\n      ],\n\n      /* Phrase boost for classic NFR language */\n      phrase: \"performance latency uptime availability security scalability localization\",\n\n      /* Rescore phrase for tight relevance */\n      rescore_query: \"performance OR uptime OR security OR scalability\",\n\n      description:\n        \"Surface all non-functional requirements that impact architecture, DevOps, security, performance, monitoring, or support.\"\n    }\n  }\n];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        448,
        3360
      ],
      "id": "38d22060-59a1-4f51-a563-c77f9e21226e",
      "name": "Queries8"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "http://192.168.20.70:11434/api/embed",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"model\": \"nomic-embed-text:latest\",\n  \"input\": [\"{{ $json.query }}\"]\n}",
        "options": {}
      },
      "id": "b73016b2-6155-42aa-92aa-e802c29800f6",
      "name": "Embed Query - ollama8",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        624,
        3360
      ]
    },
    {
      "parameters": {
        "jsCode": "// 1. Gather ES-RAG context\nconst contextForPrompt = $input.first().json.context;\n\n// 2. System prompt (static)\nconst systemPrompt = `\nYou are a strict JSON extractor. The user will supply raw excerpts from a software RFP.\nIdentify every distinct Non-Functional Requirement (how the system must perform or be operated).\nDo NOT invent, merge, or omit anything.\nDo NOT extract functional requirements.\nReturn **only** a valid JSON array—no headings, no markdown, no extra text.\n`;\n\n// 3. User prompt (dynamic)\nconst userPrompt = `\nBelow are RFP excerpts related to performance, security, scalability, uptime, DevOps, accessibility, or other non-functional expectations.\n\n### excerpts:\n\n${contextForPrompt}\n\nInstructions:\n- Extract each non-functional requirement (NFR) as its own object.\n- Make sure that there are no functional requirements\n- Categories to use: Performance, Availability, Security, Scalability, Accessibility, SEO, Localization/Languages, DevOps/Deployment, Monitoring/Logging, Maintainability, Compliance.\n- Do not summarise or combine items.\n- Provide a short \"rationale\" if the category is inferred.\n- Sort by section number ascending.\n- I Localization / Languages are nonexistent, choose English.\n- Return **only** the JSON\n— no extra text.\n`;\n\nreturn {\n  json: {\n    userPrompt,\n    systemPrompt\n  }\n};\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1008,
        3584
      ],
      "id": "30639f07-0295-4847-9254-72e64314e61e",
      "name": "PreparePrompts7"
    },
    {
      "parameters": {
        "content": "## Inference NonFunctional Requirements\n",
        "height": 860,
        "width": 1740,
        "color": 2
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        32,
        3168
      ],
      "id": "00580120-8462-4147-8012-6f291604714d",
      "name": "Sticky Note"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "mode": "list",
          "value": "claude-3-7-sonnet-20250219",
          "cachedResultName": "Claude 3.7 Sonnet"
        },
        "options": {
          "thinking": true
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatAnthropic",
      "typeVersion": 1.3,
      "position": [
        1088,
        3792
      ],
      "id": "b884df8a-eabd-4131-8ce0-50184ab22309",
      "name": "Claude 3.1",
      "credentials": {
        "anthropicApi": {
          "id": "qzCm5Ds2qD9ZY1W5",
          "name": "Anthropic account"
        }
      }
    },
    {
      "parameters": {
        "operation": "getAll",
        "indexId": "={{ $('Start RFP Analysis').first().json.body.indexName }}",
        "limit": 30,
        "simple": false,
        "options": {
          "query": "={\n  \"size\": 30,\n  \"min_score\": 1.5,\n  \"_source\": [\n    \"chunk_id\",\"section_title\",\"text\",\n    \"metadata.filename\",\"metadata.page_numbers\",\n    \"metadata.parent_chunk_id\",\"metadata.is_split_chunk\",\n    \"metadata.split_part\",\"metadata.total_parts\"\n  ],\n  \"knn\": {\n    \"field\": \"embeddings\",\n    \"query_vector\": [ {{ $json.embeddings }} ],\n    \"k\": 60,\n    \"num_candidates\": 300\n  },\n  \"query\": {\n    \"bool\": {\n      \"should\": [\n        {\n          \"match_phrase\": {\n            \"text\": {\n              \"query\": \"performance latency uptime availability\",\n              \"slop\": 3,\n              \"boost\": 2.0\n            }\n          }\n        },\n        {\n          \"multi_match\": {\n            \"query\": \"{{ $('Queries8').item.json.keywords.join(' ') }}\",\n            \"fields\": [\"text^2\",\"section_title^3\"],\n            \"type\": \"most_fields\",\n            \"minimum_should_match\": 1,\n            \"boost\": 1.2\n          }\n        },\n        {\n          \"terms_set\": {\n            \"text.keyword\": {\n              \"terms\": {{ JSON.stringify($('Queries8').item.json.keywords) }},\n              \"minimum_should_match_script\": { \"source\": \"1\" }\n            }\n          }\n        }\n      ],\n      \"minimum_should_match\": 1\n    }\n  },\n  \"rescore\": {\n    \"window_size\": 100,\n    \"query\": {\n      \"rescore_query\": {\n        \"match_phrase\": {\n          \"text\": {\n            \"query\": \"{{ $('Queries8').item.json.rescore_query }}\",\n            \"slop\": 2\n          }\n        }\n      },\n      \"query_weight\": 0.5,\n      \"rescore_query_weight\": 0.5\n    }\n  },\n  \"highlight\": {\n    \"type\": \"unified\",\n    \"fields\": { \"text\": {}, \"section_title\": {} }\n  }\n}\n"
        }
      },
      "type": "n8n-nodes-base.elasticsearch",
      "typeVersion": 1,
      "position": [
        992,
        3360
      ],
      "id": "bb546bb0-1cd6-44b0-8e39-9e28189aaddf",
      "name": "Query - Full11",
      "alwaysOutputData": true,
      "credentials": {
        "elasticsearchApi": {
          "id": "wwaILZtoajWrVXwt",
          "name": "Elasticsearch account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// n8n Function Node: Corrected Merge Split-Chunk Groups\n\nconst grouped = {};\n\n// 1. Group all items by the “true” chunk identifier\nfor (const item of $input.all()) {\n  const data = item.json;\n  // Use parent_chunk_id if it exists, else chunk_id\n  const parentId = data.metadata?.is_split_chunk\n    ? data.metadata.parent_chunk_id\n    : data.chunk_id;\n\n  if (!grouped[parentId]) grouped[parentId] = [];\n  grouped[parentId].push(data);\n}\n\nconst merged = [];\n\n// 2. For each group, produce exactly one merged record\nfor (const [parentId, parts] of Object.entries(grouped)) {\n  // Sort by the split_part if present (else leave order)\n  parts.sort((a, b) => \n    (a.metadata?.split_part ?? 0) - (b.metadata?.split_part ?? 0)\n  );\n\n  // Stitch text together\n  const text = parts.map(p => p.text).join(\"\\n\\n\");\n\n  // Merge platform_origins arrays from all parts (dedupe by platform)\n  const allOrigins = parts.flatMap(p => p.platform_origins || []);\n  const platform_origins = [];\n  for (const o of allOrigins) {\n    if (!platform_origins.some(existing => existing.platform === o.platform)) {\n      platform_origins.push(o);\n    }\n  }\n\n  // Pick the highest-scoring part to inherit section_title, filename, pages, and score\n  const bestPart = parts.reduce((best, p) => \n    p._score > best._score ? p : best\n  , parts[0]);\n\n  // Build the single merged record\n  const record = {\n    chunk_id: parentId,\n    _score: bestPart._score,\n    section_title: bestPart.section_title,\n    text,\n    metadata: {\n      ...bestPart.metadata,\n      is_split_chunk: false,\n      parent_chunk_id: undefined,\n      split_part: undefined,\n      total_parts: undefined\n    },\n    platform_origins\n  };\n\n  merged.push({ json: record });\n}\nmerged.sort((a, b) => b.json._score - a.json._score);\nreturn merged;\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        448,
        3584
      ],
      "id": "9c6a6da9-68d5-46d2-ad27-ec856f2c7a08",
      "name": "Merge Chunks8"
    },
    {
      "parameters": {
        "jsCode": "// n8n Function Node: Dedupe → Merge Origins → Filter → Sort → Fallback\n\nconst MIN_SCORE = 1.0;\nconst DESIRED_COUNT = 20;\n\n// Step 1: Deduplicate & merge platform origins, keep highest‐score record\nconst seen = {};\nfor (const item of $input.all()) {\n  const { chunk_id, platform, _score, ...rest } = item.json;\n  \n  if (!seen[chunk_id]) {\n    // First time seeing this chunk\n    seen[chunk_id] = {\n      chunk_id,\n      _score,\n      ...rest,\n      platform_origins: [{ platform, score: _score }],\n    };\n  } else {\n    // Merge new platform origin\n    const record = seen[chunk_id];\n    if (!record.platform_origins.some(p => p.platform === platform)) {\n      record.platform_origins.push({ platform, score: _score });\n    }\n    // If this hit has a higher score, overwrite core fields\n    if (_score > record._score) {\n      record._score = _score;\n      Object.assign(record, rest);\n    }\n  }\n}\n\n// Convert deduped map back to array of items\nlet deduped = Object.values(seen).map(r => ({ json: r }));\n\n// Step 2: Filter by score and sort descending\nlet filtered = deduped\n  .filter(item => item.json._score >= MIN_SCORE)\n  .sort((a, b) => b.json._score - a.json._score);\n\n// Step 3: Fallback if too few hits\nif (filtered.length < DESIRED_COUNT) {\n  // Return top DESIRED_COUNT from deduped (regardless of score)\n  filtered = deduped\n    .sort((a, b) => b.json._score - a.json._score)\n    .slice(0, DESIRED_COUNT);\n}\n\n// Step 4: Ensure we only return up to DESIRED_COUNT\nfiltered = filtered.slice(0, DESIRED_COUNT);\n\n// Return in n8n-compatible format\nreturn filtered;\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1392,
        3360
      ],
      "id": "231e75fb-9b85-4aa3-b2e5-d6f520eb1e2f",
      "name": "Deduplicate and Best Score8"
    },
    {
      "parameters": {
        "jsCode": "// Configuration\nconst TOKEN_LIMIT = 7000;\nconst MIN_STRONG_SCORE = 16.0;\n\n// Rough token estimator (1 token ~ 4 characters)\nfunction estimateTokenCount(text) {\n  if (!text) return 0;\n  return Math.ceil(text.length / 4);\n}\n\n// Input already filtered and sorted!\nconst chunks = $input.all().map(item => item.json);\n\n// Build the final list\nconst selectedChunks = [];\nlet tokenCount = 0;\n\nfor (const chunk of chunks) {\n  const tokens = estimateTokenCount(chunk.text);\n\n  if ((tokenCount + tokens) <= TOKEN_LIMIT) {\n    selectedChunks.push(chunk);\n    tokenCount += tokens;\n  } else if (chunk._score >= MIN_STRONG_SCORE) {\n    // Allow overflow for very strong chunks\n    selectedChunks.push(chunk);\n    tokenCount += tokens;\n  } else {\n    break; // Stop adding\n  }\n}\n\n// Prepare output\nconst output = selectedChunks.map(chunk => ({ json: chunk }));\n\n// Add token usage metadata (attach to first item for simplicity)\nif (output.length > 0) {\n  output[0].json._token_summary = {\n    total_tokens_estimated: tokenCount,\n    total_chunks_selected: selectedChunks.length,\n  };\n}\n\nreturn output;\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        624,
        3584
      ],
      "id": "ea7dfab5-8e71-4e06-a004-c1e73c5300e8",
      "name": "Token Budgeting7"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "gpt-5-mini",
          "mode": "list",
          "cachedResultName": "gpt-5-mini"
        },
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        896,
        3808
      ],
      "id": "cf5ab05c-fe73-4399-b83d-fd6b9317a293",
      "name": "OpenAI Chat Model",
      "credentials": {
        "openAiApi": {
          "id": "M8xqWvEC6mH6LNuk",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "/**\n * Prepare ES chunks for Claude, without chunk‐length limiting.\n */\nfunction prepareSecurityRegulatoryContextForClaude(esResults) {\n  if (!Array.isArray(esResults)) {\n    throw new Error(\"Input must be an array of Elasticsearch results\");\n  }\n\n  // simple Markdown escaper\n  function mdEscape(str) {\n    return str.replace(/(`|\\*|_|~|>|\\[|\\])/g, \"\\\\$1\");\n  }\n\n  // normalize bullets and split into lines\n  function cleanText(raw) {\n    return raw\n      .replace(/^\\s*-\\s+/gm, \"\\n- \")\n      .replace(/^\\s*\\*\\s+/gm, \"\\n- \")\n      .replace(/[ \\t]+/g, \" \")\n      .replace(/\\. ([A-Z])/g, \".\\n$1\")\n      .replace(/\\n{3,}/g, \"\\n\\n\")\n      .trim();\n  }\n\n  const blocks = esResults.map(chunk => {\n    const { chunk_id, section_title, text = \"\", metadata = {}, _score, regScore, locScore } = chunk;\n\n    // Heading\n    const title = section_title\n      ? mdEscape(section_title)\n      : `Untitled Section (${chunk_id})`;\n\n    // Build YAML metadata\n    const pages = Array.isArray(metadata.page_numbers)\n      ? metadata.page_numbers.join(\", \")\n      : metadata.page_numbers || \"Unknown\";\n\n    const metaLines = [\n      `filename: ${metadata.filename || \"Unknown Document\"}`,\n      `pages: ${pages}`,\n      `score: ${_score.toFixed(2)}`,\n    ];\n    if (typeof regScore === \"number\") metaLines.push(`regScore: ${regScore.toFixed(2)}`);\n    if (typeof locScore === \"number\") metaLines.push(`locScore: ${locScore.toFixed(2)}`);\n    if (metadata.document_type) metaLines.push(`type: ${metadata.document_type}`);\n    if (metadata.languages) metaLines.push(`language: ${metadata.languages.join(\", \")}`);\n\n    const metaBlock = metaLines.join(\"\\n\");\n\n    // Clean and escape body\n    const body = mdEscape(cleanText(text));\n\n    return [\n      `### ${title}`,\n      \"```yaml\",\n      metaBlock,\n      \"```\",\n      \"\",\n      body\n    ].join(\"\\n\");\n  });\n\n  // Join with clear separators\n  return blocks.join(\"\\n\\n---\\n\\n\");\n}\n\n// Usage in n8n Function node:\nconst esResults = $input.all().map(i => i.json);\nconst contextForPrompt = prepareSecurityRegulatoryContextForClaude(esResults);\n\nreturn [{ json: { context: contextForPrompt } }];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        832,
        3584
      ],
      "id": "c114679f-49af-443f-ae96-6fca5b6fd37a",
      "name": "Prepare Context6"
    },
    {
      "parameters": {},
      "type": "@n8n/n8n-nodes-langchain.toolThink",
      "typeVersion": 1,
      "position": [
        1360,
        3792
      ],
      "id": "a865e971-ba1e-482c-9046-4cd69984aea6",
      "name": "Think1"
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "17f9e7d3-307e-4d60-92ef-e32285cbec29",
              "name": "_score",
              "value": "={{ $json._score }}",
              "type": "number"
            },
            {
              "id": "618f58cd-27c7-4ab4-8612-899f048afb6c",
              "name": "_id",
              "value": "={{ $json._id }}",
              "type": "string"
            },
            {
              "id": "a8cfb079-48c6-4ce2-a54c-251304107206",
              "name": "chunk_id",
              "value": "={{ $json._source.chunk_id }}",
              "type": "string"
            },
            {
              "id": "22e6e029-7ff1-4870-a1c2-d3b025a2748b",
              "name": "section_title",
              "value": "={{ $json._source.section_title }}",
              "type": "string"
            },
            {
              "id": "27e9a9ac-b6ed-4320-bb21-027f8659e7c5",
              "name": "text",
              "value": "={{ $json._source.text }}",
              "type": "string"
            },
            {
              "id": "6830a868-6492-405b-b8fb-1ae36ea184b2",
              "name": "metadata",
              "value": "={{ $json._source.metadata }}",
              "type": "object"
            },
            {
              "id": "e5dce93c-eb16-42be-8b42-47ca5cfacc52",
              "name": "platform",
              "value": "={{ $('Queries8').item.json.platform }}",
              "type": "string"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        1200,
        3360
      ],
      "id": "b309cb89-0906-4761-aec3-c37f6b13e554",
      "name": "Map Response8"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ $json.userPrompt }}",
        "hasOutputParser": true,
        "options": {
          "systemMessage": "={{ $json.systemPrompt }}"
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.9,
      "position": [
        1248,
        3584
      ],
      "id": "f5932dae-f7a3-4815-8811-ccd99a2cce51",
      "name": "NonFunctional Requirements",
      "onError": "continueErrorOutput"
    },
    {
      "parameters": {
        "jsCode": "/**\n * n8n Function node ─ “Build NFR snippet”\n *\n * Input shape (first item):\n * [\n *   {\n *     output: [\n *       { title, description, category, rationale, reference_section },\n *       ...\n *     ]\n *   }\n * ]\n *\n * Output (for the next node):\n * { nonFunctionalRequirementsSnippet: '### NON_FUNCTIONAL_REQUIREMENTS …' }\n */\n\n// --- Grab first item -------------------------------------------------------\nconst nfrArray = $input.first().json.output || [];\n\n// --- Basic validation ------------------------------------------------------\nif (!Array.isArray(nfrArray) || nfrArray.length === 0) {\n  throw new Error('Expected non-empty output array of NFR objects from previous step.');\n}\n\n// --- Build the snippet -----------------------------------------------------\nconst nonFunctionalRequirementsSnippet = [\n  '### NON_FUNCTIONAL_REQUIREMENTS (authoritative, extracted in a prior step)',\n  JSON.stringify(nfrArray, null, 2),  // pretty-printed JSON array\n  '',\n  'Treat this NFR list as fixed scope impacting architecture, DevOps, performance, and QA in downstream estimation.',\n].join('\\n');\n\n// --- Return for downstream use --------------------------------------------\nreturn [\n  {\n    json: {\n      nonFunctionalRequirementsSnippet,\n    },\n  },\n];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1808,
        3584
      ],
      "id": "20d20cd3-a074-4cc2-ac25-90c8aa983fcb",
      "name": "NonFunctional Requirements Output"
    },
    {
      "parameters": {
        "jsCode": "return [\n  {\n    json: {\n      key: \"web_stack\",\n      query: \"What frontend or web frameworks are mentioned?\",\n      keywords: \"React, Angular, Vue, Svelte, Next.js, Nuxt.js, web framework, frontend, front-end, web app, web application, JavaScript, TypeScript, HTML, CSS\",\n      phrase: \"frontend web application\",\n      rescore_query: \"React OR Angular OR Vue OR Next.js\"\n    }\n  },\n  {\n    json: {\n      key: \"design\",\n      query: \"What design system or UI components are referenced?\",\n      keywords: \"Shadcn, Tailwind, Bootstrap, Material UI, design system, UI kit, style guide, branding, UX, Figma, wireframes, visual design, WCAG, Radix, Ant Design\",\n      phrase: \"design system UI kit\",\n      rescore_query: \"Shadcn OR Material UI OR Tailwind\"\n    }\n  },\n  {\n    json: {\n      key: \"mobile_stack\",\n      query: \"What mobile development technologies are mentioned?\",\n      keywords: \"Flutter, React Native, Swift, Kotlin, iOS, Android, mobile app, mobile development, native mobile, cupertino\",\n      phrase: \"mobile development mobile app\",\n      rescore_query: \"Flutter OR React Native OR Kotlin OR Swift\"\n    }\n  },\n  {\n    json: {\n      key: \"backend_stack\",\n      query: \"What backend technologies or server frameworks are used?\",\n      keywords: \"Node.js, Python, Django, Java, Spring, PHP, Laravel, Ruby, Rails, Express, .NET, API, backend server, server-side, Go, Rust, FastAPI, NestJS\",\n      phrase: \"backend server backend technology\",\n      rescore_query: \"Node.js OR Django OR Laravel OR Java OR Spring\"\n    }\n  },\n  {\n    json: {\n      key: \"ai_needed\",\n      query: \"Does the project involve AI, ML, or data processing?\",\n      keywords: \"AI, artificial intelligence, machine learning, ML, chatbot, NLP, LLM, model training, predictive analytics, smart assistant, automation, algorithm, TensorFlow, PyTorch, OpenAI, Azure AI\",\n      phrase: \"AI functionality ML features\",\n      rescore_query: \"AI OR ML OR LLM OR chatbot\"\n    }\n  },\n  {\n    json: {\n      key: \"database\",\n      query: \"What kind of database or data storage is required?\",\n      keywords: \"PostgreSQL, MySQL, MongoDB, Redis, database, data storage, data layer, NoSQL, SQL, relational database, DBMS, backend storage, SQL Server, Oracle, DynamoDB, Firebase\",\n      phrase: \"data storage database\",\n      rescore_query: \"PostgreSQL OR MongoDB OR database system\"\n    }\n  },\n  {\n    json: {\n      key: \"deployment\",\n      query: \"Where is the system hosted or deployed?\",\n      keywords: \"AWS, Azure, GCP, cloud hosting, on-premises, hybrid, deployment, infrastructure, Kubernetes, Docker, container, server, on-premise, self-hosted, serverless, Kubernetes\",\n      phrase: \"deployment infrastructure hosting\",\n      rescore_query: \"AWS OR Azure OR cloud hosting\"\n    }\n  },\n  {\n    json: {\n      key: \"integrations\",\n      query: \"What external systems, APIs, or services need to be integrated?\",\n      keywords: \"integration, OAuth, SAML, API, APIs, third-party service, external system, SSO, payment gateway, Stripe, REST API, GraphQL, CRM, ERP\",\n      phrase: \"integration third-party system\",\n      rescore_query: \"OAuth OR API OR SSO OR Stripe\"\n    }\n  }\n];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -4384,
        4432
      ],
      "id": "7e1a916c-fe9c-4479-9adf-37764978e14f",
      "name": "Queries7"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "http://192.168.20.70:11434/api/embed",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"model\": \"nomic-embed-text:latest\",\n  \"input\": [\"{{ $json.query }}\"]\n}",
        "options": {}
      },
      "id": "008570b8-1343-43a1-a4ba-f92362499e1b",
      "name": "Embed Query - ollama7",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -4208,
        4432
      ]
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "17f9e7d3-307e-4d60-92ef-e32285cbec29",
              "name": "_score",
              "value": "={{ $json._score }}",
              "type": "number"
            },
            {
              "id": "618f58cd-27c7-4ab4-8612-899f048afb6c",
              "name": "_id",
              "value": "={{ $json._id }}",
              "type": "string"
            },
            {
              "id": "a8cfb079-48c6-4ce2-a54c-251304107206",
              "name": "chunk_id",
              "value": "={{ $json._source.chunk_id }}",
              "type": "string"
            },
            {
              "id": "22e6e029-7ff1-4870-a1c2-d3b025a2748b",
              "name": "section_title",
              "value": "={{ $json._source.section_title }}",
              "type": "string"
            },
            {
              "id": "27e9a9ac-b6ed-4320-bb21-027f8659e7c5",
              "name": "text",
              "value": "={{ $json._source.text }}",
              "type": "string"
            },
            {
              "id": "6830a868-6492-405b-b8fb-1ae36ea184b2",
              "name": "metadata",
              "value": "={{ $json._source.metadata }}",
              "type": "object"
            },
            {
              "id": "e5dce93c-eb16-42be-8b42-47ca5cfacc52",
              "name": "platform",
              "value": "={{ $('Queries7').item.json.platform }}",
              "type": "string"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        -4496,
        4672
      ],
      "id": "c66ffa51-0dc6-41d1-8f67-ac93372b214a",
      "name": "Map Response3"
    },
    {
      "parameters": {
        "jsCode": "// ---------------------------------------------------------------------------\n// gather snippets\n// ---------------------------------------------------------------------------\nconst ctxChunks = $input.first().json.context || \"\";;\nconst platforms = $('Platforms Output').first().json.detectedPlatformsSnippet;\nconst requirements  = $('Combined Requirements Output').first().json.combinedRequirementsSnippet;\n\n// ---------------------------------------------------------------------------\n// system prompt\n// ---------------------------------------------------------------------------\nconst systemPrompt = `\nYou are a senior solution-architect.\nReturn ONLY a valid JSON object under the key \"tech_stack\".\nDo NOT output headings, markdown, or commentary.\n`;\n\n// ---------------------------------------------------------------------------\n// user prompt\n// ---------------------------------------------------------------------------\nconst userPrompt = `\nYou are analysing RFP excerpts to define the optimal technology stack.\n\n### CONTEXT\n${ctxChunks}\n\n${platforms}\n\n${requirements}\n\n### TASK\nSelect **one** primary technology (or an empty list) for each dimension and build the JSON object below.\nIMPORTANT: Only define platforms that are explicitly listed in the “platforms” excerpt.\nIf a platform is not included in the list, leave its corresponding value empty (e.g., if web is not listed in “platforms”, then set webstack: \"\"). Do not assume or invent platforms outside the provided list.\n\n1. **Selection priority**  \n   a. Use tech the RFP **explicitly** names.  \n   b. Else use tech the RFP **implicitly** requires (e.g., WordPress ⇒ PHP + MySQL).  \n   c. Else apply our **house defaults**:  \n      • web_stack = \"React\"  \n      • backend_stack = \"PHP Symfony\"  \n      • mobile_stack = \"Flutter\"  \n      • design = \"Shadcn\"  \n      • database = \"PostgreSQL\"  \n      • deployment = \"AWS\"\n\n2. **Heavily AI-generated shortcut**  \n   If BOTH conditions hold:  \n   • Design is not Custom or demanding.  \n   • Functional Requirements describe mainly CRUD tables & simple admin UI.\n   • Techstack is not explicitly defined in RFP.  \n   → Override rule 1 and set:  \n     • web_stack = \"Next.js\"  \n     • backend_stack = \"Supabase\"  \n     • database = \"Supabase\"  \n     • design = \"Shadcn\"  \n     • stack_model = \"fullstack\"  \n     • Begin rationale with **\"Heavily AI-generated:\"**.\n\n3. **Additional industry heuristics** (activate only if rule 1 or 2 hasn’t decided the dimension):\n\n   • *Marketing / Blog CMS*: React + Next.js front, Node JS back, Postgres, headless CMS (“Strapi”, “Sanity”, etc.), stack_model = separated.  \n   • *Finance / high-compliance with no tech named*: backend_stack = \"Java Spring Boot\" **or** \".NET\"; note compliance in rationale.  \n   • *Real-time / microservice wording*: add Node JS **or** Go plus Redis cache.  \n   • *EU data residency, cloud unnamed*: deployment = \"AWS (eu-central-1)\" **or** \"Azure (West Europe)\".  \n   • *Elastic traffic spikes*: append \"serverless\" or \"containerized (Docker/K8s)\".  \n   • *Native device features (camera, AR)*: mobile_stack = \"Swift\" **or** \"Kotlin\".  \n   • *WCAG / strict design*: design = \"Material UI\".  \n   • *Analytics / BI tooling*: add \"Snowflake\" **or** \"BigQuery\".  \n\n   **Domain-specific triggers**  \n   – *E-commerce / checkout*: ensure integrations include \"Stripe\"; backend maybe \"Node.js\" or \"PHP Laravel\"; add \"Cloudflare CDN\" to deployment.  \n   – *Government / FedRAMP*: deployment = \"AWS GovCloud\" or \"Azure Government\"; backend = \".NET\" or \"Java Spring Boot\".  \n   – *Heavy video streaming*: integrations include \"AWS MediaConvert\" or \"Cloudflare Stream\"; add \"Redis\" cache.  \n   – *Multi-language localisation*: add \"i18next\" or \"next-intl\" integration.  \n   – *Strict CI/CD named*: mention chosen CI tool in rationale; deployment includes Docker/K8s.  \n   – *Legacy .NET stack referenced*: backend_stack = \".NET Core\".  \n   – *Open-source mandate*: avoid commercial DBs; enforce PostgreSQL and Linux hosting.  \n   – *99.9 % SLA / observability*: integrations include \"Prometheus\", \"Grafana\".\n  \n\n4. **ai_needed**  \n   true if RFP **mentions OR implies** AI/ML, chatbot, predictive, NLP, recommendation, smart search, forecasting, etc.; else false.\n\n5. **integrations**  \n   List only systems explicitly mentioned or strongly implied (CRM, ERP, SSO, payment, etc.).  \n   – Always include \"REST APIs\" when CRM/ERP/SSO appears.  \n   – If SAML, OAuth, Okta, Keycloak appear, list them.\n\n6. **stack_model**  \n   \"fullstack\" if FE & BE share one runtime (React + Supabase, React + Node, etc.); otherwise \"separated\".\n\n7. **Output constraints**  \n   • Provide **exactly one** entry per tech list (except integrations, where you should only put one solution choise - for example, in Inregrations, If we can use Stripe or Paypal, choose one thats best, dont return both of them).  \n   • Remove duplicates.  \n   • Rationale ≤ 700 words and must start with **Extracted:**, **Inferred:**, or **Heavily AI-generated:** indicating the rule used.  \n   • Mention how DETECTED_PLATFORMS informed defaults when defaults are chosen.\n   • Extract the techstack only for platforms that you got in DETECTED_PLATFORMS, leave the others one empty\n   . If you can choose bitween React Native and Flutter, choose Flutter\n   IMPORTANT: Only define platforms that are explicitly listed in the “platforms” excerpt.\nIf a platform is not included in the list, leave its corresponding value empty (e.g., if web is not listed in “platforms”, then set webstack: \"\"). Do not assume or invent platforms outside the provided list.\n\n**IMPORTANT: Format the rationale field using markdown markup for better readability:**\n- Use **bold text** for key points and important terms\n- Use ## headers for main sections\n- Use ### subheaders for subsections  \n- Use bullet points (- item) for lists\n- Use numbered lists (1. item) for sequential steps\n- Use \"code\" formatting for technical terms\n- Structure the rationale with clear sections and hierarchy\n- Keep Rationale < 300 words\n`;\n\nreturn { json: { systemPrompt, userPrompt } };\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -3648,
        4672
      ],
      "id": "8bf3b663-b833-40f6-92c4-dac67eb4faba",
      "name": "PreparePrompts6"
    },
    {
      "parameters": {
        "content": "## Inference Techstack\n",
        "height": 860,
        "width": 1480,
        "color": 3
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        -4608,
        4224
      ],
      "id": "ba7c393a-d1cd-4d13-bbf8-c59cdc569d5c",
      "name": "Sticky Note11"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "claude-sonnet-4-20250514",
          "mode": "list",
          "cachedResultName": "Claude Sonnet 4"
        },
        "options": {
          "maxTokensToSample": 6096,
          "temperature": 0.3,
          "thinking": false
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatAnthropic",
      "typeVersion": 1.3,
      "position": [
        -3664,
        4864
      ],
      "id": "03f877ac-f4e3-415f-a3a1-a39d5b8cd0ad",
      "name": "Claude 3.8",
      "credentials": {
        "anthropicApi": {
          "id": "qzCm5Ds2qD9ZY1W5",
          "name": "Anthropic account"
        }
      }
    },
    {
      "parameters": {
        "jsonSchemaExample": "{\n  \"tech_stack\": {\n    \"stack_model\": \"fullstack\",\n    \"backend_stack\": [\"Node.js\", \"Java\", \"Python\"],\n    \"web_stack\": [\"React\", \"Vue\", \"Angular\"],\n    \"mobile_stack\": [\"Flutter\", \"Swift\", \"Kotlin\"],\n    \"design\": [\"Shadcn\", \"Material UI\", \"Custom\"],\n    \"ai_needed\": true,\n    \"database\": \"PostgreSQL\",\n    \"deployment\": \"cloud\",\n    \"integrations\": [\"OAuth\", \"SAML\", \"third-party APIs\"],\n    \"rationale\": \"Why this tech stack is appropriate for this project\"\n  }\n}"
      },
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "typeVersion": 1.2,
      "position": [
        -3296,
        4864
      ],
      "id": "8b178ccc-0254-4bc7-848b-657c81aa933c",
      "name": "Platforms + Rationale2"
    },
    {
      "parameters": {
        "operation": "getAll",
        "indexId": "={{ $('Start RFP Analysis').first().json.body.indexName }}",
        "limit": 10,
        "simple": false,
        "options": {
          "query": "={\n  \"size\": 10,\n  \"min_score\": 1.5,\n  \"_source\": [\n    \"chunk_id\",\"section_title\",\"text\",\n    \"metadata.filename\",\"metadata.page_numbers\",\n    \"metadata.parent_chunk_id\",\"metadata.is_split_chunk\",\n    \"metadata.split_part\",\"metadata.total_parts\",\n    \"vector_metadata.token_count\",\"vector_metadata.is_split\",\n    \"vector_metadata.chunk_index\"\n  ],\n  \"knn\": {\n    \"field\": \"embeddings\",\n    \"query_vector\": [ {{ $json.embeddings }} ],\n    \"k\": 20,\n    \"num_candidates\": 50\n  },\n  \"query\": {\n    \"bool\": {\n      \"should\": [\n        {\n          \"match_phrase\": {\n            \"text\": {\n              \"query\": \"{{ $('Queries7').item.json.phrase }}\",\n              \"slop\": 4,\n              \"boost\": 2.0\n            }\n          }\n        },\n        {\n          \"multi_match\": {\n            \"query\": \"{{ $('Queries7').item.json.keywords }}\",\n            \"fields\": [\"text^2\",\"section_title^3\"],\n            \"type\": \"most_fields\",\n            \"minimum_should_match\": 2,\n            \"boost\": 1.2\n          }\n        },\n        {\n          \"terms_set\": {\n            \"text.keyword\": {\n              \"terms\": {{ JSON.stringify($('Queries7').item.json.keywords.split(',').map(k => k.trim())) }},\n\n              \"minimum_should_match_script\": {\n                \"source\": \"Math.min(params.num_terms, 2)\"\n              }\n            }\n          }\n        }\n      ],\n      \"minimum_should_match\": 1\n    }\n  },\n  \"rescore\": {\n    \"window_size\": 20,\n    \"query\": {\n      \"rescore_query\": {\n        \"match_phrase\": {\n          \"text\": {\n            \"query\": \"{{ $('Queries7').item.json.rescore_query }}\",\n            \"slop\": 8\n          }\n        }\n      },\n      \"query_weight\": 0.7,\n      \"rescore_query_weight\": 0.3\n    }\n  },\n  \"highlight\": {\n    \"type\": \"unified\",\n    \"fields\": { \"text\": {}, \"section_title\": {} }\n  }\n}\n"
        }
      },
      "type": "n8n-nodes-base.elasticsearch",
      "typeVersion": 1,
      "position": [
        -3888,
        4432
      ],
      "id": "a618eb3c-508b-4696-a766-01fcdb70404a",
      "name": "Query - Full10",
      "alwaysOutputData": true,
      "credentials": {
        "elasticsearchApi": {
          "id": "wwaILZtoajWrVXwt",
          "name": "Elasticsearch account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// n8n Function Node: Corrected Merge Split-Chunk Groups\n\nconst grouped = {};\n\n// 1. Group all items by the “true” chunk identifier\nfor (const item of $input.all()) {\n  const data = item.json;\n  // Use parent_chunk_id if it exists, else chunk_id\n  const parentId = data.metadata?.is_split_chunk\n    ? data.metadata.parent_chunk_id\n    : data.chunk_id;\n\n  if (!grouped[parentId]) grouped[parentId] = [];\n  grouped[parentId].push(data);\n}\n\nconst merged = [];\n\n// 2. For each group, produce exactly one merged record\nfor (const [parentId, parts] of Object.entries(grouped)) {\n  // Sort by the split_part if present (else leave order)\n  parts.sort((a, b) => \n    (a.metadata?.split_part ?? 0) - (b.metadata?.split_part ?? 0)\n  );\n\n  // Stitch text together\n  const text = parts.map(p => p.text).join(\"\\n\\n\");\n\n  // Merge platform_origins arrays from all parts (dedupe by platform)\n  const allOrigins = parts.flatMap(p => p.platform_origins || []);\n  const platform_origins = [];\n  for (const o of allOrigins) {\n    if (!platform_origins.some(existing => existing.platform === o.platform)) {\n      platform_origins.push(o);\n    }\n  }\n\n  // Pick the highest-scoring part to inherit section_title, filename, pages, and score\n  const bestPart = parts.reduce((best, p) => \n    p._score > best._score ? p : best\n  , parts[0]);\n\n  // Build the single merged record\n  const record = {\n    chunk_id: parentId,\n    _score: bestPart._score,\n    section_title: bestPart.section_title,\n    text,\n    metadata: {\n      ...bestPart.metadata,\n      is_split_chunk: false,\n      parent_chunk_id: undefined,\n      split_part: undefined,\n      total_parts: undefined\n    },\n    platform_origins\n  };\n\n  merged.push({ json: record });\n}\nmerged.sort((a, b) => b.json._score - a.json._score);\nreturn merged;\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -4144,
        4672
      ],
      "id": "6e3b61f4-e78b-414b-807b-ad0b1feeeb43",
      "name": "Merge Chunks7"
    },
    {
      "parameters": {
        "jsCode": "// n8n Function Node: Dedupe → Merge Origins → Filter → Sort → Fallback\n\nconst MIN_SCORE = 3.0;\nconst DESIRED_COUNT = 10;\n\n// Step 1: Deduplicate & merge platform origins, keep highest‐score record\nconst seen = {};\nfor (const item of $input.all()) {\n  const { chunk_id, platform, _score, ...rest } = item.json;\n  \n  if (!seen[chunk_id]) {\n    // First time seeing this chunk\n    seen[chunk_id] = {\n      chunk_id,\n      _score,\n      ...rest,\n      platform_origins: [{ platform, score: _score }],\n    };\n  } else {\n    // Merge new platform origin\n    const record = seen[chunk_id];\n    if (!record.platform_origins.some(p => p.platform === platform)) {\n      record.platform_origins.push({ platform, score: _score });\n    }\n    // If this hit has a higher score, overwrite core fields\n    if (_score > record._score) {\n      record._score = _score;\n      Object.assign(record, rest);\n    }\n  }\n}\n\n// Convert deduped map back to array of items\nlet deduped = Object.values(seen).map(r => ({ json: r }));\n\n// Step 2: Filter by score and sort descending\nlet filtered = deduped\n  .filter(item => item.json._score >= MIN_SCORE)\n  .sort((a, b) => b.json._score - a.json._score);\n\n// Step 3: Fallback if too few hits\nif (filtered.length < DESIRED_COUNT) {\n  // Return top DESIRED_COUNT from deduped (regardless of score)\n  filtered = deduped\n    .sort((a, b) => b.json._score - a.json._score)\n    .slice(0, DESIRED_COUNT);\n}\n\n// Step 4: Ensure we only return up to DESIRED_COUNT\nfiltered = filtered.slice(0, DESIRED_COUNT);\n\n// Return in n8n-compatible format\nreturn filtered;\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -4320,
        4672
      ],
      "id": "6397f688-6a0c-4517-97a5-f284b851d302",
      "name": "Deduplicate and Best Score7"
    },
    {
      "parameters": {
        "jsCode": "// Configuration\nconst TOKEN_LIMIT = 5000;\nconst MIN_STRONG_SCORE = 7.0;\n\n// Rough token estimator (1 token ~ 4 characters)\nfunction estimateTokenCount(text) {\n  if (!text) return 0;\n  return Math.ceil(text.length / 4);\n}\n\n// Input already filtered and sorted!\nconst chunks = $input.all().map(item => item.json);\n\n// Build the final list\nconst selectedChunks = [];\nlet tokenCount = 0;\n\nfor (const chunk of chunks) {\n  const tokens = estimateTokenCount(chunk.text);\n\n  if ((tokenCount + tokens) <= TOKEN_LIMIT) {\n    selectedChunks.push(chunk);\n    tokenCount += tokens;\n  } else if (chunk._score >= MIN_STRONG_SCORE) {\n    // Allow overflow for very strong chunks\n    selectedChunks.push(chunk);\n    tokenCount += tokens;\n  } else {\n    break; // Stop adding\n  }\n}\n\n// Prepare output\nconst output = selectedChunks.map(chunk => ({ json: chunk }));\n\n// Add token usage metadata (attach to first item for simplicity)\nif (output.length > 0) {\n  output[0].json._token_summary = {\n    total_tokens_estimated: tokenCount,\n    total_chunks_selected: selectedChunks.length,\n  };\n}\n\nreturn output;\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -3984,
        4672
      ],
      "id": "549f709e-37ed-4b2f-8014-0f9ccb0b8cee",
      "name": "Token Budgeting5"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "gpt-4.1",
          "mode": "list",
          "cachedResultName": "gpt-4.1"
        },
        "options": {
          "temperature": 0.4
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        -3504,
        4944
      ],
      "id": "b70f34fe-235b-485f-b818-eea362868105",
      "name": "OpenAI Chat Model5",
      "credentials": {
        "openAiApi": {
          "id": "M8xqWvEC6mH6LNuk",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "/**\n * Prepare ES chunks for Claude, without chunk‐length limiting.\n */\nfunction prepareSecurityRegulatoryContextForClaude(esResults) {\n  if (!Array.isArray(esResults)) {\n    throw new Error(\"Input must be an array of Elasticsearch results\");\n  }\n\n  // simple Markdown escaper\n  function mdEscape(str) {\n    return str.replace(/(`|\\*|_|~|>|\\[|\\])/g, \"\\\\$1\");\n  }\n\n  // normalize bullets and split into lines\n  function cleanText(raw) {\n    return raw\n      .replace(/^\\s*-\\s+/gm, \"\\n- \")\n      .replace(/^\\s*\\*\\s+/gm, \"\\n- \")\n      .replace(/[ \\t]+/g, \" \")\n      .replace(/\\. ([A-Z])/g, \".\\n$1\")\n      .replace(/\\n{3,}/g, \"\\n\\n\")\n      .trim();\n  }\n\n  const blocks = esResults.map(chunk => {\n    const { chunk_id, section_title, text = \"\", metadata = {}, _score, regScore, locScore } = chunk;\n\n    // Heading\n    const title = section_title\n      ? mdEscape(section_title)\n      : `Untitled Section (${chunk_id})`;\n\n    // Build YAML metadata\n    const pages = Array.isArray(metadata.page_numbers)\n      ? metadata.page_numbers.join(\", \")\n      : metadata.page_numbers || \"Unknown\";\n\n    const metaLines = [\n      `filename: ${metadata.filename || \"Unknown Document\"}`,\n      `pages: ${pages}`,\n      `score: ${_score.toFixed(2)}`,\n    ];\n    if (typeof regScore === \"number\") metaLines.push(`regScore: ${regScore.toFixed(2)}`);\n    if (typeof locScore === \"number\") metaLines.push(`locScore: ${locScore.toFixed(2)}`);\n    if (metadata.document_type) metaLines.push(`type: ${metadata.document_type}`);\n    if (metadata.languages) metaLines.push(`language: ${metadata.languages.join(\", \")}`);\n\n    const metaBlock = metaLines.join(\"\\n\");\n\n    // Clean and escape body\n    const body = mdEscape(cleanText(text));\n\n    return [\n      `### ${title}`,\n      \"```yaml\",\n      metaBlock,\n      \"```\",\n      \"\",\n      body\n    ].join(\"\\n\");\n  });\n\n  // Join with clear separators\n  return blocks.join(\"\\n\\n---\\n\\n\");\n}\n\n// Usage in n8n Function node:\nconst esResults = $input.all().map(i => i.json);\nconst contextForPrompt = prepareSecurityRegulatoryContextForClaude(esResults);\n\nreturn [{ json: { context: contextForPrompt } }];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -3824,
        4672
      ],
      "id": "4f2fbc5d-1c49-4264-9901-aad1b586345d",
      "name": "Prepare Context5"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ $json.userPrompt }}",
        "hasOutputParser": true,
        "options": {
          "systemMessage": "={{ $json.systemPrompt }}"
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.9,
      "position": [
        -3504,
        4672
      ],
      "id": "db95799a-cb89-4c8c-8f40-2afc55c9ecfe",
      "name": "Get Techstack",
      "onError": "continueErrorOutput"
    },
    {
      "parameters": {
        "jsCode": "/**\n * n8n Function node\n * Input  : first item from the previous “tech-stack agent” node\n *          {\n *            output: {\n *              tech_stack: { ... }\n *            }\n *          }\n * Output : { detectedTechStackSnippet: '### DETECTED_TECH_STACK …' }\n */\n\nconst { tech_stack } = $input.first().json.output || {};\n\n// --- Sanity check ----------------------------------------------------------\nif (!tech_stack || typeof tech_stack !== 'object') {\n  throw new Error('Expected output.tech_stack object from previous step.');\n}\n\n// --- Build the snippet -----------------------------------------------------\nconst detectedTechStackSnippet = [\n  '### DETECTED_TECH_STACK (authoritative, extracted in a prior step)',\n  JSON.stringify(tech_stack, null, 2),  // pretty-printed JSON\n  '',\n  'Treat this \"tech_stack\" as the baseline when refining or merging technology recommendations in the next step.',\n].join('\\n');\n\n// --- Return for the next node ---------------------------------------------\nreturn [\n  {\n    json: {\n      detectedTechStackSnippet,\n    },\n  },\n];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -3056,
        4672
      ],
      "id": "0df6b44a-a509-4000-863b-515689861634",
      "name": "Techstack Output"
    },
    {
      "parameters": {
        "jsonSchemaExample": "{\n  \"features\": \n\t\t[\n  {\n    \"title\": \"Title\",\n    \"description\": \"Clear and specific requirement\",\n    \"reference_section\":\"\"\n  }\n]\n}"
      },
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "typeVersion": 1.2,
      "position": [
        -464,
        3760
      ],
      "id": "a54d9855-8a52-45d0-af3d-8f2682dafb1c",
      "name": "Title + Desc + Section"
    },
    {
      "parameters": {
        "jsonSchemaExample": "{\n  \"features\": \n\t\t[\n  {\n    \"title\": \"Title\",\n    \"description\": \"Clear and specific requirement\"\n  }\n]\n}"
      },
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "typeVersion": 1.2,
      "position": [
        -320,
        3760
      ],
      "id": "d4bbe503-3bf7-45d1-b815-d95c06cd603c",
      "name": "Description"
    },
    {
      "parameters": {
        "jsonSchemaExample": "[\n  {\n    \"title\": \"Brief requirement title\",\n    \"description\": \"Exact or paraphrased requirement statement\",\n    \"category\": \"Performance | Availability | Security | ...\",\n    \"rationale\": \"Why this is an NFR and chosen category\",\n    \"reference_section\": \"2.3\"\n  }\n]"
      },
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "typeVersion": 1.2,
      "position": [
        1504,
        3792
      ],
      "id": "596dc45d-1072-4acd-bd4e-ef8376016567",
      "name": "Full"
    },
    {
      "parameters": {
        "jsonSchemaExample": "[\n  {\n    \"title\": \"Title\",\n    \"description\": \"Exact or paraphrased requirement statement\",\n    \"category\": \"Performance | Availability | Security | ...\"\n  }\n]"
      },
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "typeVersion": 1.2,
      "position": [
        1600,
        3792
      ],
      "id": "0658783b-e07d-4baa-8d6c-861912e70fc5",
      "name": "Description + Category"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "gpt-5-mini",
          "mode": "list",
          "cachedResultName": "gpt-5-mini"
        },
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        2064,
        3744
      ],
      "id": "d9e8e862-7fd2-46d2-a441-acf2940554bd",
      "name": "OpenAI Chat Model6",
      "credentials": {
        "openAiApi": {
          "id": "M8xqWvEC6mH6LNuk",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=You are analyzing two sets of extracted software project requirements from an RFP.\n\n{{ $('Functional Requirements Output').first().json.featureListSnippet }}\n\n{{ $json.nonFunctionalRequirementsSnippet }}\n\nInstructions:\n- Preserve the Functional Requirements exactly as they are.\n- From the Non-Functional list, remove any item that overlaps in meaning with the Functional list.\n- Deduplicate by meaning, not exact wording.\n- Reclassify each item as either:\n  - \"Functional\"\n  - \"Non-Functional\"\n\nDo not include commentary, markdown, or headings — return only the raw JSON.\n",
        "hasOutputParser": true,
        "options": {
          "systemMessage": "=You are a precise and structured assistant that consolidates software project requirements.\n\nYou will receive two sets of input:\n- Functional Requirements: what the system must do (e.g., user features, system behaviors)\n- Non-Functional Requirements: how the system must behave (e.g., performance, security, usability)\n\nYour task is to:\n- Preserve all Functional Requirements exactly as given.\n- From the Non-Functional Requirements, exclude anything that overlaps with the Functional list (based on intent).\n- Classify each requirement under \"Functional\" or \"Non-Functional\".\n- Ensure phrasing is specific, unambiguous, and clean.\n- Return a single valid JSON object with this structure:\n\nEach item must include:\ntitle: Short summary\ndescription: Specific requirement\n\nDo not omit meaningful content. Do not return explanations."
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.9,
      "position": [
        2128,
        3552
      ],
      "id": "d252e03f-6a2f-47d1-84cc-a4276911c6d1",
      "name": "Combine Requirements",
      "onError": "continueErrorOutput"
    },
    {
      "parameters": {
        "jsonSchemaExample": "[\n  {\n    \"functional\": [\n      {\n        \"title\": \"Short title\",\n        \"description\": \"Detailed and unambiguous requirement\"\n      }\n    ],\n    \"non_functional\": [\n      {\n        \"title\": \"Security Captcha on Admin Login\",\n        \"description\": \"Login to admin panel must include CAPTCHA and CSRF protection.\"\n      }\n    ]\n  }\n]\n"
      },
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "typeVersion": 1.2,
      "position": [
        2288,
        3760
      ],
      "id": "7945b96a-7a1e-4d2b-8d38-b440ba32bb26",
      "name": "Structured Output Parser"
    },
    {
      "parameters": {
        "jsCode": "/**\n * n8n Function Node — \"Build Combined Requirements Snippet\"\n *\n * Input shape:\n * [\n *   {\n *     output: [\n *       {\n *         functional: [ { title, description }, ... ],\n *         non_functional: [ { title, description }, ... ]\n *       }\n *     ]\n *   }\n * ]\n *\n * Output shape:\n * {\n *   combinedRequirementsSnippet: '### COMBINED_REQUIREMENTS …'\n * }\n */\n\n// --- Grab input safely -----------------------------------------------------\nconst input = $input.first().json.output?.[0] || {};\nconst functional = input.functional || [];\nconst nonFunctional = input.non_functional || [];\n\n// --- Basic validation ------------------------------------------------------\nif (!Array.isArray(functional) || !Array.isArray(nonFunctional)) {\n  throw new Error('Expected arrays for functional and non_functional requirements.');\n}\n\n// --- Build the snippet -----------------------------------------------------\nconst combinedRequirementsSnippet = [\n  '### FUNCTIONAL AND NON-FUNCTIONAL REQUIREMENTS (authoritative, merged functional and non-functional set)',\n  JSON.stringify({ functional, non_functional: nonFunctional }, null, 2),\n  '',\n  'Treat this merged list as the unified scope for all downstream steps including tech stack reasoning, risk estimation, and delivery planning.'\n].join('\\n');\n\n// --- Return for downstream use --------------------------------------------\nreturn [\n  {\n    json: {\n      combinedRequirementsSnippet\n    }\n  }\n];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        2528,
        3552
      ],
      "id": "c232c8b7-74a4-40ba-8daa-b54775e3e795",
      "name": "Combined Requirements Output"
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "2eb926dc-6f8b-4145-a627-2a699038399a",
              "name": "detectedPlatformsSnippet",
              "value": "={{ $('Platforms Output').first().json.detectedPlatformsSnippet }}",
              "type": "string"
            },
            {
              "id": "224cb69c-4a9f-4228-a215-25531d77b261",
              "name": "combinedRequirementsSnippet",
              "value": "={{ $json.combinedRequirementsSnippet }}",
              "type": "string"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        2752,
        3552
      ],
      "id": "acd6fe77-f3b4-4c3d-a200-264e71cd81b2",
      "name": "Dependencies1"
    },
    {
      "parameters": {
        "content": "## Combined Requirements\n",
        "height": 900,
        "width": 900
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        1968,
        3120
      ],
      "id": "9d54805f-fb55-413a-8a44-f90cd0ba5c95",
      "name": "Sticky Note1"
    },
    {
      "parameters": {
        "jsonSchemaExample": "{\n  \"team_plan\": {\n    \"roles\": [\n      { \"role\": \"Product Owner\", \"fte\": 1.0, \"rationale\": \"≤ 200 words explaining the decisions.\" },\n      { \"role\": \"Scrum Master\", \"fte\": 0.5, \"rationale\": \"≤ 200 words explaining the decisions.\" }\n    ],\n    \"rationale\": \"≤ 500 words explaining the decisions.\"\n  }\n}"
      },
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "typeVersion": 1.2,
      "position": [
        -1456,
        4784
      ],
      "id": "05ff0064-576b-4153-bc21-fd6a61a9c60d",
      "name": "Team Composition1"
    },
    {
      "parameters": {
        "content": "## Team Compositon\n",
        "height": 860,
        "width": 1140,
        "color": 4
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        -2288,
        4224
      ],
      "id": "2a66e44c-017e-4503-b826-1672f6be41a4",
      "name": "Sticky Note3"
    },
    {
      "parameters": {
        "jsCode": "/**\n * n8n Function node\n * Input  : first item from the previous “Team-Composition” LLM step\n * Output : { teamCompositionSnippet: '### TEAM_COMPOSITION …' }\n */\n\nconst team_plan = $input.first().json.output?.team_plan;\n\nif (!team_plan || typeof team_plan !== 'object') {\n  throw new Error('Expected output.team_plan object from previous step.');\n}\n\nconst teamCompositionSnippet = [\n  '### TEAM_COMPOSITION (authoritative, extracted in a prior step)',\n  JSON.stringify(team_plan, null, 2),\n  '',\n  'Treat this team structure as a baseline for effort, duration, and cost calculations downstream.'\n].join('\\n');\n\nreturn [\n  {\n    json: {\n      teamCompositionSnippet,\n    },\n  },\n];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1056,
        4464
      ],
      "id": "15cdddc5-75cf-48dc-abdd-1f297efc297b",
      "name": "Team Composition Output"
    },
    {
      "parameters": {
        "jsonSchemaExample": "{\n\t\"min_sprints\": 0,\n\t\"max_sprints\": 0,\n    \"rationale\":\"\"\n}"
      },
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "typeVersion": 1.2,
      "position": [
        640,
        4512
      ],
      "id": "d0fef5a3-5194-4c54-a27d-d3d80ba153f9",
      "name": "Greenfield + Rationale"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "gpt-5",
          "mode": "list",
          "cachedResultName": "gpt-5"
        },
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        448,
        4528
      ],
      "id": "c40cbe69-0691-4854-a4eb-62e5e184b824",
      "name": "GPT 4.1 Mini4",
      "credentials": {
        "openAiApi": {
          "id": "M8xqWvEC6mH6LNuk",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "const snippets = [\n  $('Dependencies1').first().json.combinedRequirementsSnippet,\n].join('\\n\\n');\n\nconst techstack = $('Techstack Output').first().json.detectedTechStackSnippet;\nconst team = $('Team Composition Output').first().json.teamCompositionSnippet;\n\n\nconst systemPrompt = `\nYou are a senior delivery strategist estimating agile effort for software projects.\nYour goal is to output a realistic 2-week sprint range (min to max) based on high-level scope and delivery context.\nAlways assume:\n• Optimal AI-assisted development using modern tooling (AI pair programming, codegen, automated testing)\n• A capable cross-functional team with each developer delivering 15 story points per sprint\n• High delivery velocity without unnecessary padding\nYour output must be a valid JSON object under the key \"sprint_estimate\". Do not include any other text or formatting.\n`;\n\nconst userPrompt = `\nBelow are structured excerpts that describe the project context:\n\n${snippets}\n${team}\n${techstack}\n\nTASK:\n1. Estimate the number of 2-week sprints needed to implement the full scope (MVP).\n2. Return:\n   - \"min_sprints\": lower-bound estimate\n   - \"max_sprints\": upper-bound estimate\n   - \"rationale\": a short explanation (< 700 characters)\n\nESTIMATION RULES:\n• Narrow the sprint range if the scope is well-defined and straightforward.\n• Consider the number of developers, assuming they can work in parallel on the same tech stack or domain area.\n• Use a broader range when there are significant risks (e.g. vague NFRs, unclear integrations, or regulatory complexity).\n• Exclude wide buffers, discovery work, and post-launch support.\n• Only estimate the implementation phase (from kick-off to MVP launch).\n• Do NOT break down or estimate features individually.\n• Output must be in JSON only—no markdown, bullet points, or additional text.\n• The \"rationale\" field must clearly explain how scope, risk, and delivery dynamics affect the sprint estimate.\n\nPROJECT DURATION PRINCIPLE:\nAssume that developers and supporting roles work in parallel across their own domains.  \nHowever, the **total project duration should be anchored to the development stream that carries the most effort** (e.g., frontend-heavy projects should span as long as frontend implementation takes).  \nOther roles (e.g., backend, QA, PM) should be proportional in effort and capacity (FTE), but not dictate overall duration if they finish earlier.  \nDo not artificially serialize tasks, but reflect the true critical path of the most effort-heavy track.\n\n• For projects using a \"Heavily AI Generated\" tech stack, assume high delivery velocity and minimal risk overhead—this should reduce the lower-bound estimate.\n• If the RFP includes a fixed deadline or time budget:\n  - Suggest team composition adjustments (e.g., adding developers) to meet the timeline.\n  - Propose requirement descoping strategies (e.g., removing non-critical, high-risk features) to help fit the scope within constraints.\n  - Use this reasoning to support the “note” field in the JSON output.\n\n  **IMPORTANT: Format the rationale field using markdown markup for better readability:**\n- Use **bold text** for key points and important terms\n- Use ## headers for main sections\n- Use ### subheaders for subsections  \n- Use bullet points (- item) for lists\n- Use numbered lists (1. item) for sequential steps\n- Use \"code\" formatting for technical terms\n- Structure the rationale with clear sections and hierarchy\n`;\n\nreturn {\n  json: {\n    systemPrompt,\n    userPrompt\n  }\n};\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        112,
        4288
      ],
      "id": "cd0111f8-89dc-472d-9773-e04e1507e7d2",
      "name": "Code2"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "claude-sonnet-4-20250514",
          "mode": "list",
          "cachedResultName": "Claude Sonnet 4"
        },
        "options": {
          "maxTokensToSample": 6000,
          "temperature": 0.1,
          "thinking": false
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatAnthropic",
      "typeVersion": 1.3,
      "position": [
        304,
        4528
      ],
      "id": "2570bad8-f8b3-40e2-a700-4316a11b1010",
      "name": "Anthropic Chat Model2",
      "credentials": {
        "anthropicApi": {
          "id": "qzCm5Ds2qD9ZY1W5",
          "name": "Anthropic account"
        }
      }
    },
    {
      "parameters": {
        "content": "## Effort Estimation\n",
        "height": 740,
        "width": 2000,
        "color": 5
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        -304,
        4208
      ],
      "id": "0f8cc880-d295-406d-b79a-32991beb4795",
      "name": "Sticky Note13"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ $json.userPrompt }}",
        "hasOutputParser": true,
        "options": {
          "systemMessage": "={{ $json.systemPrompt }}"
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.9,
      "position": [
        400,
        4288
      ],
      "id": "b1d70e2b-7058-4500-99bf-312348174f02",
      "name": "Effort Estimation",
      "onError": "continueErrorOutput"
    },
    {
      "parameters": {},
      "type": "@n8n/n8n-nodes-langchain.toolCalculator",
      "typeVersion": 1,
      "position": [
        544,
        4528
      ],
      "id": "f177d962-c601-46ee-80d6-82b3db56bc0d",
      "name": "Calculator"
    },
    {
      "parameters": {
        "jsonSchemaExample": "{\n  \"phases\": [\n    {\n      \"name\": \"Planning and Foundation\",\n      \"sprints\": { \"start\": 1, \"end\": 2 },\n      \"items\": [\n        \"Set up environments and CI/CD pipeline\",\n        \"Define architecture and technical frameworks\",\n        \"Implement user authentication and role system\"\n      ]\n    },\n    {\n      \"name\": \"Core Development\",\n      \"sprints\": { \"start\": 3, \"end\": 6 },\n      \"items\": [\n        \"Develop mission system and rewards engine\",\n        \"Integrate forest visualization and topic feed\"\n      ]\n    }\n  ],\n  \"cross_cutting\": {\n    \"infrastructure\": [ \"CI/CD setup\", \"VPN access configuration\" ],\n    \"security\": [ \"Access control\", \"Penetration testing\" ],\n    \"testing\": [ \"Unit testing\", \"UAT\" ],\n    \"documentation\": [ \"API documentation\", \"User guides\" ],\n    \"deployment\": [ \"Staging environment\", \"Production rollout\" ]\n  }\n}"
      },
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "typeVersion": 1.2,
      "position": [
        2448,
        4672
      ],
      "id": "057308d2-e271-4dec-a182-1e272f60b81e",
      "name": "Greenfield + Rationale3"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "gpt-5",
          "mode": "list",
          "cachedResultName": "gpt-5"
        },
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        2208,
        4672
      ],
      "id": "c97c6f41-6887-4bbb-9d48-12c560485e89",
      "name": "GPT 4.1 Mini5",
      "credentials": {
        "openAiApi": {
          "id": "M8xqWvEC6mH6LNuk",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "const snippets = [\n  $('Dependencies1').first().json.combinedRequirementsSnippet,\n].join('\\n\\n');\n\nconst team = $('Team Composition Output').first().json.teamCompositionSnippet;\nconst estimation = $('Effort Estimate Output').first().json.effortEstimationSnippet;\n\nconst systemPrompt = `\nYou are a senior technical project planner and agile delivery strategist. You design high-level sprint-based development plans for software projects based on known scope and estimated duration.\nYou always:\n- Organize the plan into clear sprint phases\n- Include key delivery activities per phase\n- Address cross-cutting themes like infrastructure, testing, and security\n- Avoid repeating or re-estimating effort\n`;\n\nconst userPrompt = `\nBelow are structured excerpts that describe the project context:\n\n${snippets}\n${team}\n${estimation}\n\nYour task:\n- Do not include discovery phase\n- Take into consideration the optimal AI Assisted Development and setup for that\n- Consider the number of developers, assuming they can work in parallel on the same tech stack or domain area.\n- Use the \"min_sprints\" and \"max_sprints\" from the effort estimation as the timeline range.\n- Assume Agile 2-week sprints.\n1. Create a high-level **sprint-based development plan** that aligns with the estimated duration.\n2. Organize the plan into **semantically labeled phases** based on common delivery flow, such as:\n   - \"Setup and Foundation\"\n   - \"Core Development\"\n   - \"Feature Completion and Polishing\"\n   - \"Finalization and Handover\"\n3. For each phase, include:\n   - A \"name\" (semantic label as described)\n   - A \"sprints\" object with \"start\" and \"end\" sprint numbers\n   - A list of \"items\" representing deliverables, feature groups, or technical milestones\n\n4. Also provide a \"cross_cutting\" section with grouped items under:\n   - \"infrastructure\"\n   - \"security\"\n   - \"testing\"\n   - \"documentation\"\n   - \"deployment\"\nAvoid generic items. Make cross-cutting work as concrete and contextualized as possible (e.g. “Configure Firebase Analytics for event tracking” under analytics).\nYou must not re-estimate effort. Use the sprint range provided.\n\n`;\n\nreturn {\n  json: {\n    systemPrompt,\n    userPrompt\n  }\n};\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1920,
        4448
      ],
      "id": "770bf6a0-b8a3-4237-91e2-3d85c25c8b3d",
      "name": "Code3"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "claude-sonnet-4-20250514",
          "mode": "list",
          "cachedResultName": "Claude Sonnet 4"
        },
        "options": {
          "maxTokensToSample": 8000,
          "temperature": 0.3,
          "thinking": false
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatAnthropic",
      "typeVersion": 1.3,
      "position": [
        2080,
        4672
      ],
      "id": "e35ccaa3-967a-41f1-91ca-fe604f2e0ff5",
      "name": "Anthropic Chat Model3",
      "credentials": {
        "anthropicApi": {
          "id": "qzCm5Ds2qD9ZY1W5",
          "name": "Anthropic account"
        }
      }
    },
    {
      "parameters": {
        "content": "## Development Plan\n",
        "height": 740,
        "width": 1340,
        "color": 6
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        1888,
        4224
      ],
      "id": "7589c422-69a2-4f2f-9d8b-6196203a498b",
      "name": "Sticky Note14"
    },
    {
      "parameters": {},
      "type": "@n8n/n8n-nodes-langchain.toolCalculator",
      "typeVersion": 1,
      "position": [
        2320,
        4672
      ],
      "id": "85e1ca77-0c1d-455f-af65-59f627280f50",
      "name": "Calculator1"
    },
    {
      "parameters": {
        "jsCode": "/**\n * n8n Function node\n * Input  : first item from the previous “Effort Estimation” LLM step\n * Output : { effortEstimationSnippet: '### EFFORT_ESTIMATION …' }\n */\n\nconst effort = $input.first().json.output;\n\nif (!effort || typeof effort !== 'object') {\n  throw new Error('Expected output object with min_sprints, max_sprints, rationale, and discovery_steps.');\n}\n\nconst effortEstimationSnippet = [\n  '### EFFORT_ESTIMATION (authoritative, generated in prior step)',\n  JSON.stringify(effort, null, 2),\n  '',\n  'Treat this sprint range and rationale as the base reference for downstream cost, buffer, and delivery planning.'\n].join('\\n');\n\nreturn [\n  {\n    json: {\n      effortEstimationSnippet,\n    },\n  },\n];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        848,
        4288
      ],
      "id": "9ea899e4-64e7-406c-8303-923f47851d5f",
      "name": "Effort Estimate Output"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ $json.userPrompt }}",
        "hasOutputParser": true,
        "options": {
          "systemMessage": "={{ $json.systemPrompt }}"
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.9,
      "position": [
        2144,
        4400
      ],
      "id": "6b55c03a-f3c9-4516-9853-9595f1b5e13a",
      "name": "Development Plan",
      "onError": "continueErrorOutput"
    },
    {
      "parameters": {
        "jsCode": "const snippets = [\n  $('Dependencies').first().json.regulatoryComplianceSnippet,\n  $('Dependencies').first().json.combinedRequirementsSnippet,\n  $('Dependencies').first().json.projectClassificationSnippet,\n  $('Dependencies').first().json.deliveryRequirementsSnippet,\n  $('Dependencies').first().json.detectedTechStackSnippet,\n  $('Dependencies').first().json.teamCompositionSnippet,\n  $input.first().json.riskRegisterSnippet\n].join('\\n\\n');\n\nconst systemPrompt = `\nYou are a senior delivery strategist estimating agile effort for software projects.\nYour goal is to output a realistic 2-week sprint range (min to max) based on high-level scope and delivery context.\nAlways assume:\n• Optimal AI-assisted development using modern tooling (AI pair programming, codegen, automated testing)\n• A capable cross-functional team with each developer delivering 15 story points per sprint\n• High delivery velocity without unnecessary padding\nYour output must be a valid JSON object under the key \"sprint_estimate\". Do not include any other text or formatting.\n`;\n\nconst userPrompt = `\nBelow are structured excerpts that describe the project context:\n\n${snippets}\n\nTASK:\n1. Estimate the number of 2-week sprints needed to implement the full scope (MVP).\n2. Return:\n   - \"min_sprints\": lower-bound estimate\n   - \"max_sprints\": upper-bound estimate\n   - \"rationale\": a short explanation < 700 characters\n   - \"discovery steps\": steps that should be done in discovery to mitigate risks and reduce the buffer\n\nESTIMATION RULES:\nDiscovery is excluded from the sprint count, but provide discovery steps to reduce uncertainty\n• Narrow the sprint range if the scope is well-defined and straightforward.\n• Consider the number of developers, assuming they can work in parallel on the same tech stack or domain area.\n• Use a broader range when there are significant risks (e.g. vague NFRs, unclear integrations, or regulatory complexity).\n• Exclude wide buffers, discovery work, and post-launch support.\n• Only estimate the implementation phase (from kick-off to MVP launch).\n• Do NOT break down or estimate features individually.\n• Output must be in JSON only—no markdown, bullet points, or additional text.\n• The \"rationale\" field must clearly explain how scope, risk, and delivery dynamics affect the sprint estimate.\n• Anchor the timeline to the developer role bearing the most implementation load (e.g., frontend-heavy projects should reflect frontend effort primarily, with others scaled accordingly).\n• For projects using a \"Heavily AI Generated\" tech stack, assume high delivery velocity and minimal risk overhead—this should reduce the lower-bound estimate.\n• If the RFP includes a fixed deadline or time budget:\n  - Suggest team composition adjustments (e.g., adding developers) to meet the timeline.\n  - Propose requirement descoping strategies (e.g., removing non-critical, high-risk features) to help fit the scope within constraints.\n  - Use this reasoning to support the “note” field in the JSON output.\n`;\n\nreturn {\n  json: {\n    systemPrompt,\n    userPrompt\n  }\n};\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        112,
        4448
      ],
      "id": "ecc40983-0600-412c-86ff-ddab93b2bf97",
      "name": "Code4"
    },
    {
      "parameters": {
        "jsCode": "/**\n * n8n Function node\n * Input  : first item from the previous domain-specific “Effort Estimation” LLM step\n * Output : { frontendEffortSnippet: '### FRONTEND_EFFORT_ESTIMATION …' }\n */\n\nconst effort = $input.first().json.output;\n\nif (\n  !effort ||\n  typeof effort !== 'object' ||\n  !('min_days' in effort) ||\n  !('max_days' in effort)\n) {\n  throw new Error('Expected output object with min_days, max_days, rationale, and acceleration_basis.');\n}\n\nconst frontendEffortSnippet = [\n  '### FRONTEND_EFFORT_ESTIMATION (authoritative, domain-specific)',\n  JSON.stringify(effort, null, 2),\n  '',\n  'This is the effort estimation for frontend development only. Use it as a partial input for aggregating total duration or converting to sprint-based planning downstream.'\n].join('\\n');\n\nreturn [\n  {\n    json: {\n      frontendEffortSnippet,\n    },\n  },\n];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -5008,
        6912
      ],
      "id": "fcd57076-5f29-4898-b56c-5fff8911382a",
      "name": "Total Effort Estimate Output"
    },
    {
      "parameters": {
        "formTitle": "RFP",
        "formFields": {
          "values": [
            {
              "fieldLabel": "file",
              "fieldType": "file",
              "multipleFiles": false,
              "acceptFileTypes": ".pdf"
            }
          ]
        },
        "options": {},
        "path": "9cb9abba-cf8a-4450-82c1-a9fb11d38415"
      },
      "type": "n8n-nodes-base.formTrigger",
      "typeVersion": 2.2,
      "position": [
        -3936,
        1840
      ],
      "id": "21bbf737-decb-463a-87ac-50d71eda11ca",
      "name": "RFP Upload",
      "webhookId": "9cb9abba-cf8a-4450-82c1-a9fb11d38415",
      "disabled": true
    },
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "4fd01a13-fde3-4af9-b229-f31898d4c5dc",
        "options": {}
      },
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 2,
      "position": [
        -3968,
        2192
      ],
      "id": "8063c9c6-ab13-4cfc-b016-c29ef0c25d71",
      "name": "Start RFP Analysis",
      "webhookId": "4fd01a13-fde3-4af9-b229-f31898d4c5dc"
    },
    {
      "parameters": {
        "jsCode": "\nconst outputs = $('Get Platforms').all().map(item => item.json.output);\nconst sessionId = $('Start RFP Analysis').first().json.body.sessionId || \"no-session\";\n\nconst payload = {\n  step: \"platforms\",\n  title: \"Step 2. Platforms Info\",\n  sessionId:sessionId,\n  output: JSON.stringify(outputs ?? {}),\n};\n\nreturn [\n  {\n    json: {\n      platforms: JSON.stringify(payload)\n    }\n  }\n];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -2608,
        3568
      ],
      "id": "5aa6b8ba-b43f-4ddf-bb33-1f695ca6410b",
      "name": "Prepare for frontend8"
    },
    {
      "parameters": {
        "jsCode": "// Get the output from the Combined Requirements Output node\nconst combinedOutput = $('Combine Requirements').first().json.output;\nconst sessionId = $('Start RFP Analysis').first().json.body.sessionId || \"no-session\";\n\n// Extract only titles from both functional and non-functional requirements\nconst titlesOnly = combinedOutput.map(section => {\n  const processedSection = {};\n  \n  // Process each category (functional, non-functional, etc.)\n  Object.keys(section).forEach(category => {\n    if (Array.isArray(section[category])) {\n      processedSection[category] = section[category].map(req => req.title);\n    }\n  });\n  \n  return processedSection;\n});\n\nconst payload = {\n  step: \"requirements\",\n  title: \"Step 3. Requirements\",\n  sessionId: sessionId,\n  output: JSON.stringify(titlesOnly)\n};\n\nreturn [{\n  json: payload\n}];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        3008,
        3552
      ],
      "id": "0fb5f569-9db8-492c-a879-da454b1f89af",
      "name": "Prepare for frontend9"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://sse-estimation-tool.onrender.com/progress",
        "sendBody": true,
        "contentType": "raw",
        "rawContentType": "application/json",
        "body": "={{ $json}}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        3008,
        3984
      ],
      "id": "d550105e-74d3-4796-8f7c-ca43aac634f5",
      "name": "SSE - Requirements"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://sse-estimation-tool.onrender.com/progress",
        "sendBody": true,
        "contentType": "raw",
        "rawContentType": "application/json",
        "body": "={{ $json.platforms }}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -2448,
        3568
      ],
      "id": "b5f3b7a6-3f33-43a8-9b51-eae763697cc5",
      "name": "SSE - Platforms"
    },
    {
      "parameters": {
        "jsCode": "// Get the output from the Combined Requirements Output node\nconst techstack = $('Get Techstack').first().json.output;\nconst sessionId = $('Start RFP Analysis').first().json.body.sessionId || \"no-session\";\n\nconst payload = {\n  step: \"techstack\",\n  title: \"Step 4. Techstack\",\n  sessionId: sessionId,\n  output: JSON.stringify(techstack)\n};\n\nreturn [{\n  json: payload\n}];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -2816,
        4672
      ],
      "id": "5fe0be57-27f4-4687-b133-ab0e3a69bc23",
      "name": "Prepare for frontend10"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://sse-estimation-tool.onrender.com/progress",
        "sendBody": true,
        "contentType": "raw",
        "rawContentType": "application/json",
        "body": "={{ $json}}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -2560,
        4672
      ],
      "id": "7308bb13-c21e-47c3-9621-2877544dae76",
      "name": "SSE - Techstack"
    },
    {
      "parameters": {
        "jsCode": "// Get the output from the Combined Requirements Output node\nconst team = $('Team Composition').first().json.output;\nconst sessionId = $('Start RFP Analysis').first().json.body.sessionId || \"no-session\";\n\nconst payload = {\n  step: \"team_composition\",\n  title: \"Step 5. Team Composition\",\n  sessionId: sessionId,\n  output: JSON.stringify(team)\n};\n\nreturn [{\n  json: payload\n}];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -800,
        4464
      ],
      "id": "c29dfb3f-f9d8-40cf-a4e9-4b4f9fa3c36b",
      "name": "Prepare for frontend11"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://sse-estimation-tool.onrender.com/progress",
        "sendBody": true,
        "contentType": "raw",
        "rawContentType": "application/json",
        "body": "={{ $json}}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -528,
        4464
      ],
      "id": "59447777-9cf5-4291-a57b-19e2837c817b",
      "name": "SSE - Team Composition"
    },
    {
      "parameters": {
        "jsCode": "// Get the output from the Combined Requirements Output node\nconst effort = $('Effort Estimation').first().json.output;\nconst sessionId = $('Start RFP Analysis').first().json.body.sessionId || \"no-session\";\n\nconst payload = {\n  step: \"effort_estimation\",\n  title: \"Step 6. Effort Estimation\",\n  sessionId: sessionId,\n  output: JSON.stringify(effort)\n};\n\nreturn [{\n  json: payload\n}];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1088,
        4288
      ],
      "id": "aaaa797f-0d9b-4ed9-8f7c-c1000f4958c1",
      "name": "Prepare for frontend12"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://sse-estimation-tool.onrender.com/progress",
        "sendBody": true,
        "contentType": "raw",
        "rawContentType": "application/json",
        "body": "={{ $json}}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        1328,
        4272
      ],
      "id": "88af303f-0f5a-49b1-b3dd-7731718a4543",
      "name": "SSE - Effort Estimation"
    },
    {
      "parameters": {
        "jsCode": "// Get the output from the Combined Requirements Output node\nconst plan = $('Development Plan').first().json.output;\nconst sessionId = $('Start RFP Analysis').first().json.body.sessionId || \"no-session\";\n\nconst payload = {\n  step: \"development_plan\",\n  title: \"Step 7. Development Plan\",\n  sessionId: sessionId,\n  output: JSON.stringify(plan)\n};\n\nreturn [{\n  json: payload\n}];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        2784,
        4400
      ],
      "id": "51b9a281-39fc-4f79-80e2-f90c99a1bd0b",
      "name": "Prepare for frontend13"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://sse-estimation-tool.onrender.com/progress",
        "sendBody": true,
        "contentType": "raw",
        "rawContentType": "application/json",
        "body": "={{ $json}}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        3008,
        4400
      ],
      "id": "e0e9881b-9fce-4b75-bffa-a14e7a10c00e",
      "name": "SSE - Development Plan"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "claude-sonnet-4-20250514",
          "mode": "list",
          "cachedResultName": "Claude Sonnet 4"
        },
        "options": {
          "maxTokensToSample": 6096,
          "thinking": true
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatAnthropic",
      "typeVersion": 1.3,
      "position": [
        3584,
        4608
      ],
      "id": "df37a7af-a725-41be-a886-1255297386b6",
      "name": "Anthropic Chat Model5",
      "credentials": {
        "anthropicApi": {
          "id": "qzCm5Ds2qD9ZY1W5",
          "name": "Anthropic account"
        }
      }
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ $json.userPrompt }}",
        "options": {
          "systemMessage": "={{ $json.systemPrompt }}"
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.8,
      "position": [
        3584,
        4432
      ],
      "id": "6ae99d25-534e-45be-a726-af192a85d612",
      "name": "Reporter",
      "onError": "continueErrorOutput"
    },
    {
      "parameters": {
        "jsCode": "const input = $input.first().json.output;\nconst sessionId = $('Start RFP Analysis').first().json.body.sessionId || \"no-session\";\n\nconst payload = {\n  step: \"final_report\",\n  title: \"Step 8. Final Report\",\n  sessionId: sessionId,\n  output: input\n};\n\nreturn [{\n  json: payload\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        3984,
        4432
      ],
      "id": "9dfe3e2a-b9ba-4cfd-9adb-b94c2548fe4c",
      "name": "Prepare for frontend7"
    },
    {
      "parameters": {
        "jsCode": "\n//const requirements = $('Dependencies1').first().json.combinedRequirementsSnippet;\nconst team = $('Team Composition Output').first().json.teamCompositionSnippet;\nconst estimation = $('Effort Estimate Output').first().json.effortEstimationSnippet;\nconst dev = $('Development Plan Output').first().json.developmentPlanOutput;\nconst techstack = $('Techstack Output').first().json.detectedTechStackSnippet\nconst platforms = $('Platforms Output').first().json.detectedPlatformsSnippet\n\nconst systemPrompt = `\nYou are a professional document formatter specialized in creating executive-grade PDF reports. Your role is to take structured project data and present it in a clean, professional format optimized for PDF rendering.\n\nCRITICAL REQUIREMENTS:\n- Present existing data in professional PDF format - DO NOT add new analysis\n- Use clean markdown formatting with proper line breaks\n- Format existing information into professional tables and sections\n- Use executive summary styling and highlight boxes for key information\n- Keep content high-level and focused on presenting the provided data clearly\n`;\n\nconst userPrompt = `\nFormat the provided project analysis data into a professional executive summary document optimized for PDF export.\n\nFORMATTING REQUIREMENTS:\n- Use proper markdown syntax (not escaped characters)\n- Present data in professional tables and sections\n- Use **RECOMMENDATION**, **RISK**, **SUCCESS** for any existing insights\n- Structure with clear headers using # ## ### syntax\n- Include executive summary with key metrics from provided data\n\n**DATA TO FORMAT:**\n\n**PLATFORMS:** ${platforms}\n**TECHNOLOGY STACK:** ${techstack}  \n**TEAM COMPOSITION:** ${team}\n**EFFORT ESTIMATION:** ${estimation}\n**DEVELOPMENT PLAN:** ${dev}\n\nGenerate a professional document with this structure:\n\n# PROJECT DELIVERY SUMMARY\n## [Extract project name/type from data]\n\n<div class=\"executive-summary\">\n\n**PROJECT INVESTMENT SUMMARY**\n\n[Create 150-200 word summary using ONLY the provided data, highlighting:\n- Platform scope (from platforms data)\n- Technology approach (from techstack data) \n- Team size and timeline (from team/estimation data)\n- Key deliverables (from dev plan data)]\n\n**Key Investment Metrics:**\n- **Timeline:** [Extract from estimation data] sprints ([calculate weeks])\n- **Team Size:** [Sum FTE from team data] FTE resources\n- **Platforms:** [List from platforms data]\n- **Technology Stack:** [Summary from techstack data]\n\n</div>\n\n## Platform and Technology Overview\n\n### Target Platforms\n[Create table from platforms data showing platform types and descriptions]\n\n### Technology Architecture  \n[Format techstack data into clear sections:\n- Backend: [from backend_stack]\n- Frontend: [from web_stack] \n- Mobile: [from mobile_stack]\n- Database: [from database]\n- Deployment: [from deployment]\n- Key Integrations: [from integrations]]\n\n## Team Structure and Resource Allocation\n\n[Create professional table from team data with columns:]\n| **Role** | **FTE Allocation** | **Key Responsibilities** |\n|----------|-------------------|--------------------------|\n[Format each role from team composition data]\n| **Total Team** | **[Sum all FTE]** | **Complete project delivery** |\n\n## Development Timeline and Phases\n\n### Project Timeline\n- **Sprint Range:** [min_sprints] - [max_sprints] sprints\n- **Estimated Duration:** [calculate weeks/months from sprint data]\n- **Methodology:** Agile with 2-week sprints\n\n### Development Phases\n[For each phase in development plan, create structured overview:]\n\n**Phase [X]: [phase name]** (Sprints [start]-[end])\n- **Duration:** [calculate sprint count] sprints  \n- **Key Focus:** [summarize 2-3 main items from phase items]\n\n[Continue for all phases in dev plan...]\n\n\n## Executive Summary\n\n<div class=\"highlight-box\">\n\n**PROJECT DELIVERY OVERVIEW**\n\n**Total Investment:** [Sum team FTE] FTE resources over [estimation range] sprints\n\n**Technology Approach:** [Brief summary of separated/unified architecture from techstack]\n\n**Delivery Confidence:** Based on [estimation rationale summary]\n\n**Key Success Factors:**\n- [Extract 2-3 points from team/estimation rationale]\n\n\n</div>\n\nIMPORTANT INSTRUCTIONS:\n- Use ONLY the data provided - do not add new analysis or conclusions\n- Format existing information into professional presentation\n- Keep requirements section as overview/summary only (do not list all requirements)\n- Present data clearly without adding interpretation beyond what's already provided\n- Use professional formatting that works well with PDF generation\n`;\n\nreturn {\n  json: {\n    systemPrompt,\n    userPrompt\n  }\n};"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        3360,
        4400
      ],
      "id": "9a88ac7a-f122-4e64-b508-2c6b3d1ea3a0",
      "name": "Prompt"
    },
    {
      "parameters": {
        "jsCode": "/**\n * n8n Function node\n * Input  : first item from the previous “Effort Estimation” LLM step\n * Output : { effortEstimationSnippet: '### EFFORT_ESTIMATION …' }\n */\n\nconst effort = $input.first().json.output;\n\nif (!effort || typeof effort !== 'object') {\n  throw new Error('Expected output object with development plan.');\n}\n\nconst developmentPlanOutput = [\n  '### DEVELOPMENT_PLAN (authoritative, generated in prior step)',\n  JSON.stringify(effort, null, 2),\n  '',\n  'Treat this development plan as the base reference.'\n].join('\\n');\n\nreturn [\n  {\n    json: {\n      developmentPlanOutput,\n    },\n  },\n];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        2592,
        4400
      ],
      "id": "63b831c9-298e-4271-a270-a2b90800a259",
      "name": "Development Plan Output"
    },
    {
      "parameters": {},
      "type": "@n8n/n8n-nodes-langchain.toolCalculator",
      "typeVersion": 1,
      "position": [
        3840,
        4640
      ],
      "id": "1dcc4ba4-b922-4d64-aace-e6243f010440",
      "name": "Calculator2"
    },
    {
      "parameters": {},
      "type": "@n8n/n8n-nodes-langchain.toolThink",
      "typeVersion": 1,
      "position": [
        3744,
        4640
      ],
      "id": "04c72328-f361-4a58-86e5-55085b836e67",
      "name": "Think2"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://sse-estimation-tool.onrender.com/progress",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ $json }}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        4240,
        4432
      ],
      "id": "44e84185-5be4-4857-a301-6c183a19da68",
      "name": "SSE - Final Report"
    },
    {
      "parameters": {
        "jsCode": "// Get sessionId from previous step\nconst sessionId = $('Start RFP Analysis').first().json.body.sessionId || \"no-session\";\n\n// Professional PDF content example\nconst professionalContent = `# PROJECT2 DELIVERY SUMMARY\n## Enterprise CRM & Customer Management Platform\n\n<div class=\"executive-summary\">\n\n**PROJECT INVESTMENT SUMMARY**\n\nThis comprehensive enterprise CRM platform represents a strategic digital transformation initiative requiring 18-24 months and 12.5 FTE resources. The solution encompasses web applications, mobile platforms (iOS/Android), and robust backend services with extensive third-party integrations including Microsoft 365, Salesforce, and QuickBooks Online.\n\nThe project scope includes 45 functional requirements spanning user management, advanced analytics, customer journey mapping, automated marketing workflows, and comprehensive reporting capabilities. Additionally, 28 non-functional requirements mandate enterprise-grade security, GDPR compliance, scalability to support 1000+ concurrent users, and 99.9% uptime SLA.\n\n**Key Investment Metrics:**\n- **Estimated Timeline:** 18-24 months\n- **Required Team Size:** 12.5 FTE resources  \n- **Total Investment:** 300-450 person-months\n- **Confidence Level:** High (88%)\n- **Overall Risk Level:** Medium\n\n**Strategic Recommendation:** Proceed with phased implementation approach to minimize risk and deliver incremental business value.\n\n</div>\n\n## Project Scope and Requirements Analysis\n\n**Project Complexity Rating:** Highly Complex\n\nThe comprehensive requirements analysis reveals a sophisticated enterprise-level platform with multiple integration points and advanced functionality requirements.\n\n### Requirements Quality Assessment\n\n- **Completeness Rating:** Excellent (92%) - Well-defined functional and technical specifications\n- **Technical Clarity:** High - Clear architectural requirements and integration specifications  \n- **Implementation Feasibility:** High - Technically achievable with recommended team structure\n\n**RECOMMENDATION**: Requirements are well-defined and ready for implementation. Recommend conducting technical discovery workshops for Microsoft 365 and Salesforce integration specifics.\n\n**RISK**: Complex third-party integrations may introduce timeline dependencies on external vendor support and API limitations.\n\n## Investment Analysis and Resource Planning\n\n### Development Effort Estimation\n\n| **Investment Metric** | **Minimum Scenario** | **Most Likely** | **Maximum Scenario** | **Recommended Planning** |\n|----------------------|---------------------|-----------------|---------------------|-------------------------|\n| **Development Duration** | 16 months | 20 months | 24 months | 20 months |\n| **Sprint Count** | 32 sprints | 40 sprints | 48 sprints | 40 sprints |\n| **Team Size (FTE)** | 10.0 FTE | 12.5 FTE | 15.0 FTE | 12.5 FTE |\n| **Confidence Level** | 75% | 88% | 95% | 88% |\n| **Total Investment** | 267 person-months | 333 person-months | 450 person-months | 333 person-months |\n\n### Timeline and Risk Analysis\n\n**Estimation Methodology:** Three-point estimation using industry benchmarks for enterprise CRM implementations, adjusted for project complexity and team experience.\n\n**Critical Timeline Factors:**\n- Third-party API integration complexity and documentation quality\n- Customer data migration from legacy systems (estimated 2.5M records)\n- Enterprise security compliance and penetration testing requirements\n- User acceptance testing across multiple business units (250+ users)\n\n**RISK**: Microsoft 365 integration timeline dependent on tenant configuration complexity and may require additional 2-4 weeks if custom permissions are needed.\n\n**SUCCESS**: Strong technical leadership availability and clear business requirements will accelerate development velocity by an estimated 15-20%.\n\n## Team Composition and Resource Strategy\n\n### Recommended Team Structure\n\n| **Role** | **FTE Allocation** | **Duration (months)** | **Key Responsibilities** | **Seniority Required** |\n|----------|-------------------|-----------------------|-------------------------|----------------------|\n| **Technical Lead** | 1.0 FTE | 20 months | Architecture, code reviews, technical decisions | Senior (8+ years) |\n| **Backend Developers** | 3.0 FTE | 18 months | API development, database design, integrations | Mid-Senior (5+ years) |\n| **Frontend Developers** | 2.5 FTE | 16 months | React web app, responsive design, UX implementation | Mid-Level (3+ years) |\n| **Mobile Developers** | 2.0 FTE | 14 months | iOS/Android native apps, mobile UX optimization | Mid-Senior (4+ years) |\n| **DevOps Engineer** | 1.0 FTE | 20 months | CI/CD, infrastructure, monitoring, security | Senior (6+ years) |\n| **QA Engineers** | 2.0 FTE | 18 months | Test automation, manual testing, UAT coordination | Mid-Level (3+ years) |\n| **UI/UX Designer** | 1.0 FTE | 12 months | Design system, prototypes, user research | Mid-Senior (4+ years) |\n| **Total Team** | **12.5 FTE** | **20 months** | **Complete enterprise platform delivery** | **Mixed experience levels** |\n\n### Resource Strategy\n\n**Team Composition Rationale:** Balanced team structure emphasizing backend expertise for complex integrations while ensuring strong frontend capabilities for user experience excellence.\n\n**Critical Skills and Expertise:**\n- Microsoft 365 API integration experience (Graph API, SharePoint)\n- Enterprise security implementation (OAuth 2.0, SAML, encryption)\n- High-volume data processing and optimization\n- Mobile application development with offline capabilities\n\n**RECOMMENDATION**: Prioritize hiring technical lead and senior backend developers first to establish architecture foundation. Consider Microsoft-certified developers for Graph API integration.\n\n**SUCCESS**: Cross-functional team with previous enterprise CRM experience will reduce learning curve and improve delivery predictability by 25-30%.\n\n## Development Methodology and Delivery Phases\n\n### Development Approach\n\nAgile methodology with 2-week sprints, emphasizing continuous integration, automated testing, and regular stakeholder feedback loops. Parallel development tracks for web, mobile, and backend components with clearly defined integration milestones.\n\n### Delivery Phase Breakdown\n\n**Phase 1: Foundation & Core Platform** (Sprints 1-12)\n- **Duration:** 12 sprints (24 weeks)\n- **Key Deliverables:** \n  - Core authentication and user management system\n  - Basic CRM functionality (contacts, accounts, opportunities)\n  - Database schema and API foundation\n  - Development infrastructure and CI/CD pipeline\n- **Success Criteria:** User authentication, basic CRUD operations, automated testing framework\n- **Dependencies:** Infrastructure setup, third-party service accounts provisioning\n\n**Phase 2: Advanced Features & Integrations** (Sprints 13-28)\n- **Duration:** 16 sprints (32 weeks)\n- **Key Deliverables:** \n  - Microsoft 365 integration (Calendar, Email, SharePoint)\n  - Advanced analytics and reporting engine\n  - Mobile applications (iOS and Android)\n  - Automated workflow engine\n- **Success Criteria:** Full integration functionality, mobile app store deployment, analytics dashboard\n- **Dependencies:** Microsoft 365 tenant configuration, mobile developer account setup\n\n**Phase 3: Enterprise Features & Optimization** (Sprints 29-40)\n- **Duration:** 12 sprints (24 weeks)\n- **Key Deliverables:** \n  - Advanced security features and compliance\n  - Performance optimization and scalability testing\n  - Data migration tools and legacy system integration\n  - User training materials and documentation\n- **Success Criteria:** Security certification, performance benchmarks met, successful data migration\n- **Dependencies:** Legacy system access, security audit scheduling\n\n### Project Success Framework\n\n**SUCCESS**: Key factors ensuring project success include dedicated product owner engagement, regular stakeholder reviews, and phased user acceptance testing with business units.\n\n**RISK**: Primary project risks include third-party API changes, scope creep from additional integration requests, and resource availability during peak development phases. Mitigation includes API versioning strategy, formal change control process, and backup resource planning.\n\n## Executive Summary and Investment Recommendation\n\n<div class=\"highlight-box\">\n\n**FINAL INVESTMENT RECOMMENDATION**\n\n**Total Project Investment:** 333 person-months over 20 months\n\n**Strategic Recommendation:** **PROCEED** with phased implementation approach\n\n**Confidence Assessment:** High confidence (88%) in delivery estimates based on detailed technical analysis and industry benchmarks\n\n**Critical Success Dependencies:**\n- Dedicated technical leadership and senior backend development expertise\n- Early Microsoft 365 integration planning and tenant configuration\n- Committed product owner with decision-making authority for requirement clarifications\n- Phased user acceptance testing approach with business unit representatives\n\n**Immediate Next Steps:**\n1. **Technical Discovery Phase** (2-4 weeks) - Microsoft 365 integration assessment and architecture design\n2. **Team Assembly** (4-6 weeks) - Recruit technical lead and core backend development team\n3. **Infrastructure Setup** (2-3 weeks) - Development environment, CI/CD pipeline, and monitoring tools\n\n**ROI Projection:** Expected 300% ROI within 18 months post-deployment through improved sales efficiency, automated workflows, and enhanced customer insights.\n\n</div>\n\n**RECOMMENDATION**: This enterprise CRM platform represents a strategic investment with clear business value and technical feasibility. The phased approach minimizes risk while delivering incremental value. Recommend proceeding with immediate technical discovery and team assembly.\n\n## Risk Assessment and Mitigation Strategy\n\n**RISK**: **Third-Party Integration Complexity** - Microsoft 365 and Salesforce API limitations may impact timeline\n- *Mitigation:* Conduct technical proof-of-concept during discovery phase\n- *Contingency:* 2-week buffer built into Phase 2 timeline\n\n**RISK**: **Team Scaling Challenges** - Difficulty finding experienced enterprise developers\n- *Mitigation:* Engage technical recruiting partner, consider remote team members\n- *Contingency:* Adjust timeline by 10-15% if key positions remain unfilled after 6 weeks\n\n**SUCCESS**: **Strong Business Sponsorship** - Executive commitment ensures resource availability and decision-making speed\n- *Advantage:* Reduces requirement clarification delays, accelerates UAT cycles\n- *Impact:* Potential 15-20% timeline improvement with dedicated product ownership\n\nThis comprehensive analysis demonstrates high confidence in successful delivery of an enterprise-grade CRM platform that will transform customer relationship management capabilities and drive significant business value.`;\n\nconst payload = {\n  step: \"final_report\",\n  title: \"Step 8. Final Report\",\n  sessionId: sessionId,\n  output: professionalContent\n};\n\nreturn [{\n  json: payload\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        3360,
        4624
      ],
      "id": "0c96398c-9f62-456e-ad00-011ff6baf645",
      "name": "mock"
    },
    {
      "parameters": {
        "operation": "getAll",
        "indexId": "={{ $('Start RFP Analysis').first().json.body.indexName }}",
        "limit": 10,
        "simple": false,
        "options": {
          "query": "={\n  \"size\": 10,\n  \"min_score\": 1.0,\n  \"_source\": [\n    \"chunk_id\",\"section_title\",\"text\",\n    \"metadata.filename\",\"metadata.page_numbers\",\n    \"metadata.parent_chunk_id\",\"metadata.is_split_chunk\",\n    \"metadata.split_part\",\"metadata.total_parts\",\n    \"vector_metadata.token_count\",\"vector_metadata.is_split\",\n    \"vector_metadata.chunk_index\"\n  ],\n  \"knn\": {\n    \"field\": \"embeddings\",\n    \"query_vector\": [ {{ $json.embeddings }} ],\n    \"k\": 20,\n    \"num_candidates\": 50\n  },\n  \"query\": {\n    \"bool\": {\n      \"should\": [\n        {\n          \"match_phrase\": {\n            \"text\": {\n              \"query\": \"{{ $('Queries').item.json.phrase }}\",\n              \"slop\": 4,\n              \"boost\": 2.0\n            }\n          }\n        },\n        {\n          \"multi_match\": {\n            \"query\": \"{{ $('Queries').item.json.keywords }}\",\n            \"fields\": [\"text^2\",\"section_title^3\"],\n            \"type\": \"most_fields\",\n            \"minimum_should_match\": 2,\n            \"boost\": 1.2\n          }\n        },\n        {\n          \"terms_set\": {\n            \"text.keyword\": {\n              \"terms\": {{ JSON.stringify($('Queries').item.json.keywords.split(',').map(k => k.trim())) }},\n\n              \"minimum_should_match_script\": {\n                \"source\": \"Math.min(params.num_terms, 2)\"\n              }\n            }\n          }\n        }\n      ],\n      \"minimum_should_match\": 1\n    }\n  },\n  \"rescore\": {\n    \"window_size\": 20,\n    \"query\": {\n      \"rescore_query\": {\n        \"match_phrase\": {\n          \"text\": {\n            \"query\": \"{{ $('Queries').item.json.rescore_query }}\",\n            \"slop\": 8\n          }\n        }\n      },\n      \"query_weight\": 0.7,\n      \"rescore_query_weight\": 0.3\n    }\n  },\n  \"highlight\": {\n    \"type\": \"unified\",\n    \"fields\": { \"text\": {}, \"section_title\": {} }\n  }\n}\n"
        }
      },
      "type": "n8n-nodes-base.elasticsearch",
      "typeVersion": 1,
      "position": [
        -3456,
        3152
      ],
      "id": "fe31cdcf-fa5c-43cd-9fe3-aa99f41e3b55",
      "name": "Query - Full1",
      "alwaysOutputData": true,
      "credentials": {
        "elasticsearchApi": {
          "id": "wwaILZtoajWrVXwt",
          "name": "Elasticsearch account"
        }
      }
    },
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "ba9641e5-6ef7-49b9-9301-615a10aae761",
        "responseMode": "responseNode",
        "options": {}
      },
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 2,
      "position": [
        -4384,
        5744
      ],
      "id": "0d5e3a20-6f1c-4869-9600-594a79680056",
      "name": "Send PDF to Email",
      "webhookId": "ba9641e5-6ef7-49b9-9301-615a10aae761"
    },
    {
      "parameters": {
        "sendTo": "={{ $json.email }}",
        "subject": "=Your Q AI RFP Analysis Report is Ready for {{ $json.body.fileName }}",
        "message": "=<!DOCTYPE html>\n<html>\n  <head>\n    <meta charset=\"UTF-8\" />\n    <title>Q AI RFP Analysis Report</title>\n  </head>\n  <body style=\"font-family: Arial, sans-serif; background-color: #f5f5f5; padding: 20px; margin: 0;\">\n    <table width=\"100%\" cellpadding=\"0\" cellspacing=\"0\" border=\"0\" style=\"max-width: 600px; margin: auto; background-color: #ffffff; border-radius: 8px; overflow: hidden;\">\n      <tr>\n        <td style=\"padding: 30px 40px;\">\n          <h2 style=\"color: #333333;\">Dear {{ $json.name }},</h2>\n          <p style=\"font-size: 16px; color: #555555; line-height: 1.6;\">\n            Thank you for using the <strong>Q AI RFP Analysis Tool</strong>.\n          </p>\n          <p style=\"font-size: 16px; color: #555555; line-height: 1.6;\">\n            Attached to this email, you will find the informative analysis report generated based on the RFP you uploaded.\n            The report includes insights related to <strong>estimated effort</strong>, <strong>key requirements</strong>, <strong>potential risks</strong>, and other relevant aspects of the document.\n          </p>\n          <p style=\"font-size: 16px; color: #555555; line-height: 1.6;\">\n            We hope this helps you streamline your decision-making process and improve planning efficiency.\n          </p>\n          <p style=\"font-size: 16px; color: #555555; line-height: 1.6;\">\n            <strong>Please note:</strong> This report was generated using the <strong>limited free version</strong> of our Q Estimation Tool.\n          </p>\n          <p style=\"font-size: 16px; color: #555555; line-height: 1.6;\">\n            To explore the full range of features, visit <a href=\"https://q.agency/products/q-estimation-tool/\" style=\"color: #1a73e8; text-decoration: none;\"><strong>Q Estimation Tool</strong></a>.\n          </p>\n          <p style=\"font-size: 16px; color: #555555; line-height: 1.6;\">\n            If you have any questions or would like further support, feel free to reach us at <a href=\"mailto:hello@q.agency\" style=\"color: #1a73e8; text-decoration: none;\"><strong>hello@q.agency</strong></a>.\n          </p>\n          <p style=\"font-size: 16px; color: #333333; margin-top: 30px;\">\n            Best regards,<br/>\n            <strong>AI Team at Q Agency</strong>\n          </p>\n        </td>\n      </tr>\n      <tr>\n        <td style=\"background-color: #eeeeee; padding: 20px; text-align: center; font-size: 12px; color: #888888;\">\n          © 2025 Q Agency. All rights reserved.\n        </td>\n      </tr>\n    </table>\n  </body>\n</html>",
        "options": {
          "appendAttribution": false,
          "attachmentsUi": {
            "attachmentsBinary": [
              {
                "property": "pdf"
              }
            ]
          },
          "bccList": "zlatko.matokanovic@q.agency"
        },
        "path": "91a57cc9-2a1b-43c6-82e5-04150be9f48e"
      },
      "type": "n8n-nodes-base.gmail",
      "typeVersion": 2.1,
      "position": [
        -3664,
        5744
      ],
      "id": "4f9ab3f4-a4ec-47ad-a35e-2de059589184",
      "name": "Gmail",
      "webhookId": "91a57cc9-2a1b-43c6-82e5-04150be9f48e",
      "credentials": {
        "gmailOAuth2": {
          "id": "AnMIdKkQ5ToxkLrh",
          "name": "Gmail account"
        }
      }
    },
    {
      "parameters": {
        "mode": "combine",
        "combineBy": "combineAll",
        "options": {}
      },
      "type": "n8n-nodes-base.merge",
      "typeVersion": 3,
      "position": [
        -3920,
        5744
      ],
      "id": "442f562e-90a2-4f83-8e56-b5bf3697d7bd",
      "name": "Merge"
    },
    {
      "parameters": {
        "jsCode": "function extractNameFromEmail(email) {\n  if (!email || typeof email !== 'string') return '';\n\n  const localPart = email.split('@')[0];\n\n  // Replace separators with spaces\n  const raw = localPart.replace(/[\\._\\-]+/g, ' ').trim();\n\n  // Split and capitalize\n  const nameParts = raw\n    .split(' ')\n    .filter(Boolean)\n    .map(w => w.charAt(0).toUpperCase() + w.slice(1).toLowerCase());\n\n  return nameParts.join(' ');\n}\n\nconst input = $input.first().json;\n\nconst email = input.body?.email || '';\nconst sessionId = input.body?.sessionId || '';\nconst name = extractNameFromEmail(email);\nconst fileName = $input.first().json.body.originalFilename\n\n\nreturn [\n  {\n    json: {\n      email,\n      name,\n      sessionId,\n      fileName,\n      binary: input.binary\n    }\n  }\n];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -4144,
        5872
      ],
      "id": "b194f9c5-4406-4f35-a7d5-661c5bb2cc65",
      "name": "Code6"
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 2
          },
          "conditions": [
            {
              "id": "9a436325-f8ac-491f-99aa-c66f916b471d",
              "leftValue": "={{$json._index === undefined}}",
              "rightValue": "",
              "operator": {
                "type": "boolean",
                "operation": "false",
                "singleValue": true
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [
        -3248,
        3152
      ],
      "id": "b9040bb7-f1fa-4cbe-928c-c86bc26ecee9",
      "name": "Has Hits?"
    },
    {
      "parameters": {
        "content": "## Email Trigger - Client\n",
        "height": 860,
        "width": 1320,
        "color": 4
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        -4464,
        5504
      ],
      "id": "c5b6999a-cf03-4542-a3d6-f2e995660eca",
      "name": "Sticky Note5"
    },
    {
      "parameters": {
        "content": "## Final Report\n",
        "height": 520,
        "width": 1080
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        3328,
        4320
      ],
      "id": "6a81a120-8c94-46da-88c6-8beb8ad209bd",
      "name": "Sticky Note2"
    },
    {
      "parameters": {
        "amount": 0.7,
        "path": "dfe9b092-6df1-43db-9306-7257fa8b5542"
      },
      "type": "n8n-nodes-base.wait",
      "typeVersion": 1.1,
      "position": [
        -3680,
        3152
      ],
      "id": "eda9322c-798a-4622-a167-38cad764bd4c",
      "name": "Wait",
      "webhookId": "dfe9b092-6df1-43db-9306-7257fa8b5542"
    },
    {
      "parameters": {
        "amount": 0.7,
        "path": "eabd31e5-8d40-4eef-9c96-3db3de6c4470"
      },
      "type": "n8n-nodes-base.wait",
      "typeVersion": 1.1,
      "position": [
        -1296,
        3344
      ],
      "id": "8942442c-3b4c-4289-9ee8-3db81cf9ecd4",
      "name": "Wait1",
      "webhookId": "eabd31e5-8d40-4eef-9c96-3db3de6c4470"
    },
    {
      "parameters": {
        "amount": 0.7,
        "path": "77860376-949d-42f2-ba56-64b8b8b39b00"
      },
      "type": "n8n-nodes-base.wait",
      "typeVersion": 1.1,
      "position": [
        800,
        3360
      ],
      "id": "774d6665-b88d-4d4d-a972-612b822d61db",
      "name": "Wait2",
      "webhookId": "77860376-949d-42f2-ba56-64b8b8b39b00"
    },
    {
      "parameters": {
        "amount": 0.7,
        "path": "dbdf745f-244f-4810-8460-90b43c1412f2"
      },
      "type": "n8n-nodes-base.wait",
      "typeVersion": 1.1,
      "position": [
        -4048,
        4432
      ],
      "id": "b3e56c31-7267-4b68-940e-a29ce82dd497",
      "name": "Wait3",
      "webhookId": "dbdf745f-244f-4810-8460-90b43c1412f2"
    },
    {
      "parameters": {
        "errorType": "errorObject",
        "errorObject": "{\n  \"title\": \"Platforms\",\n  \"message\": \"Unfortunately, we couldn’t identify the target platforms from your RFP. Since this information is essential for the analysis, the process has been halted.\"\n}"
      },
      "type": "n8n-nodes-base.stopAndError",
      "typeVersion": 1,
      "position": [
        -2944,
        3024
      ],
      "id": "6d8cc928-cc85-4284-bf0a-1019df28be80",
      "name": "Stop and Error"
    },
    {
      "parameters": {
        "jsCode": "const sessionId = $input.first().json.body.sessionId;\n\nconst executionId = $execution.id;\nconst workflowId = $workflow.id;\nconst startTime = new Date().toISOString();\n\n// Create session data object\nconst sessionData = {\n  sessionId: sessionId,\n  executionId: executionId,\n  workflowId: workflowId,\n  workflowName: $workflow.name,\n  startTime: startTime,\n  status: 'active',\n  nodeCount: 1\n};\n\n// Prepare file content\nconst fileName = `session_${executionId}.json`;\nconst fileContent = JSON.stringify(sessionData, null, 2);\nconst filePath = `/tmp/${fileName}`;\n\nconsole.log(`📁 Creating session file: ${filePath}`);\nconsole.log(`🆔 Session ID: ${sessionId}`);\n\nreturn {\n  json: {\n    sessionId: sessionId,\n    executionId: executionId,\n    fileName: fileName,\n    filePath: filePath,\n    fileContent: fileContent,\n    sessionData: sessionData,\n    \n    // Include original input data\n    ...$input.first()?.json\n  }\n};"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -3264,
        2064
      ],
      "id": "48e697c5-40a7-49e3-9b34-dd090e793dbc",
      "name": "Get Session ID and prepare file data"
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 2
          },
          "conditions": [
            {
              "id": "9a436325-f8ac-491f-99aa-c66f916b471d",
              "leftValue": "={{$json._index === undefined}}",
              "rightValue": "",
              "operator": {
                "type": "boolean",
                "operation": "false",
                "singleValue": true
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [
        -896,
        3200
      ],
      "id": "99a3023e-b982-47a3-8c6f-01e7fb3f57f2",
      "name": "Has Hits?1"
    },
    {
      "parameters": {
        "errorType": "errorObject",
        "errorObject": "{\n  \"title\": \"Functional Requirements\",\n  \"message\": \"Unfortunately, we couldn’t identify the functional requirements from your RFP. Since this information is essential for the analysis, the process has been halted.\"\n}"
      },
      "type": "n8n-nodes-base.stopAndError",
      "typeVersion": 1,
      "position": [
        -304,
        3008
      ],
      "id": "c28b3ba2-1c30-4d7d-b2fc-98a8932a4f81",
      "name": "Stop and Error1"
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 2
          },
          "conditions": [
            {
              "id": "9a436325-f8ac-491f-99aa-c66f916b471d",
              "leftValue": "={{$json._index === undefined}}",
              "rightValue": "",
              "operator": {
                "type": "boolean",
                "operation": "false",
                "singleValue": true
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [
        1088,
        3200
      ],
      "id": "1f79d81a-d38a-4045-8271-afa8aec3d7e2",
      "name": "Has Hits?2"
    },
    {
      "parameters": {
        "errorType": "errorObject",
        "errorObject": "{\n  \"title\": \"Non-Functional Requirements\",\n  \"message\": \"Unfortunately, we couldn’t identify the non-functional requirements from your RFP. Since this information is essential for the analysis, the process has been halted.\"\n}"
      },
      "type": "n8n-nodes-base.stopAndError",
      "typeVersion": 1,
      "position": [
        1648,
        3024
      ],
      "id": "2a7e77d9-4030-4a3a-86ca-415c43927c7b",
      "name": "Stop and Error2"
    },
    {
      "parameters": {
        "errorType": "errorObject",
        "errorObject": "{\n  \"title\": \"Functional Requirements\",\n  \"message\": \"Unfortunately, we couldn’t identify the functional requirements from your RFP. Since this information is essential for the analysis, the process has been halted.\"\n}"
      },
      "type": "n8n-nodes-base.stopAndError",
      "typeVersion": 1,
      "position": [
        2480,
        2992
      ],
      "id": "9e0aae96-3662-4bed-84e8-bcb1546f742b",
      "name": "Stop and Error3"
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 2
          },
          "conditions": [
            {
              "id": "9a436325-f8ac-491f-99aa-c66f916b471d",
              "leftValue": "={{$json._index === undefined}}",
              "rightValue": "",
              "operator": {
                "type": "boolean",
                "operation": "false",
                "singleValue": true
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [
        -3728,
        4432
      ],
      "id": "435d8bfb-d028-43e9-81cc-8ba3a36731fd",
      "name": "Has Hits?3"
    },
    {
      "parameters": {
        "errorType": "errorObject",
        "errorObject": "{\n  \"title\": \"Techstack\",\n  \"message\": \"Unfortunately, we couldn’t identify the techstack from your RFP. Since this information is essential for the analysis, the process has been halted.\"\n}"
      },
      "type": "n8n-nodes-base.stopAndError",
      "typeVersion": 1,
      "position": [
        -3056,
        4848
      ],
      "id": "88dade38-8583-45fb-8761-fbf26f082855",
      "name": "Stop and Error4"
    },
    {
      "parameters": {
        "errorType": "errorObject",
        "errorObject": "{\n  \"title\": \"Team Composition\",\n  \"message\": \"Unfortunately, we couldn’t identify the team composition from your RFP. Since this information is essential for the analysis, the process has been halted.\"\n}"
      },
      "type": "n8n-nodes-base.stopAndError",
      "typeVersion": 1,
      "position": [
        -1248,
        4080
      ],
      "id": "b08f8c38-1be7-4013-81d3-2b39e2387da9",
      "name": "Stop and Error5"
    },
    {
      "parameters": {
        "errorType": "errorObject",
        "errorObject": "{\n  \"title\": \"Effort Estimation\",\n  \"message\": \"Unfortunately, something went wrong while generating the effort estimation. Please try again or upload a revised RFP if the issue persists.\"\n}"
      },
      "type": "n8n-nodes-base.stopAndError",
      "typeVersion": 1,
      "position": [
        768,
        4080
      ],
      "id": "2a72bbb0-1cea-40b4-a7b1-e5fc415f41b1",
      "name": "Stop and Error6"
    },
    {
      "parameters": {
        "errorType": "errorObject",
        "errorObject": "{\n  \"title\": \"Roadmap\",\n  \"message\": \"Unfortunately, something went wrong while generating the roadmap. Please try again or upload a revised RFP if the issue persists.\"\n}"
      },
      "type": "n8n-nodes-base.stopAndError",
      "typeVersion": 1,
      "position": [
        2480,
        4080
      ],
      "id": "794c61a6-35d8-455d-8348-e4cac1cf3b28",
      "name": "Stop and Error7"
    },
    {
      "parameters": {
        "errorType": "errorObject",
        "errorObject": "{\n  \"title\": \"Final Report\",\n  \"message\": \"Unfortunately, something went wrong while generating the final report. Please try again or upload a revised RFP if the issue persists.\"\n}"
      },
      "type": "n8n-nodes-base.stopAndError",
      "typeVersion": 1,
      "position": [
        3888,
        4160
      ],
      "id": "8e9be6b8-8c5d-433f-a586-ebb63c2c52d6",
      "name": "Stop and Error8"
    },
    {
      "parameters": {
        "command": "=rm -f /tmp/session_{{ $('Get Session ID and prepare file data').first().json.execution.id }}.json && echo \"Session file cleaned up\"\n"
      },
      "type": "n8n-nodes-base.executeCommand",
      "typeVersion": 1,
      "position": [
        4512,
        4432
      ],
      "id": "b8f7a29f-e783-48db-9838-5254680f765e",
      "name": "Delete tmp file"
    },
    {
      "parameters": {
        "options": {
          "responseCode": 200
        }
      },
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1.4,
      "position": [
        -3424,
        5744
      ],
      "id": "986aeff3-040e-41b5-bf9b-4120c0c2f152",
      "name": "Respond to Webhook"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ $json.userPrompt }}",
        "hasOutputParser": true,
        "options": {
          "systemMessage": "={{ $json.systemPrompt }}"
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.9,
      "position": [
        -3264,
        3552
      ],
      "id": "8950c9fb-6f46-438c-8c47-0bdd0ed5612b",
      "name": "Get Platforms"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "gpt-4.1-mini",
          "mode": "list",
          "cachedResultName": "gpt-4.1-mini"
        },
        "options": {
          "temperature": 0.1
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        1216,
        3952
      ],
      "id": "eb8cbc3d-519a-47c8-9822-21aa79540697",
      "name": "OpenAI Chat Model4",
      "credentials": {
        "openAiApi": {
          "id": "M8xqWvEC6mH6LNuk",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "gpt-4.1-mini",
          "mode": "list",
          "cachedResultName": "gpt-4.1-mini"
        },
        "options": {
          "temperature": 0.1
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        2128,
        3936
      ],
      "id": "a52c1c2c-1d66-4354-ad84-c9a85769fa2b",
      "name": "OpenAI Chat Model7",
      "credentials": {
        "openAiApi": {
          "id": "M8xqWvEC6mH6LNuk",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "gpt-4.1-mini",
          "mode": "list",
          "cachedResultName": "gpt-4.1-mini"
        },
        "options": {
          "temperature": 0.1
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        512,
        4704
      ],
      "id": "b4ecb9f0-c3fa-4f2c-8a99-53172b4fbccc",
      "name": "OpenAI Chat Model8",
      "credentials": {
        "openAiApi": {
          "id": "M8xqWvEC6mH6LNuk",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "qwen3-coder-30b-32k",
          "mode": "list",
          "cachedResultName": "qwen3-coder-30b-32k"
        },
        "options": {
          "responseFormat": "json_object",
          "temperature": 0.1
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        -3408,
        3760
      ],
      "id": "4d1af9f6-aa0f-4cf5-824c-66435fe5776b",
      "name": "vllm",
      "credentials": {
        "openAiApi": {
          "id": "09tIxrZPXx1gwPgx",
          "name": "vllm"
        }
      }
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "ibm-granite/granite-docling-258M",
          "mode": "list",
          "cachedResultName": "ibm-granite/granite-docling-258M"
        },
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        -4000,
        3824
      ],
      "id": "04408e49-7049-43a1-bef6-defd8bfd8dfe",
      "name": "Granite VLM",
      "credentials": {
        "openAiApi": {
          "id": "brOJKQDPVam7TIKg",
          "name": "Granite VLM"
        }
      }
    },
    {
      "parameters": {
        "url": "={{ $('Get Session ID and prepare file data').item.json.body.link }}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.3,
      "position": [
        -2864,
        2064
      ],
      "id": "432e321d-889f-41f6-be15-5051ab8881b9",
      "name": "Download File"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "http://192.168.20.74:8878/parse/file",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "accept",
              "value": "application/json"
            },
            {
              "name": "Authorization",
              "value": "Bearer dev-key"
            }
          ]
        },
        "sendBody": true,
        "contentType": "multipart-form-data",
        "bodyParameters": {
          "parameters": [
            {
              "parameterType": "formBinaryData",
              "name": "file",
              "inputDataFieldName": "data"
            },
            {
              "name": "optimize_pdf",
              "value": "true"
            },
            {
              "name": "enable_chunking",
              "value": "true"
            },
            {
              "name": "max_tokens_per_chunk",
              "value": "400"
            },
            {
              "name": "merge_peers",
              "value": "true"
            },
            {
              "name": "include_full_metadata",
              "value": "true"
            },
            {
              "name": "embedding_model",
              "value": "nomic-ai/nomic-embed-text-v1.5"
            },
            {
              "name": "serialize_tables",
              "value": "true"
            },
            {
              "name": "semantic_refinement",
              "value": "false"
            }
          ]
        },
        "options": {
          "response": {}
        }
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -2688,
        2064
      ],
      "id": "98c15812-112a-49fa-b7db-c08eefa413f5",
      "name": "Chunker Full"
    },
    {
      "parameters": {
        "jsCode": "\nconst newItems = items\n  .map(item => {\n    // ensure metadata path exists\n    const meta = item.json.metadata;\n    if (!meta) {\n      return null;\n    }\n    // check for table structure flag\n    if (meta.has_table_structure === true) {\n      return item;\n    }\n    return null;\n  })\n  .filter(item => item !== null);\n\n// Return filtered items\nreturn newItems;"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        352,
        1808
      ],
      "id": "71d5993f-37e8-45ea-99f8-b43704bc5796",
      "name": "Table only"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "http://192.168.20.74:8879/api/parse-and-chunk",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "accept",
              "value": "application/json"
            },
            {
              "name": "Authorization",
              "value": "Bearer dev-key"
            }
          ]
        },
        "sendBody": true,
        "contentType": "multipart-form-data",
        "bodyParameters": {
          "parameters": [
            {
              "parameterType": "formBinaryData",
              "name": "file",
              "inputDataFieldName": "data"
            },
            {
              "name": "optimize_pdf",
              "value": "false"
            },
            {
              "name": "enable_chunking",
              "value": "true"
            },
            {
              "name": "max_tokens_per_chunk",
              "value": "768"
            },
            {
              "name": "merge_peers",
              "value": "true"
            },
            {
              "name": "include_full_metadata",
              "value": "false"
            },
            {
              "name": "embedding_model",
              "value": "nomic-ai/nomic-embed-text-v1.5"
            },
            {
              "name": "serialize_tables",
              "value": "true"
            }
          ]
        },
        "options": {
          "response": {}
        }
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -2864,
        1840
      ],
      "id": "78341a5e-d115-4f3e-93d9-e9ca81f73d0a",
      "name": "Chunker VLM"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ $json.userPrompt }}",
        "hasOutputParser": true,
        "messages": {
          "messageValues": [
            {
              "message": "={{ $json.systemPrompt }}"
            }
          ]
        },
        "batching": {}
      },
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "typeVersion": 1.7,
      "position": [
        -2880,
        2368
      ],
      "id": "ef99859e-257e-405c-a7d8-06f57dc06d77",
      "name": "Optimize Chunks"
    },
    {
      "parameters": {
        "mode": "runOnceForEachItem",
        "jsCode": "const contextForPrompt = $json.text;\nconst contextForPrompt_id = $json.chunk_id;\nconst systemPrompt = `You are a metadata extraction specialist for RFP documents.\n\nYour task is to analyze document chunks and identify which topics they SUBSTANTIALLY discuss.\n\nCRITICAL RULES:\n1. Only assign topics that are CLEARLY and SUBSTANTIALLY present in the chunk\n2. A brief mention does NOT qualify - the chunk must meaningfully discuss the topic\n3. Most chunks should have 1-3 topics maximum\n4. When in doubt, DO NOT assign the topic\n5. Distinguish between RFP DOCUMENT information vs PROJECT information\n\nOutput valid JSON only, no explanations.`;\n\nconst userPrompt = `Analyze this chunk and identify which topics it SUBSTANTIALLY discusses.\n\nSELECTIVITY RULES:\n- Only assign a topic if the chunk contains MEANINGFUL information about it\n- Brief mentions or implied connections DO NOT count\n- Ask yourself: \"Could someone answer a specific question about this topic using ONLY this chunk?\"\n- If the answer is NO, don't assign that topic\n\nIMPORTANT DISTINCTION:\n- \"rfp_metadata\" = Information ABOUT the RFP document itself (submission process, deadlines, evaluation)\n- Other topics = Requirements/details about THE PROJECT to be built\n\nTOPIC DEFINITIONS:\n\nPROJECT-RELATED TOPICS (about the system/product to be built):\n\n\"project_context\" - ONLY if chunk explicitly discusses:\n  ✓ WHY the project is needed (business problems, pain points)\n  ✓ Current situation that needs improvement\n  ✓ Strategic goals or business objectives\n  ✗ NOT just because it mentions \"project\" or \"system\"\n\n\"platforms\" - ONLY if chunk explicitly names target platforms:\n  ✓ Web, mobile (iOS/Android), desktop, backend, API, admin panel\n  ✗ NOT just because it says \"application\" or \"website\"\n\n\"techstack\" - ONLY if chunk specifies actual technologies:\n  ✓ Programming languages, frameworks, databases (React, Python, PostgreSQL)\n  ✗ NOT just because it mentions \"technology\" or \"system\"\n\n\"greenfield\" - ONLY if chunk explicitly states:\n  ✓ Building new from scratch OR modifying existing system\n  ✗ NOT assumed - must be explicitly mentioned\n\n\"functional_requirements\" - ONLY if chunk describes what users/system can do:\n  ✓ User features, workflows, capabilities, business logic\n  ✓ System behavior, data processing, operations\n  ✓ \"Users can X\", \"System generates Y\", \"Application allows Z\"\n\n\"non_functional_requirements\" - ONLY if chunk specifies performance/quality attributes:\n  ✓ Performance metrics, security standards, scalability requirements\n  ✓ Usability requirements, accessibility standards (WCAG)\n  ✗ NOT functional features, even if security-related features\n\n\"integrations\" - ONLY if chunk names SPECIFIC third-party services:\n  ✓ Named services: Stripe, SendGrid, Auth0, Salesforce, Google Maps\n  ✗ NOT generic mentions like \"payment gateway\" or \"email service\"\n\n\"data_migration\" - ONLY if chunk discusses moving/importing existing data:\n  ✓ Migrating from old systems, importing records, ETL processes\n  ✗ NOT just database requirements or data storage\n\n\"regulatory_compliance\" - ONLY if chunk names SPECIFIC regulations:\n  ✓ GDPR, HIPAA, SOC2, ISO standards, PCI-DSS, legal requirements\n  ✗ NOT just \"secure\" or \"compliant\" without specifics\n\n\"delivery_details\" - ONLY if chunk discusses project timeline/phases:\n  ✓ MVP scope, sprint plans, milestones, delivery dates, phased rollout\n  ✗ NOT just deadline mentions without project phase details\n\n\"training_requirements\" - ONLY if chunk discusses training/documentation:\n  ✓ User training, admin training, knowledge transfer, training materials\n  ✗ NOT just \"documentation\" as a deliverable\n\n\"support_maintenance\" - ONLY if chunk discusses post-launch support:\n  ✓ Warranty periods, SLAs, maintenance contracts, support expectations\n  ✗ NOT just \"support\" mentioned casually\n\nRFP DOCUMENT TOPICS (about the RFP process itself):\n\n\"rfp_metadata\" - ONLY if chunk contains RFP administrative information:\n  ✓ RFP reference number, submission deadlines, contact information\n  ✓ Proposal format requirements, evaluation criteria, scoring weights\n  ✓ Client/company name in RFP header context\n  ✗ NOT project/product details\n\n---\n\nChunk to analyze:\n\"\"\"\n${contextForPrompt}\n\"\"\"\n\nChunk Id to pass on:\n\"\"\"\n${contextForPrompt_id}\n\"\"\"\n\n---\n\nEXAMPLE CLASSIFICATIONS:\n\nGood Examples (what to do):\n\nChunk: \"Users can create events with unique IDs. Each event is assigned a 12-character ID based on date and serial number.\"\nTopics: [\"functional_requirements\"]\nWhy: Describes system behavior and data structure - that's functional requirements only\n\nChunk: \"Our current spreadsheet system is error-prone and inefficient. We need a modern solution to reduce errors by 80%.\"\nTopics: [\"project_context\"]\nWhy: Explains current problems and business goals\n\nChunk: \"Must integrate with Stripe (payments) and SendGrid (emails)\"\nTopics: [\"integrations\"]\nWhy: Names specific third-party services\n\nChunk: \"The web app must work on iOS, Android, and modern browsers\"\nTopics: [\"platforms\"]\nWhy: Explicitly lists target platforms\n\nChunk: \"System must handle 10,000 concurrent users with <2s response time and 99.9% uptime\"\nTopics: [\"non_functional_requirements\"]\nWhy: Specifies performance and reliability metrics\n\nChunk: \"Must comply with GDPR and achieve SOC2 Type II certification\"\nTopics: [\"regulatory_compliance\"]\nWhy: Names specific compliance requirements\n\nChunk: \"Proposals due May 30, 2025 at 5pm to procurement@company.com. Include technical and cost proposals.\"\nTopics: [\"rfp_metadata\"]\nWhy: RFP submission instructions\n\nBad Examples (what to avoid):\n\nChunk: \"The system generates unique identifiers for tracking\"\nTopics: [] or [\"functional_requirements\"]\nNOT: [\"techstack\", \"platforms\", \"integrations\"]\nWhy: Only describes a feature - no tech, platform, or integration details\n\nChunk: \"Users must be able to securely login with password\"\nTopics: [\"functional_requirements\"]\nNOT: [\"non_functional_requirements\", \"security\"]\nWhy: Login is a functional feature. Security requirements would specify standards like \"must use bcrypt with 12 rounds\" or \"must support MFA\"\n\nChunk: \"The portal will be accessible online\"\nTopics: []\nNOT: [\"platforms\"]\nWhy: Too vague - \"online\" doesn't specify web vs mobile vs API\n\nCRITICAL: Be STRICT. When analyzing, ask yourself:\n1. Is this topic CLEARLY and SUBSTANTIALLY discussed? (not just implied)\n2. Could someone answer specific questions about this topic from this chunk alone?\n3. Is there actual INFORMATION here, or just a vague mention?\n\nIf you're unsure, DO NOT include the topic.\n\nOutput format (strict JSON):\n{\n  \"chunk_id\": \"chunk_id\",\n  \"chunk_text\": \"chunk\",\n  \"topics\": []\n}\n\nAnalyze the chunk now and return ONLY the JSON.`;\n\nreturn {\n  json: {\n    userPrompt,\n    systemPrompt\n  }\n};"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -2240,
        2368
      ],
      "id": "fff03a8e-da89-4b3f-b51c-841c7c13a99d",
      "name": "PreparePrompts - Metadata Enrichment"
    },
    {
      "parameters": {
        "operation": "upsert",
        "schema": {
          "__rl": true,
          "mode": "list",
          "value": "public"
        },
        "table": {
          "__rl": true,
          "value": "={{ $('Start RFP Analysis').first().json.body.indexName }}",
          "mode": "name"
        },
        "columns": {
          "mappingMode": "defineBelow",
          "value": {
            "chunk_id": "={{ $('Add Metadata to Original').item.json.chunk_id }}",
            "section_title": "={{ $('Add Metadata to Original').item.json.section_title }}",
            "text": "={{ $('Add Metadata to Original').item.json.text }}",
            "topics": "={{ $('Add Metadata to Original').item.json.metadata.topics }}",
            "metadata": "={{ $('Add Metadata to Original').item.json.metadata }}",
            "full_metadata": "={{ $('Add Metadata to Original').item.json.full_metadata }}",
            "embedding": "={{ $json.embedding }}"
          },
          "matchingColumns": [
            "chunk_id"
          ],
          "schema": [
            {
              "id": "id",
              "displayName": "id",
              "required": false,
              "defaultMatch": true,
              "display": true,
              "type": "string",
              "canBeUsedToMatch": true,
              "removed": true
            },
            {
              "id": "chunk_id",
              "displayName": "chunk_id",
              "required": true,
              "defaultMatch": false,
              "display": true,
              "type": "string",
              "canBeUsedToMatch": true,
              "removed": false
            },
            {
              "id": "section_title",
              "displayName": "section_title",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "type": "string",
              "canBeUsedToMatch": false
            },
            {
              "id": "text",
              "displayName": "text",
              "required": true,
              "defaultMatch": false,
              "display": true,
              "type": "string",
              "canBeUsedToMatch": false
            },
            {
              "id": "topics",
              "displayName": "topics",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "type": "array",
              "canBeUsedToMatch": false
            },
            {
              "id": "metadata",
              "displayName": "metadata",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "type": "object",
              "canBeUsedToMatch": false
            },
            {
              "id": "full_metadata",
              "displayName": "full_metadata",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "type": "object",
              "canBeUsedToMatch": false
            },
            {
              "id": "embedding",
              "displayName": "embedding",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "type": "string",
              "canBeUsedToMatch": false
            },
            {
              "id": "created_at",
              "displayName": "created_at",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "type": "dateTime",
              "canBeUsedToMatch": false
            },
            {
              "id": "updated_at",
              "displayName": "updated_at",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "type": "dateTime",
              "canBeUsedToMatch": false
            }
          ],
          "attemptToConvertTypes": false,
          "convertFieldsToString": false
        },
        "options": {}
      },
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.6,
      "position": [
        -704,
        2368
      ],
      "id": "dcf98385-1572-4b75-9503-b91b0ba525c0",
      "name": "Insert or update rows in a table",
      "credentials": {
        "postgres": {
          "id": "wK2pSCG9jTniRU28",
          "name": "Postgres account 2"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "const input = $input.all().map(item => item.json);\n\n// Normalize and test against known patterns\nfunction isTOC(title) {\n  if (!title || typeof title !== 'string') return false;\n\n  const normalized = title\n    .toLowerCase()\n    .replace(/[^a-z0-9]/g, ' ') // replace punctuation with space\n    .replace(/\\s+/g, ' ')       // collapse spaces\n    .trim();\n\n  const tocKeywords = [\n    'table of contents',\n    'table of content',\n    'contents',\n    'toc'\n  ];\n\n  return tocKeywords.some(keyword => normalized.includes(keyword));\n}\n\n// Filter out chunks where the title suggests it's TOC\nconst filtered = input.filter(chunk => {\n  const title = chunk.section_title || chunk.text || '';\n  return !isTOC(title);\n});\n\nreturn filtered.map(chunk => ({ json: chunk }));\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -2064,
        2064
      ],
      "id": "c3cca42a-551b-4941-ad51-1033747c9e3b",
      "name": "Remove TOC1",
      "alwaysOutputData": true
    },
    {
      "parameters": {
        "jsCode": "/**\n * Minimal, safe hygiene for embedding payloads.\n * - No manual JSON escaping\n * - Removes control chars (except \\n and \\t)\n * - Normalizes Unicode and whitespace\n * - Preserves existing indices\n */\n\nfunction normalizeText(s) {\n  if (!s) return \"\";\n  if (typeof s.normalize === \"function\") s = s.normalize(\"NFKC\"); // Unicode normalize\n  s = s.replace(/\\u00A0/g, ' ');                                  // NBSP -> space\n  s = s.replace(/[\\u0000-\\u0008\\u000B\\u000C\\u000E-\\u001F\\u007F-\\u009F]/g, ' '); // rm control (keep \\t,\\n)\n  s = s.replace(/\\r\\n?/g, '\\n');                                   // CRLF -> LF\n  s = s.replace(/[ \\t]+/g, ' ');                                   // collapse spaces/tabs\n  s = s.replace(/\\n{3,}/g, '\\n\\n');                                // limit consecutive newlines\n  return s.trim();\n}\n\nconst items = $input.all();\nconst out = [];\n\nfor (const item of items) {\n  let chunks;\n  if (Array.isArray(item.json)) chunks = item.json;\n  else if (Array.isArray(item.json?.chunks)) chunks = item.json.chunks;\n  else chunks = [item.json];\n\n  const sanitized = chunks.map((c) => {\n    const copy = { ...c };\n    if (copy.text != null) copy.text = normalizeText(copy.text);\n    if (copy.text_to_embed != null) copy.text_to_embed = normalizeText(copy.text_to_embed);\n    if (copy.section_title != null) copy.section_title = normalizeText(copy.section_title);\n\n    // keep source-of-truth indices; don't invent new ones here\n    if (!copy.vector_metadata) copy.vector_metadata = {};\n    if (copy.chunk_index != null && copy.vector_metadata.chunk_index == null) {\n      copy.vector_metadata.chunk_index = copy.chunk_index;\n    }\n    return copy;\n  });\n\n  if (Array.isArray(item.json)) out.push({ json: sanitized });\n  else if (Array.isArray(item.json?.chunks)) out.push({ json: { ...item.json, chunks: sanitized } });\n  else out.push({ json: sanitized[0] });\n}\n\nreturn out;\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1872,
        2064
      ],
      "id": "546f8c5a-ad70-4268-9f1d-f20b5b6fe437",
      "name": "Final Escaping1"
    },
    {
      "parameters": {
        "jsCode": "const slug = s => (s ?? \"\").toLowerCase()\n  .replace(/[^a-z0-9]+/g, '_')\n  .replace(/^_|_$/g, '')\n  .slice(0, 50);\n\nconst final = ($input.first()?.json?.data?.chunks ?? []).map((c, i) => {\n  const sectionTitle = c?.section_title ?? \"\";\n  const text = c?.text ?? \"\";\n  const chunkIndex = c?.chunk_index ?? \"\";\n\n  const chunkId = `${slug(sectionTitle)}_${i}`;\n  const metadata = {\n    ...(c?.metadata ?? {}),\n    chunk_index: chunkIndex\n  };\n  const full_metadata = c.full_metadata;\n\n  // Remove heading_path if it exists\n  //if (\"heading_path\" in metadata) {\n    //delete metadata.heading_path;\n // }\n\n  return {\n    section_title: sectionTitle,\n    chunk_id: chunkId,\n    text: text,\n    metadata: metadata,\n    full_metadata:full_metadata\n  };\n});\n\nreturn final.map(j => ({ json: j }));\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -2496,
        2064
      ],
      "id": "4bca7a3c-459c-4604-a678-f10926d3f66a",
      "name": "Format Output1"
    },
    {
      "parameters": {
        "jsonSchemaExample": "{\n  \"chunk_id\": \"chunk_id\",\n  \"chunk_text\": \"chunk\",\n  \"topics\": []\n}",
        "autoFix": true
      },
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "typeVersion": 1.3,
      "position": [
        -1648,
        2592
      ],
      "id": "9d9eb931-937c-42fd-b6a1-8670c0e7b948",
      "name": "Topics"
    },
    {
      "parameters": {
        "jsonSchemaExample": "{\n  \"chunk_id\": \"${contextForPromptChunkId}\",\n  \"needs_splitting\": true,\n  \"reason\": \"brief reason why splitting or why not\",\n  \"sub_chunks\": [\n    {\n      \"text\": \"sub-chunk content with preserved formatting and numbering\",\n      \"topic\": \"brief human-readable description of what this sub-chunk is about\"\n    }\n  ]\n}",
        "autoFix": true
      },
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "typeVersion": 1.3,
      "position": [
        -2560,
        2608
      ],
      "id": "48997e4f-52e1-42aa-a8fb-ccdf08c57ce6",
      "name": "Subchunking"
    },
    {
      "parameters": {
        "jsCode": "// Assuming input is array of chunks\nconst chunks = $input.all().map(item => item.json);\n\n// Simple token estimation: ~4 characters per token (rough but fast)\nfunction estimateTokens(text) {\n  return Math.ceil(text.length / 4);\n}\n\n// Filter chunks that need splitting (>= 200 tokens)\nconst chunksNeedingSplitting = chunks.filter(chunk => {\n  const tokenCount = estimateTokens(chunk.text);\n  return tokenCount >= 300;\n});\n\n// Return only chunks that need splitting\nreturn chunksNeedingSplitting.map(chunk => ({\n  json: {\n    ...chunk,\n    estimated_tokens: estimateTokens(chunk.text)\n  }\n}));"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -3264,
        2368
      ],
      "id": "ada42563-3f1f-4bfd-ad5f-44ae99205641",
      "name": "Only Big Chunks"
    },
    {
      "parameters": {
        "mode": "runOnceForEachItem",
        "jsCode": "const contextForPromptText = $json.text;\nconst contextForPromptChunkId = $json.chunk_id;\nconst contextForPromptMetadata = $json.metadata;\n\nconst systemPrompt = `You are an RFP document chunking specialist optimizing chunks for semantic search.\n\nCORE RULES:\n1. Target: 200-350 tokens per sub-chunk\n2. Minimum: 100 tokens per sub-chunk (NEVER go below this)\n3. Maximum: 5 sub-chunks per original chunk\n4. Each sub-chunk must be independently understandable\n\nOutput valid JSON only.`;\n\nconst userPrompt = `Analyze this chunk and decide if it needs splitting.\n\n⚠️ MANDATORY SPLITTING CRITERIA (split if ANY apply):\n1. Chunk exceeds 500 tokens\n2. Contains 10+ numbered/bulleted items\n3. Mixes multiple distinct topics (e.g., technical requirements + RFP deadlines)\n4. Combines PROJECT requirements with RFP PROCESS information\n\n📋 HOW TO SPLIT LISTS:\n- For lists with 10+ items: Split into groups of 4-6 related items\n- Each group should be 200-350 tokens\n- Keep list context/header with first group\n- Preserve all numbering\n\nExample for 12-item list:\n✅ Sub-chunk 1: \"Features 1-6: [inventory tracking, scanning, transfers, replenishment, picking, returns]\"\n✅ Sub-chunk 2: \"Features 7-12: [traceability, cycle counting, mobile app, dashboard, reporting, user management]\"\n❌ Sub-chunk 1: \"All 12 features together\" (if >500 tokens)\n❌ Sub-chunk 1: \"Feature 1\" (too granular)\n\n🔒 STRICT MINIMUM ENFORCEMENT:\n- If a sub-chunk would be <100 tokens, MERGE it with adjacent content\n- Single sentences MUST be merged, never standalone\n- Confidentiality notices, deadlines, Q&A info: merge together as \"RFP Process Details\"\n\n✅ DO split:\n- Chunks >500 tokens\n- Lists >10 items\n- Mixed PROJECT + PROCESS content\n- Multiple distinct technical topics\n\n❌ DON'T split:\n- Chunks <400 tokens with single topic\n- Lists <10 items (unless >400 tokens total)\n- Cohesive narratives about one topic\n\n---\n\nChunk to analyze:\n\"\"\"\n${contextForPromptText}\n\"\"\"\n\nChunk ID: ${contextForPromptChunkId}\nMetadata: ${JSON.stringify(contextForPromptMetadata)}\n\n---\n\nOutput JSON:\n{\n  \"chunk_id\": \"${contextForPromptChunkId}\",\n  \"needs_splitting\": true/false,\n  \"reason\": \"why split or not - mention token count if relevant\",\n  \"sub_chunks\": [\n    {\n      \"text\": \"sub-chunk text with full context\",\n      \"topic\": \"brief description\"\n    }\n  ]\n}\n\nVALIDATION: Before submitting, verify:\n- If needs_splitting=true: created 2-5 sub-chunks, each 100+ tokens\n- If needs_splitting=false: original chunk is <500 tokens\n- No sub-chunk is <100 tokens`;\n\nreturn {\n  json: {\n    userPrompt,\n    systemPrompt\n  }\n};"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -3072,
        2368
      ],
      "id": "ddf4b5c3-dad3-49a9-bb0a-521a37a658aa",
      "name": "PreparePrompts - subchunking"
    },
    {
      "parameters": {
        "mode": "runOnceForEachItem",
        "jsCode": "const contextForPromptText = $json.text;\nconst contextForPromptChunkId = $json.chunk_id;\n\nconst systemPrompt = `You are a document chunking optimization specialist. Your task is to analyze document chunks and split them into smaller, semantically coherent sub-chunks when needed for optimal RAG retrieval.\n\nRules:\n1. Split chunks that contain multiple distinct topics, concepts, or document sections\n2. Each sub-chunk should focus on ONE clear topic or section\n3. Target 150-500 tokens per sub-chunk for optimal embedding\n4. Preserve complete original text - no content loss\n5. Keep naturally cohesive paragraphs together\n6. Each sub-chunk must be independently understandable\n7. Pass on the original chunk_id\n\nOutput valid JSON only, no explanations.`;\n\n// 3. Define the user prompt\nconst userPrompt = `Analyze this chunk and determine if it should be split into smaller, focused sub-chunks for better semantic retrieval.\n\nSplit criteria:\n- Multiple distinct topics/sections\n- Mixed content types (narrative + tables/lists)\n- Topic shifts within the text\n- Size exceeds ~500 tokens\nFor sections with multiple feature categories (bulleted lists with subsections), consider splitting by logical feature groupings if the section exceeds 250 tokens.\n\nOriginal chunk:\n${contextForPromptText}\n---------\nOriginal chunk_id:\n${contextForPromptChunkId}\n---------\nIf no splitting needed, return single sub-chunk with original text. \n\nThis must be json ouput structure:\n\n{\n  \"chunk\": \"original_chunk\",\n  \"chunk_id\": \"chunk_id\",\n  \"needs_splitting\": true,\n  \"reason\": \"brief reason if splitting\",\n  \"sub_chunks\": [\n    {\n      \"sub_chunk_id\": 1,\n      \"text\": \"sub-chunk content\",\n      \"topic\": \"brief topic description\"\n    }\n  ]\n}\n`;\n\nreturn {\n  json: {\n    userPrompt,\n    systemPrompt: systemPrompt\n  }\n};"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1648,
        1808
      ],
      "id": "87482f35-4d24-43ed-bf3b-758ba0f59357",
      "name": "PreparePrompts - subchunking2"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "qwen3-coder-30b-32k",
          "mode": "list",
          "cachedResultName": "qwen3-coder-30b-32k"
        },
        "options": {
          "maxTokens": 6000,
          "responseFormat": "json_object",
          "temperature": 0,
          "topP": 0.9
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        -1872,
        2560
      ],
      "id": "153a517a-49c7-496f-beb1-a5e85c45ff09",
      "name": "Qwen",
      "credentials": {
        "openAiApi": {
          "id": "09tIxrZPXx1gwPgx",
          "name": "vllm"
        }
      }
    },
    {
      "parameters": {
        "mode": "runOnceForEachItem",
        "jsCode": "const contextForPrompt = $json.text;\n\nconst systemPrompt = `You are an RFP metadata extraction specialist.\n\nAnalyze chunks and identify topics they SUBSTANTIALLY discuss (not just mention).\n\nRules:\n- Only assign topics with CLEAR, MEANINGFUL information\n- Most chunks = 1-3 topics max\n- When unsure, DO NOT assign\n- Distinguish: RFP document info vs. project requirements\n\nOutput valid JSON only.`;\n\nconst userPrompt = `Identify topics this chunk SUBSTANTIALLY discusses.\n\nSELECTIVITY: Only assign if chunk answers specific questions about that topic. Brief mentions don't count.\n\nTOPICS:\n\nPROJECT (about system being built):\n- project_context - WHY project needed, business goals, current problems\n- platforms - Explicit platforms: web/mobile/desktop/API (not just \"app\")\n- techstack - Specific tech: React/Python/PostgreSQL (not just \"technology\")\n- greenfield - Explicitly states new vs. existing system modification\n- functional_requirements - What system/users DO: features, workflows, capabilities\n- non_functional_requirements - HOW system performs: performance metrics, security standards, scalability\n- integrations - Named services: Stripe/SendGrid/Auth0 (not generic \"payment gateway\")\n- data_migration - Moving/importing existing data, ETL\n- regulatory_compliance - Named regulations: GDPR/HIPAA/SOC2\n- delivery_details - Timeline, MVP, sprints, milestones, phases\n- training_requirements - User training, documentation, knowledge transfer\n- support_maintenance - Post-launch support, warranty, SLAs\n\nRFP DOCUMENT (about RFP process):\n- rfp_metadata - Deadlines, contact info, evaluation criteria, submission format\n\nChunk:\n\"\"\"\n${contextForPrompt}\n\"\"\"\n\nExamples:\n\n✓ \"Users create events with 12-char IDs (date+serial+system code)\"\n→ {\"topics\": [\"functional_requirements\"]}\n(Describes system behavior only)\n\n✓ \"Current spreadsheet system error-prone, need 80% error reduction\"\n→ {\"topics\": [\"project_context\"]}\n\n✓ \"Integrate Stripe (payments) & SendGrid (email)\"\n→ {\"topics\": [\"integrations\"]}\n\n✓ \"iOS, Android, web browsers\"\n→ {\"topics\": [\"platforms\"]}\n\n✓ \"10K concurrent users, <2s response, 99.9% uptime\"\n→ {\"topics\": [\"non_functional_requirements\"]}\n\n✓ \"Comply with GDPR and SOC2 Type II\"\n→ {\"topics\": [\"regulatory_compliance\"]}\n\n✓ \"Proposals due May 30 to contact@company.com\"\n→ {\"topics\": [\"rfp_metadata\"]}\n\n✗ \"System generates unique identifiers\"\n→ {\"topics\": [\"functional_requirements\"]}\nNOT: techstack, platforms (no tech/platform mentioned)\n\n✗ \"Users securely login with password\"\n→ {\"topics\": [\"functional_requirements\"]}\nNOT: non_functional_requirements (login is a feature, not performance/security metric)\n\n✗ \"Portal accessible online\"\n→ {\"topics\": []}\n(Too vague - not enough detail for any topic)\n\nValidation questions:\n1. Is topic CLEARLY discussed (not implied)?\n2. Can someone answer questions about it from this chunk?\n3. Actual information present (not vague mention)?\n\nIf unsure → DON'T assign.\n\nOutput JSON only:\n{\"topics\": []}`;\n\nreturn {\n  json: {\n    userPrompt,\n    systemPrompt\n  }\n};"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1872,
        1808
      ],
      "id": "1807bd8d-2786-4ba5-9875-fc8b3c5ac4fb",
      "name": "PreparePrompts - Metadata - short"
    },
    {
      "parameters": {
        "modelName": "models/gemini-2.5-flash-lite",
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "typeVersion": 1,
      "position": [
        -2992,
        2608
      ],
      "id": "ea2e38de-73d2-4d27-874b-8632fa403c68",
      "name": "Google Gemini - Free",
      "credentials": {
        "googlePalmApi": {
          "id": "TJ0yEUGcCyO1AqYW",
          "name": "Google Gemini - Free"
        }
      }
    },
    {
      "parameters": {
        "modelName": "models/gemini-2.5-flash-lite",
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "typeVersion": 1,
      "position": [
        -1984,
        2704
      ],
      "id": "7c1b77b3-5505-4e15-9d22-11094f8a511a",
      "name": "Google Gemini - Payed",
      "credentials": {
        "googlePalmApi": {
          "id": "Ix2j2Yr3QW5lFklE",
          "name": "Google Gemini - ZM"
        }
      }
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ $json.userPrompt }}",
        "hasOutputParser": true,
        "needsFallback": true,
        "messages": {
          "messageValues": [
            {
              "message": "={{ $json.systemPrompt }}"
            }
          ]
        },
        "batching": {}
      },
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "typeVersion": 1.7,
      "position": [
        -1984,
        2368
      ],
      "id": "ac4ad0a1-9b5b-402d-b608-4ce03bc70ec9",
      "name": "Optimize Chunks - Metadata"
    },
    {
      "parameters": {
        "jsCode": "const originalChunks = $('Add topic to Text').all();\nconst llmResults = $input.all();\n\n// Create topics map\nconst topicsMap = new Map();\nllmResults.forEach(result => {\n  const output = result.json.output || result.json;\n  if (output.chunk_id && output.topics) {\n    topicsMap.set(output.chunk_id, output.topics);\n  }\n});\n\n// Merge topics into original chunks\nconst enrichedChunks = originalChunks.map(chunk => {\n  const topics = topicsMap.get(chunk.json.chunk_id);\n  \n  if (!topics) {\n    console.warn(`⚠️  No topics found for chunk_id: ${chunk.json.chunk_id}`);\n  }\n  \n  return {\n    json: {\n      ...chunk.json,\n      metadata: {\n        ...chunk.json.metadata,\n        topics: topics || [] // Add topics to metadata\n      }\n    }\n  };\n});\n\n// Log statistics\nconst chunksWithTopics = enrichedChunks.filter(c => c.json.metadata.topics && c.json.metadata.topics.length > 0).length;\nconsole.log(`✅ Enriched ${chunksWithTopics}/${enrichedChunks.length} chunks with topics`);\n\nreturn enrichedChunks;"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1536,
        2368
      ],
      "id": "ee76cf08-43b2-4685-a65e-12669b5afeba",
      "name": "Add Metadata to Original"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "http://192.168.20.70:11434/api/embed",
        "sendBody": true,
        "bodyParameters": {
          "parameters": [
            {
              "name": "model",
              "value": "nomic-embed-text:latest"
            },
            {
              "name": "input",
              "value": "={{ $('Prepare Embedding Text').item.json.text }}"
            }
          ]
        },
        "options": {}
      },
      "id": "838c7a51-a3b6-4114-9209-dd64e3c201d1",
      "name": "Embed Chunks1",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -1088,
        2368
      ]
    },
    {
      "parameters": {
        "mode": "runOnceForEachItem",
        "jsCode": "const input = $json;\nreturn {\n  json: {\n    embedding: input.embeddings[0]\n  }\n};"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -880,
        2368
      ],
      "id": "c843b1b1-9b46-4e29-81d5-e056f2aee0a8",
      "name": "Embedding Isolated1"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://sse-estimation-tool.onrender.com/progress",
        "sendBody": true,
        "contentType": "raw",
        "rawContentType": "application/json",
        "body": "={{ $json.body }}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -336,
        2368
      ],
      "id": "95b16671-f275-41d4-b147-35f76a944c4d",
      "name": "SSE - Document Preparation1"
    },
    {
      "parameters": {
        "jsCode": "// Get sessionId from the RFP Upload node\nconst sessionId = $('Start RFP Analysis').first().json.body.sessionId || \"no-session\";\n\n// Transform into the desired format\n// return [{\n//   json: {\n//     step: \"document_preparation\",\n//     title: \"Step 1: Document Preparation\", \n//     sessionId: sessionId,\n//     output: JSON.stringify(outputData || {})\n//   }\n// }];\n\nconst payload = {\n    step: \"document_preparation\",\n    title: \"Step 1: Document Preparation\", \n    sessionId: sessionId,\n    output: \"Document parsed\"\n};\n\nreturn [\n  {\n    json: {\n      body: JSON.stringify(payload)\n    }\n  }\n];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -512,
        2368
      ],
      "id": "8021c445-417f-4263-9903-33e1bcecd047",
      "name": "Prepare for frontend1"
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 3,
      "position": [
        1264,
        3216
      ],
      "id": "a06ee37e-444a-4aab-b9f6-aafe2872ed63",
      "name": "AI Agent"
    },
    {
      "parameters": {
        "operation": "deleteRows",
        "dataTableId": {
          "__rl": true,
          "value": "qS4XuYo2wZl1DdYR",
          "mode": "list",
          "cachedResultName": "Estimation Tool",
          "cachedResultUrl": "/projects/NM7VZoSXkcKo262s/datatables/qS4XuYo2wZl1DdYR"
        },
        "filters": {
          "conditions": [
            {
              "keyName": "execution_id",
              "keyValue": "={{ $('Error Trigger').item.json.execution.id }}"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.dataTable",
      "typeVersion": 1,
      "position": [
        4528,
        4608
      ],
      "id": "45d238b5-36be-4601-b91a-4076be9ef83d",
      "name": "Delete row(s)"
    },
    {
      "parameters": {
        "dataTableId": {
          "__rl": true,
          "value": "qS4XuYo2wZl1DdYR",
          "mode": "list",
          "cachedResultName": "Estimation Tool",
          "cachedResultUrl": "/projects/NM7VZoSXkcKo262s/datatables/qS4XuYo2wZl1DdYR"
        },
        "columns": {
          "mappingMode": "defineBelow",
          "value": {
            "execution_id": "={{ $json.executionId }}",
            "session_id": "={{ $json.sessionId }}"
          },
          "matchingColumns": [],
          "schema": [
            {
              "id": "session_id",
              "displayName": "session_id",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "type": "string",
              "readOnly": false,
              "removed": false
            },
            {
              "id": "execution_id",
              "displayName": "execution_id",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "type": "string",
              "readOnly": false,
              "removed": false
            }
          ],
          "attemptToConvertTypes": false,
          "convertFieldsToString": false
        },
        "options": {
          "optimizeBulk": false
        }
      },
      "type": "n8n-nodes-base.dataTable",
      "typeVersion": 1,
      "position": [
        -3072,
        2064
      ],
      "id": "37e97d87-925d-45ef-81f8-6c6f8f7c89d3",
      "name": "Add Execution id"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "qwen3-coder-30b-32k",
          "mode": "list",
          "cachedResultName": "qwen3-coder-30b-32k"
        },
        "options": {
          "maxTokens": 6000,
          "responseFormat": "json_object",
          "temperature": 0,
          "topP": 0.9
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        -2688,
        2544
      ],
      "id": "cd59d2c0-da9c-44f2-ac44-7272c111cc8b",
      "name": "Qwen1",
      "credentials": {
        "openAiApi": {
          "id": "09tIxrZPXx1gwPgx",
          "name": "vllm"
        }
      }
    },
    {
      "parameters": {
        "modelName": "models/gemini-2.5-flash-lite",
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "typeVersion": 1,
      "position": [
        -2864,
        2608
      ],
      "id": "a77e37e1-9a53-44a2-8f5c-83da27c2e11b",
      "name": "Google Gemini - Payed1",
      "credentials": {
        "googlePalmApi": {
          "id": "Ix2j2Yr3QW5lFklE",
          "name": "Google Gemini - ZM"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "const originalChunks = $('Final Escaping1').all().map(item => item.json);\nconst subchunkResults = $input.all().map(item => item.json);\n\n// Create a map of chunk_id -> sub_chunks\nconst subchunksMap = new Map();\nsubchunkResults.forEach(result => {\n  const output = result.output || result;\n  if (output.sub_chunks && output.sub_chunks.length > 0) {\n    subchunksMap.set(output.chunk_id, output.sub_chunks);\n  }\n});\n\n// Process each original chunk\nconst processedChunks = [];\n\noriginalChunks.forEach(chunk => {\n  const subchunks = subchunksMap.get(chunk.chunk_id);\n  \n  if (subchunks && subchunks.length > 1) {\n    // Has multiple sub-chunks, create separate entries for each\n    subchunks.forEach((subchunk, index) => {\n      processedChunks.push({\n        section_title: chunk.section_title,\n        chunk_id: `${chunk.chunk_id}_sub${index + 1}`,\n        text: subchunk.text,\n        metadata: {\n          ...chunk.metadata,\n          parent_chunk_id: chunk.chunk_id,\n          subchunk_index: index + 1,\n          total_subchunks: subchunks.length,\n          subchunk_topic: subchunk.topic\n        },\n        full_metadata: chunk.full_metadata\n      });\n    });\n  } else if (subchunks && subchunks.length === 1) {\n    // Single sub-chunk (no split), keep original but update text if different\n    processedChunks.push({\n      ...chunk,\n      text: subchunks[0].text,\n      metadata: {\n        ...chunk.metadata,\n        subchunk_topic: subchunks[0].topic,\n        was_subchunked: false\n      }\n    });\n  } else {\n    // No sub-chunks found (shouldn't happen, but handle it)\n    processedChunks.push({\n      ...chunk,\n      metadata: {\n        ...chunk.metadata,\n        was_subchunked: false\n      }\n    });\n  }\n});\n\n// Log statistics\nconst originalCount = originalChunks.length;\nconst processedCount = processedChunks.length;\nconsole.log(`✅ Processed ${originalCount} original chunks into ${processedCount} final chunks`);\nconsole.log(`📊 Expansion ratio: ${(processedCount / originalCount).toFixed(2)}x`);\n\nreturn processedChunks.map(chunk => ({ json: chunk }));"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -2592,
        2368
      ],
      "id": "34c9cbee-4427-4677-9f3f-19a38da12b31",
      "name": "Merge with original chunks"
    },
    {
      "parameters": {
        "jsCode": "const allChunks = $input.all().map(item => item.json);\n\n// Filter to only subchunked chunks (those with _sub in chunk_id)\nconst subchunkedOnly = allChunks.filter(chunk => {\n  return chunk.chunk_id.includes('_sub') || \n         chunk.metadata?.parent_chunk_id ||\n         chunk.metadata?.total_subchunks > 1;\n});\n\n// Group by parent for easier viewing\nconst groupedByParent = {};\nsubchunkedOnly.forEach(chunk => {\n  const parentId = chunk.metadata?.parent_chunk_id || chunk.chunk_id.replace(/_sub\\d+$/, '');\n  \n  if (!groupedByParent[parentId]) {\n    groupedByParent[parentId] = {\n      parent_id: parentId,\n      total_subchunks: chunk.metadata?.total_subchunks || 0,\n      subchunks: []\n    };\n  }\n  \n  groupedByParent[parentId].subchunks.push({\n    chunk_id: chunk.chunk_id,\n    subchunk_index: chunk.metadata?.subchunk_index,\n    topic: chunk.metadata?.subchunk_topic,\n    text_preview: chunk.text,\n    text_length: chunk.text.length,\n    estimated_tokens: Math.ceil(chunk.text.length / 4)\n  });\n});\n\n// Convert to array and sort\nconst grouped = Object.values(groupedByParent).map(group => {\n  group.subchunks.sort((a, b) => a.subchunk_index - b.subchunk_index);\n  return group;\n});\n\n// Statistics\nconst stats = {\n  total_chunks: allChunks.length,\n  subchunked_chunks: subchunkedOnly.length,\n  parent_chunks_split: grouped.length,\n  chunks_not_split: allChunks.length - subchunkedOnly.length,\n  expansion_ratio: (subchunkedOnly.length / grouped.length).toFixed(2)\n};\n\nconsole.log('📊 Subchunking Statistics:');\nconsole.log(`   Total chunks: ${stats.total_chunks}`);\nconsole.log(`   Chunks that were split: ${stats.parent_chunks_split}`);\nconsole.log(`   Resulting subchunks: ${stats.subchunked_chunks}`);\nconsole.log(`   Chunks NOT split: ${stats.chunks_not_split}`);\nconsole.log(`   Avg subchunks per parent: ${stats.expansion_ratio}x`);\n\nconsole.log('\\n🔍 Subchunked Chunks by Parent:');\ngrouped.forEach(group => {\n  console.log(`\\n📦 Parent: ${group.parent_id} (${group.total_subchunks} subchunks)`);\n  group.subchunks.forEach(sub => {\n    console.log(`   └─ ${sub.chunk_id}`);\n    console.log(`      Topic: ${sub.topic}`);\n    console.log(`      Tokens: ~${sub.estimated_tokens}`);\n    console.log(`      Preview: ${sub.text_preview}`);\n  });\n});\n\n// Return grouped structure for further processing\nreturn grouped.map(group => ({ json: group }));"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -2256,
        2560
      ],
      "id": "62b7c429-54c7-4c60-838a-fc24fa750dab",
      "name": "Only subchunked"
    },
    {
      "parameters": {
        "jsCode": "// Add subchunk_topic to text if it exists\nconst chunks = $input.all().map(item => item.json);\n\nconst enrichedChunks = chunks.map(chunk => {\n  // Check if subchunk_topic exists in metadata\n  const subchunkTopic = chunk.metadata?.subchunk_topic;\n  \n  if (subchunkTopic) {\n    // Prepend topic as a header to the text\n    chunk.text = `## ${subchunkTopic}\\n\\n${chunk.text}`;\n  }\n  \n  return chunk;\n});\n\nreturn enrichedChunks.map(chunk => ({ json: chunk }));"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -2432,
        2368
      ],
      "id": "f6680943-6272-4811-a9bb-9309a16d9b13",
      "name": "Add topic to Text"
    },
    {
      "parameters": {
        "jsCode": "const chunks = $input.all().map(item => item.json);\n\nconst cleanedChunks = chunks.map(chunk => {\n  // Remove \"search_document:\" or \"search_documents:\" prefix (case insensitive)\n  chunk.text = chunk.text.replace(/^search_documents?:\\s*/i, '');\n  \n  return chunk;\n});\n\nreturn cleanedChunks.map(chunk => ({ json: chunk }));"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -2288,
        2064
      ],
      "id": "e3422356-b9d4-48b4-93df-a8558ba97018",
      "name": "Remove Search Documents prefix"
    },
    {
      "parameters": {
        "jsCode": "const chunks = $input.all().map(item => item.json);\n\nconst prefixedChunks = chunks.map(chunk => {\n  // Only add prefix if it doesn't already exist\n  if (!chunk.text.match(/^search_documents?:\\s*/i)) {\n    chunk.text = `search_document: ${chunk.text}`;\n  }\n  \n  return chunk.text;\n});\n\nreturn prefixedChunks.map(text => ({ json: { text } }));"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1296,
        2368
      ],
      "id": "3029252b-417b-45a9-befc-976ec956e5d0",
      "name": "Prepare Embedding Text"
    },
    {
      "parameters": {
        "workflowId": {
          "__rl": true,
          "value": "aKpGZQLxTLr3FkPY",
          "mode": "list",
          "cachedResultUrl": "/workflow/aKpGZQLxTLr3FkPY",
          "cachedResultName": "RFP Analysis Public - Ingestion"
        },
        "workflowInputs": {
          "mappingMode": "defineBelow",
          "value": {
            "sessionId": "={{ $json.body.sessionId }}",
            "md5": "={{ $json.body.md5 }}",
            "fileName": "={{ $json.body.fileName }}",
            "date": "={{ $json.body.date }}",
            "link": "={{ $json.body.link }}",
            "indexName": "={{ $json.body.indexName }}"
          },
          "matchingColumns": [],
          "schema": [
            {
              "id": "sessionId",
              "displayName": "sessionId",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "canBeUsedToMatch": true,
              "type": "string",
              "removed": false
            },
            {
              "id": "md5",
              "displayName": "md5",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "canBeUsedToMatch": true,
              "type": "string",
              "removed": false
            },
            {
              "id": "fileName",
              "displayName": "fileName",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "canBeUsedToMatch": true,
              "type": "string",
              "removed": false
            },
            {
              "id": "date",
              "displayName": "date",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "canBeUsedToMatch": true,
              "type": "string",
              "removed": false
            },
            {
              "id": "link",
              "displayName": "link",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "canBeUsedToMatch": true,
              "type": "string",
              "removed": false
            },
            {
              "id": "indexName",
              "displayName": "indexName",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "canBeUsedToMatch": true,
              "type": "string",
              "removed": false
            }
          ],
          "attemptToConvertTypes": false,
          "convertFieldsToString": true
        },
        "options": {}
      },
      "type": "n8n-nodes-base.executeWorkflow",
      "typeVersion": 1.3,
      "position": [
        -3744,
        2192
      ],
      "id": "a6b23e33-c874-49c0-96d1-7daab925098a",
      "name": "Call 'RFP Analysis Public - Ingestion'"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://sse-estimation-tool.onrender.com/progress",
        "sendBody": true,
        "contentType": "raw",
        "rawContentType": "application/json",
        "body": "={{ $json.body }}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -3344,
        2528
      ],
      "id": "5fd2fe1f-e26f-475f-823a-c920fb3b0276",
      "name": "SSE - Document Preparation"
    },
    {
      "parameters": {
        "jsCode": "// Get sessionId from the RFP Upload node\nconst sessionId = $('Start RFP Analysis').first().json.body.sessionId || \"no-session\";\n\n// Transform into the desired format\n// return [{\n//   json: {\n//     step: \"document_preparation\",\n//     title: \"Step 1: Document Preparation\", \n//     sessionId: sessionId,\n//     output: JSON.stringify(outputData || {})\n//   }\n// }];\n\nconst payload = {\n    step: \"document_preparation\",\n    title: \"Step 1: Document Preparation\", \n    sessionId: sessionId,\n    output: \"Document parsed\"\n};\n\nreturn [\n  {\n    json: {\n      body: JSON.stringify(payload)\n    }\n  }\n];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -3520,
        2528
      ],
      "id": "a406dbba-a87e-4713-8d5c-0a853fb22d68",
      "name": "Prepare for frontend"
    }
  ],
  "pinData": {
    "PreparePrompts - subchunking": [
      {
        "json": {
          "userPrompt": "Analyze this chunk and decide if it needs splitting.\n\n⚠️ MANDATORY SPLITTING CRITERIA (split if ANY apply):\n1. Chunk exceeds 500 tokens\n2. Contains 10+ numbered/bulleted items\n3. Mixes multiple distinct topics (e.g., technical requirements + RFP deadlines)\n4. Combines PROJECT requirements with RFP PROCESS information\n\n📋 HOW TO SPLIT LISTS:\n- For lists with 10+ items: Split into groups of 4-6 related items\n- Each group should be 200-350 tokens\n- Keep list context/header with first group\n- Preserve all numbering\n\nExample for 12-item list:\n✅ Sub-chunk 1: \"Features 1-6: [inventory tracking, scanning, transfers, replenishment, picking, returns]\"\n✅ Sub-chunk 2: \"Features 7-12: [traceability, cycle counting, mobile app, dashboard, reporting, user management]\"\n❌ Sub-chunk 1: \"All 12 features together\" (if >500 tokens)\n❌ Sub-chunk 1: \"Feature 1\" (too granular)\n\n🔒 STRICT MINIMUM ENFORCEMENT:\n- If a sub-chunk would be <100 tokens, MERGE it with adjacent content\n- Single sentences MUST be merged, never standalone\n- Confidentiality notices, deadlines, Q&A info: merge together as \"RFP Process Details\"\n\n✅ DO split:\n- Chunks >500 tokens\n- Lists >10 items\n- Mixed PROJECT + PROCESS content\n- Multiple distinct technical topics\n\n❌ DON'T split:\n- Chunks <400 tokens with single topic\n- Lists <10 items (unless >400 tokens total)\n- Cohesive narratives about one topic\n\n---\n\nChunk to analyze:\n\"\"\"\n**Request for Proposal (RFP)**\n**Project Title:** GreenLeaf Environmental Foundation Website Redesign & Development\n**RFP Reference Number:** GLF-WEB-2025-01\n**Issued By:** GreenLeaf Environmental Foundation\n**Issue Date:** April 22, 2025\n**Submission Deadline:** May 23, 2025, 17:00 CEST\n- ---\n**(Page 1 of 5)**\n**1. INTRODUCTION**\n**1.1 Purpose of the RFP** The GreenLeaf Environmental Foundation (\"GreenLeaf\", \"the Foundation\"), based in Zagreb, Croatia, invites proposals from qualified web design and development agencies (\"Vendors\") to redesign and develop its primary public-facing website (www.greenleaf-foundation.fict). The goal is to create a modern, engaging, accessible, and mobile-responsive website that effectively communicates our mission, showcases our projects, encourages community engagement, and facilitates online donations.\n**1.2 About GreenLeaf Environmental Foundation** Founded in 2010, GreenLeaf is a non-profit organization dedicated to promoting environmental conservation, sustainable practices, and ecological education within Croatia and the surrounding region. We focus on reforestation projects, wildlife protection initiatives, and community workshops. Our current website, launched in 2017, no longer meets our needs in terms of design, functionality, or user experience.\n\"\"\"\n\nChunk ID: _0\nMetadata: {\"content_type\":\"list\",\"heading_path\":null,\"pages\":[1,2],\"has_table_structure\":null,\"doc_items_count\":11,\"chunk_index\":0}\n\n---\n\nOutput JSON:\n{\n  \"chunk_id\": \"_0\",\n  \"needs_splitting\": true/false,\n  \"reason\": \"why split or not - mention token count if relevant\",\n  \"sub_chunks\": [\n    {\n      \"text\": \"sub-chunk text with full context\",\n      \"topic\": \"brief description\"\n    }\n  ]\n}\n\nVALIDATION: Before submitting, verify:\n- If needs_splitting=true: created 2-5 sub-chunks, each 100+ tokens\n- If needs_splitting=false: original chunk is <500 tokens\n- No sub-chunk is <100 tokens",
          "systemPrompt": "You are an RFP document chunking specialist optimizing chunks for semantic search.\n\nCORE RULES:\n1. Target: 200-350 tokens per sub-chunk\n2. Minimum: 100 tokens per sub-chunk (NEVER go below this)\n3. Maximum: 5 sub-chunks per original chunk\n4. Each sub-chunk must be independently understandable\n\nOutput valid JSON only."
        }
      },
      {
        "json": {
          "userPrompt": "Analyze this chunk and decide if it needs splitting.\n\n⚠️ MANDATORY SPLITTING CRITERIA (split if ANY apply):\n1. Chunk exceeds 500 tokens\n2. Contains 10+ numbered/bulleted items\n3. Mixes multiple distinct topics (e.g., technical requirements + RFP deadlines)\n4. Combines PROJECT requirements with RFP PROCESS information\n\n📋 HOW TO SPLIT LISTS:\n- For lists with 10+ items: Split into groups of 4-6 related items\n- Each group should be 200-350 tokens\n- Keep list context/header with first group\n- Preserve all numbering\n\nExample for 12-item list:\n✅ Sub-chunk 1: \"Features 1-6: [inventory tracking, scanning, transfers, replenishment, picking, returns]\"\n✅ Sub-chunk 2: \"Features 7-12: [traceability, cycle counting, mobile app, dashboard, reporting, user management]\"\n❌ Sub-chunk 1: \"All 12 features together\" (if >500 tokens)\n❌ Sub-chunk 1: \"Feature 1\" (too granular)\n\n🔒 STRICT MINIMUM ENFORCEMENT:\n- If a sub-chunk would be <100 tokens, MERGE it with adjacent content\n- Single sentences MUST be merged, never standalone\n- Confidentiality notices, deadlines, Q&A info: merge together as \"RFP Process Details\"\n\n✅ DO split:\n- Chunks >500 tokens\n- Lists >10 items\n- Mixed PROJECT + PROCESS content\n- Multiple distinct technical topics\n\n❌ DON'T split:\n- Chunks <400 tokens with single topic\n- Lists <10 items (unless >400 tokens total)\n- Cohesive narratives about one topic\n\n---\n\nChunk to analyze:\n\"\"\"\n* **Content Management System (CMS):** * User-friendly interface for non-technical staff to easily update text, images, blog posts, event listings, and project pages. * Flexible page templates. * User role management (e.g., Editor, Administrator). * Recommended CMS: WordPress (preferred), Drupal, or a comparable open-source platform. Justify any alternative recommendations. * **Responsive Design:** Fully responsive layout adapting seamlessly to desktop, tablet, and mobile devices. * **Core Pages:** Homepage, About Us (Mission, Team, History), Our Work (Projects section with filterable categories), Get Involved (Volunteer opportunities, Events calendar), News/Blog, Donate, Contact Us. * **Project Showcase:** Dynamic section to feature ongoing and past projects with descriptions, image galleries, impact metrics, and location maps (simple integration, e.g., embedded Google Maps). * **Events Calendar:** Ability to list upcoming events (workshops, cleanups, fundraisers) with details, dates, locations, and potentially simple RSVP/registration links (linking to external forms is acceptable for MVP). * **News/Blog:** Standard blog functionality with categories, tags, author attribution, and social sharing options. * **Donation Integration:** Seamless integration with GreenLeaf's existing third-party donation processor (details provided to shortlisted vendors). Prominent calls-to-action for donations. * **Contact Form:** Secure contact form with spam protection (e.g., reCAPTCHA). * **Search Functionality:** Site-wide search capability. * **Accessibility:** Compliance with WCAG 2.1 Level AA guidelines. * **Basic SEO:** Implementation of SEO best practices (semantic HTML, meta tags,\n\"\"\"\n\nChunk ID: _2\nMetadata: {\"content_type\":\"text\",\"heading_path\":null,\"pages\":[3,4],\"has_table_structure\":null,\"doc_items_count\":1,\"chunk_index\":2}\n\n---\n\nOutput JSON:\n{\n  \"chunk_id\": \"_2\",\n  \"needs_splitting\": true/false,\n  \"reason\": \"why split or not - mention token count if relevant\",\n  \"sub_chunks\": [\n    {\n      \"text\": \"sub-chunk text with full context\",\n      \"topic\": \"brief description\"\n    }\n  ]\n}\n\nVALIDATION: Before submitting, verify:\n- If needs_splitting=true: created 2-5 sub-chunks, each 100+ tokens\n- If needs_splitting=false: original chunk is <500 tokens\n- No sub-chunk is <100 tokens",
          "systemPrompt": "You are an RFP document chunking specialist optimizing chunks for semantic search.\n\nCORE RULES:\n1. Target: 200-350 tokens per sub-chunk\n2. Minimum: 100 tokens per sub-chunk (NEVER go below this)\n3. Maximum: 5 sub-chunks per original chunk\n4. Each sub-chunk must be independently understandable\n\nOutput valid JSON only."
        }
      },
      {
        "json": {
          "userPrompt": "Analyze this chunk and decide if it needs splitting.\n\n⚠️ MANDATORY SPLITTING CRITERIA (split if ANY apply):\n1. Chunk exceeds 500 tokens\n2. Contains 10+ numbered/bulleted items\n3. Mixes multiple distinct topics (e.g., technical requirements + RFP deadlines)\n4. Combines PROJECT requirements with RFP PROCESS information\n\n📋 HOW TO SPLIT LISTS:\n- For lists with 10+ items: Split into groups of 4-6 related items\n- Each group should be 200-350 tokens\n- Keep list context/header with first group\n- Preserve all numbering\n\nExample for 12-item list:\n✅ Sub-chunk 1: \"Features 1-6: [inventory tracking, scanning, transfers, replenishment, picking, returns]\"\n✅ Sub-chunk 2: \"Features 7-12: [traceability, cycle counting, mobile app, dashboard, reporting, user management]\"\n❌ Sub-chunk 1: \"All 12 features together\" (if >500 tokens)\n❌ Sub-chunk 1: \"Feature 1\" (too granular)\n\n🔒 STRICT MINIMUM ENFORCEMENT:\n- If a sub-chunk would be <100 tokens, MERGE it with adjacent content\n- Single sentences MUST be merged, never standalone\n- Confidentiality notices, deadlines, Q&A info: merge together as \"RFP Process Details\"\n\n✅ DO split:\n- Chunks >500 tokens\n- Lists >10 items\n- Mixed PROJECT + PROCESS content\n- Multiple distinct technical topics\n\n❌ DON'T split:\n- Chunks <400 tokens with single topic\n- Lists <10 items (unless >400 tokens total)\n- Cohesive narratives about one topic\n\n---\n\nChunk to analyze:\n\"\"\"\nalt text fields, XML sitemap generation).\n**2.3 Technical Requirements** * **Technology Stack:** Propose a suitable technology stack (e.g., PHP/MySQL for WordPress/Drupal). Justify choices based on performance, security, and maintainability. * **Hosting:** The website will be hosted on GreenLeaf's existing hosting provider (details provided later). Vendor to ensure compatibility. * **Performance:** Optimize for fast loading times (target Google PageSpeed Insights scores above 80 for mobile and desktop). * **Security:** Implement standard web security best practices (HTTPS, input sanitization, protection against common vulnerabilities like XSS, SQL injection). * **Browser Compatibility:** Support for the latest versions of major browsers (Chrome, Firefox, Safari, Edge).\n**2.4 Content Migration** * Vendor to propose a strategy for migrating essential content (approx. 50 existing blog posts, 10 project pages, core text pages) from the current website. Manual migration support by GreenLeaf staff is possible, but vendor should plan for structure and potential automated assistance.\n- ---\n**(Page 3 of 5)**\n**3. SUBMISSION GUIDELINES**\n**3.1 RFP Timeline** * RFP Issued: April 22, 2025 * Deadline for Questions: May 6, 2025 * Responses to Questions Issued: May 13, 2025 * **Proposal Submission Deadline:** **May 23, 2025, 17:00 CEST** * Vendor Presentations (Shortlisted): June 9-11, 2025 (Tentative) * Vendor Selection Notification: June 20, 2025 * Project Kick-off Target: July 1, 2025\n\"\"\"\n\nChunk ID: _3\nMetadata: {\"content_type\":\"list\",\"heading_path\":null,\"pages\":[3,4,5],\"has_table_structure\":null,\"doc_items_count\":7,\"chunk_index\":3}\n\n---\n\nOutput JSON:\n{\n  \"chunk_id\": \"_3\",\n  \"needs_splitting\": true/false,\n  \"reason\": \"why split or not - mention token count if relevant\",\n  \"sub_chunks\": [\n    {\n      \"text\": \"sub-chunk text with full context\",\n      \"topic\": \"brief description\"\n    }\n  ]\n}\n\nVALIDATION: Before submitting, verify:\n- If needs_splitting=true: created 2-5 sub-chunks, each 100+ tokens\n- If needs_splitting=false: original chunk is <500 tokens\n- No sub-chunk is <100 tokens",
          "systemPrompt": "You are an RFP document chunking specialist optimizing chunks for semantic search.\n\nCORE RULES:\n1. Target: 200-350 tokens per sub-chunk\n2. Minimum: 100 tokens per sub-chunk (NEVER go below this)\n3. Maximum: 5 sub-chunks per original chunk\n4. Each sub-chunk must be independently understandable\n\nOutput valid JSON only."
        }
      },
      {
        "json": {
          "userPrompt": "Analyze this chunk and decide if it needs splitting.\n\n⚠️ MANDATORY SPLITTING CRITERIA (split if ANY apply):\n1. Chunk exceeds 500 tokens\n2. Contains 10+ numbered/bulleted items\n3. Mixes multiple distinct topics (e.g., technical requirements + RFP deadlines)\n4. Combines PROJECT requirements with RFP PROCESS information\n\n📋 HOW TO SPLIT LISTS:\n- For lists with 10+ items: Split into groups of 4-6 related items\n- Each group should be 200-350 tokens\n- Keep list context/header with first group\n- Preserve all numbering\n\nExample for 12-item list:\n✅ Sub-chunk 1: \"Features 1-6: [inventory tracking, scanning, transfers, replenishment, picking, returns]\"\n✅ Sub-chunk 2: \"Features 7-12: [traceability, cycle counting, mobile app, dashboard, reporting, user management]\"\n❌ Sub-chunk 1: \"All 12 features together\" (if >500 tokens)\n❌ Sub-chunk 1: \"Feature 1\" (too granular)\n\n🔒 STRICT MINIMUM ENFORCEMENT:\n- If a sub-chunk would be <100 tokens, MERGE it with adjacent content\n- Single sentences MUST be merged, never standalone\n- Confidentiality notices, deadlines, Q&A info: merge together as \"RFP Process Details\"\n\n✅ DO split:\n- Chunks >500 tokens\n- Lists >10 items\n- Mixed PROJECT + PROCESS content\n- Multiple distinct technical topics\n\n❌ DON'T split:\n- Chunks <400 tokens with single topic\n- Lists <10 items (unless >400 tokens total)\n- Cohesive narratives about one topic\n\n---\n\nChunk to analyze:\n\"\"\"\n**3.2 Point of Contact** All inquiries regarding this RFP must be directed via email to:\n* Petra Novak, Communications Manager * Email: p.novak@greenleaf-foundation.fict (Fictional Email)\n*Please include \"RFP GLF-WEB-2025-01 Question\" in the subject line.* **3.3 Proposal Format** Proposals must be submitted electronically in PDF format to the Point of Contact by the deadline. Please include the following sections: 1. **Cover Letter:** Introduction and statement of understanding. 2. **Company Overview:** Background, relevant experience, team size, location. 3. **Project Understanding & Approach:** Demonstrate understanding of GreenLeaf's goals and outline your proposed methodology (discovery, design, development, testing, launch phases). 4. **Proposed Solution:** * Confirmation of meeting functional requirements. * Proposed CMS and technology stack justification. * UI/UX design approach and philosophy. * Approach to accessibility and responsive design. * Content migration strategy. * Basic SEO approach. 5. **Portfolio & Case Studies:** Provide links to at least 3 relevant website projects (non-profit or similar preferred) and brief descriptions/case studies. 6. **Proposed Project Team:** Roles and brief bios/experience of key personnel\n- assigned to this project.\n7. **Project Timeline:** Detailed timeline outlining key phases and deliverables. 8. **Pricing Proposal:** Detailed breakdown of costs (e.g., Design, Development,\n- Project Management, QA, Content Migration assistance, optional post-launch support). Specify fixed price or hourly rates with estimated hours per phase.\n9. **References:** Contact information for 2-3 client references.\n---\n\"\"\"\n\nChunk ID: _4\nMetadata: {\"content_type\":\"list\",\"heading_path\":null,\"pages\":[5,6,7],\"has_table_structure\":null,\"doc_items_count\":8,\"chunk_index\":4}\n\n---\n\nOutput JSON:\n{\n  \"chunk_id\": \"_4\",\n  \"needs_splitting\": true/false,\n  \"reason\": \"why split or not - mention token count if relevant\",\n  \"sub_chunks\": [\n    {\n      \"text\": \"sub-chunk text with full context\",\n      \"topic\": \"brief description\"\n    }\n  ]\n}\n\nVALIDATION: Before submitting, verify:\n- If needs_splitting=true: created 2-5 sub-chunks, each 100+ tokens\n- If needs_splitting=false: original chunk is <500 tokens\n- No sub-chunk is <100 tokens",
          "systemPrompt": "You are an RFP document chunking specialist optimizing chunks for semantic search.\n\nCORE RULES:\n1. Target: 200-350 tokens per sub-chunk\n2. Minimum: 100 tokens per sub-chunk (NEVER go below this)\n3. Maximum: 5 sub-chunks per original chunk\n4. Each sub-chunk must be independently understandable\n\nOutput valid JSON only."
        }
      },
      {
        "json": {
          "userPrompt": "Analyze this chunk and decide if it needs splitting.\n\n⚠️ MANDATORY SPLITTING CRITERIA (split if ANY apply):\n1. Chunk exceeds 500 tokens\n2. Contains 10+ numbered/bulleted items\n3. Mixes multiple distinct topics (e.g., technical requirements + RFP deadlines)\n4. Combines PROJECT requirements with RFP PROCESS information\n\n📋 HOW TO SPLIT LISTS:\n- For lists with 10+ items: Split into groups of 4-6 related items\n- Each group should be 200-350 tokens\n- Keep list context/header with first group\n- Preserve all numbering\n\nExample for 12-item list:\n✅ Sub-chunk 1: \"Features 1-6: [inventory tracking, scanning, transfers, replenishment, picking, returns]\"\n✅ Sub-chunk 2: \"Features 7-12: [traceability, cycle counting, mobile app, dashboard, reporting, user management]\"\n❌ Sub-chunk 1: \"All 12 features together\" (if >500 tokens)\n❌ Sub-chunk 1: \"Feature 1\" (too granular)\n\n🔒 STRICT MINIMUM ENFORCEMENT:\n- If a sub-chunk would be <100 tokens, MERGE it with adjacent content\n- Single sentences MUST be merged, never standalone\n- Confidentiality notices, deadlines, Q&A info: merge together as \"RFP Process Details\"\n\n✅ DO split:\n- Chunks >500 tokens\n- Lists >10 items\n- Mixed PROJECT + PROCESS content\n- Multiple distinct technical topics\n\n❌ DON'T split:\n- Chunks <400 tokens with single topic\n- Lists <10 items (unless >400 tokens total)\n- Cohesive narratives about one topic\n\n---\n\nChunk to analyze:\n\"\"\"\n**(Page 4 of 5)** **4. EVALUATION CRITERIA** Proposals will be evaluated based on the following criteria (weights are approximate):\n* **Understanding of Project Goals & Requirements (20%):** Demonstrated comprehension of GreenLeaf's needs and objectives. * **Proposed Solution & Technical Approach (30%):** Suitability of the proposed CMS, technology stack, design philosophy, approach to key requirements (responsiveness, accessibility, CMS usability). * **Vendor Experience & Portfolio (20%):** Proven track record with similar projects, quality of portfolio examples, client references. * **Project Plan & Timeline (10%):** Realism and clarity of the proposed project plan and timeline.\n* **Pricing & Value (20%):** Reasonableness and clarity of the proposed cost relative to the scope and perceived quality.\nGreenLeaf may shortlist vendors for presentations or interviews before making a final decision.\n**5. TERMS AND CONDITIONS**\n**5.1 Confidentiality** All information provided by GreenLeaf within this RFP or during the proposal process is confidential. Vendor proposals will also be treated as confidential by GreenLeaf.\n**5.2 Proposal Costs** GreenLeaf is not responsible for any costs incurred by Vendors in the preparation or submission of their proposals.\n**5.3 Contract Award** GreenLeaf reserves the right to accept or reject any or all proposals, to negotiate with vendors, and to cancel this RFP at any time. The selected Vendor will be expected to enter into a formal service agreement with GreenLeaf, the terms of which will be negotiated. Key terms will include scope, deliverables, timeline, payment schedule, intellectual property (GreenLeaf will own the final website code and design), warranties, and support.\n**5.4 Validity**\n\"\"\"\n\nChunk ID: _5\nMetadata: {\"content_type\":\"list\",\"heading_path\":null,\"pages\":[7,8],\"has_table_structure\":null,\"doc_items_count\":9,\"chunk_index\":5}\n\n---\n\nOutput JSON:\n{\n  \"chunk_id\": \"_5\",\n  \"needs_splitting\": true/false,\n  \"reason\": \"why split or not - mention token count if relevant\",\n  \"sub_chunks\": [\n    {\n      \"text\": \"sub-chunk text with full context\",\n      \"topic\": \"brief description\"\n    }\n  ]\n}\n\nVALIDATION: Before submitting, verify:\n- If needs_splitting=true: created 2-5 sub-chunks, each 100+ tokens\n- If needs_splitting=false: original chunk is <500 tokens\n- No sub-chunk is <100 tokens",
          "systemPrompt": "You are an RFP document chunking specialist optimizing chunks for semantic search.\n\nCORE RULES:\n1. Target: 200-350 tokens per sub-chunk\n2. Minimum: 100 tokens per sub-chunk (NEVER go below this)\n3. Maximum: 5 sub-chunks per original chunk\n4. Each sub-chunk must be independently understandable\n\nOutput valid JSON only."
        }
      }
    ]
  },
  "repo_name": "n8n-backup-zm",
  "repo_owner": "zlatkomq",
  "repo_path": "",
  "settings": {
    "executionOrder": "v1",
    "callerPolicy": "workflowsFromSameOwner",
    "errorWorkflow": "052VdzVIz9bFK2dw"
  },
  "shared": [
    {
      "updatedAt": "2025-11-13T13:51:57.867Z",
      "createdAt": "2025-11-13T13:51:57.867Z",
      "role": "workflow:owner",
      "workflowId": "hppcM3kSB73vO8X2",
      "projectId": "NM7VZoSXkcKo262s"
    }
  ],
  "staticData": null,
  "tags": [
    {
      "updatedAt": "2025-04-24T10:59:44.979Z",
      "createdAt": "2025-04-24T10:59:44.979Z",
      "id": "qEREEA2JvunvA9Nv",
      "name": "Estimation Tool"
    }
  ],
  "triggerCount": 2,
  "updatedAt": "2025-11-13T13:51:57.867Z",
  "versionId": "59e66429-3c6e-4809-9f29-0d50a2b4f442"
}