{
  "active": false,
  "connections": {
    "When clicking ‘Test workflow’": {
      "main": [
        [
          {
            "node": "Queries",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Queries": {
      "main": [
        [
          {
            "node": "Embed Query - ollama",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Embed Query - ollama": {
      "main": [
        [
          {
            "node": "Query - Full",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Map Response": {
      "main": [
        [
          {
            "node": "Deduplicate and Best Score",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "PreparePrompts": {
      "main": [
        [
          {
            "node": "Get Platforms",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Claude 3.7": {
      "ai_languageModel": [
        []
      ]
    },
    "Platforms + Rationale": {
      "ai_outputParser": [
        [
          {
            "node": "Get Platforms",
            "type": "ai_outputParser",
            "index": 0
          }
        ]
      ]
    },
    "Query - Full": {
      "main": [
        [
          {
            "node": "Map Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Merge Chunks": {
      "main": [
        [
          {
            "node": "Token Budgeting",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Deduplicate and Best Score": {
      "main": [
        [
          {
            "node": "Merge Chunks",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Token Budgeting": {
      "main": [
        [
          {
            "node": "Prepare Context3",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Chat Model1": {
      "ai_languageModel": [
        [
          {
            "node": "Get Platforms",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Queries1": {
      "main": [
        [
          {
            "node": "Embed Query - ollama1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Embed Query - ollama1": {
      "main": [
        [
          {
            "node": "Query - Full1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Map Response1": {
      "main": [
        [
          {
            "node": "Deduplicate and Best Score1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Query - Full1": {
      "main": [
        [
          {
            "node": "Map Response1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Merge Chunks1": {
      "main": [
        [
          {
            "node": "Token Budgeting1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Deduplicate and Best Score1": {
      "main": [
        [
          {
            "node": "Filter low Scores and Sort1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Filter low Scores and Sort1": {
      "main": [
        [
          {
            "node": "Merge Chunks1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Token Budgeting1": {
      "main": [
        [
          {
            "node": "PreparePrompts1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "PreparePrompts1": {
      "main": [
        [
          {
            "node": "Information Extractor1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Chat Model2": {
      "ai_languageModel": [
        [
          {
            "node": "Information Extractor1",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Queries3": {
      "main": [
        [
          {
            "node": "Embed Query - ollama3",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Embed Query - ollama3": {
      "main": [
        [
          {
            "node": "Query - Full3",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Query - Full3": {
      "main": [
        [
          {
            "node": "Map Response4",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Map Response4": {
      "main": [
        [
          {
            "node": "Deduplicate and Best Score3",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Deduplicate and Best Score3": {
      "main": [
        [
          {
            "node": "Merge Chunks3",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "PreparePrompts3": {
      "main": [
        [
          {
            "node": "Delivery Context",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Merge Chunks3": {
      "main": [
        [
          {
            "node": "Token Budgeting3",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Token Budgeting3": {
      "main": [
        [
          {
            "node": "Prepare Context2",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Think2": {
      "ai_tool": [
        [
          {
            "node": "Delivery Context",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Chat Model4": {
      "ai_languageModel": [
        [
          {
            "node": "Delivery Context",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Delivery Context1": {
      "ai_outputParser": [
        [
          {
            "node": "Delivery Context",
            "type": "ai_outputParser",
            "index": 0
          }
        ]
      ]
    },
    "Queries4": {
      "main": [
        [
          {
            "node": "Embed Query - ollama4",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Embed Query - ollama4": {
      "main": [
        [
          {
            "node": "Query - Full6",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Map Response5": {
      "main": [
        [
          {
            "node": "Merge",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Deduplicate and Best Score4": {
      "main": [
        [
          {
            "node": "Merge Chunks4",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Merge Chunks4": {
      "main": [
        [
          {
            "node": "Token Budgeting4",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Token Budgeting4": {
      "main": [
        [
          {
            "node": "Prepare Context",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Think3": {
      "ai_tool": [
        [
          {
            "node": "Regulatory",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Delivery Context3": {
      "ai_outputParser": [
        [
          {
            "node": "Regulatory",
            "type": "ai_outputParser",
            "index": 0
          }
        ]
      ]
    },
    "Queries5": {
      "main": [
        [
          {
            "node": "Embed Query - ollama5",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Embed Query - ollama5": {
      "main": [
        [
          {
            "node": "Query - Full5",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Query - Full5": {
      "main": [
        [
          {
            "node": "Map Response6",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Map Response6": {
      "main": [
        [
          {
            "node": "Merge",
            "type": "main",
            "index": 1
          }
        ]
      ]
    },
    "Merge": {
      "main": [
        [
          {
            "node": "Deduplicate and Best Score4",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Query - Full6": {
      "main": [
        [
          {
            "node": "Map Response5",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Regulatory": {
      "main": [
        [
          {
            "node": "Regulatory Output",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare Context": {
      "main": [
        [
          {
            "node": "PreparePrompts5",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "PreparePrompts5": {
      "main": [
        [
          {
            "node": "Regulatory",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Queries6": {
      "main": [
        [
          {
            "node": "Embed Query - ollama6",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Embed Query - ollama6": {
      "main": [
        [
          {
            "node": "Query - Full8",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Query - Full8": {
      "main": [
        [
          {
            "node": "Map Response7",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Map Response7": {
      "main": [
        [
          {
            "node": "Deduplicate and Best Score5",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Deduplicate and Best Score5": {
      "main": [
        [
          {
            "node": "Merge Chunks6",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Merge Chunks6": {
      "main": [
        [
          {
            "node": "Token Budgeting6",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Token Budgeting6": {
      "main": [
        [
          {
            "node": "Prepare Context1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Greenfield + Rationale1": {
      "ai_outputParser": [
        [
          {
            "node": "Greenfield?1",
            "type": "ai_outputParser",
            "index": 0
          }
        ]
      ]
    },
    "GPT 4.1 Mini": {
      "ai_languageModel": [
        [
          {
            "node": "Regulatory",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "GPT 4.1 Mini1": {
      "ai_languageModel": [
        [
          {
            "node": "Greenfield?1",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Prepare Context1": {
      "main": [
        [
          {
            "node": "PreparePrompts8",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "PreparePrompts8": {
      "main": [
        [
          {
            "node": "Greenfield?1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare Context2": {
      "main": [
        [
          {
            "node": "PreparePrompts3",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare Context3": {
      "main": [
        [
          {
            "node": "PreparePrompts",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Queries2": {
      "main": [
        [
          {
            "node": "Embed Query - ollama2",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Embed Query - ollama2": {
      "main": [
        [
          {
            "node": "Query - Full9",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Map Response2": {
      "main": [
        [
          {
            "node": "Deduplicate and Best Score6",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "PreparePrompts4": {
      "main": [
        [
          {
            "node": "Functional requirements",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Query - Full9": {
      "main": [
        [
          {
            "node": "Map Response2",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Merge Chunks5": {
      "main": [
        [
          {
            "node": "Token Budgeting2",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Deduplicate and Best Score6": {
      "main": [
        [
          {
            "node": "Merge Chunks5",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Token Budgeting2": {
      "main": [
        [
          {
            "node": "Prepare Context4",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Chat Model3": {
      "ai_languageModel": [
        [
          {
            "node": "Functional requirements",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Prepare Context4": {
      "main": [
        [
          {
            "node": "PreparePrompts4",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Claude 3.": {
      "ai_languageModel": [
        []
      ]
    },
    "Functional requirements": {
      "main": [
        [
          {
            "node": "Functional Requirements Output",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Think": {
      "ai_tool": [
        [
          {
            "node": "Functional requirements",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Get Platforms": {
      "main": [
        [
          {
            "node": "Platforms Output",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Platforms Output": {
      "main": [
        [
          {
            "node": "Queries1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Information Extractor1": {
      "main": [
        [
          {
            "node": "General Info Output",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "General Info Output": {
      "main": [
        [
          {
            "node": "Queries3",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Delivery Context": {
      "main": [
        [
          {
            "node": "Delivery Context Ouput",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Delivery Context Ouput": {
      "main": [
        [
          {
            "node": "Queries6",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Greenfield?1": {
      "main": [
        [
          {
            "node": "GreenField Output",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "GreenField Output": {
      "main": [
        [
          {
            "node": "Queries4",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Regulatory Output": {
      "main": [
        [
          {
            "node": "Queries2",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "GPT 4.1 Mini2": {
      "ai_languageModel": [
        []
      ]
    },
    "Dependencies": {
      "main": [
        [
          {
            "node": "Code1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Code": {
      "main": [
        [
          {
            "node": "Team Composition",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Anthropic Chat Model": {
      "ai_languageModel": [
        [
          {
            "node": "Team Composition",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Functional Requirements Output": {
      "main": [
        [
          {
            "node": "Queries8",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Queries8": {
      "main": [
        [
          {
            "node": "Embed Query - ollama8",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Embed Query - ollama8": {
      "main": [
        [
          {
            "node": "Query - Full11",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "PreparePrompts7": {
      "main": [
        [
          {
            "node": "NonFunctional Requirements",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Query - Full11": {
      "main": [
        [
          {
            "node": "Map Response8",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Merge Chunks8": {
      "main": [
        [
          {
            "node": "Token Budgeting7",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Deduplicate and Best Score8": {
      "main": [
        [
          {
            "node": "Merge Chunks8",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Token Budgeting7": {
      "main": [
        [
          {
            "node": "Prepare Context6",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Chat Model": {
      "ai_languageModel": [
        [
          {
            "node": "NonFunctional Requirements",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Prepare Context6": {
      "main": [
        [
          {
            "node": "PreparePrompts7",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Think1": {
      "ai_tool": [
        [
          {
            "node": "NonFunctional Requirements",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Map Response8": {
      "main": [
        [
          {
            "node": "Deduplicate and Best Score8",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "NonFunctional Requirements": {
      "main": [
        [
          {
            "node": "NonFunctional Requirements Output",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "NonFunctional Requirements Output": {
      "main": [
        [
          {
            "node": "Combine Requirements",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Greenfield + Rationale2": {
      "ai_outputParser": [
        [
          {
            "node": "Risks",
            "type": "ai_outputParser",
            "index": 0
          }
        ]
      ]
    },
    "Code1": {
      "main": [
        [
          {
            "node": "Risks",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Anthropic Chat Model1": {
      "ai_languageModel": [
        []
      ]
    },
    "Queries7": {
      "main": [
        [
          {
            "node": "Embed Query - ollama7",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Embed Query - ollama7": {
      "main": [
        [
          {
            "node": "Query - Full10",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Map Response3": {
      "main": [
        [
          {
            "node": "Deduplicate and Best Score7",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "PreparePrompts6": {
      "main": [
        [
          {
            "node": "Get Techstack",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Claude 3.8": {
      "ai_languageModel": [
        [
          {
            "node": "Get Techstack",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Platforms + Rationale2": {
      "ai_outputParser": [
        [
          {
            "node": "Get Techstack",
            "type": "ai_outputParser",
            "index": 0
          }
        ]
      ]
    },
    "Query - Full10": {
      "main": [
        [
          {
            "node": "Map Response3",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Merge Chunks7": {
      "main": [
        [
          {
            "node": "Token Budgeting5",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Deduplicate and Best Score7": {
      "main": [
        [
          {
            "node": "Merge Chunks7",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Token Budgeting5": {
      "main": [
        [
          {
            "node": "Prepare Context5",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare Context5": {
      "main": [
        [
          {
            "node": "PreparePrompts6",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Get Techstack": {
      "main": [
        [
          {
            "node": "Techstack Output",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Chat Model5": {
      "ai_languageModel": [
        []
      ]
    },
    "Title + Desc + Section": {
      "ai_outputParser": [
        []
      ]
    },
    "Description": {
      "ai_outputParser": [
        [
          {
            "node": "Functional requirements",
            "type": "ai_outputParser",
            "index": 0
          }
        ]
      ]
    },
    "Full": {
      "ai_outputParser": [
        []
      ]
    },
    "Description + Category": {
      "ai_outputParser": [
        [
          {
            "node": "NonFunctional Requirements",
            "type": "ai_outputParser",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Chat Model6": {
      "ai_languageModel": [
        [
          {
            "node": "Combine Requirements",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Structured Output Parser": {
      "ai_outputParser": [
        [
          {
            "node": "Combine Requirements",
            "type": "ai_outputParser",
            "index": 0
          }
        ]
      ]
    },
    "Combine Requirements": {
      "main": [
        [
          {
            "node": "Combined Requirements Output",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Combined Requirements Output": {
      "main": [
        [
          {
            "node": "Dependencies1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Dependencies1": {
      "main": [
        [
          {
            "node": "Queries7",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Techstack Output": {
      "main": [
        [
          {
            "node": "Code",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Team Composition1": {
      "ai_outputParser": [
        [
          {
            "node": "Team Composition",
            "type": "ai_outputParser",
            "index": 0
          }
        ]
      ]
    },
    "Team Composition": {
      "main": [
        [
          {
            "node": "Team Composition Output",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "GPT 4.1 Mini3": {
      "ai_languageModel": [
        [
          {
            "node": "Risks",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Team Composition Output": {
      "main": [
        [
          {
            "node": "Dependencies",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Greenfield + Rationale": {
      "ai_outputParser": [
        [
          {
            "node": "Effort Estimation",
            "type": "ai_outputParser",
            "index": 0
          }
        ]
      ]
    },
    "GPT 4.1 Mini4": {
      "ai_languageModel": [
        [
          {
            "node": "Effort Estimation",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Code2": {
      "main": [
        [
          {
            "node": "Effort Estimation",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Risks": {
      "main": [
        [
          {
            "node": "Risks Output",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Risks Output": {
      "main": [
        [
          {
            "node": "Backend Estimation Rules",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Calculator": {
      "ai_tool": [
        [
          {
            "node": "Effort Estimation",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Anthropic Chat Model2": {
      "ai_languageModel": [
        []
      ]
    },
    "Greenfield + Rationale3": {
      "ai_outputParser": [
        [
          {
            "node": "Development Plan",
            "type": "ai_outputParser",
            "index": 0
          }
        ]
      ]
    },
    "Code3": {
      "main": [
        [
          {
            "node": "Development Plan",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Anthropic Chat Model3": {
      "ai_languageModel": [
        [
          {
            "node": "Development Plan",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Calculator1": {
      "ai_tool": [
        [
          {
            "node": "Development Plan",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Effort Estimation": {
      "main": [
        [
          {
            "node": "Effort Estimate Output",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Effort Estimate Output": {
      "main": [
        [
          {
            "node": "Code3",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "file_upload1": {
      "main": [
        [
          {
            "node": "Wait",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "data_extraction1": {
      "main": [
        [
          {
            "node": "Wait2",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "scope_analysis1": {
      "main": [
        [
          {
            "node": "Wait3",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "effort_estimation1": {
      "main": [
        [
          {
            "node": "Wait4",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "team_composition1": {
      "main": [
        [
          {
            "node": "Wait5",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "development_plan1": {
      "main": [
        [
          {
            "node": "Wait6",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Wait": {
      "main": [
        [
          {
            "node": "document_preparation1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Wait1": {
      "main": [
        [
          {
            "node": "data_extraction1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Wait2": {
      "main": [
        [
          {
            "node": "scope_analysis1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Wait3": {
      "main": [
        [
          {
            "node": "effort_estimation1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Wait4": {
      "main": [
        [
          {
            "node": "team_composition1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Wait5": {
      "main": [
        [
          {
            "node": "development_plan1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Wait6": {
      "main": [
        [
          {
            "node": "final_report1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "document_preparation1": {
      "main": [
        [
          {
            "node": "Wait1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "RFP Upload1": {
      "main": [
        [
          {
            "node": "file_upload1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Greenfield + Rationale4": {
      "ai_outputParser": [
        [
          {
            "node": "Frontend Estimation",
            "type": "ai_outputParser",
            "index": 0
          }
        ]
      ]
    },
    "GPT 4.1 Mini6": {
      "ai_languageModel": [
        [
          {
            "node": "Frontend Estimation",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Code5": {
      "main": [
        [
          {
            "node": "Frontend Estimation",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Calculator2": {
      "ai_tool": [
        [
          {
            "node": "Frontend Estimation",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Frontend Estimation": {
      "main": [
        []
      ]
    },
    "Anthropic Chat Model4": {
      "ai_languageModel": [
        []
      ]
    },
    "Think4": {
      "ai_tool": [
        [
          {
            "node": "Frontend Estimation",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Greenfield + Rationale5": {
      "ai_outputParser": [
        [
          {
            "node": "Backend Estimation",
            "type": "ai_outputParser",
            "index": 0
          }
        ]
      ]
    },
    "Calculator3": {
      "ai_tool": [
        [
          {
            "node": "Backend Estimation",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Think5": {
      "ai_tool": [
        [
          {
            "node": "Backend Estimation",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "GPT 4.1": {
      "ai_languageModel": [
        []
      ]
    },
    "Anthropic Chat Model5": {
      "ai_languageModel": [
        [
          {
            "node": "Backend Estimation",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Greenfield + Rationale6": {
      "ai_outputParser": [
        [
          {
            "node": "AI Speedup Backend",
            "type": "ai_outputParser",
            "index": 0
          }
        ]
      ]
    },
    "Code7": {
      "main": [
        [
          {
            "node": "AI Speedup Backend",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Anthropic Chat Model6": {
      "ai_languageModel": [
        [
          {
            "node": "AI Speedup Backend",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Calculator4": {
      "ai_tool": [
        [
          {
            "node": "AI Speedup Backend",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Think6": {
      "ai_tool": [
        [
          {
            "node": "AI Speedup Backend",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Backend Estimation": {
      "main": [
        [
          {
            "node": "Code7",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prompt Backend Estimation": {
      "main": [
        [
          {
            "node": "Backend Estimation",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Backend Estimation Rules": {
      "main": [
        [
          {
            "node": "Prompt Backend Estimation",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "createdAt": "2025-06-17T07:02:40.778Z",
  "id": "ZbHMKsiavwFA5iD6",
  "isArchived": false,
  "meta": {
    "templateCredsSetupCompleted": true
  },
  "name": "RFP Analysis Internal",
  "nodes": [
    {
      "parameters": {},
      "id": "b2021262-fab6-435b-9873-97f5bdf9e658",
      "name": "When clicking ‘Test workflow’",
      "type": "n8n-nodes-base.manualTrigger",
      "typeVersion": 1,
      "position": [
        -4760,
        3400
      ]
    },
    {
      "parameters": {
        "jsCode": "return [\n  {\n    json: {\n      platform: \"web\",\n      query: \"What web technologies or platforms are mentioned in the RFP?\",\n      keywords: \"web technology, technologies, platform, platforms, website, webapp, web application, HTML, CSS, JavaScript, TypeScript, React, Angular, Vue, Svelte, Next.js, Nuxt.js, PHP, Python, Django, Flask, Ruby, Rails, Node.js, Express, .NET, ASP.NET, Java, Spring, Laravel, Drupal, WordPress, CMS, frontend, backend, server-side, client-side, SaaS, PaaS, cloud hosting\",\n      phrase: \"web technology platform web application\",\n      rescore_query: \"web application OR React OR Angular OR Vue OR HTML OR CSS\"\n    }\n  },\n  {\n    json: {\n      platform: \"mobile\",\n      query: \"Is a mobile app required or mentioned in the RFP? Android, iOS or Flutter?\",\n      keywords: \"mobile app, application, Android, iOS, Flutter, React Native, Swift, Kotlin, cross-platform, smartphone, tablet, mobile device, iPhone, iPad, Play Store, App Store\",\n      phrase: \"mobile application mobile app\",\n      rescore_query: \"mobile app OR Android OR iOS OR Flutter OR React Native\"\n    }\n  },\n  {\n    json: {\n      platform: \"backend\",\n      query: \"Are there backend services or APIs involved in the RFP?\",\n      keywords: \"backend service, services, API, APIs, REST, RESTful, GraphQL, server, database, microservice, microservices, endpoint, endpoints, integration, integration layer, middleware, backend system, data storage, authentication, authorization, business logic\",\n      phrase: \"backend service API integration\",\n      rescore_query: \"REST API OR GraphQL OR microservice OR backend service\"\n    }\n  },\n  {\n    json: {\n      platform: \"admin\",\n      query: \"Does the RFP include an admin portal or dashboard?\",\n      keywords: \"admin portal, dashboard, administration, control panel, admin interface, management console, backend portal, admin dashboard, reporting, analytics, monitoring, configuration settings, user management\",\n      phrase: \"admin portal admin dashboard\",\n      rescore_query: \"admin portal OR admin dashboard OR management console\"\n    }\n  },\n  {\n    json: {\n      platform: \"desktop\",\n      query: \"Is desktop software or a desktop client part of the RFP scope?\",\n      keywords: \"desktop software, client application, Windows, MacOS, Linux, desktop app, Electron, desktop client, installable application, native desktop, cross-platform desktop, program, executable\",\n      phrase: \"desktop software desktop client\",\n      rescore_query: \"desktop app OR Electron OR native desktop\"\n    }\n  },\n  {\n    json: {\n      platform: \"kiosk\",\n      query: \"Are kiosk systems or interfaces required in the RFP?\",\n      keywords: \"kiosk system, systems, interface, interfaces, self-service terminal, touch screen, touchscreen, kiosk application, kiosk mode, interactive kiosk, public kiosk, digital kiosk, POS, point of sale\",\n      phrase: \"kiosk system kiosk interface\",\n      rescore_query: \"kiosk interface OR touchscreen OR point of sale\"\n    }\n  },\n  {\n    json: {\n      platform: \"system-architecture\",\n      query: \"Describe the overall system structure and functionality mentioned in the RFP.\",\n      keywords: \"system structure, architecture, functionality, components, modules, workflow, process, integration, overview, system design, system diagram, technical architecture, high-level design, system overview\",\n      phrase: \"system structure system functionality\",\n      rescore_query: \"system architecture OR technical architecture OR system design\"\n    }\n  },\n  {\n    json: {\n      platform: \"technical-components\",\n      query: \"What are the main technical or system components described in the RFP?\",\n      keywords: \"technical component, components, system element, elements, module, modules, subsystem, subsystems, architecture, infrastructure, technology stack, platform, integration, interface, API, backend, frontend, database, server, client\",\n      phrase: \"technical component system component\",\n      rescore_query: \"technical component OR system module OR technology stack\"\n    }\n  }\n];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -4040,
        3380
      ],
      "id": "56580fbe-84f5-4af2-85c0-780a0a05cfff",
      "name": "Queries"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "http://192.168.20.70:11434/api/embed",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"model\": \"nomic-embed-text:latest\",\n  \"input\": [\"{{ $json.query }}\"]\n}",
        "options": {}
      },
      "id": "f5763b19-2d74-4742-ab5b-12203069adbb",
      "name": "Embed Query - ollama",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -3860,
        3380
      ]
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "17f9e7d3-307e-4d60-92ef-e32285cbec29",
              "name": "_score",
              "value": "={{ $json._score }}",
              "type": "number"
            },
            {
              "id": "618f58cd-27c7-4ab4-8612-899f048afb6c",
              "name": "_id",
              "value": "={{ $json._id }}",
              "type": "string"
            },
            {
              "id": "a8cfb079-48c6-4ce2-a54c-251304107206",
              "name": "chunk_id",
              "value": "={{ $json._source.chunk_id }}",
              "type": "string"
            },
            {
              "id": "22e6e029-7ff1-4870-a1c2-d3b025a2748b",
              "name": "section_title",
              "value": "={{ $json._source.section_title }}",
              "type": "string"
            },
            {
              "id": "27e9a9ac-b6ed-4320-bb21-027f8659e7c5",
              "name": "text",
              "value": "={{ $json._source.text }}",
              "type": "string"
            },
            {
              "id": "6830a868-6492-405b-b8fb-1ae36ea184b2",
              "name": "metadata",
              "value": "={{ $json._source.metadata }}",
              "type": "object"
            },
            {
              "id": "e5dce93c-eb16-42be-8b42-47ca5cfacc52",
              "name": "platform",
              "value": "={{ $('Queries').item.json.platform }}",
              "type": "string"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        -3480,
        3380
      ],
      "id": "73565924-434d-412e-a132-6a8561ab2f6e",
      "name": "Map Response"
    },
    {
      "parameters": {
        "jsCode": "// 2. Format the context\nconst contextForPrompt = $input.first().json.context;\nconst systemPrompt = \"You are a precise assistant that extracts structured insights from project documents, such as RFPs or technical scopes. Your primary goal is to identify platform requirements based on the content provided. Focus on what is clearly described, but use practical software development reasoning when appropriate: - If a frontend (web or mobile) is described in detail, and no backend is mentioned, assume a backend is required unless the RFP explicitly states otherwise.- If user-facing workflows imply system control or role management, you may reasonably infer that an admin interface is needed. Never invent features or platforms not supported by the text or standard architectural logic. If something is unclear or missing, say so clearly. Be structured, realistic, and accurate in all your conclusions.\";\n// 3. Define the user prompt\nconst userPrompt = `You are reviewing excerpts from an RFP document to determine which technology platforms are explicitly required.\n\n\\n\\n### excerpts:\\n\\n${contextForPrompt}\n\nInstructions:\n- Only list platforms that are clearly described or required in the text.\n- For each platform you list, provide a **short rationale** explaining what in the text led you to include it.\n- If no platforms are clearly required, say: “No platform requirements explicitly stated.”\n\nOnly identify platforms from the list below:\n- Web applications\n- Mobile apps (mention iOS/Android if stated)\n- Backend/API services\n- Admin portals or dashboards\n- Desktop applications\n- Specialized systems (e.g., kiosks, IoT)\n\n**Additional notes**:\n- If a web or mobile frontend is clearly described but no backend is mentioned, **assume a backend is needed** unless explicitly stated otherwise.\n- If the RFP includes user-facing features that typically require admin management (e.g., content moderation, approval workflows, user roles), you may infer that an **admin portal** is required even if not explicitly named.\n- Use Think tool to help you with reasoning.\n\nRemember: Base your answers strictly on the provided Context.  \nYou may make minimal inferences only when explicitly allowed in the instructions above (e.g., assuming a backend for a described frontend).  \nDo not invent platform requirements beyond that.\n`;\n\nreturn {\n  json: {\n    userPrompt,\n    systemPrompt: systemPrompt\n  }\n};\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -3480,
        3600
      ],
      "id": "9b10ef5c-13a0-4c53-8751-ff05785d1061",
      "name": "PreparePrompts"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ $json.userPrompt }}",
        "hasOutputParser": true,
        "options": {
          "systemMessage": "={{ $json.systemPrompt }}"
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.9,
      "position": [
        -3240,
        3600
      ],
      "id": "f830b915-f28b-4064-8626-dee0f215c157",
      "name": "Get Platforms"
    },
    {
      "parameters": {
        "content": "## Inference PLATFORMS\nYou are reviewing excerpts \nfrom an RFP document \nto determine which technology \nplatforms are explicitly required.\n\nUse only the following categories:\n- Web applications\n- Mobile apps (mention iOS/Android if stated)\n- Backend/API services\n- Admin portals or dashboards\n- Desktop applications\n- Specialized systems (e.g., kiosks, IoT)\n\nFor each platform you identify, \nexplain briefly what in the text\n led you to that conclusion.\nOnly include platforms that are\n clearly required or described.\n\nIf nothing is clear, say \n“No platform requirements explicitly stated.”",
        "height": 860,
        "width": 1740
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        -4460,
        3180
      ],
      "id": "ba8e26db-4795-4955-b428-6cac83cdda02",
      "name": "Sticky Note4"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "mode": "list",
          "value": "claude-3-7-sonnet-20250219",
          "cachedResultName": "Claude 3.7 Sonnet"
        },
        "options": {
          "thinking": true
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatAnthropic",
      "typeVersion": 1.3,
      "position": [
        -3400,
        3800
      ],
      "id": "7a83a166-5308-42ae-a85a-abf6ea90de49",
      "name": "Claude 3.7",
      "credentials": {
        "anthropicApi": {
          "id": "qzCm5Ds2qD9ZY1W5",
          "name": "Anthropic account"
        }
      }
    },
    {
      "parameters": {
        "jsonSchemaExample": "{\n\t\"platforms\": [\"Los Angeles\", \"San Francisco\", \"San Diego\"],\n  \"rationale\": \"\"\n}"
      },
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "typeVersion": 1.2,
      "position": [
        -3040,
        3800
      ],
      "id": "26a2411b-ff50-4021-9531-3933fd956ada",
      "name": "Platforms + Rationale"
    },
    {
      "parameters": {
        "operation": "getAll",
        "indexId": "=est_tool_rfp",
        "limit": 10,
        "simple": false,
        "options": {
          "query": "={\n  \"size\": 10,\n  \"min_score\": 1.5,\n  \"_source\": [\n    \"chunk_id\",\"section_title\",\"text\",\n    \"metadata.filename\",\"metadata.page_numbers\",\n    \"metadata.parent_chunk_id\",\"metadata.is_split_chunk\",\n    \"metadata.split_part\",\"metadata.total_parts\",\n    \"vector_metadata.token_count\",\"vector_metadata.is_split\",\n    \"vector_metadata.chunk_index\"\n  ],\n  \"knn\": {\n    \"field\": \"embeddings\",\n    \"query_vector\": [ {{ $json.embeddings }} ],\n    \"k\": 20,\n    \"num_candidates\": 50\n  },\n  \"query\": {\n    \"bool\": {\n      \"should\": [\n        {\n          \"match_phrase\": {\n            \"text\": {\n              \"query\": \"{{ $('Queries').item.json.phrase }}\",\n              \"slop\": 4,\n              \"boost\": 2.0\n            }\n          }\n        },\n        {\n          \"multi_match\": {\n            \"query\": \"{{ $('Queries').item.json.keywords }}\",\n            \"fields\": [\"text^2\",\"section_title^3\"],\n            \"type\": \"most_fields\",\n            \"minimum_should_match\": 2,\n            \"boost\": 1.2\n          }\n        },\n        {\n          \"terms_set\": {\n            \"text.keyword\": {\n              \"terms\": {{ JSON.stringify($('Queries').item.json.keywords.split(',').map(k => k.trim())) }},\n\n              \"minimum_should_match_script\": {\n                \"source\": \"Math.min(params.num_terms, 2)\"\n              }\n            }\n          }\n        }\n      ],\n      \"minimum_should_match\": 1\n    }\n  },\n  \"rescore\": {\n    \"window_size\": 20,\n    \"query\": {\n      \"rescore_query\": {\n        \"match_phrase\": {\n          \"text\": {\n            \"query\": \"{{ $('Queries').item.json.rescore_query }}\",\n            \"slop\": 8\n          }\n        }\n      },\n      \"query_weight\": 0.7,\n      \"rescore_query_weight\": 0.3\n    }\n  },\n  \"highlight\": {\n    \"type\": \"unified\",\n    \"fields\": { \"text\": {}, \"section_title\": {} }\n  }\n}\n"
        }
      },
      "type": "n8n-nodes-base.elasticsearch",
      "typeVersion": 1,
      "position": [
        -3660,
        3380
      ],
      "id": "8437e7a5-d50b-424a-a036-1e8fe6d0f732",
      "name": "Query - Full",
      "credentials": {
        "elasticsearchApi": {
          "id": "wwaILZtoajWrVXwt",
          "name": "Elasticsearch account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// n8n Function Node: Corrected Merge Split-Chunk Groups\n\nconst grouped = {};\n\n// 1. Group all items by the “true” chunk identifier\nfor (const item of $input.all()) {\n  const data = item.json;\n  // Use parent_chunk_id if it exists, else chunk_id\n  const parentId = data.metadata?.is_split_chunk\n    ? data.metadata.parent_chunk_id\n    : data.chunk_id;\n\n  if (!grouped[parentId]) grouped[parentId] = [];\n  grouped[parentId].push(data);\n}\n\nconst merged = [];\n\n// 2. For each group, produce exactly one merged record\nfor (const [parentId, parts] of Object.entries(grouped)) {\n  // Sort by the split_part if present (else leave order)\n  parts.sort((a, b) => \n    (a.metadata?.split_part ?? 0) - (b.metadata?.split_part ?? 0)\n  );\n\n  // Stitch text together\n  const text = parts.map(p => p.text).join(\"\\n\\n\");\n\n  // Merge platform_origins arrays from all parts (dedupe by platform)\n  const allOrigins = parts.flatMap(p => p.platform_origins || []);\n  const platform_origins = [];\n  for (const o of allOrigins) {\n    if (!platform_origins.some(existing => existing.platform === o.platform)) {\n      platform_origins.push(o);\n    }\n  }\n\n  // Pick the highest-scoring part to inherit section_title, filename, pages, and score\n  const bestPart = parts.reduce((best, p) => \n    p._score > best._score ? p : best\n  , parts[0]);\n\n  // Build the single merged record\n  const record = {\n    chunk_id: parentId,\n    _score: bestPart._score,\n    section_title: bestPart.section_title,\n    text,\n    metadata: {\n      ...bestPart.metadata,\n      is_split_chunk: false,\n      parent_chunk_id: undefined,\n      split_part: undefined,\n      total_parts: undefined\n    },\n    platform_origins\n  };\n\n  merged.push({ json: record });\n}\nmerged.sort((a, b) => b.json._score - a.json._score);\nreturn merged;\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -4040,
        3600
      ],
      "id": "dfd643f0-9939-49f3-83b3-4217b0cd2a18",
      "name": "Merge Chunks"
    },
    {
      "parameters": {
        "jsCode": "// n8n Function Node: Dedupe → Merge Origins → Filter → Sort → Fallback\n\nconst MIN_SCORE = 3.0;\nconst DESIRED_COUNT = 10;\n\n// Step 1: Deduplicate & merge platform origins, keep highest‐score record\nconst seen = {};\nfor (const item of $input.all()) {\n  const { chunk_id, platform, _score, ...rest } = item.json;\n  \n  if (!seen[chunk_id]) {\n    // First time seeing this chunk\n    seen[chunk_id] = {\n      chunk_id,\n      _score,\n      ...rest,\n      platform_origins: [{ platform, score: _score }],\n    };\n  } else {\n    // Merge new platform origin\n    const record = seen[chunk_id];\n    if (!record.platform_origins.some(p => p.platform === platform)) {\n      record.platform_origins.push({ platform, score: _score });\n    }\n    // If this hit has a higher score, overwrite core fields\n    if (_score > record._score) {\n      record._score = _score;\n      Object.assign(record, rest);\n    }\n  }\n}\n\n// Convert deduped map back to array of items\nlet deduped = Object.values(seen).map(r => ({ json: r }));\n\n// Step 2: Filter by score and sort descending\nlet filtered = deduped\n  .filter(item => item.json._score >= MIN_SCORE)\n  .sort((a, b) => b.json._score - a.json._score);\n\n// Step 3: Fallback if too few hits\nif (filtered.length < DESIRED_COUNT) {\n  // Return top DESIRED_COUNT from deduped (regardless of score)\n  filtered = deduped\n    .sort((a, b) => b.json._score - a.json._score)\n    .slice(0, DESIRED_COUNT);\n}\n\n// Step 4: Ensure we only return up to DESIRED_COUNT\nfiltered = filtered.slice(0, DESIRED_COUNT);\n\n// Return in n8n-compatible format\nreturn filtered;\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -3300,
        3380
      ],
      "id": "16e6807e-7565-47db-8d5d-e07b9178d34a",
      "name": "Deduplicate and Best Score"
    },
    {
      "parameters": {
        "jsCode": "// Configuration\nconst TOKEN_LIMIT = 5000;\nconst MIN_STRONG_SCORE = 7.0;\n\n// Rough token estimator (1 token ~ 4 characters)\nfunction estimateTokenCount(text) {\n  if (!text) return 0;\n  return Math.ceil(text.length / 4);\n}\n\n// Input already filtered and sorted!\nconst chunks = $input.all().map(item => item.json);\n\n// Build the final list\nconst selectedChunks = [];\nlet tokenCount = 0;\n\nfor (const chunk of chunks) {\n  const tokens = estimateTokenCount(chunk.text);\n\n  if ((tokenCount + tokens) <= TOKEN_LIMIT) {\n    selectedChunks.push(chunk);\n    tokenCount += tokens;\n  } else if (chunk._score >= MIN_STRONG_SCORE) {\n    // Allow overflow for very strong chunks\n    selectedChunks.push(chunk);\n    tokenCount += tokens;\n  } else {\n    break; // Stop adding\n  }\n}\n\n// Prepare output\nconst output = selectedChunks.map(chunk => ({ json: chunk }));\n\n// Add token usage metadata (attach to first item for simplicity)\nif (output.length > 0) {\n  output[0].json._token_summary = {\n    total_tokens_estimated: tokenCount,\n    total_chunks_selected: selectedChunks.length,\n  };\n}\n\nreturn output;\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -3860,
        3600
      ],
      "id": "5b6684a8-8e2e-407f-810c-cd9e0ddd84fc",
      "name": "Token Budgeting"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "gpt-4.1",
          "mode": "list",
          "cachedResultName": "gpt-4.1"
        },
        "options": {
          "temperature": 0.1
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        -3240,
        3800
      ],
      "id": "9b4b62e3-1a07-4011-aa8e-88d9be2c7a03",
      "name": "OpenAI Chat Model1",
      "credentials": {
        "openAiApi": {
          "id": "M8xqWvEC6mH6LNuk",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// Function Node: Create Query Packs\n\nreturn [\n  {\n    json: {\n      info_type: \"client_name\",\n      keywords: \"client name, company name, organization name, issuer, requesting authority, contracting authority\",\n      phrase: \"client name OR company name OR organization name OR issuer OR requesting authority OR contracting authority\"\n    }\n  },\n  {\n    json: {\n      info_type: \"contact_email\",\n      keywords: \"contact email, email address, point of contact, submit proposals to, RFP contact, send proposals to\",\n      phrase: \"contact email OR email address OR point of contact OR submit proposals OR RFP contact\"\n    }\n  },\n  {\n    json: {\n      info_type: \"dates\",\n      keywords: \"issue date, release date, proposal due date, submission deadline, question deadline\",\n      phrase: \"issue date OR release date OR proposal due OR deadline for submission OR question deadline\"\n    }\n  },\n  {\n    json: {\n      info_type: \"industry\",\n      keywords: \"industry sector, business area, company activity, organizational focus, company type\",\n      phrase: \"industry OR sector OR business focus OR organization type\"\n    }\n  },\n  {\n    json: {\n      info_type: \"project_name\",\n      keywords: \"project name, RFP title, tender title, project title\",\n      phrase: \"project name OR RFP title OR tender title OR project title\"\n    }\n  }\n];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1880,
        3220
      ],
      "id": "9efd36df-a7a9-42c4-bb94-006bdda72050",
      "name": "Queries1"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "http://192.168.20.70:11434/api/embed",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"model\": \"nomic-embed-text:latest\",\n  \"input\": [\"{{ $json.keywords }}\"]\n}",
        "options": {}
      },
      "id": "8a43e97b-8a57-4113-aee8-5b9c3c3bf552",
      "name": "Embed Query - ollama1",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -1700,
        3220
      ]
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "17f9e7d3-307e-4d60-92ef-e32285cbec29",
              "name": "_score",
              "value": "={{ $json._score }}",
              "type": "number"
            },
            {
              "id": "618f58cd-27c7-4ab4-8612-899f048afb6c",
              "name": "_id",
              "value": "={{ $json._id }}",
              "type": "string"
            },
            {
              "id": "a8cfb079-48c6-4ce2-a54c-251304107206",
              "name": "chunk_id",
              "value": "={{ $json._source.chunk_id }}",
              "type": "string"
            },
            {
              "id": "22e6e029-7ff1-4870-a1c2-d3b025a2748b",
              "name": "section_title",
              "value": "={{ $json._source.section_title }}",
              "type": "string"
            },
            {
              "id": "27e9a9ac-b6ed-4320-bb21-027f8659e7c5",
              "name": "text",
              "value": "={{ $json._source.text }}",
              "type": "string"
            },
            {
              "id": "6830a868-6492-405b-b8fb-1ae36ea184b2",
              "name": "metadata",
              "value": "={{ $json._source.metadata }}",
              "type": "object"
            },
            {
              "id": "e5dce93c-eb16-42be-8b42-47ca5cfacc52",
              "name": "platform",
              "value": "={{ $('Queries1').item.json.info_type }}",
              "type": "string"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        -1320,
        3220
      ],
      "id": "bdbb1942-3bec-46ae-a783-a5483777dd23",
      "name": "Map Response1"
    },
    {
      "parameters": {
        "jsCode": "// Function: Prepare context and prompts for Metadata Extraction from Elasticsearch results\n\nfunction prepareMetadataEnhancedContextForClaude(esResults) {\n  if (!Array.isArray(esResults)) {\n    throw new Error(\"Input must be an array of Elasticsearch results\");\n  }\n\n  return esResults.map(result => {\n    const sectionTitle = result.section_title || \"Untitled Section\";\n    const text = result.text || \"\";\n    const metadata = result.metadata || {};\n    \n    const filename = metadata.filename || \"Unknown Document\";\n    const pageNumbers = Array.isArray(metadata.page_numbers) \n      ? (metadata.page_numbers.flat ? metadata.page_numbers.flat() : metadata.page_numbers)\n      : [metadata.page_numbers];\n    const pageList = pageNumbers && pageNumbers.length \n      ? pageNumbers.join(', ') \n      : \"Unknown\";\n\n    const metadataYAML = [\n      `filename: ${filename}`,\n      `pages: ${pageList}`,\n      ...(metadata.languages ? [`language: ${metadata.languages.join(', ')}`] : []),\n      ...(metadata.document_type ? [`type: ${metadata.document_type}`] : [])\n    ].join(\"\\n\");\n\n    const enhancedText = text\n      .replace(/\\s*-\\s+/g, \"\\n- \")\n      .replace(/\\*\\s+/g, \"\\n- \")\n      .replace(/[ \\t]+/g, \" \")\n      .replace(/\\. ([A-Z])/g, \".\\n$1\")\n      .replace(/\\n{3,}/g, \"\\n\\n\")\n      .trim();\n\n    return `### ${sectionTitle}\\n${metadataYAML ? `\\n\\n${metadataYAML}\\n\\n---` : ''}\\n\\n${enhancedText}`;\n\n  }).join(\"\\n\\n---\\n\\n\");\n}\n\n// 1. Get Elasticsearch results\nconst esResults = $input.all().map(item => item.json);\n\n// 2. Format context\nconst contextForPrompt = prepareMetadataEnhancedContextForClaude(esResults);\n\n// 3. Define user prompt\n// const userPrompt = `You are reviewing excerpts from an RFP document to extract key metadata fields.\n\n// Extract the following fields from the context if possible:\n// - Client Name\n// - Project Name\n// - Industry Sector\n// - RFP Issued Date\n// - Submission Deadline Date\n// - Questions Submission Deadline Date\n// - Contact Email Address\n\n// **Instructions:**\n// - Be precise and only extract what is explicitly mentioned or strongly implied.\n// - If a field is missing, clearly state: \"Not specified.\"\n// - For dates, use the format YYYY-MM-DD if possible.\n// - For emails, extract full addresses (e.g., example@company.com).\n// - If multiple values are possible (e.g., multiple contacts), list them clearly.\n\n//### Context:\nconst userPrompt = `${contextForPrompt}`;\n\nreturn {\n  json: {\n    userPrompt,\n    systemPrompt: \"You are a structured information extraction assistant specialized in analyzing project documents like RFPs. Your task is to carefully extract key metadata fields exactly as requested. Focus only on information clearly present in the context. If a field is missing or unclear, explicitly state 'Not specified.' Never hallucinate or assume facts beyond the provided excerpts. Be accurate, concise, and reliable.\"\n  }\n};\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1680,
        3720
      ],
      "id": "edf37fce-08e8-4670-bf5b-09204f965368",
      "name": "PreparePrompts1"
    },
    {
      "parameters": {
        "operation": "getAll",
        "indexId": "=est_tool_rfp",
        "limit": 10,
        "simple": false,
        "options": {
          "query": "={\n  \"size\": 10,\n  \"min_score\": 5.0,\n  \"_source\": [\n    \"chunk_id\",\n    \"section_title\",\n    \"text\",\n    \"metadata.filename\",\n    \"metadata.page_numbers\",\n    \"metadata.parent_chunk_id\",\n    \"metadata.is_split_chunk\",\n    \"metadata.split_part\",\n    \"metadata.total_parts\",\n    \"vector_metadata.token_count\",\n    \"vector_metadata.is_split\",\n    \"vector_metadata.chunk_index\"\n  ],\n  \"knn\": {\n    \"field\": \"embeddings\",\n    \"query_vector\": [{{ $json.embeddings }}],\n    \"k\": 10,\n    \"num_candidates\": 50\n  },\n  \"query\": {\n    \"bool\": {\n      \"should\": [\n        {\n          \"multi_match\": {\n            \"query\": \"{{ $('Queries1').item.json.keywords }}\",\n            \"fields\": [\"text^3\", \"section_title^5\"],\n            \"type\": \"best_fields\",\n            \"operator\": \"OR\",\n            \"minimum_should_match\": \"30%\"\n          }\n        }\n      ],\n      \"filter\": [\n        {\n          \"exists\": {\n            \"field\": \"text\"\n          }\n        }\n      ]\n    }\n  },\n  \"rescore\": {\n    \"window_size\": 20,\n    \"query\": {\n      \"rescore_query\": {\n        \"match_phrase\": {\n          \"text\": {\n            \"query\": \"{{ $('Queries1').item.json.phrase }}\",\n            \"slop\": 20\n          }\n        }\n      },\n      \"query_weight\": 0.8,\n      \"rescore_query_weight\": 0.2\n    }\n  }\n}\n"
        }
      },
      "type": "n8n-nodes-base.elasticsearch",
      "typeVersion": 1,
      "position": [
        -1500,
        3220
      ],
      "id": "4086ad7a-2406-46da-90ec-0c2fc7a09cb4",
      "name": "Query - Full1",
      "credentials": {
        "elasticsearchApi": {
          "id": "wwaILZtoajWrVXwt",
          "name": "Elasticsearch account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// n8n Function Node: Corrected Merge Split-Chunk Groups\n\nconst grouped = {};\n\n// 1. Group all items by the “true” chunk identifier\nfor (const item of $input.all()) {\n  const data = item.json;\n  // Use parent_chunk_id if it exists, else chunk_id\n  const parentId = data.metadata?.is_split_chunk\n    ? data.metadata.parent_chunk_id\n    : data.chunk_id;\n\n  if (!grouped[parentId]) grouped[parentId] = [];\n  grouped[parentId].push(data);\n}\n\nconst merged = [];\n\n// 2. For each group, produce exactly one merged record\nfor (const [parentId, parts] of Object.entries(grouped)) {\n  // Sort by the split_part if present (else leave order)\n  parts.sort((a, b) => \n    (a.metadata?.split_part ?? 0) - (b.metadata?.split_part ?? 0)\n  );\n\n  // Stitch text together\n  const text = parts.map(p => p.text).join(\"\\n\\n\");\n\n  // Merge platform_origins arrays from all parts (dedupe by platform)\n  const allOrigins = parts.flatMap(p => p.platform_origins || []);\n  const platform_origins = [];\n  for (const o of allOrigins) {\n    if (!platform_origins.some(existing => existing.platform === o.platform)) {\n      platform_origins.push(o);\n    }\n  }\n\n  // Pick the highest-scoring part to inherit section_title, filename, pages, and score\n  const bestPart = parts.reduce((best, p) => \n    p._score > best._score ? p : best\n  , parts[0]);\n\n  // Build the single merged record\n  const record = {\n    chunk_id: parentId,\n    _score: bestPart._score,\n    section_title: bestPart.section_title,\n    text,\n    metadata: {\n      ...bestPart.metadata,\n      is_split_chunk: false,\n      parent_chunk_id: undefined,\n      split_part: undefined,\n      total_parts: undefined\n    },\n    platform_origins\n  };\n\n  merged.push({ json: record });\n}\nmerged.sort((a, b) => b.json._score - a.json._score);\nreturn merged;\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1480,
        3480
      ],
      "id": "7aea58af-869c-4f5c-b715-c8fce0ca7e31",
      "name": "Merge Chunks1"
    },
    {
      "parameters": {
        "jsCode": "const seen = {};\nconst results = [];\n\nfor (const item of $input.all()) {\n  const { chunk_id, platform, _score } = item.json;\n\n  if (!seen[chunk_id]) {\n    // First time seeing this chunk_id\n    seen[chunk_id] = {\n      ...item.json,\n      platform_origins: [{ platform, score: _score }], // <-- Save score per platform\n    };\n    delete seen[chunk_id].platform_origin;\n    results.push({ json: seen[chunk_id] });\n  } else {\n    // Merge platform origins\n    const existing = seen[chunk_id].platform_origins;\n\n    if (!existing.some(p => p.platform === platform)) {\n      existing.push({ platform, score: _score });\n    }\n\n    // Check if this new hit has a better score\n    if (_score > seen[chunk_id]._score) {\n      Object.assign(seen[chunk_id], {\n        ...item.json,\n        platform_origins: existing, // preserve merged origins with scores\n      });\n    }\n  }\n}\n\nreturn results;\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1880,
        3480
      ],
      "id": "e7a0894a-7bd5-4029-b36c-3cf3f8fab66b",
      "name": "Deduplicate and Best Score1"
    },
    {
      "parameters": {
        "jsCode": "const MIN_SCORE = 1.0;\n\nconst filtered = $input.all()\n  .map(item => item.json)\n  .filter(chunk => chunk._score >= MIN_SCORE)   // Remove low-score chunks\n  .sort((a, b) => b._score - a._score);          // Sort high to low\n\nreturn filtered.map(chunk => ({ json: chunk }));"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1680,
        3480
      ],
      "id": "5d1709aa-4b56-4998-9749-7c565a93e89e",
      "name": "Filter low Scores and Sort1"
    },
    {
      "parameters": {
        "jsCode": "// Configuration\nconst TOKEN_LIMIT = 5000;\nconst MIN_STRONG_SCORE = 7.0;\n\n// Rough token estimator (1 token ~ 4 characters)\nfunction estimateTokenCount(text) {\n  if (!text) return 0;\n  return Math.ceil(text.length / 4);\n}\n\n// Input already filtered and sorted!\nconst chunks = $input.all().map(item => item.json);\n\n// Build the final list\nconst selectedChunks = [];\nlet tokenCount = 0;\n\nfor (const chunk of chunks) {\n  const tokens = estimateTokenCount(chunk.text);\n\n  if ((tokenCount + tokens) <= TOKEN_LIMIT) {\n    selectedChunks.push(chunk);\n    tokenCount += tokens;\n  } else if (chunk._score >= MIN_STRONG_SCORE) {\n    // Allow overflow for very strong chunks\n    selectedChunks.push(chunk);\n    tokenCount += tokens;\n  } else {\n    break; // Stop adding\n  }\n}\n\n// Prepare output\nconst output = selectedChunks.map(chunk => ({ json: chunk }));\n\n// Add token usage metadata (attach to first item for simplicity)\nif (output.length > 0) {\n  output[0].json._token_summary = {\n    total_tokens_estimated: tokenCount,\n    total_chunks_selected: selectedChunks.length,\n  };\n}\n\nreturn output;\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1880,
        3720
      ],
      "id": "ade9b8f6-479f-46ce-8ea9-a035ee38e37a",
      "name": "Token Budgeting1"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "gpt-4.1-nano",
          "mode": "list",
          "cachedResultName": "gpt-4.1-nano"
        },
        "options": {
          "temperature": 0.1
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        -1440,
        3920
      ],
      "id": "2358862e-b629-472c-abab-aedc6682669e",
      "name": "OpenAI Chat Model2",
      "credentials": {
        "openAiApi": {
          "id": "M8xqWvEC6mH6LNuk",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "text": "={{ $json.userPrompt }}",
        "attributes": {
          "attributes": [
            {
              "name": "=client_name",
              "description": "=The name of the organization issuing the RFP."
            },
            {
              "name": "project_name",
              "description": "The official title of the project."
            },
            {
              "name": "industry",
              "description": "The sector or domain relevant to the project."
            },
            {
              "name": "publish_date",
              "description": "The date when the RFP was published."
            },
            {
              "name": "submission_deadline",
              "description": "The final date for submitting proposals."
            },
            {
              "name": "questions_deadline",
              "description": "The last date to submit queries regarding the RFP."
            },
            {
              "name": "contact_email",
              "description": "The email provided for correspondence."
            }
          ]
        },
        "options": {
          "systemPromptTemplate": "={{ $json.systemPrompt }}"
        }
      },
      "type": "@n8n/n8n-nodes-langchain.informationExtractor",
      "typeVersion": 1,
      "position": [
        -1440,
        3720
      ],
      "id": "4d4d35cc-98a1-4bd0-b8a4-f84716e57cbe",
      "name": "Information Extractor1"
    },
    {
      "parameters": {
        "content": "## Inference BASIC INFO\n\"client_name\"\n\"project_name\"\n\"industry\"\n\"publish_date\"\n\"submission_deadline\"\n\"questions_deadline\"\n\"contact_email\"\n",
        "height": 920,
        "width": 1320,
        "color": 5
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        -2340,
        3160
      ],
      "id": "fd3222fa-60b1-45c6-b5dc-0d2d2bdc28d7",
      "name": "Sticky Note5"
    },
    {
      "parameters": {
        "jsCode": "const queries = [\n  {\n    query_type: \"delivery_details\",\n    query: \"Does this RFP specify an MVP, agile sprints, or a delivery schedule with timelines and deadlines?\",\n    keywords: \"MVP, minimum viable product, agile methodology, sprints, Scrum, delivery date, project timeline, delivery schedule, kickoff date, development timeframe\",\n    phrase: \"MVP OR agile OR sprints OR Scrum OR delivery date OR project timeline OR schedule\",\n    description: \"Extract whether an MVP is mentioned, Agile methodology is referenced, and whether a delivery timeline is provided.\"\n  }\n\n];\n\nreturn queries.map(q => ({\n  json: {\n    ...q\n  }\n}));\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -320,
        3500
      ],
      "id": "67f0b477-0f12-4166-aff9-a74740f149cf",
      "name": "Queries3"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "http://192.168.20.70:11434/api/embed",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"model\": \"nomic-embed-text:latest\",\n  \"input\": [\"{{ $json.query }}\"]\n}",
        "options": {}
      },
      "id": "5d37d693-9cf7-4df0-bf75-680d24540bdd",
      "name": "Embed Query - ollama3",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -140,
        3500
      ]
    },
    {
      "parameters": {
        "operation": "getAll",
        "indexId": "=est_tool_rfp",
        "limit": 12,
        "simple": false,
        "options": {
          "query": "={\n  \"size\": 12,\n  \"min_score\": 3.5,\n  \"_source\": [\n    \"chunk_id\",\"section_title\",\"text\",\n    \"metadata.filename\",\"metadata.page_numbers\",\n    \"metadata.parent_chunk_id\",\"metadata.is_split_chunk\",\n    \"metadata.split_part\",\"metadata.total_parts\",\n    \"vector_metadata.token_count\",\"vector_metadata.is_split\",\n    \"vector_metadata.chunk_index\"\n  ],\n\n  \"knn\": {\n    \"field\": \"embeddings\",\n    \"query_vector\": [{{ $json.embeddings[0] }}],\n    \"k\": 20,\n    \"num_candidates\": 80\n  },\n\n  \"query\": {\n    \"bool\": {\n      \"should\": [\n        {\n          \"match_phrase\": {\n            \"text\": {\n              \"query\": \"MVP OR agile OR sprints OR Scrum OR delivery date OR project timeline OR schedule\",\n              \"slop\": 5,\n              \"boost\": 2.0\n            }\n          }\n        },\n        {\n          \"multi_match\": {\n            \"query\": \"MVP, minimum viable product, agile methodology, sprints, Scrum, delivery date, project timeline, delivery schedule, kickoff date, development timeframe\",\n            \"fields\": [\"text^2\",\"section_title^3\"],\n            \"type\": \"most_fields\",\n            \"minimum_should_match\": 2,\n            \"boost\": 1.5\n          }\n        },\n        {\n          \"terms_set\": {\n            \"text.keyword\": {\n              \"terms\": [\n                \"MVP\",\"minimum viable product\",\"agile methodology\",\n                \"sprints\",\"Scrum\",\"delivery date\",\n                \"project timeline\",\"delivery schedule\",\n                \"kickoff date\",\"development timeframe\"\n              ],\n              \"minimum_should_match_script\": {\n                \"source\": \"Math.min(params.num_terms, 2)\"\n              }\n            }\n          }\n        }\n      ],\n      \"minimum_should_match\": 1\n    }\n  },\n\n  \"rescore\": {\n    \"window_size\": 50,\n    \"query\": {\n      \"rescore_query\": {\n        \"match_phrase\": {\n          \"text\": {\n            \"query\": \"MVP OR agile OR sprints OR Scrum OR delivery date OR project timeline OR schedule\",\n            \"slop\": 5\n          }\n        }\n      },\n      \"query_weight\": 0.6,\n      \"rescore_query_weight\": 0.4\n    }\n  },\n\n  \"highlight\": {\n    \"type\": \"unified\",\n    \"fields\": {\n      \"text\": {},\n      \"section_title\": {}\n    }\n  }\n}\n"
        }
      },
      "type": "n8n-nodes-base.elasticsearch",
      "typeVersion": 1,
      "position": [
        40,
        3500
      ],
      "id": "cee73afe-18d8-4048-93fc-d9d3fc5520a1",
      "name": "Query - Full3",
      "credentials": {
        "elasticsearchApi": {
          "id": "wwaILZtoajWrVXwt",
          "name": "Elasticsearch account"
        }
      }
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "17f9e7d3-307e-4d60-92ef-e32285cbec29",
              "name": "_score",
              "value": "={{ $json._score }}",
              "type": "number"
            },
            {
              "id": "618f58cd-27c7-4ab4-8612-899f048afb6c",
              "name": "_id",
              "value": "={{ $json._id }}",
              "type": "string"
            },
            {
              "id": "a8cfb079-48c6-4ce2-a54c-251304107206",
              "name": "chunk_id",
              "value": "={{ $json._source.chunk_id }}",
              "type": "string"
            },
            {
              "id": "22e6e029-7ff1-4870-a1c2-d3b025a2748b",
              "name": "section_title",
              "value": "={{ $json._source.section_title }}",
              "type": "string"
            },
            {
              "id": "27e9a9ac-b6ed-4320-bb21-027f8659e7c5",
              "name": "text",
              "value": "={{ $json._source.text }}",
              "type": "string"
            },
            {
              "id": "6830a868-6492-405b-b8fb-1ae36ea184b2",
              "name": "metadata",
              "value": "={{ $json._source.metadata }}",
              "type": "object"
            },
            {
              "id": "e5dce93c-eb16-42be-8b42-47ca5cfacc52",
              "name": "platform",
              "value": "={{ $('Queries3').item.json.query_type }}",
              "type": "string"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        320,
        3500
      ],
      "id": "321672e1-4e24-414f-a4cd-fcd46d3207c8",
      "name": "Map Response4"
    },
    {
      "parameters": {
        "jsCode": "// n8n Function Node: Dedupe → Merge Origins → Filter → Sort → Fallback\n\nconst MIN_SCORE = 3.0;\nconst DESIRED_COUNT = 10;\n\n// Step 1: Deduplicate & merge platform origins, keep highest‐score record\nconst seen = {};\nfor (const item of $input.all()) {\n  const { chunk_id, platform, _score, ...rest } = item.json;\n  \n  if (!seen[chunk_id]) {\n    // First time seeing this chunk\n    seen[chunk_id] = {\n      chunk_id,\n      _score,\n      ...rest,\n      platform_origins: [{ platform, score: _score }],\n    };\n  } else {\n    // Merge new platform origin\n    const record = seen[chunk_id];\n    if (!record.platform_origins.some(p => p.platform === platform)) {\n      record.platform_origins.push({ platform, score: _score });\n    }\n    // If this hit has a higher score, overwrite core fields\n    if (_score > record._score) {\n      record._score = _score;\n      Object.assign(record, rest);\n    }\n  }\n}\n\n// Convert deduped map back to array of items\nlet deduped = Object.values(seen).map(r => ({ json: r }));\n\n// Step 2: Filter by score and sort descending\nlet filtered = deduped\n  .filter(item => item.json._score >= MIN_SCORE)\n  .sort((a, b) => b.json._score - a.json._score);\n\n// Step 3: Fallback if too few hits\nif (filtered.length < DESIRED_COUNT) {\n  // Return top DESIRED_COUNT from deduped (regardless of score)\n  filtered = deduped\n    .sort((a, b) => b.json._score - a.json._score)\n    .slice(0, DESIRED_COUNT);\n}\n\n// Step 4: Ensure we only return up to DESIRED_COUNT\nfiltered = filtered.slice(0, DESIRED_COUNT);\n\n// Return in n8n-compatible format\nreturn filtered;\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -320,
        3700
      ],
      "id": "0fc4e834-e7d2-48c2-92e8-7c74f1e036ab",
      "name": "Deduplicate and Best Score3"
    },
    {
      "parameters": {
        "jsCode": "\nconst contextForPrompt = $input.first().json.context;\n\nconst systemPrompt = \"You are a precise assistant that extracts structured delivery information from RFP excerpts. Focus only on the provided context. If something is not specified, state that clearly. Provide concise, realistic, and fact-based summaries.\"\n\nconst userPrompt = `You are analyzing excerpts from an RFP to extract key information about **delivery and implementation strategy**.\n\n### excerpts:\n\n${contextForPrompt}\n\nIdentify and summarize, if available:\n\n- Is the project scoped as an **MVP (Minimum Viable Product)**, a **phased rollout**, or a **full (big bang) launch**?\n- Are there any **delivery methodology indications** (e.g., Agile, Scrum, Waterfall)?\n- Are there **delivery deadlines** or **development timeframes** specified?\n- Any explicit requirements for **post-delivery support**, **maintenance**, **knowledge transfer**, or **end-user training**?\n\n**Instructions**:\n- If an aspect is clearly stated, summarize it briefly in few words and factually.\n- If not clearly mentioned, write: “Not specified in the provided context.”\n- Think critically but base your conclusions strictly on the Context excerpts provided.\n- Minor standard industry reasoning (like MVPs needing acceptance testing) is allowed if strongly hinted.\n- Use Think tool to help you with reasoning.\n- If no information is found, say: “Not specified in the provided context.”\n\nRemember: **Do not hallucinate or invent details** beyond the excerpts.\n`;\n\nreturn {\n  json: {\n    userPrompt,\n    systemPrompt: systemPrompt\n  }\n};\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        500,
        3700
      ],
      "id": "3f9eb1f5-24a7-4f1e-bcaf-a71f27b86fb7",
      "name": "PreparePrompts3"
    },
    {
      "parameters": {
        "jsCode": "// n8n Function Node: Corrected Merge Split-Chunk Groups\n\nconst grouped = {};\n\n// 1. Group all items by the “true” chunk identifier\nfor (const item of $input.all()) {\n  const data = item.json;\n  // Use parent_chunk_id if it exists, else chunk_id\n  const parentId = data.metadata?.is_split_chunk\n    ? data.metadata.parent_chunk_id\n    : data.chunk_id;\n\n  if (!grouped[parentId]) grouped[parentId] = [];\n  grouped[parentId].push(data);\n}\n\nconst merged = [];\n\n// 2. For each group, produce exactly one merged record\nfor (const [parentId, parts] of Object.entries(grouped)) {\n  // Sort by the split_part if present (else leave order)\n  parts.sort((a, b) => \n    (a.metadata?.split_part ?? 0) - (b.metadata?.split_part ?? 0)\n  );\n\n  // Stitch text together\n  const text = parts.map(p => p.text).join(\"\\n\\n\");\n\n  // Merge platform_origins arrays from all parts (dedupe by platform)\n  const allOrigins = parts.flatMap(p => p.platform_origins || []);\n  const platform_origins = [];\n  for (const o of allOrigins) {\n    if (!platform_origins.some(existing => existing.platform === o.platform)) {\n      platform_origins.push(o);\n    }\n  }\n\n  // Pick the highest-scoring part to inherit section_title, filename, pages, and score\n  const bestPart = parts.reduce((best, p) => \n    p._score > best._score ? p : best\n  , parts[0]);\n\n  // Build the single merged record\n  const record = {\n    chunk_id: parentId,\n    _score: bestPart._score,\n    section_title: bestPart.section_title,\n    text,\n    metadata: {\n      ...bestPart.metadata,\n      is_split_chunk: false,\n      parent_chunk_id: undefined,\n      split_part: undefined,\n      total_parts: undefined\n    },\n    platform_origins\n  };\n\n  merged.push({ json: record });\n}\nmerged.sort((a, b) => b.json._score - a.json._score);\nreturn merged;\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -120,
        3700
      ],
      "id": "8b97f05a-2239-45e8-b99b-f3f9f7040548",
      "name": "Merge Chunks3"
    },
    {
      "parameters": {
        "jsCode": "// Configuration\nconst TOKEN_LIMIT = 5000;\nconst MIN_STRONG_SCORE = 7.0;\n\n// Rough token estimator (1 token ~ 4 characters)\nfunction estimateTokenCount(text) {\n  if (!text) return 0;\n  return Math.ceil(text.length / 4);\n}\n\n// Input already filtered and sorted!\nconst chunks = $input.all().map(item => item.json);\n\n// Build the final list\nconst selectedChunks = [];\nlet tokenCount = 0;\n\nfor (const chunk of chunks) {\n  const tokens = estimateTokenCount(chunk.text);\n\n  if ((tokenCount + tokens) <= TOKEN_LIMIT) {\n    selectedChunks.push(chunk);\n    tokenCount += tokens;\n  } else if (chunk._score >= MIN_STRONG_SCORE) {\n    // Allow overflow for very strong chunks\n    selectedChunks.push(chunk);\n    tokenCount += tokens;\n  } else {\n    break; // Stop adding\n  }\n}\n\n// Prepare output\nconst output = selectedChunks.map(chunk => ({ json: chunk }));\n\n// Add token usage metadata (attach to first item for simplicity)\nif (output.length > 0) {\n  output[0].json._token_summary = {\n    total_tokens_estimated: tokenCount,\n    total_chunks_selected: selectedChunks.length,\n  };\n}\n\nreturn output;\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        80,
        3700
      ],
      "id": "5a50bce0-76fd-4fe5-bb5a-b48f2a43d307",
      "name": "Token Budgeting3"
    },
    {
      "parameters": {},
      "type": "@n8n/n8n-nodes-langchain.toolThink",
      "typeVersion": 1,
      "position": [
        900,
        3800
      ],
      "id": "fd4e9ddb-984d-4c73-aa12-925e4da758e2",
      "name": "Think2"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "gpt-4.1",
          "mode": "list",
          "cachedResultName": "gpt-4.1"
        },
        "options": {
          "temperature": 0.1
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        740,
        3760
      ],
      "id": "ae088624-ed96-4ca6-8361-081de5f80066",
      "name": "OpenAI Chat Model4",
      "credentials": {
        "openAiApi": {
          "id": "M8xqWvEC6mH6LNuk",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "content": "## Delivery Context\n",
        "height": 680,
        "width": 1680,
        "color": 3
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        -400,
        3360
      ],
      "id": "b72e0ed9-51f0-4c16-aadd-53c9a506a18c",
      "name": "Sticky Note7"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ $json.userPrompt }}",
        "hasOutputParser": true,
        "options": {
          "systemMessage": "={{ $json.systemPrompt }}"
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.9,
      "position": [
        800,
        3500
      ],
      "id": "94da106c-2b5e-4464-a188-f337ad3ee4e5",
      "name": "Delivery Context"
    },
    {
      "parameters": {
        "jsonSchemaExample": "{\n  \"delivery_model\": \"\",\n  \"delivery_methodology\": \"\",\n  \"delivery_timeframe\": \"\",\n  \"post_delivery_support\": \"\",\n  \"rationale\": \"\"\n}"
      },
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "typeVersion": 1.2,
      "position": [
        1060,
        3780
      ],
      "id": "d038e4db-a404-4834-9765-d7696c950ae3",
      "name": "Delivery Context1"
    },
    {
      "parameters": {
        "jsCode": "const queries = [\n  {\n    query_type: \"regulatory_compliance\",\n    query: \"What regulatory compliance frameworks, security and privacy standards, or legal obligations must the project adhere to?\",\n    keywords: [\n        \"gdpr\", \"hipaa\", \"pci dss\", \"iso 27001\", \"iso 22301\",\n        \"soc 2\", \"soc 1\", \"fisma\", \"fedramp\", \"ccpa\",\n        \"nist 800-53\", \"lgpd\", \"pdpl\", \"nca ecc\",\n        \"uae data law\", \"qatar data protection law\",\n        \"gdpr compliance\", \"hipaa compliance\", \"cybersecurity standards\",\n        \"security compliance\", \"data protection law\", \"regulatory requirements\",\n        \"legal obligations\", \"privacy regulations\", \"sovereignty laws\",\n        \"local data protection\", \"industry compliance\",\n        \"legal regulatory compliance\", \"on premise deployment\"\n      ],\n    phrase: \"GDPR OR HIPAA OR PCI DSS OR ISO 27001 OR ISO 22301 OR SOC 2 OR FedRAMP OR compliance OR regulatory requirements OR data protection OR sovereignty law OR privacy regulation OR on premise deployment\",\n    description: \"Extract all explicitly mentioned regulatory frameworks, compliance standards, and related legal obligations from the RFP.\"\n  }\n];\n\nreturn queries.map(q => ({\n  json: {\n    ...q\n  }\n}));\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -2440,
        4340
      ],
      "id": "7a985dff-161c-4686-8a9f-ee63a11daf20",
      "name": "Queries4"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "http://192.168.20.70:11434/api/embed",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"model\": \"nomic-embed-text:latest\",\n  \"input\": [\"{{ $json.query }}\"]\n}",
        "options": {}
      },
      "id": "45ca75d4-2d7c-4478-a743-39526e301d6a",
      "name": "Embed Query - ollama4",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -2260,
        4340
      ]
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "17f9e7d3-307e-4d60-92ef-e32285cbec29",
              "name": "_score",
              "value": "={{ $json._score }}",
              "type": "number"
            },
            {
              "id": "618f58cd-27c7-4ab4-8612-899f048afb6c",
              "name": "_id",
              "value": "={{ $json._id }}",
              "type": "string"
            },
            {
              "id": "a8cfb079-48c6-4ce2-a54c-251304107206",
              "name": "chunk_id",
              "value": "={{ $json._source.chunk_id }}",
              "type": "string"
            },
            {
              "id": "22e6e029-7ff1-4870-a1c2-d3b025a2748b",
              "name": "section_title",
              "value": "={{ $json._source.section_title }}",
              "type": "string"
            },
            {
              "id": "27e9a9ac-b6ed-4320-bb21-027f8659e7c5",
              "name": "text",
              "value": "={{ $json._source.text }}",
              "type": "string"
            },
            {
              "id": "6830a868-6492-405b-b8fb-1ae36ea184b2",
              "name": "metadata",
              "value": "={{ $json._source.metadata }}",
              "type": "object"
            },
            {
              "id": "e5dce93c-eb16-42be-8b42-47ca5cfacc52",
              "name": "platform",
              "value": "={{ $('Queries4').item.json.query_type }}",
              "type": "string"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        -1860,
        4340
      ],
      "id": "b1d01f33-dd86-4efa-9f38-9496a4b1c87f",
      "name": "Map Response5"
    },
    {
      "parameters": {
        "jsCode": "// n8n Function Node: Dedupe → Merge Origins → Filter → Sort → Fallback\n\nconst MIN_SCORE = 3.0;\nconst DESIRED_COUNT = 10;\n\n// Step 1: Deduplicate & merge platform origins, keep highest‐score record\nconst seen = {};\nfor (const item of $input.all()) {\n  const { chunk_id, platform, _score, ...rest } = item.json;\n  \n  if (!seen[chunk_id]) {\n    // First time seeing this chunk\n    seen[chunk_id] = {\n      chunk_id,\n      _score,\n      ...rest,\n      platform_origins: [{ platform, score: _score }],\n    };\n  } else {\n    // Merge new platform origin\n    const record = seen[chunk_id];\n    if (!record.platform_origins.some(p => p.platform === platform)) {\n      record.platform_origins.push({ platform, score: _score });\n    }\n    // If this hit has a higher score, overwrite core fields\n    if (_score > record._score) {\n      record._score = _score;\n      Object.assign(record, rest);\n    }\n  }\n}\n\n// Convert deduped map back to array of items\nlet deduped = Object.values(seen).map(r => ({ json: r }));\n\n// Step 2: Filter by score and sort descending\nlet filtered = deduped\n  .filter(item => item.json._score >= MIN_SCORE)\n  .sort((a, b) => b.json._score - a.json._score);\n\n// Step 3: Fallback if too few hits\nif (filtered.length < DESIRED_COUNT) {\n  // Return top DESIRED_COUNT from deduped (regardless of score)\n  filtered = deduped\n    .sort((a, b) => b.json._score - a.json._score)\n    .slice(0, DESIRED_COUNT);\n}\n\n// Step 4: Ensure we only return up to DESIRED_COUNT\nfiltered = filtered.slice(0, DESIRED_COUNT);\n\n// Return in n8n-compatible format\nreturn filtered;\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -2440,
        4740
      ],
      "id": "a680a283-3d32-4798-8a83-82df8df7c8fc",
      "name": "Deduplicate and Best Score4"
    },
    {
      "parameters": {
        "jsCode": "// n8n Function Node: Corrected Merge Split-Chunk Groups\n\nconst grouped = {};\n\n// 1. Group all items by the “true” chunk identifier\nfor (const item of $input.all()) {\n  const data = item.json;\n  // Use parent_chunk_id if it exists, else chunk_id\n  const parentId = data.metadata?.is_split_chunk\n    ? data.metadata.parent_chunk_id\n    : data.chunk_id;\n\n  if (!grouped[parentId]) grouped[parentId] = [];\n  grouped[parentId].push(data);\n}\n\nconst merged = [];\n\n// 2. For each group, produce exactly one merged record\nfor (const [parentId, parts] of Object.entries(grouped)) {\n  // Sort by the split_part if present (else leave order)\n  parts.sort((a, b) => \n    (a.metadata?.split_part ?? 0) - (b.metadata?.split_part ?? 0)\n  );\n\n  // Stitch text together\n  const text = parts.map(p => p.text).join(\"\\n\\n\");\n\n  // Merge platform_origins arrays from all parts (dedupe by platform)\n  const allOrigins = parts.flatMap(p => p.platform_origins || []);\n  const platform_origins = [];\n  for (const o of allOrigins) {\n    if (!platform_origins.some(existing => existing.platform === o.platform)) {\n      platform_origins.push(o);\n    }\n  }\n\n  // Pick the highest-scoring part to inherit section_title, filename, pages, and score\n  const bestPart = parts.reduce((best, p) => \n    p._score > best._score ? p : best\n  , parts[0]);\n\n  // Build the single merged record\n  const record = {\n    chunk_id: parentId,\n    _score: bestPart._score,\n    section_title: bestPart.section_title,\n    text,\n    metadata: {\n      ...bestPart.metadata,\n      is_split_chunk: false,\n      parent_chunk_id: undefined,\n      split_part: undefined,\n      total_parts: undefined\n    },\n    platform_origins\n  };\n\n  merged.push({ json: record });\n}\nmerged.sort((a, b) => b.json._score - a.json._score);\nreturn merged;\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -2260,
        4740
      ],
      "id": "e1818449-77f2-40c2-b5c5-ce47bc1cc568",
      "name": "Merge Chunks4"
    },
    {
      "parameters": {
        "jsCode": "// CONFIG\nconst TOKEN_LIMIT      = 5000;\nconst RESERVED_TOKENS  = 100;\nconst MIN_STRONG_SCORE = 7.0;\nconst SLOT_RESERVE     = 2;\nconst TOKEN_RESERVE    = 800;\nvar overflow;\n\nfunction estimateTokens(text) {\n  return Math.ceil(text.length / 4);\n}\n\n// 1. Annotate each chunk with locScore & regScore\nconst all = $input.all().map(i => {\n  const origins = i.json.platform_origins;\n  const loc = origins.find(o => o.platform === 'project_location');\n  const reg = origins.find(o => o.platform === 'regulatory_compliance');\n  return {\n    ...i.json,\n    locScore: loc  ? loc.score : 0,\n    regScore: reg  ? reg.score : 0,\n  };\n});\n\n// 2. Split into country vs regulatory pools\nconst countryPool    = all.filter(c => c.locScore > 0);\nconst regulatoryPool = all.filter(c => c.regScore > 0);\n\n// 3. Sort each by its dedicated score\ncountryPool.sort((a,b)    => b.locScore - a.locScore);\nregulatoryPool.sort((a,b) => b.regScore - a.regScore);\n\nlet tokensUsed = RESERVED_TOKENS;\nconst selected = [];\n\n// 4. Reserve country slots by locScore\nfor (const c of countryPool) {\n  if (selected.filter(x => x.locScore > 0).length >= SLOT_RESERVE) break;\n  const t = estimateTokens(c.text);\n  if (tokensUsed + t > TOKEN_LIMIT) break;\n  selected.push(c);\n  tokensUsed += t;\n}\n\n// 5. Reserve token budget for country\nconst countryTokensSoFar = selected\n  .filter(c => c.locScore > 0)\n  .reduce((sum,c) => sum + estimateTokens(c.text), 0);\nconst countryTokensLeft = Math.max(0, TOKEN_RESERVE - countryTokensSoFar);\n\n// 6. Fill with reg chunks by regScore\nfor (const c of regulatoryPool) {\n  const t = estimateTokens(c.text);\n  if (tokensUsed + t > TOKEN_LIMIT - countryTokensLeft) break;\n  selected.push(c);\n  tokensUsed += t;\n}\n\n// 7. Top up any additional country chunks\nfor (const c of countryPool.slice(SLOT_RESERVE)) {\n  const t = estimateTokens(c.text);\n  if (tokensUsed + t > TOKEN_LIMIT) break;\n  selected.push(c);\n  tokensUsed += t;\n}\n\n// 8. Optional overflow by the higher of locScore/regScore\nconst hasStrong = selected.some(c => Math.max(c.locScore, c.regScore) >= MIN_STRONG_SCORE);\nif (!hasStrong) {\n  overflow = [...countryPool, ...regulatoryPool]\n    .sort((a,b) => Math.max(b.locScore,b.regScore) - Math.max(a.locScore,a.regScore))\n    .find(c => Math.max(c.locScore, c.regScore) >= MIN_STRONG_SCORE);\n  if (overflow) {\n    selected.push(overflow);\n    tokensUsed += estimateTokens(overflow.text);\n  }\n}\n\n// 9. Wrap & add summary\nconst output = selected.map(c => ({ json: c }));\nif (output.length) {\n  output[0].json._token_summary = {\n    total_tokens: tokensUsed,\n    country_chunks:    selected.filter(c => c.locScore    > 0).length,\n    regulatory_chunks: selected.filter(c => c.regScore    > 0).length,\n    overflow_used:     !hasStrong && !!overflow\n  };\n}\n\nreturn output;"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -2080,
        4740
      ],
      "id": "cf6b2637-9f05-44da-866e-a7a1580fc6db",
      "name": "Token Budgeting4"
    },
    {
      "parameters": {},
      "type": "@n8n/n8n-nodes-langchain.toolThink",
      "typeVersion": 1,
      "position": [
        -1160,
        4640
      ],
      "id": "d1a708bf-78f1-4837-8fe5-775f0fa7bb09",
      "name": "Think3"
    },
    {
      "parameters": {
        "content": "### Regulatory",
        "height": 680,
        "width": 1680
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        -2480,
        4280
      ],
      "id": "74bddc81-2cd0-4672-97e8-0a2157fb61de",
      "name": "Sticky Note8"
    },
    {
      "parameters": {
        "jsonSchemaExample": "{\n  \"regulatory_compliance\": [\n    {\n      \"name\": \"GDPR\",\n      \"source\": \"Explicitly stated\"\n    },\n    {\n      \"name\": \"NCA ECC\",\n      \"source\": \"Inferred based on Saudi Arabia hosting\"\n    }\n  ],\n  \"country\": \"\",\n  \"regulatory_classification\": {\n    \"level\": \"Ultra Highly Regulated | Highly Regulated | Moderately Regulated | Lightly Regulated\",\n    \"confidence\": \"High | Medium | Low\",\n    \"rationale\": \"Brief explanation based on context findings.\"\n  }\n}"
      },
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "typeVersion": 1.2,
      "position": [
        -1020,
        4640
      ],
      "id": "3f3062a1-5660-4ba7-8ea6-dbe4add696d0",
      "name": "Delivery Context3"
    },
    {
      "parameters": {},
      "type": "n8n-nodes-base.merge",
      "typeVersion": 3.1,
      "position": [
        -1660,
        4520
      ],
      "id": "d4b20970-c07e-4610-b987-4e1d31faed64",
      "name": "Merge"
    },
    {
      "parameters": {
        "jsCode": "const queries = [\n  {\n    query_type: \"project_location\",\n    query: \"Where will the system be deployed or hosted? Which country or region is specified for data residency?\",\n    keywords: \"project location, hosting location, deployment country, client country, jurisdiction, operational country, hosted within, hosted in, operating region, datacenter location, within territory\",\n    phrase: \"project location OR hosting country OR jurisdiction OR operating region OR data residency\",\n    description: \"Extract where the project will be operated, deployed, or hosted.\"\n  }\n];\n\nreturn queries.map(q => ({\n  json: {\n    ...q\n  }\n}));\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -2440,
        4540
      ],
      "id": "d6294df1-954f-418e-8aad-68990f97e1ee",
      "name": "Queries5"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "http://192.168.20.70:11434/api/embed",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"model\": \"nomic-embed-text:latest\",\n  \"input\": [\"{{ $json.query }}\"]\n}",
        "options": {}
      },
      "id": "b73bb618-d49a-4a0d-836d-0a709afeeeb7",
      "name": "Embed Query - ollama5",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -2260,
        4540
      ]
    },
    {
      "parameters": {
        "operation": "getAll",
        "indexId": "=est_tool_rfp",
        "limit": 15,
        "simple": false,
        "options": {
          "query": "={\n  \"size\": 15,\n  \"min_score\": 1.5,\n  \"_source\": [\n    \"chunk_id\",\n    \"section_title\",\n    \"text\",\n    \"metadata.filename\",\n    \"metadata.page_numbers\",\n    \"metadata.parent_chunk_id\",\n    \"metadata.is_split_chunk\",\n    \"metadata.total_parts\",\n    \"vector_metadata.token_count\",\n    \"vector_metadata.is_split\",\n    \"vector_metadata.chunk_index\"\n  ],\n  \"knn\": {\n    \"field\": \"embedding\",\n    \"query_vector\": [{{ $json.embeddings }}],\n    \"k\": 25,\n    \"num_candidates\": 100\n  },\n  \"query\": {\n    \"bool\": {\n      \"should\": [\n        {\n          \"multi_match\": {\n            \"query\": \"{{ $('Queries5').item.json.query }}\",\n            \"fields\": [\n              \"text^2\",\n              \"section_title^3\"\n            ],\n            \"type\": \"best_fields\",\n            \"minimum_should_match\": \"50%\"\n          }\n        }\n      ]\n    }\n  },\n  \"rescore\": {\n    \"window_size\": 35,\n    \"query\": {\n      \"rescore_query\": {\n        \"match_phrase\": {\n          \"text\": {\n            \"query\": \"{{ $('Queries5').item.json.query }}\"\n          }\n        }\n      },\n      \"query_weight\": 0.7,\n      \"rescore_query_weight\": 0.3\n    }\n  }\n}"
        }
      },
      "type": "n8n-nodes-base.elasticsearch",
      "typeVersion": 1,
      "position": [
        -2080,
        4540
      ],
      "id": "2c521daf-4c36-4a45-9940-fee4fbe62b1d",
      "name": "Query - Full5",
      "credentials": {
        "elasticsearchApi": {
          "id": "wwaILZtoajWrVXwt",
          "name": "Elasticsearch account"
        }
      }
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "17f9e7d3-307e-4d60-92ef-e32285cbec29",
              "name": "_score",
              "value": "={{ $json._score }}",
              "type": "number"
            },
            {
              "id": "618f58cd-27c7-4ab4-8612-899f048afb6c",
              "name": "_id",
              "value": "={{ $json._id }}",
              "type": "string"
            },
            {
              "id": "a8cfb079-48c6-4ce2-a54c-251304107206",
              "name": "chunk_id",
              "value": "={{ $json._source.chunk_id }}",
              "type": "string"
            },
            {
              "id": "22e6e029-7ff1-4870-a1c2-d3b025a2748b",
              "name": "section_title",
              "value": "={{ $json._source.section_title }}",
              "type": "string"
            },
            {
              "id": "27e9a9ac-b6ed-4320-bb21-027f8659e7c5",
              "name": "text",
              "value": "={{ $json._source.text }}",
              "type": "string"
            },
            {
              "id": "6830a868-6492-405b-b8fb-1ae36ea184b2",
              "name": "metadata",
              "value": "={{ $json._source.metadata }}",
              "type": "object"
            },
            {
              "id": "e5dce93c-eb16-42be-8b42-47ca5cfacc52",
              "name": "platform",
              "value": "={{ $('Queries5').item.json.query_type }}",
              "type": "string"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        -1860,
        4540
      ],
      "id": "0d3e30b1-fecd-4267-98a4-c4de7390685b",
      "name": "Map Response6"
    },
    {
      "parameters": {
        "operation": "getAll",
        "indexId": "=est_tool_rfp",
        "limit": 10,
        "simple": false,
        "options": {
          "query": "={\n  \"size\": 10,\n  \"min_score\": 2,\n  \"_source\": [\n    \"chunk_id\",\n    \"section_title\",\n    \"text\",\n    \"metadata.filename\",\n    \"metadata.page_numbers\"\n  ],\n\n  \"knn\": {\n    \"field\": \"embeddings\",\n    \"query_vector\": [{{ $json.embeddings[0] }}],\n    \"k\": 100,\n    \"num_candidates\": 500\n  },\n\n  \"query\": {\n    \"bool\": {\n      \"should\": [\n        {\n          \"match_phrase\": {\n            \"text\": {\n              \"query\": \"{{ $('Queries4').item.json.query }}\",\n              \"slop\": 3,\n              \"boost\": 2.0\n            }\n          }\n        },\n        {\n          \"multi_match\": {\n            \"query\": \"{{ $('Queries4').item.json.query }}\",\n            \"fields\": [\"text^2\", \"section_title^3\"],\n            \"type\": \"most_fields\",\n            \"minimum_should_match\": \"30%\"\n          }\n        },\n        {\n          \"terms_set\": {\n            \"text.keyword\": {\n              \"terms\": [\n                \"gdpr\", \"hipaa\", \"pci dss\", \"iso 27001\", \"iso 22301\",\n                \"soc 2\", \"soc 1\", \"fisma\", \"fedramp\", \"ccpa\",\n                \"nist 800-53\", \"lgpd\", \"pdpl\", \"nca ecc\",\n                \"uae data law\", \"qatar data protection law\",\n                \"gdpr compliance\", \"hipaa compliance\", \"cybersecurity standards\",\n                \"security compliance\", \"data protection law\", \"regulatory requirements\",\n                \"legal obligations\", \"privacy regulations\", \"sovereignty laws\",\n                \"local data protection\", \"industry compliance\",\n                \"legal regulatory compliance\", \"on premise deployment\"\n              ],\n              \"minimum_should_match_script\": {\n                \"source\": \"Math.min(params.num_terms, 2)\"\n              }\n            }\n          }\n        }\n      ],\n      \"minimum_should_match\": 1\n    }\n  },\n\n  \"rescore\": {\n    \"window_size\": 200,\n    \"query\": {\n      \"rescore_query\": {\n        \"match_phrase\": {\n          \"text\": {\n            \"query\": \"{{ $('Queries4').item.json.query }}\",\n            \"slop\": 2\n          }\n        }\n      },\n      \"query_weight\": 0.5,\n      \"rescore_query_weight\": 0.5\n    }\n  },\n\n  \"highlight\": {\n    \"type\": \"unified\",\n    \"fields\": {\n      \"text\": {}\n    }\n  }\n}\n"
        }
      },
      "type": "n8n-nodes-base.elasticsearch",
      "typeVersion": 1,
      "position": [
        -2080,
        4340
      ],
      "id": "8c16ebe8-edc6-4804-9bd2-a221e0bf145a",
      "name": "Query - Full6",
      "credentials": {
        "elasticsearchApi": {
          "id": "wwaILZtoajWrVXwt",
          "name": "Elasticsearch account"
        }
      }
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ $json.userPrompt }}",
        "hasOutputParser": true,
        "options": {
          "systemMessage": "={{ $json.systemPrompt }}"
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.9,
      "position": [
        -1280,
        4360
      ],
      "id": "2582a314-68d4-4229-acf1-06188377f323",
      "name": "Regulatory"
    },
    {
      "parameters": {
        "operation": "getAll",
        "indexId": "=est_tool_rfp",
        "limit": 10,
        "simple": false,
        "options": {
          "query": "={\n  \"size\": 10,\n  \"min_score\": 3.0,\n  \"_source\": [\n    \"chunk_id\",\n    \"section_title\",\n    \"text\",\n    \"metadata.filename\",\n    \"metadata.page_numbers\"\n  ],\n  \"knn\": {\n    \"field\": \"embedding\",\n    \"query_vector\": [{{ $json.embeddings }}],\n    \"k\": 10,\n    \"num_candidates\": 100\n  },\n  \"query\": {\n    \"bool\": {\n      \"should\": [\n        {\n          \"multi_match\": {\n            \"query\": \"{{ $('Queries4').item.json.query }}\",\n            \"fields\": [\"text^2\", \"section_title^3\"],\n            \"type\": \"best_fields\",\n            \"minimum_should_match\": \"30%\"\n          }\n        },\n        {\n          \"terms\": {\n            \"text\": [\n              \"GDPR\", \"HIPAA\", \"PCI DSS\", \"ISO 27001\", \"SOC 2\", \n              \"ISO 22301\", \"FedRAMP\", \"NCA ECC\", \"LGPD\", \"CCPA\"\n            ],\n            \"boost\": 3.0\n          }\n        }\n      ],\n      \"minimum_should_match\": 1\n    }\n  },\n  \"rescore\": {\n    \"window_size\": 50,\n    \"query\": {\n      \"rescore_query\": {\n        \"match_phrase\": {\n          \"text\": {\n            \"query\": \"{{ $('Queries4').item.json.query }}\"\n          }\n        }\n      },\n      \"query_weight\": 0.7,\n      \"rescore_query_weight\": 0.3\n    }\n  }\n}\n"
        }
      },
      "type": "n8n-nodes-base.elasticsearch",
      "typeVersion": 1,
      "position": [
        -2080,
        4160
      ],
      "id": "d1eb6c92-cea9-4b26-a563-a1d8607a3ee4",
      "name": "Query - Full7",
      "credentials": {
        "elasticsearchApi": {
          "id": "wwaILZtoajWrVXwt",
          "name": "Elasticsearch account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "\nconst contextForPrompt = $input.first().json.context\n\nconst systemPrompt = \"You are a precise assistant tasked with extracting regulatory and compliance information from RFP excerpts. Only use the provided context—do not hallucinate. If something is not stated, explicitly say so. Always respond in the strict JSON format described by the user.\";\n\nconst userPrompt = `You are analyzing excerpts from an RFP document to extract information related to **security, compliance, and regulatory requirements**.\n\nAllowed frameworks to extract:\nGDPR, HIPAA, PCI DSS, ISO 27001, ISO 22301, SOC 2, SOC 1, FISMA, FedRAMP, CCPA, NIST 800-53, LGPD, PDPL, NCA ECC, UAE Data Law, Qatar Data Protection Law, WCAG 2.1 Level AA, on premise deployment.\n\nHere are the retrieved excerpts from the RFP:\n### excerpts:\n\n${contextForPrompt}\n\nYour tasks:\n\n1. Identify and list all explicitly mentioned regulatory standards, compliance frameworks, cybersecurity requirements or accessibility standards (e.g., GDPR, HIPAA, PCI DSS, ISO 27001, WCAG 2.1). Identify the ones that are desireable also.\n2. If the project country or hosting location is mentioned, and no specific standards are stated, reasonably infer expected regulatory frameworks based on the region (e.g., Saudi Arabia → NCA ECC, PDPL, EU -> GDPR).\n3. Classify the project's **overall regulatory level** as:\nInstruction:\nClassify the project’s regulatory level based on the definitions below. Choose one of the following categories:\n\"Ultra Highly Regulated\", \"Highly Regulated\", \"Moderately Regulated\", or \"Lightly Regulated\".\nBase your decision on deployment requirements, data handling, compliance expectations, and industry type.\n\nUltra Highly Regulated\n\t•\tMultiple strong, explicit regulatory demands\n\t•\tMust deploy on-premise (no public cloud)\n\t•\tStrict data handling: encryption required, no external API calls allowed\n\t•\tRequires formal compliance certifications (e.g., HIPAA, PCI-DSS, ISO 27001)\n\t•\tCommon industries: government, defense, banking, healthcare, critical infrastructure\nHighly Regulated\n\t•\tMultiple strong, explicit regulatory demands\n\t•\tCloud deployment allowed but under strict security conditions\n\t•\tStrong focus on compliance and protection of sensitive data\n\t•\tCommon industries: insurance, fintech, enterprise healthcare tech, telecom\nModerately Regulated\n\t•\tSome regulatory requirements or country-specific compliance hints\n\t•\tBest practices expected but not strictly enforced\n\t•\tCloud and SaaS solutions generally allowed with standard security measures\n\t•\tCommon industries: e-commerce, HR platforms, education tech, retail banking\nLightly Regulated\n\t•\tNo clear regulatory demands\n\t•\tMinimal or no compliance pressure\n\t•\tFull flexibility to use cloud, SaaS, and external APIs\n\t•\tCommon industries: marketing tech, general SaaS products, media, entertainment\nNotes:\n\t•\tPrefer “Ultra Highly Regulated” if on-premise deployment and strict compliance are explicitly required.\n\t•\tPrefer “Lightly Regulated” if no regulations or restrictions are mentioned at all.\n\n⸻\n\n**Output format (strict JSON):**\n\n\\`\\`\\`json\n{\n  \"regulatory_compliance\": [\n    {\n      \"name\": \"GDPR\",\n      \"source\": \"Explicitly stated\"\n    },\n    {\n      \"name\": \"NCA ECC\",\n      \"source\": \"Inferred based on Saudi Arabia hosting\"\n    },\n    {\n      \"name\": \"FedRAMP\",\n      \"source\": \"Desireable\"\n    }\n  ],\n  \"country\": \"\",\n  \"regulatory_classification\": {\n    \"level\": \"Ultra Highly Regulated | Highly Regulated | Moderately Regulated | Lightly Regulated\",\n    \"confidence\": \"High | Medium | Low\",\n    \"rationale\": \"Brief explanation based on context findings.\"\n  }\n}\n\\`\\`\\`\n\n---\n**Instructions**:\n- If no standards are found, implicit or explicit, set \\`regulatory_compliance\\` to an empty list.\n- If a country is mentioned (e.g., Croatia) and that country belongs to a known regulatory framework (e.g., EU → GDPR), you must infer the associated compliance standard even if it is not explicitly named.\n- Be realistic. Do not hallucinate or assume heavy compliance without basis.\n- Use critical thinking if location hints strongly at certain laws.\n- Stay strictly within the provided Context.\n- Use Think tool to help you with reasoning.`;\n\nreturn {\n  json: {\n    userPrompt,\n    systemPrompt\n  }\n};\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1660,
        4740
      ],
      "id": "d771e178-b640-4b1f-8437-06dbdabb3f4b",
      "name": "PreparePrompts5"
    },
    {
      "parameters": {
        "jsCode": "/**\n * Prepare ES chunks for Claude, without chunk‐length limiting.\n */\nfunction prepareSecurityRegulatoryContextForClaude(esResults) {\n  if (!Array.isArray(esResults)) {\n    throw new Error(\"Input must be an array of Elasticsearch results\");\n  }\n\n  // simple Markdown escaper\n  function mdEscape(str) {\n    return str.replace(/(`|\\*|_|~|>|\\[|\\])/g, \"\\\\$1\");\n  }\n\n  // normalize bullets and split into lines\n  function cleanText(raw) {\n    return raw\n      .replace(/^\\s*-\\s+/gm, \"\\n- \")\n      .replace(/^\\s*\\*\\s+/gm, \"\\n- \")\n      .replace(/[ \\t]+/g, \" \")\n      .replace(/\\. ([A-Z])/g, \".\\n$1\")\n      .replace(/\\n{3,}/g, \"\\n\\n\")\n      .trim();\n  }\n\n  const blocks = esResults.map(chunk => {\n    const { chunk_id, section_title, text = \"\", metadata = {}, _score, regScore, locScore } = chunk;\n\n    // Heading\n    const title = section_title\n      ? mdEscape(section_title)\n      : `Untitled Section (${chunk_id})`;\n\n    // Build YAML metadata\n    const pages = Array.isArray(metadata.page_numbers)\n      ? metadata.page_numbers.join(\", \")\n      : metadata.page_numbers || \"Unknown\";\n\n    const metaLines = [\n      `filename: ${metadata.filename || \"Unknown Document\"}`,\n      `pages: ${pages}`,\n      `score: ${_score.toFixed(2)}`,\n    ];\n    if (typeof regScore === \"number\") metaLines.push(`regScore: ${regScore.toFixed(2)}`);\n    if (typeof locScore === \"number\") metaLines.push(`locScore: ${locScore.toFixed(2)}`);\n    if (metadata.document_type) metaLines.push(`type: ${metadata.document_type}`);\n    if (metadata.languages) metaLines.push(`language: ${metadata.languages.join(\", \")}`);\n\n    const metaBlock = metaLines.join(\"\\n\");\n\n    // Clean and escape body\n    const body = mdEscape(cleanText(text));\n\n    return [\n      `### ${title}`,\n      \"```yaml\",\n      metaBlock,\n      \"```\",\n      \"\",\n      body\n    ].join(\"\\n\");\n  });\n\n  // Join with clear separators\n  return blocks.join(\"\\n\\n---\\n\\n\");\n}\n\n// Usage in n8n Function node:\nconst esResults = $input.all().map(i => i.json);\nconst contextForPrompt = prepareSecurityRegulatoryContextForClaude(esResults);\n\nreturn [{ json: { context: contextForPrompt } }];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1860,
        4740
      ],
      "id": "1b9e3671-3624-4379-8ffb-0e6951388aff",
      "name": "Prepare Context"
    },
    {
      "parameters": {
        "jsCode": "const queries = [\n  {\n    query_type: \"greenfield\",\n    query: \"new system build design development first deployment MVP initial rollout\",\n    keywords: \"new system, build from scratch, initial deployment, MVP, first version, brand new platform, new solution\",\n    phrase: \"new system OR build from scratch OR initial deployment OR MVP OR first version\",\n    description: \"Indicators that the project is building a completely new system.\"\n  },\n  {\n    query_type: \"upgrade_or_replacement\",\n    query: \"upgrade migration modernization replacement enhancement legacy system\",\n    keywords: \"upgrade existing system, migrate legacy system, modernization, replacement of existing platform, enhancement of current system\",\n    phrase: \"upgrade OR migration OR replacement OR modernization OR legacy system\",\n    description: \"Indicators that the project involves upgrading, migrating, or replacing an existing system.\"\n  }\n];\n\n// Return individual objects + one additional object wrapping the whole array\nreturn [\n  ...queries.map(q => ({\n    json: { ...q }\n  }))\n];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -4400,
        4400
      ],
      "id": "1dae49df-1bc5-4bb3-b6bb-3a7514c47792",
      "name": "Queries6"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "http://192.168.20.70:11434/api/embed",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"model\": \"nomic-embed-text:latest\",\n  \"input\": [\"{{ $json.query }}\"]\n}",
        "options": {}
      },
      "id": "3fc1a739-3ddf-434c-9c37-3631271b4475",
      "name": "Embed Query - ollama6",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -4220,
        4400
      ]
    },
    {
      "parameters": {
        "operation": "getAll",
        "indexId": "=est_tool_rfp",
        "limit": 10,
        "simple": false,
        "options": {
          "query": "={\n  \"size\": 10,\n  \"min_score\": 4.5,\n  \"_source\": [\n    \"chunk_id\",\n    \"section_title\",\n    \"text\",\n    \"metadata.filename\",\n    \"metadata.page_numbers\",\n    \"metadata.parent_chunk_id\",\n    \"metadata.is_split_chunk\",\n    \"metadata.split_part\",\n    \"metadata.total_parts\",\n    \"vector_metadata.token_count\",\n    \"vector_metadata.is_split\",\n    \"vector_metadata.chunk_index\"\n  ],\n  \"knn\": {\n    \"field\": \"embeddings\",\n    \"query_vector\": [{{ $json.embeddings }}],\n    \"k\": 15,\n    \"num_candidates\": 80\n  },\n  \"query\": {\n    \"bool\": {\n      \"should\": [\n        {\n          \"match\": {\n            \"text\": {\n              \"query\": \"{{ $('Queries6').item.json.keywords }}\",\n              \"boost\": 1.2\n            }\n          }\n        },\n        {\n          \"match\": {\n            \"section_title\": {\n              \"query\": \"{{ $('Queries6').item.json.phrase }}\",\n              \"boost\": 2.0\n            }\n          }\n        }\n      ],\n      \"minimum_should_match\": 1\n    }\n  },\n  \"rescore\": {\n    \"window_size\": 30,\n    \"query\": {\n      \"rescore_query\": {\n        \"match_phrase\": {\n          \"text\": {\n            \"query\": \"{{ $('Queries6').item.json.phrase }}\",\n            \"slop\": 30\n          }\n        }\n      },\n      \"query_weight\": 0.7,\n      \"rescore_query_weight\": 0.3\n    }\n  }\n}\n"
        }
      },
      "type": "n8n-nodes-base.elasticsearch",
      "typeVersion": 1,
      "position": [
        -4040,
        4400
      ],
      "id": "87d6b268-ad6d-4037-a336-08a9db9ba258",
      "name": "Query - Full8",
      "credentials": {
        "elasticsearchApi": {
          "id": "wwaILZtoajWrVXwt",
          "name": "Elasticsearch account"
        }
      }
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "17f9e7d3-307e-4d60-92ef-e32285cbec29",
              "name": "_score",
              "value": "={{ $json._score }}",
              "type": "number"
            },
            {
              "id": "618f58cd-27c7-4ab4-8612-899f048afb6c",
              "name": "_id",
              "value": "={{ $json._id }}",
              "type": "string"
            },
            {
              "id": "a8cfb079-48c6-4ce2-a54c-251304107206",
              "name": "chunk_id",
              "value": "={{ $json._source.chunk_id }}",
              "type": "string"
            },
            {
              "id": "22e6e029-7ff1-4870-a1c2-d3b025a2748b",
              "name": "section_title",
              "value": "={{ $json._source.section_title }}",
              "type": "string"
            },
            {
              "id": "27e9a9ac-b6ed-4320-bb21-027f8659e7c5",
              "name": "text",
              "value": "={{ $json._source.text }}",
              "type": "string"
            },
            {
              "id": "6830a868-6492-405b-b8fb-1ae36ea184b2",
              "name": "metadata",
              "value": "={{ $json._source.metadata }}",
              "type": "object"
            },
            {
              "id": "e5dce93c-eb16-42be-8b42-47ca5cfacc52",
              "name": "platform",
              "value": "={{ $('Queries6').item.json.query_type }}",
              "type": "string"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        -3820,
        4400
      ],
      "id": "60d1316a-c031-4fb4-96d7-a199e7de39e5",
      "name": "Map Response7"
    },
    {
      "parameters": {
        "jsCode": "// n8n Function Node: Dedupe → Merge Origins → Filter → Sort → Fallback\n\nconst MIN_SCORE = 3.0;\nconst DESIRED_COUNT = 10;\n\n// Step 1: Deduplicate & merge platform origins, keep highest‐score record\nconst seen = {};\nfor (const item of $input.all()) {\n  const { chunk_id, platform, _score, ...rest } = item.json;\n  \n  if (!seen[chunk_id]) {\n    // First time seeing this chunk\n    seen[chunk_id] = {\n      chunk_id,\n      _score,\n      ...rest,\n      platform_origins: [{ platform, score: _score }],\n    };\n  } else {\n    // Merge new platform origin\n    const record = seen[chunk_id];\n    if (!record.platform_origins.some(p => p.platform === platform)) {\n      record.platform_origins.push({ platform, score: _score });\n    }\n    // If this hit has a higher score, overwrite core fields\n    if (_score > record._score) {\n      record._score = _score;\n      Object.assign(record, rest);\n    }\n  }\n}\n\n// Convert deduped map back to array of items\nlet deduped = Object.values(seen).map(r => ({ json: r }));\n\n// Step 2: Filter by score and sort descending\nlet filtered = deduped\n  .filter(item => item.json._score >= MIN_SCORE)\n  .sort((a, b) => b.json._score - a.json._score);\n\n// Step 3: Fallback if too few hits\nif (filtered.length < DESIRED_COUNT) {\n  // Return top DESIRED_COUNT from deduped (regardless of score)\n  filtered = deduped\n    .sort((a, b) => b.json._score - a.json._score)\n    .slice(0, DESIRED_COUNT);\n}\n\n// Step 4: Ensure we only return up to DESIRED_COUNT\nfiltered = filtered.slice(0, DESIRED_COUNT);\n\n// Return in n8n-compatible format\nreturn filtered;\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -4400,
        4600
      ],
      "id": "ee8d93bd-58eb-484f-8a97-f8616c244801",
      "name": "Deduplicate and Best Score5"
    },
    {
      "parameters": {
        "jsCode": "// n8n Function Node: Corrected Merge Split-Chunk Groups\n\nconst grouped = {};\n\n// 1. Group all items by the “true” chunk identifier\nfor (const item of $input.all()) {\n  const data = item.json;\n  // Use parent_chunk_id if it exists, else chunk_id\n  const parentId = data.metadata?.is_split_chunk\n    ? data.metadata.parent_chunk_id\n    : data.chunk_id;\n\n  if (!grouped[parentId]) grouped[parentId] = [];\n  grouped[parentId].push(data);\n}\n\nconst merged = [];\n\n// 2. For each group, produce exactly one merged record\nfor (const [parentId, parts] of Object.entries(grouped)) {\n  // Sort by the split_part if present (else leave order)\n  parts.sort((a, b) => \n    (a.metadata?.split_part ?? 0) - (b.metadata?.split_part ?? 0)\n  );\n\n  // Stitch text together\n  const text = parts.map(p => p.text).join(\"\\n\\n\");\n\n  // Merge platform_origins arrays from all parts (dedupe by platform)\n  const allOrigins = parts.flatMap(p => p.platform_origins || []);\n  const platform_origins = [];\n  for (const o of allOrigins) {\n    if (!platform_origins.some(existing => existing.platform === o.platform)) {\n      platform_origins.push(o);\n    }\n  }\n\n  // Pick the highest-scoring part to inherit section_title, filename, pages, and score\n  const bestPart = parts.reduce((best, p) => \n    p._score > best._score ? p : best\n  , parts[0]);\n\n  // Build the single merged record\n  const record = {\n    chunk_id: parentId,\n    _score: bestPart._score,\n    section_title: bestPart.section_title,\n    text,\n    metadata: {\n      ...bestPart.metadata,\n      is_split_chunk: false,\n      parent_chunk_id: undefined,\n      split_part: undefined,\n      total_parts: undefined\n    },\n    platform_origins\n  };\n\n  merged.push({ json: record });\n}\nmerged.sort((a, b) => b.json._score - a.json._score);\nreturn merged;\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -4220,
        4600
      ],
      "id": "18a9449f-8a90-42eb-97f0-1ce8fa564fa5",
      "name": "Merge Chunks6"
    },
    {
      "parameters": {
        "jsCode": "// Configuration\nconst TOKEN_LIMIT = 5000;\nconst MIN_STRONG_SCORE = 7.0;\n\n// Rough token estimator (1 token ~ 4 characters)\nfunction estimateTokenCount(text) {\n  if (!text) return 0;\n  return Math.ceil(text.length / 4);\n}\n\n// Input already filtered and sorted!\nconst chunks = $input.all().map(item => item.json);\n\n// Build the final list\nconst selectedChunks = [];\nlet tokenCount = 0;\n\nfor (const chunk of chunks) {\n  const tokens = estimateTokenCount(chunk.text);\n\n  if ((tokenCount + tokens) <= TOKEN_LIMIT) {\n    selectedChunks.push(chunk);\n    tokenCount += tokens;\n  } else if (chunk._score >= MIN_STRONG_SCORE) {\n    // Allow overflow for very strong chunks\n    selectedChunks.push(chunk);\n    tokenCount += tokens;\n  } else {\n    break; // Stop adding\n  }\n}\n\n// Prepare output\nconst output = selectedChunks.map(chunk => ({ json: chunk }));\n\n// Add token usage metadata (attach to first item for simplicity)\nif (output.length > 0) {\n  output[0].json._token_summary = {\n    total_tokens_estimated: tokenCount,\n    total_chunks_selected: selectedChunks.length,\n  };\n}\n\nreturn output;\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -4040,
        4600
      ],
      "id": "9f9008f2-440f-426e-8d1e-1024e8c74e3c",
      "name": "Token Budgeting6"
    },
    {
      "parameters": {
        "content": "## Inference Greenfield\n",
        "height": 680,
        "width": 1680,
        "color": 4
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        -4480,
        4260
      ],
      "id": "4803155a-5e29-4316-bee0-ca98b59de31b",
      "name": "Sticky Note9"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ $json.userPrompt }}",
        "hasOutputParser": true,
        "options": {
          "systemMessage": "={{ $json.systemPrompt }}"
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.9,
      "position": [
        -3280,
        4400
      ],
      "id": "fed5c9ac-672b-4f5b-96fb-eb9b4520ca11",
      "name": "Greenfield?1"
    },
    {
      "parameters": {
        "jsonSchemaExample": "{\n  \"classification\": \"Greenfield | Upgrade/Migration | Unclear\",\n  \"rationale\": \"Short explanation based on the context.\"\n}"
      },
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "typeVersion": 1.2,
      "position": [
        -3060,
        4640
      ],
      "id": "9f9a0ac8-a6c6-45b5-9493-8f604cb8c7dc",
      "name": "Greenfield + Rationale1"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "gpt-4.1",
          "mode": "list",
          "cachedResultName": "gpt-4.1"
        },
        "options": {
          "temperature": 0.1,
          "topP": 1
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        -1300,
        4640
      ],
      "id": "c498431a-23ee-4593-8cd2-ac47ea3058ff",
      "name": "GPT 4.1 Mini",
      "credentials": {
        "openAiApi": {
          "id": "M8xqWvEC6mH6LNuk",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "gpt-4.1-mini",
          "mode": "list",
          "cachedResultName": "gpt-4.1-mini"
        },
        "options": {
          "temperature": 0.1
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        -3340,
        4660
      ],
      "id": "94616321-7de0-4fe3-92af-6c720ed8b7ed",
      "name": "GPT 4.1 Mini1",
      "credentials": {
        "openAiApi": {
          "id": "M8xqWvEC6mH6LNuk",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "\nconst contextForPrompt = $input.first().json.context\n\nconst systemPrompt = \"You are a careful analyst who extracts precise classifications from provided project descriptions. Base your classification only on the content shown. Do not hallucinate or assume anything not clearly stated or reasonably implied by common IT project terminology. If no clear project type can be determined, output 'Unclear'.\";\nconst userPrompt = `You are reviewing excerpts from an RFP document to determine the project type.\n\n\\n\\n### excerpts:\\n\\n${contextForPrompt}\n\n**Classify the project** as one of:\n- \"Greenfield\" → if it involves building a completely new system or platform from scratch.\n- \"Upgrade/Migration\" → if it involves replacing, improving, migrating, or rebuilding an existing system.\n- \"Unclear\" → if the context does not clearly specify.\n\n**Instructions**:\n- Only classify based on what is clearly described or strongly implied.\n- If the text mentions starting from scratch, assume Greenfield.\n- If the text talks about replacing or migrating from an existing system, assume Upgrade/Migration.\n- If unclear, select \"Unclear\".\n\n**Output format**:\n\\`\\`\\`json\n{\n  \"classification\": \"Greenfield | Upgrade/Migration | Unclear\",\n  \"rationale\": \"Short explanation based on the context.\",\n}\n\\`\\`\\`\n`;\n\nreturn {\n  json: {\n    userPrompt,\n    systemPrompt\n  }\n};\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -3620,
        4600
      ],
      "id": "5480ade4-8706-4a2c-b032-433e29df1d0d",
      "name": "PreparePrompts8"
    },
    {
      "parameters": {
        "jsCode": "/**\n * Prepare ES chunks for Claude, without chunk‐length limiting.\n */\nfunction prepareSecurityRegulatoryContextForClaude(esResults) {\n  if (!Array.isArray(esResults)) {\n    throw new Error(\"Input must be an array of Elasticsearch results\");\n  }\n\n  // simple Markdown escaper\n  function mdEscape(str) {\n    return str.replace(/(`|\\*|_|~|>|\\[|\\])/g, \"\\\\$1\");\n  }\n\n  // normalize bullets and split into lines\n  function cleanText(raw) {\n    return raw\n      .replace(/^\\s*-\\s+/gm, \"\\n- \")\n      .replace(/^\\s*\\*\\s+/gm, \"\\n- \")\n      .replace(/[ \\t]+/g, \" \")\n      .replace(/\\. ([A-Z])/g, \".\\n$1\")\n      .replace(/\\n{3,}/g, \"\\n\\n\")\n      .trim();\n  }\n\n  const blocks = esResults.map(chunk => {\n    const { chunk_id, section_title, text = \"\", metadata = {}, _score, regScore, locScore } = chunk;\n\n    // Heading\n    const title = section_title\n      ? mdEscape(section_title)\n      : `Untitled Section (${chunk_id})`;\n\n    // Build YAML metadata\n    const pages = Array.isArray(metadata.page_numbers)\n      ? metadata.page_numbers.join(\", \")\n      : metadata.page_numbers || \"Unknown\";\n\n    const metaLines = [\n      `filename: ${metadata.filename || \"Unknown Document\"}`,\n      `pages: ${pages}`,\n      `score: ${_score.toFixed(2)}`,\n    ];\n    if (typeof regScore === \"number\") metaLines.push(`regScore: ${regScore.toFixed(2)}`);\n    if (typeof locScore === \"number\") metaLines.push(`locScore: ${locScore.toFixed(2)}`);\n    if (metadata.document_type) metaLines.push(`type: ${metadata.document_type}`);\n    if (metadata.languages) metaLines.push(`language: ${metadata.languages.join(\", \")}`);\n\n    const metaBlock = metaLines.join(\"\\n\");\n\n    // Clean and escape body\n    const body = mdEscape(cleanText(text));\n\n    return [\n      `### ${title}`,\n      \"```yaml\",\n      metaBlock,\n      \"```\",\n      \"\",\n      body\n    ].join(\"\\n\");\n  });\n\n  // Join with clear separators\n  return blocks.join(\"\\n\\n---\\n\\n\");\n}\n\n// Usage in n8n Function node:\nconst esResults = $input.all().map(i => i.json);\nconst contextForPrompt = prepareSecurityRegulatoryContextForClaude(esResults);\n\nreturn [{ json: { context: contextForPrompt } }];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -3840,
        4600
      ],
      "id": "a0110b7f-4381-4249-bb8e-c179f64f4266",
      "name": "Prepare Context1"
    },
    {
      "parameters": {
        "jsCode": "/**\n * Prepare ES chunks for Claude, without chunk‐length limiting.\n */\nfunction prepareSecurityRegulatoryContextForClaude(esResults) {\n  if (!Array.isArray(esResults)) {\n    throw new Error(\"Input must be an array of Elasticsearch results\");\n  }\n\n  // simple Markdown escaper\n  function mdEscape(str) {\n    return str.replace(/(`|\\*|_|~|>|\\[|\\])/g, \"\\\\$1\");\n  }\n\n  // normalize bullets and split into lines\n  function cleanText(raw) {\n    return raw\n      .replace(/^\\s*-\\s+/gm, \"\\n- \")\n      .replace(/^\\s*\\*\\s+/gm, \"\\n- \")\n      .replace(/[ \\t]+/g, \" \")\n      .replace(/\\. ([A-Z])/g, \".\\n$1\")\n      .replace(/\\n{3,}/g, \"\\n\\n\")\n      .trim();\n  }\n\n  const blocks = esResults.map(chunk => {\n    const { chunk_id, section_title, text = \"\", metadata = {}, _score, regScore, locScore } = chunk;\n\n    // Heading\n    const title = section_title\n      ? mdEscape(section_title)\n      : `Untitled Section (${chunk_id})`;\n\n    // Build YAML metadata\n    const pages = Array.isArray(metadata.page_numbers)\n      ? metadata.page_numbers.join(\", \")\n      : metadata.page_numbers || \"Unknown\";\n\n    const metaLines = [\n      `filename: ${metadata.filename || \"Unknown Document\"}`,\n      `pages: ${pages}`,\n      `score: ${_score.toFixed(2)}`,\n    ];\n    if (typeof regScore === \"number\") metaLines.push(`regScore: ${regScore.toFixed(2)}`);\n    if (typeof locScore === \"number\") metaLines.push(`locScore: ${locScore.toFixed(2)}`);\n    if (metadata.document_type) metaLines.push(`type: ${metadata.document_type}`);\n    if (metadata.languages) metaLines.push(`language: ${metadata.languages.join(\", \")}`);\n\n    const metaBlock = metaLines.join(\"\\n\");\n\n    // Clean and escape body\n    const body = mdEscape(cleanText(text));\n\n    return [\n      `### ${title}`,\n      \"```yaml\",\n      metaBlock,\n      \"```\",\n      \"\",\n      body\n    ].join(\"\\n\");\n  });\n\n  // Join with clear separators\n  return blocks.join(\"\\n\\n---\\n\\n\");\n}\n\n// Usage in n8n Function node:\nconst esResults = $input.all().map(i => i.json);\nconst contextForPrompt = prepareSecurityRegulatoryContextForClaude(esResults);\n\nreturn [{ json: { context: contextForPrompt } }];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        300,
        3700
      ],
      "id": "126c18ad-6f62-43e6-b2ec-6cc2d1a95d40",
      "name": "Prepare Context2"
    },
    {
      "parameters": {
        "jsCode": "/**\n * Prepare ES chunks for Claude, without chunk‐length limiting.\n */\nfunction prepareSecurityRegulatoryContextForClaude(esResults) {\n  if (!Array.isArray(esResults)) {\n    throw new Error(\"Input must be an array of Elasticsearch results\");\n  }\n\n  // simple Markdown escaper\n  function mdEscape(str) {\n    return str.replace(/(`|\\*|_|~|>|\\[|\\])/g, \"\\\\$1\");\n  }\n\n  // normalize bullets and split into lines\n  function cleanText(raw) {\n    return raw\n      .replace(/^\\s*-\\s+/gm, \"\\n- \")\n      .replace(/^\\s*\\*\\s+/gm, \"\\n- \")\n      .replace(/[ \\t]+/g, \" \")\n      .replace(/\\. ([A-Z])/g, \".\\n$1\")\n      .replace(/\\n{3,}/g, \"\\n\\n\")\n      .trim();\n  }\n\n  const blocks = esResults.map(chunk => {\n    const { chunk_id, section_title, text = \"\", metadata = {}, _score, regScore, locScore } = chunk;\n\n    // Heading\n    const title = section_title\n      ? mdEscape(section_title)\n      : `Untitled Section (${chunk_id})`;\n\n    // Build YAML metadata\n    const pages = Array.isArray(metadata.page_numbers)\n      ? metadata.page_numbers.join(\", \")\n      : metadata.page_numbers || \"Unknown\";\n\n    const metaLines = [\n      `filename: ${metadata.filename || \"Unknown Document\"}`,\n      `pages: ${pages}`,\n      `score: ${_score.toFixed(2)}`,\n    ];\n    if (typeof regScore === \"number\") metaLines.push(`regScore: ${regScore.toFixed(2)}`);\n    if (typeof locScore === \"number\") metaLines.push(`locScore: ${locScore.toFixed(2)}`);\n    if (metadata.document_type) metaLines.push(`type: ${metadata.document_type}`);\n    if (metadata.languages) metaLines.push(`language: ${metadata.languages.join(\", \")}`);\n\n    const metaBlock = metaLines.join(\"\\n\");\n\n    // Clean and escape body\n    const body = mdEscape(cleanText(text));\n\n    return [\n      `### ${title}`,\n      \"```yaml\",\n      metaBlock,\n      \"```\",\n      \"\",\n      body\n    ].join(\"\\n\");\n  });\n\n  // Join with clear separators\n  return blocks.join(\"\\n\\n---\\n\\n\");\n}\n\n// Usage in n8n Function node:\nconst esResults = $input.all().map(i => i.json);\nconst contextForPrompt = prepareSecurityRegulatoryContextForClaude(esResults);\n\nreturn [{ json: { context: contextForPrompt } }];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -3660,
        3600
      ],
      "id": "6d305ae3-a895-4720-becb-ba0d1022757c",
      "name": "Prepare Context3"
    },
    {
      "parameters": {
        "jsCode": "return [\n{\n  json: {\n    query_type: \"feature_backlog\",\n    query:\n      \"Extract every user-facing feature, workflow, module, and use-case described in the RFP that will drive development effort.\",\n    /* Core verbs + backlog vocabulary (no compliance or legal terms) */\n    keywords: [\n      /* imperative verbs that usually start requirements */\n      \"shall\", \"must\", \"will\", \"should\", \"enable\", \"allow\", \"support\",\n\n      /* backlog & requirements terminology */\n      \"feature\", \"features\", \"functionality\", \"functional\", \"user story\",\n      \"user stories\", \"story\", \"stories\", \"epic\", \"use case\", \"use cases\",\n      \"acceptance criterion\", \"acceptance criteria\", \"requirement\",\n      \"requirements\", \"deliverable\", \"deliverables\",\n\n      /* common software capabilities */\n      \"dashboard\", \"report\", \"reporting\", \"search\", \"filter\", \"export\",\n      \"import\", \"authentication\", \"authorization\", \"login\", \"registration\",\n      \"profile\", \"notification\", \"messaging\", \"chat\", \"payment\", \"checkout\",\n      \"file upload\", \"download\", \"analytics\", \"admin panel\", \"cms\", \"api\",\n\n      /* workflow & domain phrases */\n      \"workflow\", \"process\", \"approval\", \"review\", \"comment\", \"feedback\",\n\n      /* MVP / release language */\n      \"MVP\", \"minimum viable product\", \"phase 1\", \"phase one\",\n      \"initial release\", \"pilot\", \"beta\"\n    ],\n\n    /* Phrase to give extra boost to clearly written requirements */\n    phrase: \"shall must will should feature user story use case\",\n\n    /* Tightest phrase for rescoring */\n    rescore_query: \"user story OR feature OR use case\",\n\n    description:\n      \"Surface all functional features and backlog items that drive development effort; ignore regulatory or contractual statements.\"\n  }\n}\n];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        20,
        4460
      ],
      "id": "e6544cce-4f5e-4b87-b422-e246035c71e3",
      "name": "Queries2"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "http://192.168.20.70:11434/api/embed",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"model\": \"nomic-embed-text:latest\",\n  \"input\": [\"{{ $json.query }}\"]\n}",
        "options": {}
      },
      "id": "4a9615e2-4456-49d7-91c8-b7495d8032c0",
      "name": "Embed Query - ollama2",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        200,
        4460
      ]
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "17f9e7d3-307e-4d60-92ef-e32285cbec29",
              "name": "_score",
              "value": "={{ $json._score }}",
              "type": "number"
            },
            {
              "id": "618f58cd-27c7-4ab4-8612-899f048afb6c",
              "name": "_id",
              "value": "={{ $json._id }}",
              "type": "string"
            },
            {
              "id": "a8cfb079-48c6-4ce2-a54c-251304107206",
              "name": "chunk_id",
              "value": "={{ $json._source.chunk_id }}",
              "type": "string"
            },
            {
              "id": "22e6e029-7ff1-4870-a1c2-d3b025a2748b",
              "name": "section_title",
              "value": "={{ $json._source.section_title }}",
              "type": "string"
            },
            {
              "id": "27e9a9ac-b6ed-4320-bb21-027f8659e7c5",
              "name": "text",
              "value": "={{ $json._source.text }}",
              "type": "string"
            },
            {
              "id": "6830a868-6492-405b-b8fb-1ae36ea184b2",
              "name": "metadata",
              "value": "={{ $json._source.metadata }}",
              "type": "object"
            },
            {
              "id": "e5dce93c-eb16-42be-8b42-47ca5cfacc52",
              "name": "platform",
              "value": "={{ $('Queries2').item.json.platform }}",
              "type": "string"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        580,
        4460
      ],
      "id": "e6450751-9975-46c3-8659-dc74fbbd100f",
      "name": "Map Response2"
    },
    {
      "parameters": {
        "jsCode": "// 2. Format the context\nconst contextForPrompt = $input.first().json.context;\nconst systemPrompt = \"You are a strict JSON extractor.The user will supply raw excerpts from a software RFP that describe project scope and backlog. Identify every distinct Functional Requirement (what the system must do). Do NOT invent, merge, or omit anything.Return **only** a valid JSON array—no headings, no markdown, no extra text.\";\n// 3. Define the user prompt\nconst userPrompt = `Below are excerpts from an RFP that describe the project scope, backlog items, and milestones.\n\n\\n\\n### excerpts:\\n\\n${contextForPrompt}\n\nYour task is to extract all meaningful features and expectations and assign them to one of the following categories:\n\n- Functional Requirement (FR): What the system must do.\n\nInstructions:\n- Do not skip, combine, or summarize any features.\n- Do not refer to “the document” or mention formatting.\n- Do not include commentary, labels, headings, or markdown blocks.\n- Sort results using section numbers, ascending.\n- Do not include documentation, \n`;\n\nreturn {\n  json: {\n    userPrompt,\n    systemPrompt: systemPrompt\n  }\n};\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        580,
        4680
      ],
      "id": "3e3bce45-ee64-4f32-aa18-cae973288c37",
      "name": "PreparePrompts4"
    },
    {
      "parameters": {
        "content": "## Inference Functional Requirements\n",
        "height": 860,
        "width": 1740,
        "color": 6
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        -400,
        4260
      ],
      "id": "68364976-8b34-43df-bc69-6f9a5cf8756f",
      "name": "Sticky Note10"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "mode": "list",
          "value": "claude-3-7-sonnet-20250219",
          "cachedResultName": "Claude 3.7 Sonnet"
        },
        "options": {
          "thinking": true
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatAnthropic",
      "typeVersion": 1.3,
      "position": [
        660,
        4880
      ],
      "id": "59ed41b8-accf-41ac-b678-55b533cd7512",
      "name": "Claude 3.",
      "credentials": {
        "anthropicApi": {
          "id": "qzCm5Ds2qD9ZY1W5",
          "name": "Anthropic account"
        }
      }
    },
    {
      "parameters": {
        "operation": "getAll",
        "indexId": "=est_tool_rfp",
        "limit": 30,
        "simple": false,
        "options": {
          "query": "={\n  \"size\": 30,\n  \"min_score\": 1.5,\n  \"_source\": [\n    \"chunk_id\",\"section_title\",\"text\",\n    \"metadata.filename\",\"metadata.page_numbers\",\n    \"metadata.parent_chunk_id\",\"metadata.is_split_chunk\",\n    \"metadata.split_part\",\"metadata.total_parts\"\n  ],\n  \"knn\": {\n    \"field\": \"embeddings\",\n    \"query_vector\":[ {{ $json.embeddings }} ],\n    \"k\": 60,\n    \"num_candidates\": 300\n  },\n  \"query\": {\n    \"bool\": {\n      \"should\": [\n        {\n          \"match_phrase\": {\n            \"text\": {\n              \"query\": \"shall must require\",\n              \"slop\":      2,\n              \"boost\":     2.0\n            }\n          }\n        },\n        {\n          \"multi_match\": {\n            \"query\": \"{{$('Queries2').item.json.keywords.join(' ') }}\",\n            \"fields\": [\"text^2\",\"section_title^3\"],\n            \"type\": \"most_fields\",\n            \"minimum_should_match\":   1,\n            \"boost\":                  1.2\n          }\n        },\n        {\n          \"terms_set\": {\n            \"text.keyword\": {\n              \"terms\": {{ JSON.stringify($('Queries2').item.json.keywords) }},\n              \"minimum_should_match_script\": {\n                \"source\": \"1\"\n              }\n            }\n          }\n        }\n      ],\n      \"minimum_should_match\": 1\n    }\n  },\n  \"rescore\": {\n    \"window_size\": 100,\n    \"query\": {\n      \"rescore_query\": {\n        \"match_phrase\": {\n          \"text\": {\n            \"query\": \"shall must require\",\n            \"slop\": 2\n          }\n        }\n      },\n      \"query_weight\":        0.5,\n      \"rescore_query_weight\":0.5\n    }\n  },\n  \"highlight\": {\n    \"type\": \"unified\",\n    \"fields\": { \"text\": {}, \"section_title\": {} }\n  }\n}\n"
        }
      },
      "type": "n8n-nodes-base.elasticsearch",
      "typeVersion": 1,
      "position": [
        400,
        4460
      ],
      "id": "5d28d1bd-e543-4aff-afdd-9483e72d3f0e",
      "name": "Query - Full9",
      "credentials": {
        "elasticsearchApi": {
          "id": "wwaILZtoajWrVXwt",
          "name": "Elasticsearch account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// n8n Function Node: Corrected Merge Split-Chunk Groups\n\nconst grouped = {};\n\n// 1. Group all items by the “true” chunk identifier\nfor (const item of $input.all()) {\n  const data = item.json;\n  // Use parent_chunk_id if it exists, else chunk_id\n  const parentId = data.metadata?.is_split_chunk\n    ? data.metadata.parent_chunk_id\n    : data.chunk_id;\n\n  if (!grouped[parentId]) grouped[parentId] = [];\n  grouped[parentId].push(data);\n}\n\nconst merged = [];\n\n// 2. For each group, produce exactly one merged record\nfor (const [parentId, parts] of Object.entries(grouped)) {\n  // Sort by the split_part if present (else leave order)\n  parts.sort((a, b) => \n    (a.metadata?.split_part ?? 0) - (b.metadata?.split_part ?? 0)\n  );\n\n  // Stitch text together\n  const text = parts.map(p => p.text).join(\"\\n\\n\");\n\n  // Merge platform_origins arrays from all parts (dedupe by platform)\n  const allOrigins = parts.flatMap(p => p.platform_origins || []);\n  const platform_origins = [];\n  for (const o of allOrigins) {\n    if (!platform_origins.some(existing => existing.platform === o.platform)) {\n      platform_origins.push(o);\n    }\n  }\n\n  // Pick the highest-scoring part to inherit section_title, filename, pages, and score\n  const bestPart = parts.reduce((best, p) => \n    p._score > best._score ? p : best\n  , parts[0]);\n\n  // Build the single merged record\n  const record = {\n    chunk_id: parentId,\n    _score: bestPart._score,\n    section_title: bestPart.section_title,\n    text,\n    metadata: {\n      ...bestPart.metadata,\n      is_split_chunk: false,\n      parent_chunk_id: undefined,\n      split_part: undefined,\n      total_parts: undefined\n    },\n    platform_origins\n  };\n\n  merged.push({ json: record });\n}\nmerged.sort((a, b) => b.json._score - a.json._score);\nreturn merged;\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        20,
        4680
      ],
      "id": "33b42c02-6ee6-499e-95fa-3c4decc4c34e",
      "name": "Merge Chunks5"
    },
    {
      "parameters": {
        "jsCode": "// n8n Function Node: Dedupe → Merge Origins → Filter → Sort → Fallback\n\nconst MIN_SCORE = 1.0;\nconst DESIRED_COUNT = 20;\n\n// Step 1: Deduplicate & merge platform origins, keep highest‐score record\nconst seen = {};\nfor (const item of $input.all()) {\n  const { chunk_id, platform, _score, ...rest } = item.json;\n  \n  if (!seen[chunk_id]) {\n    // First time seeing this chunk\n    seen[chunk_id] = {\n      chunk_id,\n      _score,\n      ...rest,\n      platform_origins: [{ platform, score: _score }],\n    };\n  } else {\n    // Merge new platform origin\n    const record = seen[chunk_id];\n    if (!record.platform_origins.some(p => p.platform === platform)) {\n      record.platform_origins.push({ platform, score: _score });\n    }\n    // If this hit has a higher score, overwrite core fields\n    if (_score > record._score) {\n      record._score = _score;\n      Object.assign(record, rest);\n    }\n  }\n}\n\n// Convert deduped map back to array of items\nlet deduped = Object.values(seen).map(r => ({ json: r }));\n\n// Step 2: Filter by score and sort descending\nlet filtered = deduped\n  .filter(item => item.json._score >= MIN_SCORE)\n  .sort((a, b) => b.json._score - a.json._score);\n\n// Step 3: Fallback if too few hits\nif (filtered.length < DESIRED_COUNT) {\n  // Return top DESIRED_COUNT from deduped (regardless of score)\n  filtered = deduped\n    .sort((a, b) => b.json._score - a.json._score)\n    .slice(0, DESIRED_COUNT);\n}\n\n// Step 4: Ensure we only return up to DESIRED_COUNT\nfiltered = filtered.slice(0, DESIRED_COUNT);\n\n// Return in n8n-compatible format\nreturn filtered;\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        760,
        4460
      ],
      "id": "259135dc-74c2-459b-84d4-8ed82c3fe0ab",
      "name": "Deduplicate and Best Score6"
    },
    {
      "parameters": {
        "jsCode": "// Configuration\nconst TOKEN_LIMIT = 7000;\nconst MIN_STRONG_SCORE = 16.0;\n\n// Rough token estimator (1 token ~ 4 characters)\nfunction estimateTokenCount(text) {\n  if (!text) return 0;\n  return Math.ceil(text.length / 4);\n}\n\n// Input already filtered and sorted!\nconst chunks = $input.all().map(item => item.json);\n\n// Build the final list\nconst selectedChunks = [];\nlet tokenCount = 0;\n\nfor (const chunk of chunks) {\n  const tokens = estimateTokenCount(chunk.text);\n\n  if ((tokenCount + tokens) <= TOKEN_LIMIT) {\n    selectedChunks.push(chunk);\n    tokenCount += tokens;\n  } else if (chunk._score >= MIN_STRONG_SCORE) {\n    // Allow overflow for very strong chunks\n    selectedChunks.push(chunk);\n    tokenCount += tokens;\n  } else {\n    break; // Stop adding\n  }\n}\n\n// Prepare output\nconst output = selectedChunks.map(chunk => ({ json: chunk }));\n\n// Add token usage metadata (attach to first item for simplicity)\nif (output.length > 0) {\n  output[0].json._token_summary = {\n    total_tokens_estimated: tokenCount,\n    total_chunks_selected: selectedChunks.length,\n  };\n}\n\nreturn output;\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        200,
        4680
      ],
      "id": "0c06bfce-1d19-4083-a38c-8c29d4048379",
      "name": "Token Budgeting2"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "gpt-4.1-mini",
          "mode": "list",
          "cachedResultName": "gpt-4.1-mini"
        },
        "options": {
          "temperature": 0.1
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        800,
        4880
      ],
      "id": "1f83bed8-2b44-4d53-a1ac-ae2073e200f8",
      "name": "OpenAI Chat Model3",
      "credentials": {
        "openAiApi": {
          "id": "M8xqWvEC6mH6LNuk",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "/**\n * Prepare ES chunks for Claude, without chunk‐length limiting.\n */\nfunction prepareSecurityRegulatoryContextForClaude(esResults) {\n  if (!Array.isArray(esResults)) {\n    throw new Error(\"Input must be an array of Elasticsearch results\");\n  }\n\n  // simple Markdown escaper\n  function mdEscape(str) {\n    return str.replace(/(`|\\*|_|~|>|\\[|\\])/g, \"\\\\$1\");\n  }\n\n  // normalize bullets and split into lines\n  function cleanText(raw) {\n    return raw\n      .replace(/^\\s*-\\s+/gm, \"\\n- \")\n      .replace(/^\\s*\\*\\s+/gm, \"\\n- \")\n      .replace(/[ \\t]+/g, \" \")\n      .replace(/\\. ([A-Z])/g, \".\\n$1\")\n      .replace(/\\n{3,}/g, \"\\n\\n\")\n      .trim();\n  }\n\n  const blocks = esResults.map(chunk => {\n    const { chunk_id, section_title, text = \"\", metadata = {}, _score, regScore, locScore } = chunk;\n\n    // Heading\n    const title = section_title\n      ? mdEscape(section_title)\n      : `Untitled Section (${chunk_id})`;\n\n    // Build YAML metadata\n    const pages = Array.isArray(metadata.page_numbers)\n      ? metadata.page_numbers.join(\", \")\n      : metadata.page_numbers || \"Unknown\";\n\n    const metaLines = [\n      `filename: ${metadata.filename || \"Unknown Document\"}`,\n      `pages: ${pages}`,\n      `score: ${_score.toFixed(2)}`,\n    ];\n    if (typeof regScore === \"number\") metaLines.push(`regScore: ${regScore.toFixed(2)}`);\n    if (typeof locScore === \"number\") metaLines.push(`locScore: ${locScore.toFixed(2)}`);\n    if (metadata.document_type) metaLines.push(`type: ${metadata.document_type}`);\n    if (metadata.languages) metaLines.push(`language: ${metadata.languages.join(\", \")}`);\n\n    const metaBlock = metaLines.join(\"\\n\");\n\n    // Clean and escape body\n    const body = mdEscape(cleanText(text));\n\n    return [\n      `### ${title}`,\n      \"```yaml\",\n      metaBlock,\n      \"```\",\n      \"\",\n      body\n    ].join(\"\\n\");\n  });\n\n  // Join with clear separators\n  return blocks.join(\"\\n\\n---\\n\\n\");\n}\n\n// Usage in n8n Function node:\nconst esResults = $input.all().map(i => i.json);\nconst contextForPrompt = prepareSecurityRegulatoryContextForClaude(esResults);\n\nreturn [{ json: { context: contextForPrompt } }];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        400,
        4680
      ],
      "id": "cd2ad9c7-a01b-4c8f-930e-688d2cb540ec",
      "name": "Prepare Context4"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ $json.userPrompt }}",
        "hasOutputParser": true,
        "options": {
          "systemMessage": "={{ $json.systemPrompt }}"
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.9,
      "position": [
        820,
        4680
      ],
      "id": "a662454e-b3b2-4a50-a201-58bc94a521e0",
      "name": "Functional requirements"
    },
    {
      "parameters": {},
      "type": "@n8n/n8n-nodes-langchain.toolThink",
      "typeVersion": 1,
      "position": [
        940,
        4880
      ],
      "id": "ae4499cd-ec47-4904-8fc5-4b3e1c13f7e0",
      "name": "Think"
    },
    {
      "parameters": {
        "jsCode": "/**\n * n8n Function node\n * Input  : first item from the previous “platform extraction” node\n *          {\n *            output: {\n *              platforms: [ ... ],\n *              rationale: \"...\"\n *            }\n *          }\n * Output : { detectedPlatformsSnippet: '### DETECTED_PLATFORMS …' }\n */\n\nconst { output } = $input.first().json;\n\n// --- Basic sanity check ----------------------------------------------------\nif (!output?.platforms || !Array.isArray(output.platforms)) {\n  throw new Error('Expected output.platforms array from previous step.');\n}\n\n// --- Build the snippet -----------------------------------------------------\nconst detectedPlatformsSnippet = [\n  '### DETECTED_PLATFORMS (authoritative, extracted in a prior step)',\n  JSON.stringify(\n    {\n      platforms: output.platforms,\n      rationale: output.rationale,\n    },\n    null,\n    2 // pretty-print indent\n  ),\n  '',\n  'You must treat the array in \"platforms\" as ground truth when selecting or defaulting technologies.',\n].join('\\n');\n\n// --- Return for the next node ---------------------------------------------\nreturn [\n  {\n    json: {\n      detectedPlatformsSnippet,\n    },\n  },\n];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -2680,
        3600
      ],
      "id": "53990b7e-a22e-4d27-ba7e-ce905d0bf31f",
      "name": "Platforms Output"
    },
    {
      "parameters": {
        "jsCode": "/**\n * n8n Function node\n * Input  : first item from the metadata-extraction step\n *          {\n *            output: {\n *              client_name: \"...\",\n *              project_name: \"...\",\n *              industry: \"...\",\n *              publish_date: \"...\",\n *              submission_deadline: \"...\",\n *              questions_deadline: \"...\",\n *              contact_email: \"...\"\n *            }\n *          }\n * Output : { rfpMetadataSnippet: '### RFP_METADATA …' }\n */\n\nconst meta = $input.first().json.output || {};\n\n// --- Sanity check ----------------------------------------------------------\nif (!meta.client_name || !meta.project_name) {\n  throw new Error('Expected metadata fields missing in previous step.');\n}\n\n// --- Build the snippet -----------------------------------------------------\nconst rfpMetadataSnippet = [\n  '### RFP_METADATA (authoritative, extracted in a prior step)',\n  JSON.stringify(meta, null, 2),\n  '',\n  'Treat this metadata as fixed reference values for all subsequent reasoning.',\n].join('\\n');\n\n// --- Return for downstream use --------------------------------------------\nreturn [\n  {\n    json: {\n      rfpMetadataSnippet,\n    },\n  },\n];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -940,
        3720
      ],
      "id": "4326984e-ab2c-4eb0-b4f8-0ded0a5d98eb",
      "name": "General Info Output"
    },
    {
      "parameters": {
        "jsCode": "/**\n * n8n Function node\n * Input  : first item from the “delivery extraction” step, shape:\n *          {\n *            output: {\n *              delivery_model: \"...\",\n *              delivery_methodology: \"...\",\n *              delivery_timeframe: \"...\",\n *              post_delivery_support: \"...\",\n *              rationale: \"...\"\n *            }\n *          }\n * Output : { deliveryRequirementsSnippet: '### DELIVERY_REQUIREMENTS …' }\n */\n\nconst delivery = $input.first().json.output || {};\n\n// Sanity check --------------------------------------------------------------\nif (!delivery.delivery_model || !delivery.delivery_methodology) {\n  throw new Error('Expected delivery fields missing in previous step.');\n}\n\n// Build snippet -------------------------------------------------------------\nconst deliveryRequirementsSnippet = [\n  '### DELIVERY_REQUIREMENTS (authoritative, extracted in a prior step)',\n  JSON.stringify(delivery, null, 2),   // pretty-printed JSON\n  '',\n  'Treat these delivery constraints as fixed when planning effort, timeline, and resource allocation in all subsequent steps.',\n].join('\\n');\n\n// Return for downstream use -------------------------------------------------\nreturn [\n  {\n    json: {\n      deliveryRequirementsSnippet,\n    },\n  },\n];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1380,
        3980
      ],
      "id": "44890f30-ac90-46ca-9e67-a6bf4fbdb0cb",
      "name": "Delivery Context Ouput"
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "dcf9995f-4f13-4062-b2c0-33e0b2efe3e2",
              "name": "regulatoryComplianceSnippet",
              "value": "={{ $('Regulatory Output').first().json.regulatoryComplianceSnippet }}",
              "type": "string"
            },
            {
              "id": "90bbc7e2-ad05-415d-b809-0d8fd7b04d26",
              "name": "projectClassificationSnippet",
              "value": "={{ $('GreenField Output').first().json.projectClassificationSnippet }}",
              "type": "string"
            },
            {
              "id": "71534caa-3f18-4edd-bd5d-83212d7e8ccf",
              "name": "deliveryRequirementsSnippet",
              "value": "={{ $('Delivery Context Ouput').first().json.deliveryRequirementsSnippet }}",
              "type": "string"
            },
            {
              "id": "deddcdb1-5bc5-47e1-8a5c-4c02fb0e9ca8",
              "name": "rfpMetadataSnippet",
              "value": "={{ $('General Info Output').first().json.rfpMetadataSnippet }}",
              "type": "string"
            },
            {
              "id": "8cbd36fd-3045-4e2b-a780-6eb529af3d37",
              "name": "detectedTechStackSnippet",
              "value": "={{ $('Techstack Output').first().json.detectedTechStackSnippet }}",
              "type": "string"
            },
            {
              "id": "2eb926dc-6f8b-4145-a627-2a699038399a",
              "name": "detectedPlatformsSnippet",
              "value": "={{ $('Platforms Output').first().json.detectedPlatformsSnippet }}",
              "type": "string"
            },
            {
              "id": "72e76e6d-1a50-45d3-a45a-87550bb36ed6",
              "name": "combinedRequirementsSnippet",
              "value": "={{ $('Combined Requirements Output').first().json.combinedRequirementsSnippet }}",
              "type": "string"
            },
            {
              "id": "3b6d4b25-a68d-43c3-b031-6f02984622e4",
              "name": "teamCompositionSnippet",
              "value": "={{ $json.teamCompositionSnippet }}",
              "type": "string"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        -4240,
        6420
      ],
      "id": "0e34ad8b-a139-45e8-a235-bee7b650044d",
      "name": "Dependencies"
    },
    {
      "parameters": {
        "jsCode": "/**\n * n8n Function node\n * Input  : first item from the “classification extraction” step\n *          {\n *            output: {\n *              classification: \"...\",\n *              rationale: \"...\"\n *            }\n *          }\n * Output : { projectClassificationSnippet: '### PROJECT_CLASSIFICATION …' }\n */\n\nconst projClass = $input.first().json.output || {};\n\n// --- Sanity check ----------------------------------------------------------\nif (!projClass.classification) {\n  throw new Error('Expected \"classification\" field missing in previous step.');\n}\n\n// --- Build the snippet -----------------------------------------------------\nconst projectClassificationSnippet = [\n  '### PROJECT_CLASSIFICATION (authoritative, extracted in a prior step)',\n  JSON.stringify(projClass, null, 2),  // pretty-printed JSON\n  '',\n  'Treat this classification (e.g., Greenfield vs. Brownfield) as fixed context when estimating effort, risk, and migration tasks in subsequent steps.',\n].join('\\n');\n\n// --- Return for downstream use --------------------------------------------\nreturn [\n  {\n    json: {\n      projectClassificationSnippet,\n    },\n  },\n];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -2680,
        4400
      ],
      "id": "e12da1ec-9228-4eb8-86de-01303454bedb",
      "name": "GreenField Output"
    },
    {
      "parameters": {
        "jsCode": "/**\n * n8n Function node\n * Input shape (first item):\n * {\n *   output: {\n *     regulatory_compliance: [{ name: \"...\", source: \"...\" }],\n *     country: \"Europe\",\n *     regulatory_classification: {\n *       level: \"Moderately Regulated\",\n *       confidence: \"High\",\n *       rationale: \"...\"\n *     }\n *   }\n * }\n *\n * Output:\n * { regulatoryComplianceSnippet: '### REGULATORY_COMPLIANCE …' }\n */\n\nconst reg = $input.first().json.output || {};\n\n// --- Basic validation ------------------------------------------------------\nif (!reg.regulatory_classification || !reg.regulatory_compliance) {\n  throw new Error('Expected regulatory compliance data missing from previous step.');\n}\n\n// --- Build snippet ---------------------------------------------------------\nconst regulatoryComplianceSnippet = [\n  '### REGULATORY_COMPLIANCE (authoritative, extracted in a prior step)',\n  JSON.stringify(reg, null, 2), // pretty-printed JSON\n  '',\n  'Treat these compliance constraints as immutable when proposing hosting, data residency, and security measures downstream.',\n].join('\\n');\n\n// --- Return for downstream nodes ------------------------------------------\nreturn [\n  {\n    json: {\n      regulatoryComplianceSnippet,\n    },\n  },\n];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -660,
        4380
      ],
      "id": "fcfabd69-7497-437d-88cf-ec042b92040f",
      "name": "Regulatory Output"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "gpt-4.1",
          "mode": "list",
          "cachedResultName": "gpt-4.1"
        },
        "options": {
          "temperature": 0.1
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        260,
        5680
      ],
      "id": "3d1e456c-3b71-48a7-8727-d1c0bddcaa17",
      "name": "GPT 4.1 Mini2",
      "credentials": {
        "openAiApi": {
          "id": "M8xqWvEC6mH6LNuk",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ $json.userPrompt }}",
        "hasOutputParser": true,
        "options": {
          "systemMessage": "={{ $json.systemPrompt }}"
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.9,
      "position": [
        580,
        5420
      ],
      "id": "b910c565-4fcc-4307-bfd2-8fe9899874a8",
      "name": "Team Composition"
    },
    {
      "parameters": {
        "jsCode": "/* n8n Function node\n   Builds the prompt for the “Team-Composition” LLM step.\n   ➜  Output JSON: { systemPrompt, userPrompt }\n*/\n\n// ---------------------------------------------------------------------------\n// 1. Collect fixed snippets prepared in earlier steps\n// ---------------------------------------------------------------------------\nconst {\n  regulatoryComplianceSnippet,\n  projectClassificationSnippet,\n  deliveryRequirementsSnippet,\n  rfpMetadataSnippet,\n  detectedPlatformsSnippet,\n} = $('Dependencies1').first().json;\n\n// Optional extra RAG context (not mandatory)\nconst techstack = $input.first().json.detectedTechStackSnippet;\n\n// ---------------------------------------------------------------------------\n// 2. Static system prompt (sent once per LLM call)\n// ---------------------------------------------------------------------------\nconst systemPrompt =\n  'You are a senior delivery manager who produces concise team-composition plans ' +\n  'for software projects. Merge the fixed project constraints below with standard ' +\n  'Agile delivery practice. Output **only** a valid JSON object under the key \"team_plan\".';\n\n// ---------------------------------------------------------------------------\n// 3. Dynamic user prompt assembled from all snippets plus rules\n// ---------------------------------------------------------------------------\nconst userPrompt = `\nONLY output the JSON object—no other text.\n\n### CONTEXT_SNIPPETS\n${regulatoryComplianceSnippet}\n\n${projectClassificationSnippet}\n\n${deliveryRequirementsSnippet}\n\n${rfpMetadataSnippet}\n\n${techstack}\n\n${detectedPlatformsSnippet}\n\n### TASK\nDefine the delivery roles needed to execute this project in line with the timeline and constraints.\nDo **not** estimate sprints, person-days, rates, or buffers—those will be calculated later.\nJust list each role, its seniority (e.g. Mid, Senior, Principal), and the average full-time-equivalent (FTE) allocation over the core delivery period.\n\n### DEFAULT & FALLBACK RULES\n\n-  Platform-driven roles:\n  • \"Web applications\" ⇒ Frontend Developer (React, Next.js)\n  • \"Mobile apps\" ⇒ Mobile Developer (Flutter by default; Swift/Kotlin if native)\n  • \"Admin portal\" ⇒ Frontend Developer with design system experience (Shadcn, Material UI)\n  • \"Backend/API services\" ⇒ Backend Developer (PHP Symfony, Node.js, or inferred)\n  • \"CMS\" or content-heavy site ⇒ CMS Developer or Content Specialist\n\nBy default add 1 Solution Arhitect at 30% -  depending on the complexity.\n\nBy default we have 1 project manager and 1 business analyst.\nIf the project is not too complex, use one Hybrid role (50% Project Manager and 50% Business Analyst).\n\n-  If compliance is \"Moderately Regulated\" or stricter:\n  • Add 1 QA Engineer minimum but in 30%\n  • Mention security-aware development practices in rationale\n  If compliance is \"Highly Regulated\":\n  add 1 QA at 50%\n\n-  If deployment seems classic (implicit or explicit):\n  • Add DevOps Engineer at 25% - if its complicated then add it at 50%\n\n-  If mobile apps required:\n  • Prefer Flutter unless RFP clearly prefers native (then Swift/Kotlin)\nIf Flutter, use 1 Flutter developer.\nIf iOS & Android, user 1 for each.\n\n-  If analytics, SEO, or tracking required:\n  • Include Analytics Specialist or Web Analyst at 30%\n\n-  If project includes “training”, “handover”, or “documentation”:\n  • Add Knowledge Transfer Lead or Documentation Specialist\n\n-  If delivery_model is “Full launch”:\n  • Treat it as a single delivery phase\n\n-  If MVP, phased delivery, or iterations mentioned:\n  • Scale team accordingly across delivery periods if needed\n\n-  If functional scope is large or complex (based on feature count or diversity):\n  • Increase number of developers or FTE allocation\n\n  -  If time line is tight:\n  • Increase number of developers or FTE allocation\n\n-  If 3rd party integrations like CRM, ERP, SSO, Stripe, etc. are required:\n  • Add some percentage to Solution Arhitect \n\n  If development aproach would be Heavily AI Generated code with Shadcn:\n  Don't add Designers. Add just one 100% NodeJS developer for development.\n  If Design is custom or if the project needs it, put 1 Designer at about 30%.\n\n  If the project needs AI, add 1 AI Engineer and, if data preparation is needed, add 1 Data Engineer.\n\n  If any requirement mentions login, authentication, payments, user roles, or GDPR, consider adding 10% to QA Engineer or Solution Architect FTE for security tasks.\n\n-  Rationale must:\n  • Start with **Extracted:**, **Inferred:**, or **Defaulted:**\n  • Be ≤ 700 words\n  • Mention platform/stack mapping to skills\n  • Justify any specialized roles added\n\nONLY output the JSON object—no other text.\n`;\n\nreturn {\n  json: {\n    systemPrompt,\n    userPrompt,\n  },\n};\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        280,
        5420
      ],
      "id": "e4529b87-90f5-469e-a851-efc9a470809f",
      "name": "Code"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "claude-sonnet-4-20250514",
          "mode": "list",
          "cachedResultName": "Claude Sonnet 4"
        },
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatAnthropic",
      "typeVersion": 1.3,
      "position": [
        480,
        5700
      ],
      "id": "48567420-501e-49c5-939c-cb2253d4b0eb",
      "name": "Anthropic Chat Model",
      "credentials": {
        "anthropicApi": {
          "id": "qzCm5Ds2qD9ZY1W5",
          "name": "Anthropic account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "/**\n * n8n Function node\n * Input (first item):\n * {\n *   \"output\": {\n *     \"features\": [\n *       { \"title\": \"...\", \"description\": \"...\", \"reference_section\": \"...\" },\n *       ...\n *     ]\n *   }\n * }\n *\n * Output:\n * { featureListSnippet: '### KEY_FEATURES …' }\n */\n\nconst feat = $input.first().json.output || {};\n\n// --- Basic validation ------------------------------------------------------\nif (!Array.isArray(feat.features) || feat.features.length === 0) {\n  throw new Error('Expected non-empty output.features array from previous step.');\n}\n\n// --- Build the snippet -----------------------------------------------------\nconst featureListSnippet = [\n  '### KEY_FEATURES (authoritative, extracted in a prior step)',\n  JSON.stringify(feat.features, null, 2), // pretty-printed JSON array\n  '',\n  'Treat this feature list as fixed functional scope for downstream sizing, sequencing, and cost estimation.',\n].join('\\n');\n\n// --- Return for downstream use --------------------------------------------\nreturn [\n  {\n    json: {\n      featureListSnippet,\n    },\n  },\n];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1380,
        5000
      ],
      "id": "49d51402-2d2e-4cbc-9926-f50328513aeb",
      "name": "Functional Requirements Output"
    },
    {
      "parameters": {
        "jsCode": "/**\n * n8n Function  ➜  “Build NFR query-pack”\n * Returns a single array item (same shape as your feature pack)\n */\nreturn [\n  {\n    json: {\n      query_type: \"non_functional_requirements\",\n      query:\n        \"Extract every non-functional requirement (performance, security, availability, scalability, accessibility, SEO, DevOps, monitoring, localization) described in the RFP that will influence architecture, DevOps, or QA effort.\",\n      /* NFR vocabulary */\n      keywords: [\n        /* performance & scale */\n        \"performance\", \"latency\", \"response time\", \"rps\", \"tps\",\n        \"load time\", \"web vitals\", \"core web vitals\", \"lighthouse\",\n        \"concurrency\", \"throughput\", \"scalability\", \"autoscale\",\n\n        /* availability & reliability */\n        \"uptime\", \"availability\", \"sla\", \"99.9%\", \"ha\", \"redundancy\",\n        \"failover\", \"disaster recovery\", \"rto\", \"rpo\",\n\n        /* security & privacy */\n        \"encryption\", \"tls\", \"ssl\", \"https\", \"owasp\", \"penetration test\",\n        \"vulnerability scan\", \"sso\", \"oauth\", \"saml\", \"jwt\", \"waf\",\n        \"access control\", \"role based access\", \"audit log\",\n\n        /* accessibility & seo */\n        \"wcag\", \"accessibility\", \"screen reader\", \"seo\", \"page speed\",\n        \"structured data\", \"sitemap.xml\",\n\n        /* DevOps & monitoring */\n        \"ci/cd\", \"pipeline\", \"deployment\", \"kubernetes\", \"docker\",\n        \"infrastructure as code\", \"terraform\", \"ansible\",\n        \"monitoring\", \"alerting\", \"logging\", \"grafana\", \"prometheus\",\n        \"observability\", \"sli\", \"slo\",\n\n        /* maintenance & support */\n        \"maintainability\", \"upgrade\", \"patching\", \"rollback\",\n        \"support window\", \"support hours\",\n\n          /* localisation & content scope */\n  \"localisation\", \"localization\", \"multilingual\", \"multi-language\",\n  \"translation\", \"i18n\", \"l10n\", \"languages\", \"locale\", \"page count\",\n  \"templates\", \"content migration\"\n      ],\n\n      /* Phrase boost for classic NFR language */\n      phrase: \"performance latency uptime availability security scalability localization\",\n\n      /* Rescore phrase for tight relevance */\n      rescore_query: \"performance OR uptime OR security OR scalability\",\n\n      description:\n        \"Surface all non-functional requirements that impact architecture, DevOps, security, performance, monitoring, or support.\"\n    }\n  }\n];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -4040,
        5380
      ],
      "id": "e29813f9-dc77-4622-8f17-f8bc7f32ea61",
      "name": "Queries8"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "http://192.168.20.70:11434/api/embed",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"model\": \"nomic-embed-text:latest\",\n  \"input\": [\"{{ $json.query }}\"]\n}",
        "options": {}
      },
      "id": "698f5675-8317-43f8-9b42-58f1e0162067",
      "name": "Embed Query - ollama8",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -3860,
        5380
      ]
    },
    {
      "parameters": {
        "jsCode": "// 1. Gather ES-RAG context\nconst contextForPrompt = $input.first().json.context;\n\n// 2. System prompt (static)\nconst systemPrompt = `\nYou are a strict JSON extractor. The user will supply raw excerpts from a software RFP.\nIdentify every distinct Non-Functional Requirement (how the system must perform or be operated).\nDo NOT invent, merge, or omit anything.\nDo NOT extract functional requirements.\nReturn **only** a valid JSON array—no headings, no markdown, no extra text.\n`;\n\n// 3. User prompt (dynamic)\nconst userPrompt = `\nBelow are RFP excerpts related to performance, security, scalability, uptime, DevOps, accessibility, or other non-functional expectations.\n\n### excerpts:\n\n${contextForPrompt}\n\nInstructions:\n- Extract each non-functional requirement (NFR) as its own object.\n- Make sure that there are no functional requirements\n- Categories to use: Performance, Availability, Security, Scalability, Accessibility, SEO, Localization/Languages, DevOps/Deployment, Monitoring/Logging, Maintainability, Compliance.\n- Do not summarise or combine items.\n- Provide a short \"rationale\" if the category is inferred.\n- Sort by section number ascending.\n- I Localization / Languages are nonexistent, choose English.\n- Return **only** the JSON\n— no extra text.\n`;\n\nreturn {\n  json: {\n    userPrompt,\n    systemPrompt\n  }\n};\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -3480,
        5600
      ],
      "id": "14225097-2be3-4fdc-a0b9-4e57f2fcf5c3",
      "name": "PreparePrompts7"
    },
    {
      "parameters": {
        "content": "## Inference NonFunctional Requirements\n",
        "height": 860,
        "width": 1740,
        "color": 2
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        -4460,
        5180
      ],
      "id": "c488d3bb-b52b-451e-9cdb-d32de77c7468",
      "name": "Sticky Note"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "mode": "list",
          "value": "claude-3-7-sonnet-20250219",
          "cachedResultName": "Claude 3.7 Sonnet"
        },
        "options": {
          "thinking": true
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatAnthropic",
      "typeVersion": 1.3,
      "position": [
        -3400,
        5800
      ],
      "id": "0a4aa008-09ef-4d11-a93a-d2c71021c0d8",
      "name": "Claude 3.1",
      "credentials": {
        "anthropicApi": {
          "id": "qzCm5Ds2qD9ZY1W5",
          "name": "Anthropic account"
        }
      }
    },
    {
      "parameters": {
        "operation": "getAll",
        "indexId": "=est_tool_rfp",
        "limit": 30,
        "simple": false,
        "options": {
          "query": "={\n  \"size\": 30,\n  \"min_score\": 1.5,\n  \"_source\": [\n    \"chunk_id\",\"section_title\",\"text\",\n    \"metadata.filename\",\"metadata.page_numbers\",\n    \"metadata.parent_chunk_id\",\"metadata.is_split_chunk\",\n    \"metadata.split_part\",\"metadata.total_parts\"\n  ],\n  \"knn\": {\n    \"field\": \"embeddings\",\n    \"query_vector\": [ {{ $json.embeddings }} ],\n    \"k\": 60,\n    \"num_candidates\": 300\n  },\n  \"query\": {\n    \"bool\": {\n      \"should\": [\n        {\n          \"match_phrase\": {\n            \"text\": {\n              \"query\": \"performance latency uptime availability\",\n              \"slop\": 3,\n              \"boost\": 2.0\n            }\n          }\n        },\n        {\n          \"multi_match\": {\n            \"query\": \"{{ $('Queries8').item.json.keywords.join(' ') }}\",\n            \"fields\": [\"text^2\",\"section_title^3\"],\n            \"type\": \"most_fields\",\n            \"minimum_should_match\": 1,\n            \"boost\": 1.2\n          }\n        },\n        {\n          \"terms_set\": {\n            \"text.keyword\": {\n              \"terms\": {{ JSON.stringify($('Queries8').item.json.keywords) }},\n              \"minimum_should_match_script\": { \"source\": \"1\" }\n            }\n          }\n        }\n      ],\n      \"minimum_should_match\": 1\n    }\n  },\n  \"rescore\": {\n    \"window_size\": 100,\n    \"query\": {\n      \"rescore_query\": {\n        \"match_phrase\": {\n          \"text\": {\n            \"query\": \"{{ $('Queries8').item.json.rescore_query }}\",\n            \"slop\": 2\n          }\n        }\n      },\n      \"query_weight\": 0.5,\n      \"rescore_query_weight\": 0.5\n    }\n  },\n  \"highlight\": {\n    \"type\": \"unified\",\n    \"fields\": { \"text\": {}, \"section_title\": {} }\n  }\n}\n"
        }
      },
      "type": "n8n-nodes-base.elasticsearch",
      "typeVersion": 1,
      "position": [
        -3660,
        5380
      ],
      "id": "86f40d64-6a1d-4ac2-8b62-c339cb13ef3a",
      "name": "Query - Full11",
      "credentials": {
        "elasticsearchApi": {
          "id": "wwaILZtoajWrVXwt",
          "name": "Elasticsearch account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// n8n Function Node: Corrected Merge Split-Chunk Groups\n\nconst grouped = {};\n\n// 1. Group all items by the “true” chunk identifier\nfor (const item of $input.all()) {\n  const data = item.json;\n  // Use parent_chunk_id if it exists, else chunk_id\n  const parentId = data.metadata?.is_split_chunk\n    ? data.metadata.parent_chunk_id\n    : data.chunk_id;\n\n  if (!grouped[parentId]) grouped[parentId] = [];\n  grouped[parentId].push(data);\n}\n\nconst merged = [];\n\n// 2. For each group, produce exactly one merged record\nfor (const [parentId, parts] of Object.entries(grouped)) {\n  // Sort by the split_part if present (else leave order)\n  parts.sort((a, b) => \n    (a.metadata?.split_part ?? 0) - (b.metadata?.split_part ?? 0)\n  );\n\n  // Stitch text together\n  const text = parts.map(p => p.text).join(\"\\n\\n\");\n\n  // Merge platform_origins arrays from all parts (dedupe by platform)\n  const allOrigins = parts.flatMap(p => p.platform_origins || []);\n  const platform_origins = [];\n  for (const o of allOrigins) {\n    if (!platform_origins.some(existing => existing.platform === o.platform)) {\n      platform_origins.push(o);\n    }\n  }\n\n  // Pick the highest-scoring part to inherit section_title, filename, pages, and score\n  const bestPart = parts.reduce((best, p) => \n    p._score > best._score ? p : best\n  , parts[0]);\n\n  // Build the single merged record\n  const record = {\n    chunk_id: parentId,\n    _score: bestPart._score,\n    section_title: bestPart.section_title,\n    text,\n    metadata: {\n      ...bestPart.metadata,\n      is_split_chunk: false,\n      parent_chunk_id: undefined,\n      split_part: undefined,\n      total_parts: undefined\n    },\n    platform_origins\n  };\n\n  merged.push({ json: record });\n}\nmerged.sort((a, b) => b.json._score - a.json._score);\nreturn merged;\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -4040,
        5600
      ],
      "id": "c5d21ab8-85ce-4e0b-9469-252b7a96352e",
      "name": "Merge Chunks8"
    },
    {
      "parameters": {
        "jsCode": "// n8n Function Node: Dedupe → Merge Origins → Filter → Sort → Fallback\n\nconst MIN_SCORE = 1.0;\nconst DESIRED_COUNT = 20;\n\n// Step 1: Deduplicate & merge platform origins, keep highest‐score record\nconst seen = {};\nfor (const item of $input.all()) {\n  const { chunk_id, platform, _score, ...rest } = item.json;\n  \n  if (!seen[chunk_id]) {\n    // First time seeing this chunk\n    seen[chunk_id] = {\n      chunk_id,\n      _score,\n      ...rest,\n      platform_origins: [{ platform, score: _score }],\n    };\n  } else {\n    // Merge new platform origin\n    const record = seen[chunk_id];\n    if (!record.platform_origins.some(p => p.platform === platform)) {\n      record.platform_origins.push({ platform, score: _score });\n    }\n    // If this hit has a higher score, overwrite core fields\n    if (_score > record._score) {\n      record._score = _score;\n      Object.assign(record, rest);\n    }\n  }\n}\n\n// Convert deduped map back to array of items\nlet deduped = Object.values(seen).map(r => ({ json: r }));\n\n// Step 2: Filter by score and sort descending\nlet filtered = deduped\n  .filter(item => item.json._score >= MIN_SCORE)\n  .sort((a, b) => b.json._score - a.json._score);\n\n// Step 3: Fallback if too few hits\nif (filtered.length < DESIRED_COUNT) {\n  // Return top DESIRED_COUNT from deduped (regardless of score)\n  filtered = deduped\n    .sort((a, b) => b.json._score - a.json._score)\n    .slice(0, DESIRED_COUNT);\n}\n\n// Step 4: Ensure we only return up to DESIRED_COUNT\nfiltered = filtered.slice(0, DESIRED_COUNT);\n\n// Return in n8n-compatible format\nreturn filtered;\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -3300,
        5380
      ],
      "id": "4b6d39bc-3408-44bb-8531-e9f0e3356156",
      "name": "Deduplicate and Best Score8"
    },
    {
      "parameters": {
        "jsCode": "// Configuration\nconst TOKEN_LIMIT = 7000;\nconst MIN_STRONG_SCORE = 16.0;\n\n// Rough token estimator (1 token ~ 4 characters)\nfunction estimateTokenCount(text) {\n  if (!text) return 0;\n  return Math.ceil(text.length / 4);\n}\n\n// Input already filtered and sorted!\nconst chunks = $input.all().map(item => item.json);\n\n// Build the final list\nconst selectedChunks = [];\nlet tokenCount = 0;\n\nfor (const chunk of chunks) {\n  const tokens = estimateTokenCount(chunk.text);\n\n  if ((tokenCount + tokens) <= TOKEN_LIMIT) {\n    selectedChunks.push(chunk);\n    tokenCount += tokens;\n  } else if (chunk._score >= MIN_STRONG_SCORE) {\n    // Allow overflow for very strong chunks\n    selectedChunks.push(chunk);\n    tokenCount += tokens;\n  } else {\n    break; // Stop adding\n  }\n}\n\n// Prepare output\nconst output = selectedChunks.map(chunk => ({ json: chunk }));\n\n// Add token usage metadata (attach to first item for simplicity)\nif (output.length > 0) {\n  output[0].json._token_summary = {\n    total_tokens_estimated: tokenCount,\n    total_chunks_selected: selectedChunks.length,\n  };\n}\n\nreturn output;\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -3860,
        5600
      ],
      "id": "4cb57d72-e81b-4fb1-8555-af9de0d734b5",
      "name": "Token Budgeting7"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "gpt-4.1-mini",
          "mode": "list",
          "cachedResultName": "gpt-4.1-mini"
        },
        "options": {
          "maxTokens": 10000,
          "temperature": 0.1
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        -3260,
        5800
      ],
      "id": "861aa009-382c-4cfe-99ff-f8b43f702fa9",
      "name": "OpenAI Chat Model",
      "credentials": {
        "openAiApi": {
          "id": "M8xqWvEC6mH6LNuk",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "/**\n * Prepare ES chunks for Claude, without chunk‐length limiting.\n */\nfunction prepareSecurityRegulatoryContextForClaude(esResults) {\n  if (!Array.isArray(esResults)) {\n    throw new Error(\"Input must be an array of Elasticsearch results\");\n  }\n\n  // simple Markdown escaper\n  function mdEscape(str) {\n    return str.replace(/(`|\\*|_|~|>|\\[|\\])/g, \"\\\\$1\");\n  }\n\n  // normalize bullets and split into lines\n  function cleanText(raw) {\n    return raw\n      .replace(/^\\s*-\\s+/gm, \"\\n- \")\n      .replace(/^\\s*\\*\\s+/gm, \"\\n- \")\n      .replace(/[ \\t]+/g, \" \")\n      .replace(/\\. ([A-Z])/g, \".\\n$1\")\n      .replace(/\\n{3,}/g, \"\\n\\n\")\n      .trim();\n  }\n\n  const blocks = esResults.map(chunk => {\n    const { chunk_id, section_title, text = \"\", metadata = {}, _score, regScore, locScore } = chunk;\n\n    // Heading\n    const title = section_title\n      ? mdEscape(section_title)\n      : `Untitled Section (${chunk_id})`;\n\n    // Build YAML metadata\n    const pages = Array.isArray(metadata.page_numbers)\n      ? metadata.page_numbers.join(\", \")\n      : metadata.page_numbers || \"Unknown\";\n\n    const metaLines = [\n      `filename: ${metadata.filename || \"Unknown Document\"}`,\n      `pages: ${pages}`,\n      `score: ${_score.toFixed(2)}`,\n    ];\n    if (typeof regScore === \"number\") metaLines.push(`regScore: ${regScore.toFixed(2)}`);\n    if (typeof locScore === \"number\") metaLines.push(`locScore: ${locScore.toFixed(2)}`);\n    if (metadata.document_type) metaLines.push(`type: ${metadata.document_type}`);\n    if (metadata.languages) metaLines.push(`language: ${metadata.languages.join(\", \")}`);\n\n    const metaBlock = metaLines.join(\"\\n\");\n\n    // Clean and escape body\n    const body = mdEscape(cleanText(text));\n\n    return [\n      `### ${title}`,\n      \"```yaml\",\n      metaBlock,\n      \"```\",\n      \"\",\n      body\n    ].join(\"\\n\");\n  });\n\n  // Join with clear separators\n  return blocks.join(\"\\n\\n---\\n\\n\");\n}\n\n// Usage in n8n Function node:\nconst esResults = $input.all().map(i => i.json);\nconst contextForPrompt = prepareSecurityRegulatoryContextForClaude(esResults);\n\nreturn [{ json: { context: contextForPrompt } }];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -3660,
        5600
      ],
      "id": "9128b046-e528-4f69-a5cc-3740063264d8",
      "name": "Prepare Context6"
    },
    {
      "parameters": {},
      "type": "@n8n/n8n-nodes-langchain.toolThink",
      "typeVersion": 1,
      "position": [
        -3120,
        5800
      ],
      "id": "b58b36b9-2a59-494a-ade5-d134a0c62d0d",
      "name": "Think1"
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "17f9e7d3-307e-4d60-92ef-e32285cbec29",
              "name": "_score",
              "value": "={{ $json._score }}",
              "type": "number"
            },
            {
              "id": "618f58cd-27c7-4ab4-8612-899f048afb6c",
              "name": "_id",
              "value": "={{ $json._id }}",
              "type": "string"
            },
            {
              "id": "a8cfb079-48c6-4ce2-a54c-251304107206",
              "name": "chunk_id",
              "value": "={{ $json._source.chunk_id }}",
              "type": "string"
            },
            {
              "id": "22e6e029-7ff1-4870-a1c2-d3b025a2748b",
              "name": "section_title",
              "value": "={{ $json._source.section_title }}",
              "type": "string"
            },
            {
              "id": "27e9a9ac-b6ed-4320-bb21-027f8659e7c5",
              "name": "text",
              "value": "={{ $json._source.text }}",
              "type": "string"
            },
            {
              "id": "6830a868-6492-405b-b8fb-1ae36ea184b2",
              "name": "metadata",
              "value": "={{ $json._source.metadata }}",
              "type": "object"
            },
            {
              "id": "e5dce93c-eb16-42be-8b42-47ca5cfacc52",
              "name": "platform",
              "value": "={{ $('Queries8').item.json.platform }}",
              "type": "string"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        -3480,
        5380
      ],
      "id": "d8748f8c-7070-48ae-9868-676db59b8993",
      "name": "Map Response8"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ $json.userPrompt }}",
        "hasOutputParser": true,
        "options": {
          "systemMessage": "={{ $json.systemPrompt }}"
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.9,
      "position": [
        -3240,
        5600
      ],
      "id": "c6443861-a722-4231-a69e-e5484411f0f0",
      "name": "NonFunctional Requirements"
    },
    {
      "parameters": {
        "jsCode": "/**\n * n8n Function node ─ “Build NFR snippet”\n *\n * Input shape (first item):\n * [\n *   {\n *     output: [\n *       { title, description, category, rationale, reference_section },\n *       ...\n *     ]\n *   }\n * ]\n *\n * Output (for the next node):\n * { nonFunctionalRequirementsSnippet: '### NON_FUNCTIONAL_REQUIREMENTS …' }\n */\n\n// --- Grab first item -------------------------------------------------------\nconst nfrArray = $input.first().json.output || [];\n\n// --- Basic validation ------------------------------------------------------\nif (!Array.isArray(nfrArray) || nfrArray.length === 0) {\n  throw new Error('Expected non-empty output array of NFR objects from previous step.');\n}\n\n// --- Build the snippet -----------------------------------------------------\nconst nonFunctionalRequirementsSnippet = [\n  '### NON_FUNCTIONAL_REQUIREMENTS (authoritative, extracted in a prior step)',\n  JSON.stringify(nfrArray, null, 2),  // pretty-printed JSON array\n  '',\n  'Treat this NFR list as fixed scope impacting architecture, DevOps, performance, and QA in downstream estimation.',\n].join('\\n');\n\n// --- Return for downstream use --------------------------------------------\nreturn [\n  {\n    json: {\n      nonFunctionalRequirementsSnippet,\n    },\n  },\n];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -2680,
        5600
      ],
      "id": "031babb7-a1c4-4788-8b41-07b3ab512786",
      "name": "NonFunctional Requirements Output"
    },
    {
      "parameters": {
        "jsonSchemaExample": "{\n  \"risks\": [\n    {\n      \"category\": \"Technical\",\n      \"statement\": \"WordPress + React/Next.js separation may cause SEO duplication issues if not handled with ISR or proper canonical tags.\",\n      \"impact\": \"Medium\",\n      \"likelihood\": \"High\",\n      \"mitigation\": \"Add SEO middleware in Next.js and run technical-SEO audit in sprint 2.\"\n    },\n    {\n      \"category\": \"Schedule\",\n      \"statement\": \"Go-Live fixed at week 17 with only 30-day QA/support window could be tight for migration and training.\",\n      \"impact\": \"High\",\n      \"likelihood\": \"Medium\",\n      \"mitigation\": \"Add buffer sprint or negotiate phased soft-launch; extend post-launch support to 60 days.\"\n    }\n  ]\n}"
      },
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "typeVersion": 1.2,
      "position": [
        -3520,
        6700
      ],
      "id": "3f6987e3-e1d3-4279-a5c3-d1bc8b6e9366",
      "name": "Greenfield + Rationale2"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "gpt-4.1-mini",
          "mode": "list",
          "cachedResultName": "gpt-4.1-mini"
        },
        "options": {
          "temperature": 0.3
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        -3680,
        6700
      ],
      "id": "27ff40ff-b54f-482a-acd6-2b5241f70430",
      "name": "GPT 4.1 Mini3",
      "credentials": {
        "openAiApi": {
          "id": "M8xqWvEC6mH6LNuk",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "/**\n * Node name: Build Risk-Analysis Prompt\n * Inputs   : all previous snippet fields (metadata, tech, NFR, features, …)\n */\n\nconst snippets = [\n$input.first().json.regulatoryComplianceSnippet,\n  $input.first().json.combinedRequirementsSnippet,\n  $input.first().json.projectClassificationSnippet,\n  $input.first().json.deliveryRequirementsSnippet,\n  $input.first().json.detectedTechStackSnippet,\n  $input.first().json.teamCompositionSnippet\n].join('\\n\\n');\n\nconst systemPrompt = `\nYou are a senior solution-architect creating a risk register for a software project.\nReturn ONLY a valid JSON object with a \"risks\" array.\nDo not include any other text.\n`;\n\nconst userPrompt = `\nBelow are structured excerpts that describe the project context.\n\n${snippets}\n\nTASK:\n1. Identify every plausible project risk or unknown that could affect scope, timeline, quality, or cost.\n2. For each risk provide json item\n3. If information is missing (e.g. integration depth) create a LOW-confidence risk with mitigation “clarify with client”.\n\n• Do not repeat similar risks unless they differ in scope or mitigation.\n• Use \"High\" likelihood if there's strong implication in RFP; use \"Low\" if it's a fallback due to missing detail.\n• Sort the risks by descending impact to prioritize review.\n\nIf key information is missing (e.g. integration depth, team size), still create a LOW-confidence risk.\n→ Use \"likelihood\": \"Low\" and \"mitigation\": \"Clarify with client before estimation.\"\n\nIf multiple risks relate to the same feature or constraint, consolidate them if possible.\nDo not repeat similar risks unless their impact or scope is materially different.\nSort the risks in order of descending impact (i.e., High-impact risks come first).\n\nTotal output should be between 5–12 risks for most projects.\nReturn ONLY the JSON object – no markdown, no explanations.\n`;\n\nreturn { json: { systemPrompt, userPrompt } };\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -4020,
        6420
      ],
      "id": "330d6ce5-df5a-471f-aa50-90ccdf9b3f2c",
      "name": "Code1"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "mode": "list",
          "value": "claude-3-7-sonnet-20250219",
          "cachedResultName": "Claude 3.7 Sonnet"
        },
        "options": {
          "maxTokensToSample": 6000,
          "temperature": 0.3,
          "thinking": false
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatAnthropic",
      "typeVersion": 1.3,
      "position": [
        -3820,
        6700
      ],
      "id": "e84410d8-b37f-49e8-994f-c71f6cda8724",
      "name": "Anthropic Chat Model1",
      "credentials": {
        "anthropicApi": {
          "id": "qzCm5Ds2qD9ZY1W5",
          "name": "Anthropic account"
        }
      }
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ $json.userPrompt }}",
        "hasOutputParser": true,
        "options": {
          "systemMessage": "={{ $json.systemPrompt }}"
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.9,
      "position": [
        -3720,
        6420
      ],
      "id": "c1d20af3-7996-4dd1-840f-501d38c982fb",
      "name": "Risks"
    },
    {
      "parameters": {
        "jsCode": "return [\n  {\n    json: {\n      key: \"web_stack\",\n      query: \"What frontend or web frameworks are mentioned?\",\n      keywords: \"React, Angular, Vue, Svelte, Next.js, Nuxt.js, web framework, frontend, front-end, web app, web application, JavaScript, TypeScript, HTML, CSS\",\n      phrase: \"frontend web application\",\n      rescore_query: \"React OR Angular OR Vue OR Next.js\"\n    }\n  },\n  {\n    json: {\n      key: \"design\",\n      query: \"What design system or UI components are referenced?\",\n      keywords: \"Shadcn, Tailwind, Bootstrap, Material UI, design system, UI kit, style guide, branding, UX, Figma, wireframes, visual design, WCAG, Radix, Ant Design\",\n      phrase: \"design system UI kit\",\n      rescore_query: \"Shadcn OR Material UI OR Tailwind\"\n    }\n  },\n  {\n    json: {\n      key: \"mobile_stack\",\n      query: \"What mobile development technologies are mentioned?\",\n      keywords: \"Flutter, React Native, Swift, Kotlin, iOS, Android, mobile app, mobile development, native mobile, cupertino\",\n      phrase: \"mobile development mobile app\",\n      rescore_query: \"Flutter OR React Native OR Kotlin OR Swift\"\n    }\n  },\n  {\n    json: {\n      key: \"backend_stack\",\n      query: \"What backend technologies or server frameworks are used?\",\n      keywords: \"Node.js, Python, Django, Java, Spring, PHP, Laravel, Ruby, Rails, Express, .NET, API, backend server, server-side, Go, Rust, FastAPI, NestJS\",\n      phrase: \"backend server backend technology\",\n      rescore_query: \"Node.js OR Django OR Laravel OR Java OR Spring\"\n    }\n  },\n  {\n    json: {\n      key: \"ai_needed\",\n      query: \"Does the project involve AI, ML, or data processing?\",\n      keywords: \"AI, artificial intelligence, machine learning, ML, chatbot, NLP, LLM, model training, predictive analytics, smart assistant, automation, algorithm, TensorFlow, PyTorch, OpenAI, Azure AI\",\n      phrase: \"AI functionality ML features\",\n      rescore_query: \"AI OR ML OR LLM OR chatbot\"\n    }\n  },\n  {\n    json: {\n      key: \"database\",\n      query: \"What kind of database or data storage is required?\",\n      keywords: \"PostgreSQL, MySQL, MongoDB, Redis, database, data storage, data layer, NoSQL, SQL, relational database, DBMS, backend storage, SQL Server, Oracle, DynamoDB, Firebase\",\n      phrase: \"data storage database\",\n      rescore_query: \"PostgreSQL OR MongoDB OR database system\"\n    }\n  },\n  {\n    json: {\n      key: \"deployment\",\n      query: \"Where is the system hosted or deployed?\",\n      keywords: \"AWS, Azure, GCP, cloud hosting, on-premises, hybrid, deployment, infrastructure, Kubernetes, Docker, container, server, on-premise, self-hosted, serverless, Kubernetes\",\n      phrase: \"deployment infrastructure hosting\",\n      rescore_query: \"AWS OR Azure OR cloud hosting\"\n    }\n  },\n  {\n    json: {\n      key: \"integrations\",\n      query: \"What external systems, APIs, or services need to be integrated?\",\n      keywords: \"integration, OAuth, SAML, API, APIs, third-party service, external system, SSO, payment gateway, Stripe, REST API, GraphQL, CRM, ERP\",\n      phrase: \"integration third-party system\",\n      rescore_query: \"OAuth OR API OR SSO OR Stripe\"\n    }\n  }\n];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1400,
        5400
      ],
      "id": "544f182f-271c-4fac-8622-042f474f591c",
      "name": "Queries7"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "http://192.168.20.70:11434/api/embed",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"model\": \"nomic-embed-text:latest\",\n  \"input\": [\"{{ $json.query }}\"]\n}",
        "options": {}
      },
      "id": "ba5f0826-a899-40a9-94e8-359fbf53eb99",
      "name": "Embed Query - ollama7",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -1220,
        5400
      ]
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "17f9e7d3-307e-4d60-92ef-e32285cbec29",
              "name": "_score",
              "value": "={{ $json._score }}",
              "type": "number"
            },
            {
              "id": "618f58cd-27c7-4ab4-8612-899f048afb6c",
              "name": "_id",
              "value": "={{ $json._id }}",
              "type": "string"
            },
            {
              "id": "a8cfb079-48c6-4ce2-a54c-251304107206",
              "name": "chunk_id",
              "value": "={{ $json._source.chunk_id }}",
              "type": "string"
            },
            {
              "id": "22e6e029-7ff1-4870-a1c2-d3b025a2748b",
              "name": "section_title",
              "value": "={{ $json._source.section_title }}",
              "type": "string"
            },
            {
              "id": "27e9a9ac-b6ed-4320-bb21-027f8659e7c5",
              "name": "text",
              "value": "={{ $json._source.text }}",
              "type": "string"
            },
            {
              "id": "6830a868-6492-405b-b8fb-1ae36ea184b2",
              "name": "metadata",
              "value": "={{ $json._source.metadata }}",
              "type": "object"
            },
            {
              "id": "e5dce93c-eb16-42be-8b42-47ca5cfacc52",
              "name": "platform",
              "value": "={{ $('Queries7').item.json.platform }}",
              "type": "string"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        -840,
        5400
      ],
      "id": "25d57ac9-7c65-40b4-aacf-261579cd0fd0",
      "name": "Map Response3"
    },
    {
      "parameters": {
        "jsCode": "// ---------------------------------------------------------------------------\n// gather snippets\n// ---------------------------------------------------------------------------\nconst ctxChunks = $input.first().json.context;\nconst platforms = $('Platforms Output').first().json.detectedPlatformsSnippet;\nconst requirements  = $('Combined Requirements Output').first().json.combinedRequirementsSnippet;\n\n// ---------------------------------------------------------------------------\n// system prompt\n// ---------------------------------------------------------------------------\nconst systemPrompt = `\nYou are a senior solution-architect.\nReturn ONLY a valid JSON object under the key \"tech_stack\".\nDo NOT output headings, markdown, or commentary.\n`;\n\n// ---------------------------------------------------------------------------\n// user prompt\n// ---------------------------------------------------------------------------\nconst userPrompt = `\nYou are analysing RFP excerpts to define the optimal technology stack.\n\n### CONTEXT\n${ctxChunks}\n\n${platforms}\n\n${requirements}\n\n### TASK\nSelect **one** primary technology (or an empty list) for each dimension and build the JSON object below.\n\n1. **Selection priority**  \n   a. Use tech the RFP **explicitly** names.  \n   b. Else use tech the RFP **implicitly** requires (e.g., WordPress ⇒ PHP + MySQL).  \n   c. Else apply our **house defaults**:  \n      • web_stack = \"React\"  \n      • backend_stack = \"PHP Symfony\"  \n      • mobile_stack = \"Flutter\"  \n      • design = \"Shadcn\"  \n      • database = \"PostgreSQL\"  \n      • deployment = \"AWS\"\n\n2. **Heavily AI-generated shortcut**  \n   If BOTH conditions hold:  \n   • Design is not Custom or demanding.  \n   • Functional Requirements describe mainly CRUD tables & simple admin UI.\n   • Techstack is not explicitly defined in RFP.  \n   → Override rule 1 and set:  \n     • web_stack = \"Next.js\"  \n     • backend_stack = \"Supabase\"  \n     • database = \"Supabase\"  \n     • design = \"Shadcn\"  \n     • stack_model = \"fullstack\"  \n     • Begin rationale with **\"Heavily AI-generated:\"**.\n\n3. **Additional industry heuristics** (activate only if rule 1 or 2 hasn’t decided the dimension):\n\n   • *Marketing / Blog CMS*: React + Next.js front, Node JS back, Postgres, headless CMS (“Strapi”, “Sanity”, etc.), stack_model = separated.  \n   • *Finance / high-compliance with no tech named*: backend_stack = \"Java Spring Boot\" **or** \".NET\"; note compliance in rationale.  \n   • *Real-time / microservice wording*: add Node JS **or** Go plus Redis cache.  \n   • *EU data residency, cloud unnamed*: deployment = \"AWS (eu-central-1)\" **or** \"Azure (West Europe)\".  \n   • *Elastic traffic spikes*: append \"serverless\" or \"containerized (Docker/K8s)\".  \n   • *Native device features (camera, AR)*: mobile_stack = \"Swift\" **or** \"Kotlin\".  \n   • *WCAG / strict design*: design = \"Material UI\".  \n   • *Analytics / BI tooling*: add \"Snowflake\" **or** \"BigQuery\".  \n\n   **Domain-specific triggers**  \n   – *E-commerce / checkout*: ensure integrations include \"Stripe\"; backend maybe \"Node.js\" or \"PHP Laravel\"; add \"Cloudflare CDN\" to deployment.  \n   – *Government / FedRAMP*: deployment = \"AWS GovCloud\" or \"Azure Government\"; backend = \".NET\" or \"Java Spring Boot\".  \n   – *Heavy video streaming*: integrations include \"AWS MediaConvert\" or \"Cloudflare Stream\"; add \"Redis\" cache.  \n   – *Multi-language localisation*: add \"i18next\" or \"next-intl\" integration.  \n   – *Strict CI/CD named*: mention chosen CI tool in rationale; deployment includes Docker/K8s.  \n   – *Legacy .NET stack referenced*: backend_stack = \".NET Core\".  \n   – *Open-source mandate*: avoid commercial DBs; enforce PostgreSQL and Linux hosting.  \n   – *99.9 % SLA / observability*: integrations include \"Prometheus\", \"Grafana\".\n  \n\n4. **ai_needed**  \n   true if RFP **mentions OR implies** AI/ML, chatbot, predictive, NLP, recommendation, smart search, forecasting, etc.; else false.\n\n5. **integrations**  \n   List only systems explicitly mentioned or strongly implied (CRM, ERP, SSO, payment, etc.).  \n   – Always include \"REST APIs\" when CRM/ERP/SSO appears.  \n   – If SAML, OAuth, Okta, Keycloak appear, list them.\n\n6. **stack_model**  \n   \"fullstack\" if FE & BE share one runtime (React + Supabase, React + Node, etc.); otherwise \"separated\".\n\n7. **Output constraints**  \n   • Provide **exactly one** entry per tech list (except integrations, where you should only put one solution choise - for example, in Inregrations, If we can use Stripe or Paypal, choose one thats best, dont return both of them).  \n   • Remove duplicates.  \n   • Rationale ≤ 700 words and must start with **Extracted:**, **Inferred:**, or **Heavily AI-generated:** indicating the rule used.  \n   • Mention how DETECTED_PLATFORMS informed defaults when defaults are chosen.\n   • Extract the techstack only for platforms that you got in DETECTED_PLATFORMS, leave the others one empty\n   . If you can choose bitween React Native and Flutter, choose Flutter\n\n### STRICT OUTPUT TEMPLATE\n{\n  \"tech_stack\": {\n    \"web_stack\": [\"React\"],\n    \"design\": [\"Shadcn\"],\n    \"mobile_stack\": [\"Flutter\"],\n    \"backend_stack\": [\"PHP Symfony\"],\n    \"ai_needed\": false,\n    \"database\": \"PostgreSQL\",\n    \"deployment\": \"AWS\",\n    \"integrations\": [],\n    \"stack_model\": \"fullstack\",\n    \"rationale\": \"…\"\n  }\n}\n`;\n\nreturn { json: { systemPrompt, userPrompt } };\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -840,
        5620
      ],
      "id": "fde8ef9c-dea5-4019-b6bd-1326b7d14c68",
      "name": "PreparePrompts6"
    },
    {
      "parameters": {
        "content": "## Inference Techstack\n",
        "height": 860,
        "width": 1340,
        "color": 3
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        -1560,
        5180
      ],
      "id": "4ce3885c-8bf9-41c8-acab-29c2728a1837",
      "name": "Sticky Note11"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "claude-sonnet-4-20250514",
          "mode": "list",
          "cachedResultName": "Claude Sonnet 4"
        },
        "options": {
          "temperature": 0.3,
          "thinking": false
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatAnthropic",
      "typeVersion": 1.3,
      "position": [
        -760,
        5820
      ],
      "id": "2617d5f7-76be-487a-8d2b-38930e3134eb",
      "name": "Claude 3.8",
      "credentials": {
        "anthropicApi": {
          "id": "qzCm5Ds2qD9ZY1W5",
          "name": "Anthropic account"
        }
      }
    },
    {
      "parameters": {
        "jsonSchemaExample": "{\n  \"tech_stack\": {\n    \"stack_model\": \"fullstack\",\n    \"backend_stack\": [\"Node.js\", \"Java\", \"Python\"],\n    \"web_stack\": [\"React\", \"Vue\", \"Angular\"],\n    \"mobile_stack\": [\"Flutter\", \"Swift\", \"Kotlin\"],\n    \"design\": [\"Shadcn\", \"Material UI\", \"Custom\"],\n    \"ai_needed\": true,\n    \"database\": \"PostgreSQL\",\n    \"deployment\": \"cloud\",\n    \"integrations\": [\"OAuth\", \"SAML\", \"third-party APIs\"],\n    \"rationale\": \"Why this tech stack is appropriate for this project\"\n  }\n}"
      },
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "typeVersion": 1.2,
      "position": [
        -400,
        5820
      ],
      "id": "42b052d5-5714-4f6e-b955-7de32e08d053",
      "name": "Platforms + Rationale2"
    },
    {
      "parameters": {
        "operation": "getAll",
        "indexId": "=est_tool_rfp",
        "limit": 10,
        "simple": false,
        "options": {
          "query": "={\n  \"size\": 10,\n  \"min_score\": 1.5,\n  \"_source\": [\n    \"chunk_id\",\"section_title\",\"text\",\n    \"metadata.filename\",\"metadata.page_numbers\",\n    \"metadata.parent_chunk_id\",\"metadata.is_split_chunk\",\n    \"metadata.split_part\",\"metadata.total_parts\",\n    \"vector_metadata.token_count\",\"vector_metadata.is_split\",\n    \"vector_metadata.chunk_index\"\n  ],\n  \"knn\": {\n    \"field\": \"embeddings\",\n    \"query_vector\": [ {{ $json.embeddings }} ],\n    \"k\": 20,\n    \"num_candidates\": 50\n  },\n  \"query\": {\n    \"bool\": {\n      \"should\": [\n        {\n          \"match_phrase\": {\n            \"text\": {\n              \"query\": \"{{ $('Queries7').item.json.phrase }}\",\n              \"slop\": 4,\n              \"boost\": 2.0\n            }\n          }\n        },\n        {\n          \"multi_match\": {\n            \"query\": \"{{ $('Queries7').item.json.keywords }}\",\n            \"fields\": [\"text^2\",\"section_title^3\"],\n            \"type\": \"most_fields\",\n            \"minimum_should_match\": 2,\n            \"boost\": 1.2\n          }\n        },\n        {\n          \"terms_set\": {\n            \"text.keyword\": {\n              \"terms\": {{ JSON.stringify($('Queries7').item.json.keywords.split(',').map(k => k.trim())) }},\n\n              \"minimum_should_match_script\": {\n                \"source\": \"Math.min(params.num_terms, 2)\"\n              }\n            }\n          }\n        }\n      ],\n      \"minimum_should_match\": 1\n    }\n  },\n  \"rescore\": {\n    \"window_size\": 20,\n    \"query\": {\n      \"rescore_query\": {\n        \"match_phrase\": {\n          \"text\": {\n            \"query\": \"{{ $('Queries7').item.json.rescore_query }}\",\n            \"slop\": 8\n          }\n        }\n      },\n      \"query_weight\": 0.7,\n      \"rescore_query_weight\": 0.3\n    }\n  },\n  \"highlight\": {\n    \"type\": \"unified\",\n    \"fields\": { \"text\": {}, \"section_title\": {} }\n  }\n}\n"
        }
      },
      "type": "n8n-nodes-base.elasticsearch",
      "typeVersion": 1,
      "position": [
        -1020,
        5400
      ],
      "id": "9d23397b-1094-4df3-97c9-983ef6f52e57",
      "name": "Query - Full10",
      "credentials": {
        "elasticsearchApi": {
          "id": "wwaILZtoajWrVXwt",
          "name": "Elasticsearch account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// n8n Function Node: Corrected Merge Split-Chunk Groups\n\nconst grouped = {};\n\n// 1. Group all items by the “true” chunk identifier\nfor (const item of $input.all()) {\n  const data = item.json;\n  // Use parent_chunk_id if it exists, else chunk_id\n  const parentId = data.metadata?.is_split_chunk\n    ? data.metadata.parent_chunk_id\n    : data.chunk_id;\n\n  if (!grouped[parentId]) grouped[parentId] = [];\n  grouped[parentId].push(data);\n}\n\nconst merged = [];\n\n// 2. For each group, produce exactly one merged record\nfor (const [parentId, parts] of Object.entries(grouped)) {\n  // Sort by the split_part if present (else leave order)\n  parts.sort((a, b) => \n    (a.metadata?.split_part ?? 0) - (b.metadata?.split_part ?? 0)\n  );\n\n  // Stitch text together\n  const text = parts.map(p => p.text).join(\"\\n\\n\");\n\n  // Merge platform_origins arrays from all parts (dedupe by platform)\n  const allOrigins = parts.flatMap(p => p.platform_origins || []);\n  const platform_origins = [];\n  for (const o of allOrigins) {\n    if (!platform_origins.some(existing => existing.platform === o.platform)) {\n      platform_origins.push(o);\n    }\n  }\n\n  // Pick the highest-scoring part to inherit section_title, filename, pages, and score\n  const bestPart = parts.reduce((best, p) => \n    p._score > best._score ? p : best\n  , parts[0]);\n\n  // Build the single merged record\n  const record = {\n    chunk_id: parentId,\n    _score: bestPart._score,\n    section_title: bestPart.section_title,\n    text,\n    metadata: {\n      ...bestPart.metadata,\n      is_split_chunk: false,\n      parent_chunk_id: undefined,\n      split_part: undefined,\n      total_parts: undefined\n    },\n    platform_origins\n  };\n\n  merged.push({ json: record });\n}\nmerged.sort((a, b) => b.json._score - a.json._score);\nreturn merged;\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1400,
        5620
      ],
      "id": "8c5be8b5-3e2f-4c65-8255-325d8f0b0236",
      "name": "Merge Chunks7"
    },
    {
      "parameters": {
        "jsCode": "// n8n Function Node: Dedupe → Merge Origins → Filter → Sort → Fallback\n\nconst MIN_SCORE = 3.0;\nconst DESIRED_COUNT = 10;\n\n// Step 1: Deduplicate & merge platform origins, keep highest‐score record\nconst seen = {};\nfor (const item of $input.all()) {\n  const { chunk_id, platform, _score, ...rest } = item.json;\n  \n  if (!seen[chunk_id]) {\n    // First time seeing this chunk\n    seen[chunk_id] = {\n      chunk_id,\n      _score,\n      ...rest,\n      platform_origins: [{ platform, score: _score }],\n    };\n  } else {\n    // Merge new platform origin\n    const record = seen[chunk_id];\n    if (!record.platform_origins.some(p => p.platform === platform)) {\n      record.platform_origins.push({ platform, score: _score });\n    }\n    // If this hit has a higher score, overwrite core fields\n    if (_score > record._score) {\n      record._score = _score;\n      Object.assign(record, rest);\n    }\n  }\n}\n\n// Convert deduped map back to array of items\nlet deduped = Object.values(seen).map(r => ({ json: r }));\n\n// Step 2: Filter by score and sort descending\nlet filtered = deduped\n  .filter(item => item.json._score >= MIN_SCORE)\n  .sort((a, b) => b.json._score - a.json._score);\n\n// Step 3: Fallback if too few hits\nif (filtered.length < DESIRED_COUNT) {\n  // Return top DESIRED_COUNT from deduped (regardless of score)\n  filtered = deduped\n    .sort((a, b) => b.json._score - a.json._score)\n    .slice(0, DESIRED_COUNT);\n}\n\n// Step 4: Ensure we only return up to DESIRED_COUNT\nfiltered = filtered.slice(0, DESIRED_COUNT);\n\n// Return in n8n-compatible format\nreturn filtered;\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -660,
        5400
      ],
      "id": "0f5cdf1d-3af5-49b9-98b8-03369b32d138",
      "name": "Deduplicate and Best Score7"
    },
    {
      "parameters": {
        "jsCode": "// Configuration\nconst TOKEN_LIMIT = 5000;\nconst MIN_STRONG_SCORE = 7.0;\n\n// Rough token estimator (1 token ~ 4 characters)\nfunction estimateTokenCount(text) {\n  if (!text) return 0;\n  return Math.ceil(text.length / 4);\n}\n\n// Input already filtered and sorted!\nconst chunks = $input.all().map(item => item.json);\n\n// Build the final list\nconst selectedChunks = [];\nlet tokenCount = 0;\n\nfor (const chunk of chunks) {\n  const tokens = estimateTokenCount(chunk.text);\n\n  if ((tokenCount + tokens) <= TOKEN_LIMIT) {\n    selectedChunks.push(chunk);\n    tokenCount += tokens;\n  } else if (chunk._score >= MIN_STRONG_SCORE) {\n    // Allow overflow for very strong chunks\n    selectedChunks.push(chunk);\n    tokenCount += tokens;\n  } else {\n    break; // Stop adding\n  }\n}\n\n// Prepare output\nconst output = selectedChunks.map(chunk => ({ json: chunk }));\n\n// Add token usage metadata (attach to first item for simplicity)\nif (output.length > 0) {\n  output[0].json._token_summary = {\n    total_tokens_estimated: tokenCount,\n    total_chunks_selected: selectedChunks.length,\n  };\n}\n\nreturn output;\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1220,
        5620
      ],
      "id": "ab9d10d7-8d73-4dcf-b019-72a04fef07fc",
      "name": "Token Budgeting5"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "gpt-4.1",
          "mode": "list",
          "cachedResultName": "gpt-4.1"
        },
        "options": {
          "temperature": 0.4
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        -600,
        5900
      ],
      "id": "9138ce5a-18ec-4332-86f7-35321acc15af",
      "name": "OpenAI Chat Model5",
      "credentials": {
        "openAiApi": {
          "id": "M8xqWvEC6mH6LNuk",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "/**\n * Prepare ES chunks for Claude, without chunk‐length limiting.\n */\nfunction prepareSecurityRegulatoryContextForClaude(esResults) {\n  if (!Array.isArray(esResults)) {\n    throw new Error(\"Input must be an array of Elasticsearch results\");\n  }\n\n  // simple Markdown escaper\n  function mdEscape(str) {\n    return str.replace(/(`|\\*|_|~|>|\\[|\\])/g, \"\\\\$1\");\n  }\n\n  // normalize bullets and split into lines\n  function cleanText(raw) {\n    return raw\n      .replace(/^\\s*-\\s+/gm, \"\\n- \")\n      .replace(/^\\s*\\*\\s+/gm, \"\\n- \")\n      .replace(/[ \\t]+/g, \" \")\n      .replace(/\\. ([A-Z])/g, \".\\n$1\")\n      .replace(/\\n{3,}/g, \"\\n\\n\")\n      .trim();\n  }\n\n  const blocks = esResults.map(chunk => {\n    const { chunk_id, section_title, text = \"\", metadata = {}, _score, regScore, locScore } = chunk;\n\n    // Heading\n    const title = section_title\n      ? mdEscape(section_title)\n      : `Untitled Section (${chunk_id})`;\n\n    // Build YAML metadata\n    const pages = Array.isArray(metadata.page_numbers)\n      ? metadata.page_numbers.join(\", \")\n      : metadata.page_numbers || \"Unknown\";\n\n    const metaLines = [\n      `filename: ${metadata.filename || \"Unknown Document\"}`,\n      `pages: ${pages}`,\n      `score: ${_score.toFixed(2)}`,\n    ];\n    if (typeof regScore === \"number\") metaLines.push(`regScore: ${regScore.toFixed(2)}`);\n    if (typeof locScore === \"number\") metaLines.push(`locScore: ${locScore.toFixed(2)}`);\n    if (metadata.document_type) metaLines.push(`type: ${metadata.document_type}`);\n    if (metadata.languages) metaLines.push(`language: ${metadata.languages.join(\", \")}`);\n\n    const metaBlock = metaLines.join(\"\\n\");\n\n    // Clean and escape body\n    const body = mdEscape(cleanText(text));\n\n    return [\n      `### ${title}`,\n      \"```yaml\",\n      metaBlock,\n      \"```\",\n      \"\",\n      body\n    ].join(\"\\n\");\n  });\n\n  // Join with clear separators\n  return blocks.join(\"\\n\\n---\\n\\n\");\n}\n\n// Usage in n8n Function node:\nconst esResults = $input.all().map(i => i.json);\nconst contextForPrompt = prepareSecurityRegulatoryContextForClaude(esResults);\n\nreturn [{ json: { context: contextForPrompt } }];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1020,
        5620
      ],
      "id": "9f6e367b-4f97-4c8d-b5fb-b3cdb23b49a7",
      "name": "Prepare Context5"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ $json.userPrompt }}",
        "hasOutputParser": true,
        "options": {
          "systemMessage": "={{ $json.systemPrompt }}"
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.9,
      "position": [
        -600,
        5620
      ],
      "id": "4600f9df-4aa2-42f2-ba84-60bd89b998b8",
      "name": "Get Techstack"
    },
    {
      "parameters": {
        "jsCode": "/**\n * n8n Function node\n * Input  : first item from the previous “tech-stack agent” node\n *          {\n *            output: {\n *              tech_stack: { ... }\n *            }\n *          }\n * Output : { detectedTechStackSnippet: '### DETECTED_TECH_STACK …' }\n */\n\nconst { tech_stack } = $input.first().json.output || {};\n\n// --- Sanity check ----------------------------------------------------------\nif (!tech_stack || typeof tech_stack !== 'object') {\n  throw new Error('Expected output.tech_stack object from previous step.');\n}\n\n// --- Build the snippet -----------------------------------------------------\nconst detectedTechStackSnippet = [\n  '### DETECTED_TECH_STACK (authoritative, extracted in a prior step)',\n  JSON.stringify(tech_stack, null, 2),  // pretty-printed JSON\n  '',\n  'Treat this \"tech_stack\" as the baseline when refining or merging technology recommendations in the next step.',\n].join('\\n');\n\n// --- Return for the next node ---------------------------------------------\nreturn [\n  {\n    json: {\n      detectedTechStackSnippet,\n    },\n  },\n];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -140,
        5620
      ],
      "id": "6acf962d-b3da-4a97-8983-3eb61e3fed6a",
      "name": "Techstack Output"
    },
    {
      "parameters": {
        "jsCode": "// 2. Format the context\nconst contextForPrompt = $input.first().json.context;\nconst systemPrompt = `You are a precise assistant that extracts structured JSON outputs from project documents such as RFPs. Your goal is to identify the likely technology stack, architecture, and rationale based on retrieved excerpts.\nStick to realistic and commonly used technologies. Favor inference from context over guessing. Output must be a valid JSON object inside the key \"tech_stack\". Do not explain anything outside the JSON object.`;\nconst platforms = $('Platforms Output').first().json.detectedPlatformsSnippet;\n\n// 3. Define the user prompt\nconst userPrompt = `\nYou are analyzing excerpts from an RFP to determine what technology stack is required or recommended.\n\n### CONTEXT:\n${contextForPrompt}\n\n${platforms}\n\n### TASK:\nExtract a realistic tech stack and architectural context, based on explicit mentions and inferred needs (e.g., admin portals, mobile apps, cloud hosting, dashboards, integrations, or AI features).\nInfer likely technologies based on phrases like \"responsive admin portal\", \"CRM integration\", \"CMS recommendation\", \"training\", or \"case studies\", even if specific tools aren't named.\n\nUse this **strict output format**. Do not include any explanations or text outside the JSON:\n\n{\n  \"tech_stack\": {\n    \"web_stack\": [\"React\", \"Vue\", \"Angular\"],\n    \"design\": [\"Shadcn\", \"Material UI\", \"Custom\"],\n    \"mobile_stack\": [\"Flutter\", \"Swift\", \"Kotlin\"],\n    \"backend_stack\": [\"Node.js\", \"Java\", \"Python\"],\n    \"ai_needed\": true,\n    \"database\": \"PostgreSQL\",\n    \"deployment\": \"cloud\",\n    \"integrations\": [\"OAuth\", \"SAML\", \"third-party APIs\"],\n    \"stack_model\": \"fullstack\",\n    \"rationale\": \"Why this tech stack is appropriate for this project\"\n  }\n}\n\n### If the context lacks details:\n- Default \"web_stack\": [\"React\", \"Next.js\"]\n- Default \"backend_stack\": [\"PHP\"]\n- Default \"mobile_stack\": [\"Flutter\"]\n- Default \"design\": [\"Shadcn\"] if admin-heavy or visual design is unspecified\n- Default \"database\": \"PostgreSQL\"\n- Default \"deployment\": \"AWS\"\n- Leave \"integrations\": [] if unclear\n- Set \"stack_model\": \"fullstack\" only if frontend and backend are clearly aligned\n- Provide a short \"rationale\" based on your reasoning, even if based on defaults\n- Only include stacks for the platforms listed in DETECTED_PLATFORMS.\n  • If \"mobile apps\" is absent, leave \"mobile_stack\": [].\n  • If \"admin portals or dashboards\" is present, always pick a design system (Shadcn, Material-UI, etc.).\n- The rationale must mention how the detected platforms informed any defaults.\n\n### Additional industry-standard heuristics (apply only when relevant):\n\n#### Architecture & stack model\n- If the RFP calls for an easily editable marketing site or “blog / insights” section but does not name a tech:\n  - \"web_stack\": [\"React\", \"Next.js\"]\n  - \"backend_stack\": [\"Node.js\"]           # serves API routes or SSR\n  - \"database\": \"PostgreSQL\"\n  - \"integrations\": [\"Strapi\", \"Sanity\", \"Contentful\", \"Hygraph\"]    # pick one if context hints; otherwise leave empty\n  - \"stack_model\": \"separated\"            # front-end decoupled from CMS API\n  - Rationale must note: “Headless CMS + React/Next.js chosen for modern JAMstack workflow, easy content editing, and superior performance over monolithic WordPress.”\n\n\n- If the domain is finance / high-compliance and no tech is named:\n  - Prefer \"backend_stack\": [\"Java\", \"Spring Boot\"] or [\".NET\"]\n  - Mention compliance suitability in the rationale.\n\n- If real-time / microservice wording appears (“event-driven”, “low latency”):\n  - Include \"Node.js\" or \"Go\" plus \"Redis\" for caching in backend/database.\n\n#### Deployment & infrastructure\n- If EU data residency is required but the cloud is not named:\n  - Use \"deployment\": \"AWS (eu-central-1)\" or \"Azure (West Europe)\".\n  - Note GDPR residency in the rationale.\n\n- If elasticity / sudden traffic spikes are emphasised:\n  - Append \"serverless\" or \"containerized (Docker/Kubernetes)\" to deployment.\n\n#### Mobile & front-end\n- If native device features are stressed (camera, sensors, AR):\n  - Set \"mobile_stack\": [\"Swift\", \"Kotlin\"] and explain native perf in rationale.\n\n- If WCAG or strict design consistency is called out:\n  - Use \"design\": [\"Material UI\"] and mention accessibility benefits.\n\n#### Data & AI\n- If analytics dashboards or BI tooling are noted:\n  - Add \"Snowflake\" or \"BigQuery\" alongside \"PostgreSQL\".\n\n- Keep \"ai_needed\": false by default, but:\n  - If terms like \"chatbot\", \"predictive\", \"NLP\", or \"personalization\" appear, set to true and add \"OpenAI\" or \"Azure AI\" to integrations.\n\n#### Integrations\n- If \"CRM\", \"ERP\", or \"SSO\" appears anywhere:\n  - Always include \"REST APIs\" in integrations.\n  - If SSO keywords (\"SAML\", \"OAuth\", \"Okta\", \"Keycloak\") appear, list them explicitly.\n\n#### Rationale formatting\n- Begin the rationale with **Extracted:** or **Inferred:** to signal origin.\n- Keep the rationale ≤ 400 words.\n\n`;\n\n\nreturn {\n  json: {\n    userPrompt,\n    systemPrompt: systemPrompt\n  }\n};\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1180,
        5860
      ],
      "id": "abff8b57-42c0-4993-a831-55d645a296c0",
      "name": "PreparePrompts9"
    },
    {
      "parameters": {
        "jsonSchemaExample": "{\n  \"features\": \n\t\t[\n  {\n    \"title\": \"Title\",\n    \"description\": \"Clear and specific requirement\",\n    \"reference_section\":\"\"\n  }\n]\n}"
      },
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "typeVersion": 1.2,
      "position": [
        1060,
        4880
      ],
      "id": "a9ddad2d-2e1d-495a-96ea-266db9313e91",
      "name": "Title + Desc + Section"
    },
    {
      "parameters": {
        "jsonSchemaExample": "{\n  \"features\": \n\t\t[\n  {\n    \"title\": \"Title\",\n    \"description\": \"Clear and specific requirement\"\n  }\n]\n}"
      },
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "typeVersion": 1.2,
      "position": [
        1180,
        4880
      ],
      "id": "95c6444b-5ab9-4952-937e-0fe9a0cda406",
      "name": "Description"
    },
    {
      "parameters": {
        "jsonSchemaExample": "[\n  {\n    \"title\": \"Brief requirement title\",\n    \"description\": \"Exact or paraphrased requirement statement\",\n    \"category\": \"Performance | Availability | Security | ...\",\n    \"rationale\": \"Why this is an NFR and chosen category\",\n    \"reference_section\": \"2.3\"\n  }\n]"
      },
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "typeVersion": 1.2,
      "position": [
        -2980,
        5800
      ],
      "id": "5ebb4a45-c4c1-471a-8674-bb11c93614a3",
      "name": "Full"
    },
    {
      "parameters": {
        "jsonSchemaExample": "[\n  {\n    \"title\": \"Title\",\n    \"description\": \"Exact or paraphrased requirement statement\",\n    \"category\": \"Performance | Availability | Security | ...\"\n  }\n]"
      },
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "typeVersion": 1.2,
      "position": [
        -2880,
        5800
      ],
      "id": "88361ebf-42d0-4750-bf63-e0680536b9ad",
      "name": "Description + Category"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "gpt-4.1-mini",
          "mode": "list",
          "cachedResultName": "gpt-4.1-mini"
        },
        "options": {
          "temperature": 0.1
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        -2420,
        5760
      ],
      "id": "e0a86aa3-7762-4ee5-830f-dcab0dd687a0",
      "name": "OpenAI Chat Model6",
      "credentials": {
        "openAiApi": {
          "id": "M8xqWvEC6mH6LNuk",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=You are analyzing two sets of extracted software project requirements from an RFP.\n\n{{ $('Functional Requirements Output').first().json.featureListSnippet }}\n\n{{ $json.nonFunctionalRequirementsSnippet }}\n\nInstructions:\n- Preserve the Functional Requirements exactly as they are.\n- From the Non-Functional list, remove any item that overlaps in meaning with the Functional list.\n- Deduplicate by meaning, not exact wording.\n- Reclassify each item as either:\n  - \"Functional\"\n  - \"Non-Functional\"\n\nDo not include commentary, markdown, or headings — return only the raw JSON.\n",
        "hasOutputParser": true,
        "options": {
          "systemMessage": "=You are a precise and structured assistant that consolidates software project requirements.\n\nYou will receive two sets of input:\n- Functional Requirements: what the system must do (e.g., user features, system behaviors)\n- Non-Functional Requirements: how the system must behave (e.g., performance, security, usability)\n\nYour task is to:\n- Preserve all Functional Requirements exactly as given.\n- From the Non-Functional Requirements, exclude anything that overlaps with the Functional list (based on intent).\n- Classify each requirement under \"Functional\" or \"Non-Functional\".\n- Ensure phrasing is specific, unambiguous, and clean.\n- Return a single valid JSON object with this structure:\n\nEach item must include:\ntitle: Short summary\ndescription: Specific requirement\n\nDo not omit meaningful content. Do not return explanations."
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.9,
      "position": [
        -2360,
        5560
      ],
      "id": "c792a852-5606-4f1a-94f9-a8e610354548",
      "name": "Combine Requirements"
    },
    {
      "parameters": {
        "jsonSchemaExample": "[\n  {\n    \"functional\": [\n      {\n        \"title\": \"Short title\",\n        \"description\": \"Detailed and unambiguous requirement\"\n      }\n    ],\n    \"non_functional\": [\n      {\n        \"title\": \"Security Captcha on Admin Login\",\n        \"description\": \"Login to admin panel must include CAPTCHA and CSRF protection.\"\n      }\n    ]\n  }\n]\n"
      },
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "typeVersion": 1.2,
      "position": [
        -2200,
        5780
      ],
      "id": "c5df66c4-c4c9-4c26-853b-72f8724caea9",
      "name": "Structured Output Parser"
    },
    {
      "parameters": {
        "jsCode": "/**\n * n8n Function Node — \"Build Combined Requirements Snippet\"\n *\n * Input shape:\n * [\n *   {\n *     output: [\n *       {\n *         functional: [ { title, description }, ... ],\n *         non_functional: [ { title, description }, ... ]\n *       }\n *     ]\n *   }\n * ]\n *\n * Output shape:\n * {\n *   combinedRequirementsSnippet: '### COMBINED_REQUIREMENTS …'\n * }\n */\n\n// --- Grab input safely -----------------------------------------------------\nconst input = $input.first().json.output?.[0] || {};\nconst functional = input.functional || [];\nconst nonFunctional = input.non_functional || [];\n\n// --- Basic validation ------------------------------------------------------\nif (!Array.isArray(functional) || !Array.isArray(nonFunctional)) {\n  throw new Error('Expected arrays for functional and non_functional requirements.');\n}\n\n// --- Build the snippet -----------------------------------------------------\nconst combinedRequirementsSnippet = [\n  '### FUNCTIONAL AND NON-FUNCTIONAL REQUIREMENTS (authoritative, merged functional and non-functional set)',\n  JSON.stringify({ functional, non_functional: nonFunctional }, null, 2),\n  '',\n  'Treat this merged list as the unified scope for all downstream steps including tech stack reasoning, risk estimation, and delivery planning.'\n].join('\\n');\n\n// --- Return for downstream use --------------------------------------------\nreturn [\n  {\n    json: {\n      combinedRequirementsSnippet\n    }\n  }\n];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1960,
        5560
      ],
      "id": "9c1802fa-346b-4903-aeba-5b07917e7a54",
      "name": "Combined Requirements Output"
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "dcf9995f-4f13-4062-b2c0-33e0b2efe3e2",
              "name": "regulatoryComplianceSnippet",
              "value": "={{ $('Regulatory Output').first().json.regulatoryComplianceSnippet }}",
              "type": "string"
            },
            {
              "id": "90bbc7e2-ad05-415d-b809-0d8fd7b04d26",
              "name": "projectClassificationSnippet",
              "value": "={{ $('GreenField Output').first().json.projectClassificationSnippet }}",
              "type": "string"
            },
            {
              "id": "71534caa-3f18-4edd-bd5d-83212d7e8ccf",
              "name": "deliveryRequirementsSnippet",
              "value": "={{ $('Delivery Context Ouput').first().json.deliveryRequirementsSnippet }}",
              "type": "string"
            },
            {
              "id": "deddcdb1-5bc5-47e1-8a5c-4c02fb0e9ca8",
              "name": "rfpMetadataSnippet",
              "value": "={{ $('General Info Output').first().json.rfpMetadataSnippet }}",
              "type": "string"
            },
            {
              "id": "2eb926dc-6f8b-4145-a627-2a699038399a",
              "name": "detectedPlatformsSnippet",
              "value": "={{ $('Platforms Output').first().json.detectedPlatformsSnippet }}",
              "type": "string"
            },
            {
              "id": "224cb69c-4a9f-4228-a215-25531d77b261",
              "name": "combinedRequirementsSnippet",
              "value": "={{ $json.combinedRequirementsSnippet }}",
              "type": "string"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        -1740,
        5560
      ],
      "id": "26679a79-8e60-4ae5-830e-00964cc8ce64",
      "name": "Dependencies1"
    },
    {
      "parameters": {
        "content": "## Combined Requirements\n",
        "height": 900,
        "width": 900
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        -2520,
        5140
      ],
      "id": "b04c504e-27a6-4d65-87ca-c7f7c2069fc6",
      "name": "Sticky Note1"
    },
    {
      "parameters": {
        "jsonSchemaExample": "{\n  \"team_plan\": {\n    \"roles\": [\n      { \"role\": \"Product Owner\", \"fte\": 1.0, \"rationale\": \"≤ 200 words explaining the decisions.\" },\n      { \"role\": \"Scrum Master\", \"fte\": 0.5, \"rationale\": \"≤ 200 words explaining the decisions.\" }\n    ],\n    \"rationale\": \"≤ 200 words explaining the decisions.\"\n  }\n}"
      },
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "typeVersion": 1.2,
      "position": [
        800,
        5740
      ],
      "id": "94a3e1c2-0484-461c-b1b8-6a3b8df9a30b",
      "name": "Team Composition1"
    },
    {
      "parameters": {
        "content": "## Team Compositon\n",
        "height": 860,
        "width": 1140,
        "color": 4
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        -20,
        5180
      ],
      "id": "f7ec4f0a-00a3-4368-b362-6abfd8fb5fee",
      "name": "Sticky Note3"
    },
    {
      "parameters": {
        "jsCode": "/**\n * n8n Function node\n * Input  : first item from the previous “Team-Composition” LLM step\n * Output : { teamCompositionSnippet: '### TEAM_COMPOSITION …' }\n */\n\nconst team_plan = $input.first().json.output?.team_plan;\n\nif (!team_plan || typeof team_plan !== 'object') {\n  throw new Error('Expected output.team_plan object from previous step.');\n}\n\nconst teamCompositionSnippet = [\n  '### TEAM_COMPOSITION (authoritative, extracted in a prior step)',\n  JSON.stringify(team_plan, null, 2),\n  '',\n  'Treat this team structure as a baseline for effort, duration, and cost calculations downstream.'\n].join('\\n');\n\nreturn [\n  {\n    json: {\n      teamCompositionSnippet,\n    },\n  },\n];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1180,
        5860
      ],
      "id": "ee8fef6a-8655-4e1c-96c0-b8dec08978f6",
      "name": "Team Composition Output"
    },
    {
      "parameters": {
        "content": "## RISKS\n",
        "height": 740,
        "width": 1340,
        "color": 6
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        -4460,
        6180
      ],
      "id": "b5c4bd58-d2af-4ff9-bfe7-ab13b7086616",
      "name": "Sticky Note12"
    },
    {
      "parameters": {
        "jsonSchemaExample": "{\n\t\"min_sprints\": 0,\n\t\"max_sprints\": 0,\n    \"rationale\":\"\"\n}"
      },
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "typeVersion": 1.2,
      "position": [
        -3500,
        8160
      ],
      "id": "7406efe8-87a2-4160-a386-dba697773ba7",
      "name": "Greenfield + Rationale"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "gpt-4.1",
          "mode": "list",
          "cachedResultName": "gpt-4.1"
        },
        "options": {
          "temperature": 0.1
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        -3700,
        8180
      ],
      "id": "d8fad0f8-2f49-40f1-800d-8d5bf4085077",
      "name": "GPT 4.1 Mini4",
      "credentials": {
        "openAiApi": {
          "id": "M8xqWvEC6mH6LNuk",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "const snippets = [\n  $('Dependencies').first().json.regulatoryComplianceSnippet,\n  $('Dependencies').first().json.combinedRequirementsSnippet,\n  $('Dependencies').first().json.projectClassificationSnippet,\n  $('Dependencies').first().json.deliveryRequirementsSnippet,\n  $('Dependencies').first().json.detectedTechStackSnippet,\n  $('Dependencies').first().json.teamCompositionSnippet,\n  $input.first().json.riskRegisterSnippet\n].join('\\n\\n');\n\nconst systemPrompt = `\nYou are a senior delivery strategist estimating agile effort for software projects.\nYour goal is to output a realistic 2-week sprint range (min to max) based on high-level scope and delivery context.\nAlways assume:\n• Optimal AI-assisted development using modern tooling (AI pair programming, codegen, automated testing)\n• A capable cross-functional team with each developer delivering 15 story points per sprint\n• High delivery velocity without unnecessary padding\nYour output must be a valid JSON object under the key \"sprint_estimate\". Do not include any other text or formatting.\n`;\n\nconst userPrompt = `\nBelow are structured excerpts that describe the project context:\n\n${snippets}\n\nTASK:\n1. Estimate the number of 2-week sprints needed to implement the full scope (MVP).\n2. Return:\n   - \"min_sprints\": lower-bound estimate\n   - \"max_sprints\": upper-bound estimate\n   - \"rationale\": a short explanation (< 700 characters)\n\nESTIMATION RULES:\n• Narrow the sprint range if the scope is well-defined and straightforward.\n• Consider the number of developers, assuming they can work in parallel on the same tech stack or domain area.\n• Use a broader range when there are significant risks (e.g. vague NFRs, unclear integrations, or regulatory complexity).\n• Exclude wide buffers, discovery work, and post-launch support.\n• Only estimate the implementation phase (from kick-off to MVP launch).\n• Do NOT break down or estimate features individually.\n• Output must be in JSON only—no markdown, bullet points, or additional text.\n• The \"rationale\" field must clearly explain how scope, risk, and delivery dynamics affect the sprint estimate.\n\nPROJECT DURATION PRINCIPLE:\nAssume that developers and supporting roles work in parallel across their own domains.  \nHowever, the **total project duration should be anchored to the development stream that carries the most effort** (e.g., frontend-heavy projects should span as long as frontend implementation takes).  \nOther roles (e.g., backend, QA, PM) should be proportional in effort and capacity (FTE), but not dictate overall duration if they finish earlier.  \nDo not artificially serialize tasks, but reflect the true critical path of the most effort-heavy track.\n\n• For projects using a \"Heavily AI Generated\" tech stack, assume high delivery velocity and minimal risk overhead—this should reduce the lower-bound estimate.\n• If the RFP includes a fixed deadline or time budget:\n  - Suggest team composition adjustments (e.g., adding developers) to meet the timeline.\n  - Propose requirement descoping strategies (e.g., removing non-critical, high-risk features) to help fit the scope within constraints.\n  - Use this reasoning to support the “note” field in the JSON output.\n`;\n\nreturn {\n  json: {\n    systemPrompt,\n    userPrompt\n  }\n};\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -4040,
        7940
      ],
      "id": "d82a7a8f-d706-4d7e-a6c6-e6720588e960",
      "name": "Code2"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "claude-sonnet-4-20250514",
          "mode": "list",
          "cachedResultName": "Claude Sonnet 4"
        },
        "options": {
          "maxTokensToSample": 6000,
          "temperature": 0.1,
          "thinking": false
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatAnthropic",
      "typeVersion": 1.3,
      "position": [
        -3840,
        8180
      ],
      "id": "51cd375a-6b1f-47b4-b3e1-fe79f08aeb63",
      "name": "Anthropic Chat Model2",
      "credentials": {
        "anthropicApi": {
          "id": "qzCm5Ds2qD9ZY1W5",
          "name": "Anthropic account"
        }
      }
    },
    {
      "parameters": {
        "content": "## Effort Estimation\n",
        "height": 740,
        "width": 1340,
        "color": 5
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        -4440,
        7860
      ],
      "id": "a8b1b6d6-776a-4029-986b-f85dbe1c565f",
      "name": "Sticky Note13"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ $json.userPrompt }}",
        "hasOutputParser": true,
        "options": {
          "systemMessage": "={{ $json.systemPrompt }}"
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.9,
      "position": [
        -3740,
        7940
      ],
      "id": "0ab1fc8b-a9be-4454-9ee4-8bc09758634d",
      "name": "Effort Estimation"
    },
    {
      "parameters": {
        "jsCode": "/**\n * n8n Function node\n * Input  : first item from the previous “Risk Analysis” step\n * Output : { riskRegisterSnippet: '### RISK_REGISTER …' }\n */\n\nconst risks = $input.first().json.output?.risks;\n\nif (!Array.isArray(risks) || risks.length === 0) {\n  throw new Error('Expected output.risks array from previous step.');\n}\n\nconst riskRegisterSnippet = [\n  '### RISK_REGISTER (authoritative, extracted in a prior step)',\n  JSON.stringify(risks, null, 2),\n  '',\n  'Treat this risk list as an input for effort ranges, contingency, and client clarification downstream.'\n].join('\\n');\n\nreturn [\n  {\n    json: {\n      riskRegisterSnippet,\n    },\n  },\n];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -3060,
        6440
      ],
      "id": "ac333363-ba38-4253-8dde-b662d0729d85",
      "name": "Risks Output"
    },
    {
      "parameters": {},
      "type": "@n8n/n8n-nodes-langchain.toolCalculator",
      "typeVersion": 1,
      "position": [
        -3600,
        8180
      ],
      "id": "6b5305ec-8314-4138-a1b5-cd60ea4cd882",
      "name": "Calculator"
    },
    {
      "parameters": {
        "jsonSchemaExample": "{\n  \"phases\": [\n    {\n      \"name\": \"Planning and Foundation\",\n      \"sprints\": { \"start\": 1, \"end\": 2 },\n      \"items\": [\n        \"Set up environments and CI/CD pipeline\",\n        \"Define architecture and technical frameworks\",\n        \"Implement user authentication and role system\"\n      ]\n    },\n    {\n      \"name\": \"Core Development\",\n      \"sprints\": { \"start\": 3, \"end\": 6 },\n      \"items\": [\n        \"Develop mission system and rewards engine\",\n        \"Integrate forest visualization and topic feed\"\n      ]\n    }\n  ],\n  \"cross_cutting\": {\n    \"infrastructure\": [ \"CI/CD setup\", \"VPN access configuration\" ],\n    \"security\": [ \"Access control\", \"Penetration testing\" ],\n    \"testing\": [ \"Unit testing\", \"UAT\" ],\n    \"documentation\": [ \"API documentation\", \"User guides\" ],\n    \"deployment\": [ \"Staging environment\", \"Production rollout\" ]\n  }\n}"
      },
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "typeVersion": 1.2,
      "position": [
        -2280,
        8300
      ],
      "id": "bc02fa77-7a2a-4bbb-866d-3e946bb89379",
      "name": "Greenfield + Rationale3"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "gpt-4.1",
          "mode": "list",
          "cachedResultName": "gpt-4.1"
        },
        "options": {
          "temperature": 0.3
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        -2520,
        8300
      ],
      "id": "34be5314-5180-4042-b240-df772902ddb2",
      "name": "GPT 4.1 Mini5",
      "credentials": {
        "openAiApi": {
          "id": "M8xqWvEC6mH6LNuk",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "const snippets = [\n  $('Dependencies').first().json.combinedRequirementsSnippet,\n  $('Dependencies').first().json.deliveryRequirementsSnippet,\n  $('Dependencies').first().json.teamCompositionSnippet,\n  $input.first().json.effortEstimationSnippet\n].join('\\n\\n');\n\nconst systemPrompt = `\nYou are a senior technical project planner and agile delivery strategist. You design high-level sprint-based development plans for software projects based on known scope and estimated duration.\nYou always:\n- Organize the plan into clear sprint phases\n- Include key delivery activities per phase\n- Address cross-cutting themes like infrastructure, testing, and security\n- Avoid repeating or re-estimating effort\n`;\n\nconst userPrompt = `\nBelow are structured excerpts that describe the project context:\n\n${snippets}\n\nYour task:\n- Do not include discovery phase\n- Take into consideration the optimal AI Assisted Development and setup for that\n- Consider the number of developers, assuming they can work in parallel on the same tech stack or domain area.\n- Use the \"min_sprints\" and \"max_sprints\" from the effort estimation as the timeline range.\n- Assume Agile 2-week sprints.\n1. Create a high-level **sprint-based development plan** that aligns with the estimated duration.\n2. Organize the plan into **semantically labeled phases** based on common delivery flow, such as:\n   - \"Setup and Foundation\"\n   - \"Core Development\"\n   - \"Feature Completion and Polishing\"\n   - \"Finalization and Handover\"\n3. For each phase, include:\n   - A \"name\" (semantic label as described)\n   - A \"sprints\" object with \"start\" and \"end\" sprint numbers\n   - A list of \"items\" representing deliverables, feature groups, or technical milestones\n\n4. Also provide a \"cross_cutting\" section with grouped items under:\n   - \"infrastructure\"\n   - \"security\"\n   - \"testing\"\n   - \"documentation\"\n   - \"deployment\"\nAvoid generic items. Make cross-cutting work as concrete and contextualized as possible (e.g. “Configure Firebase Analytics for event tracking” under analytics).\nYou must not re-estimate effort. Use the sprint range provided.\n\n`;\n\nreturn {\n  json: {\n    systemPrompt,\n    userPrompt\n  }\n};\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -2800,
        8080
      ],
      "id": "c42c7816-8039-428a-9e21-d258f42ab765",
      "name": "Code3"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "claude-sonnet-4-20250514",
          "mode": "list",
          "cachedResultName": "Claude Sonnet 4"
        },
        "options": {
          "maxTokensToSample": 6000,
          "temperature": 0.3,
          "thinking": false
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatAnthropic",
      "typeVersion": 1.3,
      "position": [
        -2640,
        8300
      ],
      "id": "911a24fe-e555-4e8c-baf0-3c74f6aeb1f6",
      "name": "Anthropic Chat Model3",
      "credentials": {
        "anthropicApi": {
          "id": "qzCm5Ds2qD9ZY1W5",
          "name": "Anthropic account"
        }
      }
    },
    {
      "parameters": {
        "content": "## Development Plan\n",
        "height": 740,
        "width": 1340,
        "color": 6
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        -2840,
        7860
      ],
      "id": "6eec7502-5450-4fe8-b57a-b4470b1c2060",
      "name": "Sticky Note14"
    },
    {
      "parameters": {},
      "type": "@n8n/n8n-nodes-langchain.toolCalculator",
      "typeVersion": 1,
      "position": [
        -2400,
        8300
      ],
      "id": "dc770ec0-edf2-4c2f-8c5f-a3e0a40e09b2",
      "name": "Calculator1"
    },
    {
      "parameters": {
        "jsCode": "/**\n * n8n Function node\n * Input  : first item from the previous “Effort Estimation” LLM step\n * Output : { effortEstimationSnippet: '### EFFORT_ESTIMATION …' }\n */\n\nconst effort = $input.first().json.output;\n\nif (!effort || typeof effort !== 'object') {\n  throw new Error('Expected output object with min_sprints, max_sprints, rationale, and discovery_steps.');\n}\n\nconst effortEstimationSnippet = [\n  '### EFFORT_ESTIMATION (authoritative, generated in prior step)',\n  JSON.stringify(effort, null, 2),\n  '',\n  'Treat this sprint range and rationale as the base reference for downstream cost, buffer, and delivery planning.'\n].join('\\n');\n\nreturn [\n  {\n    json: {\n      effortEstimationSnippet,\n    },\n  },\n];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -3040,
        7940
      ],
      "id": "c1d910d6-ea92-49df-9fa6-818d69fb9562",
      "name": "Effort Estimate Output"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ $json.userPrompt }}",
        "hasOutputParser": true,
        "options": {
          "systemMessage": "={{ $json.systemPrompt }}"
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.9,
      "position": [
        -2580,
        8040
      ],
      "id": "632a423e-504b-45a4-a4e5-7dfde32f26e3",
      "name": "Development Plan"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://sse-estimation-tool.onrender.com/progress",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"step\": \"file_upload\",\n  \"title\": \"Step 1: File Uploaded\",\n  \"output\": \"Only scope\",\n  \"sessionId\": \"{{ $json.body.sessionId }}\"\n}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -3800,
        8680
      ],
      "id": "7c6bace5-067d-444f-8267-1a2060dae7f5",
      "name": "file_upload1"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://sse-estimation-tool.onrender.com/progress",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"step\": \"data_extraction\",\n  \"title\": \"Step 3: Data Extracted\",\n  \"output\": \"Data Extracted\",\n  \"sessionId\": \"{{ $('RFP Upload1').item.json.body.sessionId }}\"\n}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -2920,
        8680
      ],
      "id": "470ed343-5222-4c0a-aa84-f71542297f23",
      "name": "data_extraction1"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://sse-estimation-tool.onrender.com/progress",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"step\": \"scope_analysis\",\n  \"title\": \"Step 4: Scope Analysis\",\n  \"output\": \"Scope Analysed\",\n  \"sessionId\": \"{{ $('RFP Upload1').item.json.body.sessionId }}\"\n}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -2480,
        8680
      ],
      "id": "3d12c791-7e05-4ce7-822c-0ddca693c72d",
      "name": "scope_analysis1"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://sse-estimation-tool.onrender.com/progress",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"step\": \"effort_estimation\",\n  \"title\": \"Step 5: Effort Estimation\",\n  \"output\": \"Effort Estimation\",\n  \"sessionId\": \"{{ $('RFP Upload1').item.json.body.sessionId }}\"\n}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -2040,
        8680
      ],
      "id": "c520d707-cf9f-410c-9dc5-fe8abcb18d02",
      "name": "effort_estimation1"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://sse-estimation-tool.onrender.com/progress",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"step\": \"team_composition\",\n  \"title\": \"Step 6: Team Composition\",\n  \"output\": \"Team Composition\",\n  \"sessionId\": \"{{ $('RFP Upload1').item.json.body.sessionId }}\"\n}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -1600,
        8680
      ],
      "id": "32c0ec4a-dd0d-4bf8-b4c5-3ede0fcb253f",
      "name": "team_composition1"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://sse-estimation-tool.onrender.com/progress",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"step\": \"development_plan\",\n  \"title\": \"Step 7: Development Plan\",\n  \"output\": \"Development Plan\",\n  \"sessionId\": \"{{ $('RFP Upload1').item.json.body.sessionId }}\"\n}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -1160,
        8680
      ],
      "id": "f875215b-bff0-4685-916b-fa0a979eca40",
      "name": "development_plan1"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://sse-estimation-tool.onrender.com/progress",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"step\": \"final_report\",\n  \"title\": \"Step 8: Final Report\",\n  \"output\": \"Final Report\",\n  \"sessionId\": \"{{ $('RFP Upload1').item.json.body.sessionId }}\"\n}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -720,
        8680
      ],
      "id": "3d6d7b07-ba80-4737-9a12-919bd6e64bb1",
      "name": "final_report1"
    },
    {
      "parameters": {
        "amount": 3,
        "path": "1ef1dede-c86d-4329-b82e-0e19f48f8a31"
      },
      "type": "n8n-nodes-base.wait",
      "typeVersion": 1.1,
      "position": [
        -3580,
        8680
      ],
      "id": "c1beb31a-90da-494c-9bd1-f6baacf4ba92",
      "name": "Wait",
      "webhookId": "1ef1dede-c86d-4329-b82e-0e19f48f8a31"
    },
    {
      "parameters": {
        "amount": 3,
        "path": "eff79f77-cf85-4edf-8503-9378af4eea88"
      },
      "type": "n8n-nodes-base.wait",
      "typeVersion": 1.1,
      "position": [
        -3140,
        8680
      ],
      "id": "e878881e-4137-4f88-982b-bd96c31cf876",
      "name": "Wait1",
      "webhookId": "eff79f77-cf85-4edf-8503-9378af4eea88"
    },
    {
      "parameters": {
        "amount": 3,
        "path": "14042787-0e14-4973-a308-9b213d2f86df"
      },
      "type": "n8n-nodes-base.wait",
      "typeVersion": 1.1,
      "position": [
        -2700,
        8680
      ],
      "id": "f66b21fd-618b-4e1f-ac38-57319bb2f29a",
      "name": "Wait2",
      "webhookId": "14042787-0e14-4973-a308-9b213d2f86df"
    },
    {
      "parameters": {
        "amount": 3,
        "path": "c26e2471-90ed-498f-a0d7-81315693c512"
      },
      "type": "n8n-nodes-base.wait",
      "typeVersion": 1.1,
      "position": [
        -2260,
        8680
      ],
      "id": "00e9952c-fdd1-4e0b-bb33-c724b9d1ae0f",
      "name": "Wait3",
      "webhookId": "c26e2471-90ed-498f-a0d7-81315693c512"
    },
    {
      "parameters": {
        "amount": 3,
        "path": "c09514dc-56f3-44c9-8812-d284e137a359"
      },
      "type": "n8n-nodes-base.wait",
      "typeVersion": 1.1,
      "position": [
        -1820,
        8680
      ],
      "id": "5fc1a5c5-a4b6-4cd4-a77c-75bb4009f6a4",
      "name": "Wait4",
      "webhookId": "c09514dc-56f3-44c9-8812-d284e137a359"
    },
    {
      "parameters": {
        "amount": 3,
        "path": "242963c1-b06e-4696-8019-a37fa18827e6"
      },
      "type": "n8n-nodes-base.wait",
      "typeVersion": 1.1,
      "position": [
        -1380,
        8680
      ],
      "id": "f8dd2b9d-c147-41fb-89f4-3a3b0bc26095",
      "name": "Wait5",
      "webhookId": "242963c1-b06e-4696-8019-a37fa18827e6"
    },
    {
      "parameters": {
        "amount": 3,
        "path": "0304985c-adbe-40e8-9062-94f651a9be45"
      },
      "type": "n8n-nodes-base.wait",
      "typeVersion": 1.1,
      "position": [
        -940,
        8680
      ],
      "id": "3f6c72e1-23eb-4a81-b028-fb5c1f8bea24",
      "name": "Wait6",
      "webhookId": "0304985c-adbe-40e8-9062-94f651a9be45"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://sse-estimation-tool.onrender.com/progress",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"step\": \"document_preparation\",\n  \"title\": \"Step 2: Document Preparation\",\n  \"output\": \"Document Preparation\",\n  \"sessionId\": \"{{ $('RFP Upload1').item.json.body.sessionId }}\"\n}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -3360,
        8680
      ],
      "id": "48b9ba90-84d2-43b0-8d54-118f0b5233d8",
      "name": "document_preparation1"
    },
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "ad924962-446e-4e5e-b3b1-bb693b249ba5",
        "options": {}
      },
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 2,
      "position": [
        -4280,
        8680
      ],
      "id": "1cffe066-b565-4995-ac2a-79ff3aca49b6",
      "name": "RFP Upload1",
      "webhookId": "ad924962-446e-4e5e-b3b1-bb693b249ba5",
      "disabled": true
    },
    {
      "parameters": {
        "jsCode": "const snippets = [\n  $('Dependencies').first().json.regulatoryComplianceSnippet,\n  $('Dependencies').first().json.combinedRequirementsSnippet,\n  $('Dependencies').first().json.projectClassificationSnippet,\n  $('Dependencies').first().json.deliveryRequirementsSnippet,\n  $('Dependencies').first().json.detectedTechStackSnippet,\n  $('Dependencies').first().json.teamCompositionSnippet,\n  $input.first().json.riskRegisterSnippet\n].join('\\n\\n');\n\nconst systemPrompt = `\nYou are a senior delivery strategist estimating agile effort for software projects.\nYour goal is to output a realistic 2-week sprint range (min to max) based on high-level scope and delivery context.\nAlways assume:\n• Optimal AI-assisted development using modern tooling (AI pair programming, codegen, automated testing)\n• A capable cross-functional team with each developer delivering 15 story points per sprint\n• High delivery velocity without unnecessary padding\nYour output must be a valid JSON object under the key \"sprint_estimate\". Do not include any other text or formatting.\n`;\n\nconst userPrompt = `\nBelow are structured excerpts that describe the project context:\n\n${snippets}\n\nTASK:\n1. Estimate the number of 2-week sprints needed to implement the full scope (MVP).\n2. Return:\n   - \"min_sprints\": lower-bound estimate\n   - \"max_sprints\": upper-bound estimate\n   - \"rationale\": a short explanation < 700 characters\n   - \"discovery steps\": steps that should be done in discovery to mitigate risks and reduce the buffer\n\nESTIMATION RULES:\nDiscovery is excluded from the sprint count, but provide discovery steps to reduce uncertainty\n• Narrow the sprint range if the scope is well-defined and straightforward.\n• Consider the number of developers, assuming they can work in parallel on the same tech stack or domain area.\n• Use a broader range when there are significant risks (e.g. vague NFRs, unclear integrations, or regulatory complexity).\n• Exclude wide buffers, discovery work, and post-launch support.\n• Only estimate the implementation phase (from kick-off to MVP launch).\n• Do NOT break down or estimate features individually.\n• Output must be in JSON only—no markdown, bullet points, or additional text.\n• The \"rationale\" field must clearly explain how scope, risk, and delivery dynamics affect the sprint estimate.\n• Anchor the timeline to the developer role bearing the most implementation load (e.g., frontend-heavy projects should reflect frontend effort primarily, with others scaled accordingly).\n• For projects using a \"Heavily AI Generated\" tech stack, assume high delivery velocity and minimal risk overhead—this should reduce the lower-bound estimate.\n• If the RFP includes a fixed deadline or time budget:\n  - Suggest team composition adjustments (e.g., adding developers) to meet the timeline.\n  - Propose requirement descoping strategies (e.g., removing non-critical, high-risk features) to help fit the scope within constraints.\n  - Use this reasoning to support the “note” field in the JSON output.\n`;\n\nreturn {\n  json: {\n    systemPrompt,\n    userPrompt\n  }\n};\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -4040,
        8100
      ],
      "id": "0fc9b780-1945-4b90-972e-9788de900910",
      "name": "Code4"
    },
    {
      "parameters": {
        "jsonSchemaExample": "{\n  \"effort_estimate\": {\n    \"raw_days\": 0,\n    \"ai_speedup_pct\": 0,\n    \"net_days\": 0,\n    \"min_days\": 8,\n    \"max_days\": 10,\n    \"rationale\": \"<justification of complexity, risks, and acceleration assumptions>\"\n  }\n}"
      },
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "typeVersion": 1.2,
      "position": [
        -3500,
        7480
      ],
      "id": "baff1187-07ba-4cbd-9713-f74bfce6734d",
      "name": "Greenfield + Rationale4"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "gpt-4.1",
          "mode": "list",
          "cachedResultName": "gpt-4.1"
        },
        "options": {
          "temperature": 0.1
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        -4020,
        7480
      ],
      "id": "33711a29-230a-41e3-b83a-8a7b7b46f43c",
      "name": "GPT 4.1 Mini6",
      "credentials": {
        "openAiApi": {
          "id": "M8xqWvEC6mH6LNuk",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "/**\n * Node: Build Frontend Effort Estimation Prompt\n * Purpose: Prompt a domain-specific LLM to estimate frontend sprint effort.\n * Output: { systemPrompt, userPrompt }\n */\n\nconst snippets = [\n  $('Dependencies').first().json.regulatoryComplianceSnippet,\n  $('Dependencies').first().json.combinedRequirementsSnippet,\n  $('Dependencies').first().json.projectClassificationSnippet,\n  $('Dependencies').first().json.deliveryRequirementsSnippet,\n  $('Dependencies').first().json.detectedTechStackSnippet,\n  $('Dependencies').first().json.teamCompositionSnippet,\n  $input.first().json.riskRegisterSnippet\n].join('\\n\\n');\n\n// -------------------------------------------------------\n// 2. AI-acceleration guide (frontend-specific)\n// -------------------------------------------------------\nconst aiAccelerationGuide = `\n### AI_ACCELERATION_REFERENCE\n| Front-End Project Context                                             | AI Speed-up | Why / When It Applies |\n|-----------------------------------------------------------------------|-------------|-----------------------|\n| Static / Jamstack marketing pages                                     | 60-80 %     | Figma-to-code, MDX generators, minimal JS           |\n| CRUD dashboards with design kit (Shadcn, MUI, Ant)                    | 50-70 %     | Table/form scaffolds, Zod schema codegen            |\n| Standard business SPA (auth, charts, moderate state)                  | 40-60 %     | Component reuse but still manual domain logic       |\n| Public-facing e-commerce / marketplace UI                             | 30-50 %     | SEO, payments, perf tuning reduce gains             |\n| Bespoke, motion-heavy, branded UI                                     | 20-40 %     | Custom animation & pixel-perfect work               |\n| WCAG AA/AAA & regulated industry UI                                   | 15-30 %     | Extra a11y & compliance reviews                     |\n| Real-time data-viz / high-freq dashboards                             | 10-25 %     | Manual perf profiling & WebGL/Canvas                |\n| Legacy jQuery/AngularJS → React migration                             | –10 %-+15 % | Refactor aids vs. parity testing overhead           |\n\n**Combining rules**  \n1. Select the single row that best matches the bulk of UI work.  \n2. Add *half* of any secondary trait’s midpoint; a third trait adds *one-quarter*, etc.  \n3. Cap total acceleration at **80 %**.  \n4. If a negative/low row applies (e.g., legacy migration), cap boost to that lower value.\n`;\n\n// -----------------------------------------------------------------------------\n// SYSTEM PROMPT (constant)\n// -----------------------------------------------------------------------------\nconst systemPrompt = `\nYou are a senior frontend architect estimating man-day effort for UI development.\nYour task is to produce a realistic estimate for implementing the frontend scope of a software project.\nReturn only a valid JSON object under the key \"effort_estimate\".\nDo not include any extra text or formatting.\n`;\n\n// -----------------------------------------------------------------------------\n// USER PROMPT (frontend-specific)\n// -----------------------------------------------------------------------------\nconst userPrompt = `\nBelow are structured project context snippets extracted from an RFP analysis:\n\n${snippets}\n\n### ESTIMATION_TASK\n\nYour job:\nEstimate the effort in **productive man-days** required by a single full-time frontend developer (React, Vue, etc.) to implement the UI layer.\n\nDo NOT include other roles like backend or mobile.\nOnly consider what the frontend developer must implement to satisfy the UI scope.\nUnit tests are expected with code coverage above 90%. This should add 5% to the overall cost.\n\n${aiAccelerationGuide}\n\nRules:\n- You must **mention** the applied speedup factor in the rationale.\n- **Do not** assume 0% AI assistance unless project domain strictly prohibits it.\n- If the prompt input includes “heavily AI-generated”, assume the **highest possible speedup**.\n- Use AI-assisted tooling assumptions: code generation, test scaffolding, component reuse, AI pair programming.\n- Compute **raw man-days** for a single full-time React/Next (or what is specified) developer, assuming\n   • 1 FTE = **5 productive man-days per week**.  \n   • Apply the chosen AI speed-up to produce **net man-days**.  \n\n### OUTPUT RULES\n\n• Output must be pure JSON (no markdown, no commentary).\n• Provide a **tight min–max range** (e.g. 25–30 days), unless there's meaningful uncertainty.\n• Do NOT convert this to sprints — another agent will do that downstream.\n• This is not a per-feature estimate. Think in terms of holistic workload.\n• Anchor to the UI developer’s role only — ignore backend/mobile/database work.}\n`;\n\nreturn {\n  json: {\n    systemPrompt,\n    userPrompt,\n  }\n};\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -4100,
        7240
      ],
      "id": "d275fa4d-f044-456c-a0c6-44d1d794b8cc",
      "name": "Code5"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "claude-sonnet-4-20250514",
          "mode": "list",
          "cachedResultName": "Claude Sonnet 4"
        },
        "options": {
          "maxTokensToSample": 6000,
          "temperature": 0.1,
          "thinking": false
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatAnthropic",
      "typeVersion": 1.3,
      "position": [
        -3900,
        7480
      ],
      "id": "cffbe292-eeca-4ac6-ad6f-0b26610d0528",
      "name": "Anthropic Chat Model4",
      "credentials": {
        "anthropicApi": {
          "id": "qzCm5Ds2qD9ZY1W5",
          "name": "Anthropic account"
        }
      }
    },
    {
      "parameters": {
        "content": "## Frontend Estimation\n",
        "height": 740,
        "width": 1340,
        "color": 5
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        -4500,
        7160
      ],
      "id": "02addf55-09f2-46ad-a217-a89af4c1037a",
      "name": "Sticky Note15"
    },
    {
      "parameters": {},
      "type": "@n8n/n8n-nodes-langchain.toolCalculator",
      "typeVersion": 1,
      "position": [
        -3620,
        7480
      ],
      "id": "785dfd0a-22e9-4f7f-bdba-b30a69a2d1ec",
      "name": "Calculator2"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ $json.userPrompt }}",
        "hasOutputParser": true,
        "options": {
          "systemMessage": "={{ $json.systemPrompt }}"
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.9,
      "position": [
        -3800,
        7240
      ],
      "id": "0b3781ff-9c7b-410f-8a27-9a501ce3f3d7",
      "name": "Frontend Estimation"
    },
    {
      "parameters": {},
      "type": "@n8n/n8n-nodes-langchain.toolThink",
      "typeVersion": 1,
      "position": [
        -3720,
        7480
      ],
      "id": "15e0e6cc-e1d1-4201-b303-8d04d45e6113",
      "name": "Think4"
    },
    {
      "parameters": {
        "jsCode": "/**\n * n8n Function node\n * Input  : first item from the previous domain-specific “Effort Estimation” LLM step\n * Output : { frontendEffortSnippet: '### FRONTEND_EFFORT_ESTIMATION …' }\n */\n\nconst effort = $input.first().json.output;\n\nif (\n  !effort ||\n  typeof effort !== 'object' ||\n  !('min_days' in effort) ||\n  !('max_days' in effort)\n) {\n  throw new Error('Expected output object with min_days, max_days, rationale, and acceleration_basis.');\n}\n\nconst frontendEffortSnippet = [\n  '### FRONTEND_EFFORT_ESTIMATION (authoritative, domain-specific)',\n  JSON.stringify(effort, null, 2),\n  '',\n  'This is the effort estimation for frontend development only. Use it as a partial input for aggregating total duration or converting to sprint-based planning downstream.'\n].join('\\n');\n\nreturn [\n  {\n    json: {\n      frontendEffortSnippet,\n    },\n  },\n];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -5000,
        6900
      ],
      "id": "2f51cd8a-c023-4ac3-989c-6a378fe55d4a",
      "name": "Total Effort Estimate Output"
    },
    {
      "parameters": {
        "jsonSchemaExample": "{\n  \"effort_estimate\": {\n    \"raw_days\": 0,\n    \"ai_speedup_pct\": 0,\n    \"net_days\": 0,\n    \"min_days\": 8,\n    \"max_days\": 10,\n    \"effort_estimation_rationale\": \"<justification of complexity, risks, and acceleration assumptions>\",\n    \"ai_speedup_rationale\": \"<justification of AI speedup>\"\n  }\n}"
      },
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "typeVersion": 1.2,
      "position": [
        -1740,
        6500
      ],
      "id": "e0181022-37ad-48e7-aa11-3c5dea6eac17",
      "name": "Greenfield + Rationale5"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "claude-sonnet-4-20250514",
          "mode": "list",
          "cachedResultName": "Claude Sonnet 4"
        },
        "options": {
          "maxTokensToSample": 6000,
          "temperature": 0.1,
          "thinking": false
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatAnthropic",
      "typeVersion": 1.3,
      "position": [
        -2140,
        6500
      ],
      "id": "5094817d-a200-4fbf-800a-69dbab98965d",
      "name": "Anthropic Chat Model5",
      "credentials": {
        "anthropicApi": {
          "id": "qzCm5Ds2qD9ZY1W5",
          "name": "Anthropic account"
        }
      }
    },
    {
      "parameters": {
        "content": "## Backend Estimation\n",
        "height": 1500,
        "width": 2920,
        "color": 4
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        -2740,
        6180
      ],
      "id": "3ce7ac41-0fa4-476a-9380-dbc009c17e36",
      "name": "Sticky Note16"
    },
    {
      "parameters": {},
      "type": "@n8n/n8n-nodes-langchain.toolCalculator",
      "typeVersion": 1,
      "position": [
        -1860,
        6500
      ],
      "id": "3edf6983-8699-4162-b192-d6cc808e24d2",
      "name": "Calculator3"
    },
    {
      "parameters": {},
      "type": "@n8n/n8n-nodes-langchain.toolThink",
      "typeVersion": 1,
      "position": [
        -1960,
        6500
      ],
      "id": "c17cdf82-29e5-4908-9340-c31291a066c0",
      "name": "Think5"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ $json.userPrompt }}",
        "hasOutputParser": true,
        "options": {
          "systemMessage": "={{ $json.systemPrompt }}"
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.9,
      "position": [
        -2040,
        6260
      ],
      "id": "30999fb4-ffe4-46d1-82bc-49de772913e7",
      "name": "Backend Estimation"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "gpt-4.1",
          "mode": "list",
          "cachedResultName": "gpt-4.1"
        },
        "options": {
          "temperature": 0.1
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        -2260,
        6500
      ],
      "id": "84fbed17-8735-4fe7-9866-fd70f58c6dd8",
      "name": "GPT 4.1",
      "credentials": {
        "openAiApi": {
          "id": "M8xqWvEC6mH6LNuk",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "jsonSchemaExample": "{\n  \"effort_estimate\": {\n    \"raw_days\": 0,\n    \"ai_speedup_pct\": 0,\n    \"net_days\": 0,\n    \"min_days\": 8,\n    \"max_days\": 10,\n    \"effort_estimation_rationale\": \"<justification of complexity, risks, and acceleration assumptions>\",\n    \"ai_speedup_rationale\": \"<justification of AI speedup>\"\n  }\n}"
      },
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "typeVersion": 1.2,
      "position": [
        -600,
        6500
      ],
      "id": "9a3edf6e-c202-46cc-89d2-6c0060052366",
      "name": "Greenfield + Rationale6"
    },
    {
      "parameters": {
        "jsCode": "/**\n * Node: Build **Backend** Effort-Estimation Prompt  \n * Purpose: Ask an LLM to estimate *backend* man-day effort (PHP, Node.js, Python, etc.)  \n * Output : { systemPrompt, userPrompt }\n */\n\nconst snippets = [\n  $('Dependencies').first().json.regulatoryComplianceSnippet,\n  $('Dependencies').first().json.combinedRequirementsSnippet,\n  $('Dependencies').first().json.projectClassificationSnippet,\n  $('Dependencies').first().json.deliveryRequirementsSnippet,\n  $('Dependencies').first().json.detectedTechStackSnippet,\n  $('Dependencies').first().json.teamCompositionSnippet,\n  $('Risks Output').first().json.riskRegisterSnippet\n].join('\\n\\n');\n\n// ---------------------------------------------------------------------------\n// 1. AI-acceleration guide  (backend-specific)\n// ---------------------------------------------------------------------------\nconst aiAccelerationGuide = `\n### AI_ACCELERATION_REFERENCE\n| Backend Project Context (pick the **closest match**)                   | AI Speed-up | Why / When It Applies |\n|-------------------------------------------------------------------------|-------------|-----------------------|\n| Simple CRUD REST API with ORM & scaffolding (Symphony, Express, Nest)   | 50–70 %     | Fast code-gen, thin business logic          |\n| Standard business services (auth, RBAC, integrations)                  | 40–60 %     | Reusable libs but non-trivial flows         |\n| Event-driven / real-time pub-sub (WebSockets, queues)                  | 25–45 %     | Boilerplate exists, but perf tuning needed  |\n| Data-pipeline / ETL jobs & migration tooling                            | 15–30 %     | Mapping, cleansing, rehearsal scripts       |\n| High-compliance (finance, health) w/ audit logging & crypto             | 15–30 %     | Extra reviews, pen-testing                  |\n| Legacy monolith ➜ micro-service refactor                                | –10 % – +15 % | Refactor aids vs. parity testing overhead  |\n\n**Combining rules**  \n1. Choose the row that covers the bulk of backend work.  \n2. Add *half* of any secondary trait’s midpoint (e.g., CRUD + High-compliance).  \n3. Third trait = *one-quarter* of its midpoint.  \n4. Cap total acceleration at **80 %**; never exceed base row’s maximum if it’s negative/low.  \n`;\n\n// ---------------------------------------------------------------------------\n// 2. Optional refinements / edge-case rules\n// ---------------------------------------------------------------------------\nconst refinementRules = `\n### ADDITIONAL BACKEND-SPECIFIC RULES\n• **Data migration / ETL**  \n  – If functional scope mentions migration, include one-time scripts + rehearsal runs in **raw_days**.  \n  – AI speed-up on migration work may NOT exceed 30 %.\n\n• **Concurrency or scaling >300 TPS**  \n  – Treat as “Event-driven / real-time” even if most endpoints are CRUD-like.\n\n• **Cloud IaC requirement (Terraform / CDK / Pulumi)**  \n  – Add **+5 raw days** to cover pipeline & multi-env provisioning.\n\n• **Highly Regulated projects**  \n  – If \\`regulatory_classification.level = \"Highly Regulated\"\\` cap speed-up at the midpoint of the chosen row.\n\n• **LLM / Gen-AI endpoint wrapping**  \n  – Treat as “Integration-heavy”; no extra speed-up beyond the primary + secondary traits.\n\n• **Rounding & checksum**  \n  – Round **net_days**, **min_days**, **max_days** to whole numbers.  \n  – Add \\`\"calc_note\"\\`: “raw_days × (1 – ai_speedup_pct) × 1.05 (unit-tests) = net_days”.\n`;\n\n// ---------------------------------------------------------------------------\n// 3. System prompt\n// ---------------------------------------------------------------------------\nconst systemPrompt = `\nYou are a senior backend architect estimating man-day effort for server-side development.\nReturn **only** a valid JSON object under the key \"effort_estimate\".\nDo *not* include markdown or commentary. \n`;\n\n// ---------------------------------------------------------------------------\n// 4. User prompt\n// ---------------------------------------------------------------------------\nconst userPrompt = `\nBelow are structured project context snippets extracted from an RFP analysis:\n\n${snippets}\n\n### ESTIMATION_TASK\nEstimate the total **productive man-days** a single full-time backend developer (PHP Symfony, Node.js, Python FastAPI, etc.) will spend delivering the server-side scope.\n\n*Ignore* UI/mobile work.  \nAssume **unit tests with ≥90 % coverage** add **5 %** to raw effort.\n\n${aiAccelerationGuide}\n\n${refinementRules}\n\n#### OUTPUT RULES\n• Output JSON only.  \n• If context says **“heavily AI-generated”**, assume the **max** speed-up allowable by the table/cap.  \n• Mention all AI adjustments (migration, IaC, compliance caps) in the ai speedup ratinale rationale.\n• Mention all details about the effort estimation in the estimation rationale.\n`;\n\nreturn {\n  json: { systemPrompt, userPrompt }\n};\n\n\n\n\n\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1200,
        6260
      ],
      "id": "ca38b0ba-1123-40ed-b500-cad8bbc6e1da",
      "name": "Code7"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "claude-sonnet-4-20250514",
          "mode": "list",
          "cachedResultName": "Claude Sonnet 4"
        },
        "options": {
          "maxTokensToSample": 6000,
          "temperature": 0.1,
          "thinking": false
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatAnthropic",
      "typeVersion": 1.3,
      "position": [
        -1000,
        6500
      ],
      "id": "8465e256-6c22-4844-8caa-27560cd769d6",
      "name": "Anthropic Chat Model6",
      "credentials": {
        "anthropicApi": {
          "id": "qzCm5Ds2qD9ZY1W5",
          "name": "Anthropic account"
        }
      }
    },
    {
      "parameters": {},
      "type": "@n8n/n8n-nodes-langchain.toolCalculator",
      "typeVersion": 1,
      "position": [
        -720,
        6500
      ],
      "id": "4640d099-2603-4dc1-950b-6500306bcc58",
      "name": "Calculator4"
    },
    {
      "parameters": {},
      "type": "@n8n/n8n-nodes-langchain.toolThink",
      "typeVersion": 1,
      "position": [
        -740,
        6580
      ],
      "id": "a6d2084d-d0bb-42a6-9b41-4c75e96b62ca",
      "name": "Think6"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "gpt-4.1",
          "mode": "list",
          "cachedResultName": "gpt-4.1"
        },
        "options": {
          "temperature": 0.1
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        -1120,
        6500
      ],
      "id": "644428f5-d4e0-4dc8-8123-68d2c1c474b1",
      "name": "GPT 4.",
      "credentials": {
        "openAiApi": {
          "id": "M8xqWvEC6mH6LNuk",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ $json.userPrompt }}",
        "hasOutputParser": true,
        "options": {
          "systemMessage": "={{ $json.systemPrompt }}"
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.9,
      "position": [
        -900,
        6260
      ],
      "id": "5f57b55a-3f0a-4310-b12b-dad4da746311",
      "name": "AI Speedup Backend"
    },
    {
      "parameters": {
        "jsCode": "/**\n * Node: Build **Backend** Effort-Estimation Prompt  \n * Purpose: Ask an LLM to estimate *backend* man-day effort (PHP, Node.js, Python, etc.)  \n * Output : { systemPrompt, userPrompt }\n */\n\nconst snippets = [\n  $('Dependencies').first().json.regulatoryComplianceSnippet,\n  $('Dependencies').first().json.combinedRequirementsSnippet,\n  $('Dependencies').first().json.projectClassificationSnippet,\n  $('Dependencies').first().json.deliveryRequirementsSnippet,\n  $('Dependencies').first().json.detectedTechStackSnippet,\n  $('Dependencies').first().json.teamCompositionSnippet,\n  $('Risks Output').first().json.riskRegisterSnippet\n].join('\\n\\n');\n\nconst refinementRules = $input.first().json.refinementRules;\n\n// ---------------------------------------------------------------------------\n// 3. System prompt\n// ---------------------------------------------------------------------------\nconst systemPrompt = `\nYou are a senior backend architect estimating man-day effort for server-side development.\nReturn **only** a valid JSON object under the key \"effort_estimate\".\nDo *not* include markdown or commentary. \n`;\n\n// ---------------------------------------------------------------------------\n// 4. User prompt\n// ---------------------------------------------------------------------------\nconst userPrompt = `\nBelow are structured project context snippets extracted from an RFP analysis:\n\n${snippets}\n\n### ESTIMATION_TASK\nEstimate the total **productive man-days** a single full-time backend developer (PHP Symfony, Node.js, Python FastAPI, etc.) will spend delivering the server-side scope.\n\n*Ignore* UI/mobile work.  \nAssume **unit tests with ≥90 % coverage** add **5 %** to raw effort.\n\n\n${refinementRules}\n\n#### OUTPUT RULES\n• Output JSON only.  \n• Mention all details about the effort estimation in the estimation rationale.\n`;\n\nreturn {\n  json: { systemPrompt, userPrompt }\n};\n\n\n\n\n\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -2340,
        6260
      ],
      "id": "da54b349-fcc6-4379-b0c0-46710701e56d",
      "name": "Prompt Backend Estimation"
    },
    {
      "parameters": {
        "jsCode": "/**\n * n8n Function node\n * Output : { refinementRules }\n */\nconst refinementRules =  `\n### BACKEND EFFORT ESTIMATION RULES\n\n#### CORE ARCHITECTURE PATTERNS\n• **Microservices Architecture**  \n  – Base microservices setup (2-5 services) → add **+10 raw_days**  \n  – Complex microservices (> 5 services) → add **+20 raw_days**  \n  – Service discovery / registry required → add **+5 raw_days**\n• **Event-driven / Real-time Systems**  \n  – Base event-driven architecture → add **+15 raw_days**  \n  – If TPS > 300 → treat as event-driven even for CRUD operations\n• **Serverless Architecture**  \n  – Lambda/Functions setup → add **+8 raw_days**  \n  – Complex orchestration (Step Functions, Durable Functions) → add **+5 raw_days** more\n\n#### DATA & STORAGE\n• **Database Schema Complexity**  \n  – > 50 tables OR heavy normalization → add **+8 raw_days**  \n  – Schema reverse-engineering from legacy DB → add **+5 raw_days**  \n  – Complex queries (3-6 JOINs, CTEs) → add **+5 raw_days**  \n  – Very complex (stored procedures, triggers, views) → add **+10 raw_days**\n• **Data Migration / ETL**  \n  – One-time migration scripts → add **+10 raw_days**  \n  – Ongoing ETL pipelines → add **+15 raw_days**  \n  – Legacy data cleanup/transformation → add **+8 raw_days**\n• **Search / Full-text**  \n  – Elasticsearch, OpenSearch, Algolia → add **+5 raw_days**  \n  – Complex search with facets/aggregations → add **+3 raw_days** more\n• **Caching Layer**  \n  – Simple caching (in-memory, basic Redis) → add **+2 raw_days**  \n  – Complex caching (Redis clusters, sophisticated invalidation) → add **+6 raw_days**\n• **File Processing / Storage**  \n  – S3/Blob storage with presigned URLs → add **+3 raw_days**  \n  – Large file processing (>100MB), video/image manipulation → add **+5 raw_days**  \n  – Document parsing (PDF, Excel, Word) → add **+4 raw_days**\n\n#### AUTHENTICATION & SECURITY\n• **Authentication & SSO**  \n  – OAuth 2.0 / SAML / OIDC → add **+10 raw_days**  \n  – Custom RBAC with complex permission models → add **+8 raw_days**  \n  – Multi-factor authentication → add **+3 raw_days**\n• **API Security**  \n  – API key management system → add **+3 raw_days**  \n  – JWT with refresh tokens → add **+2 raw_days**  \n  – Certificate-based auth → add **+5 raw_days**\n• **Data Security**  \n  – Field-level encryption → add **+5 raw_days**  \n  – Data anonymization/pseudonymization pipelines → add **+4 raw_days**  \n  – GDPR compliance (right to be forgotten, data portability) → add **+6 raw_days**\n\n#### INTEGRATIONS\n• **Third-party SaaS Integrations**  \n  – Well-documented services (Stripe, Twilio, SendGrid) → add **+3 raw_days** each  \n  – Complex SaaS (Salesforce, SAP, Dynamics) → add **+5 raw_days** each  \n  – Poorly documented/proprietary services → add **+7 raw_days** each\n• **Legacy System Integration**  \n  – SOAP/XML services → add **+5 raw_days** per service  \n  – Mainframe/AS400 → add **+10 raw_days** per integration  \n  – No test environment available → add **+10 raw_days** for mock creation\n• **Payment Processing**  \n  – First payment gateway → add **+5 raw_days**  \n  – Each additional gateway → add **+2 raw_days**  \n  – PCI compliance requirements → add **+5 raw_days**\n• **Message Queuing / Event Streaming**  \n  – RabbitMQ, Kafka, AWS SQS/SNS → add **+5 raw_days**  \n  – Exactly-once delivery or complex routing → add **+3 raw_days** more  \n  – Event sourcing pattern → add **+8 raw_days**\n\n#### API & COMMUNICATION\n• **GraphQL Implementation**  \n  – Basic GraphQL API → add **+5 raw_days**  \n  – Schema stitching / federation → add **+5 raw_days** more  \n  – Real-time subscriptions → add **+3 raw_days** more\n• **WebSocket / Real-time**  \n  – Socket.io, SignalR, raw WebSockets → add **+6 raw_days**  \n  – Scaling beyond single server → add **+3 raw_days** more  \n  – Presence system / connection management → add **+4 raw_days**\n• **API Versioning**  \n  – Multiple API versions support → add **+3 raw_days**  \n  – Backward compatibility layer → add **+2 raw_days**\n• **API Gateway / Service Mesh**  \n  – Kong, Istio, AWS API Gateway → add **+5 raw_days**  \n  – Custom rate limiting, transformations → add **+3 raw_days** more\n\n#### INFRASTRUCTURE & DEVOPS\n• **Cloud IaC (Terraform/CDK/Pulumi)**  \n  – Basic IaC setup → add **+5 raw_days**  \n  – Multi-environment provisioning → add **+3 raw_days**\n• **Containerization & Orchestration**  \n  – Docker + Kubernetes/ECS → add **+7 raw_days**  \n  – Service mesh (Istio, Linkerd) → add **+5 raw_days**  \n  – Note: Don't double-count with IaC rule\n• **CI/CD Pipeline**  \n  – Basic pipeline setup → add **+3 raw_days**  \n  – Complex with multiple stages/environments → add **+5 raw_days**  \n  – GitOps approach → add **+3 raw_days** more\n• **Observability & Monitoring**  \n  – Prometheus/Grafana or ELK/Splunk → add **+4 raw_days**  \n  – Distributed tracing (Jaeger, Zipkin) → add **+3 raw_days**  \n  – Custom dashboards and alerts → add **+2 raw_days**\n\n#### PERFORMANCE & SCALING\n• **High Performance Requirements**  \n  – Strict SLA (95th percentile latency) → add **+4 raw_days**  \n  – Load testing infrastructure → add **+3 raw_days**  \n  – Performance optimization phase → add **+5 raw_days**\n• **Multi-Tenant Architecture**  \n  – Tenant isolation at DB level → add **+6 raw_days**  \n  – Row-level security → add **+4 raw_days**  \n  – Tenant-specific customization → add **+5 raw_days**\n• **Rate Limiting & Throttling**  \n  – Per API key/tenant limits → add **+3 raw_days**  \n  – Complex quota management → add **+2 raw_days** more\n• **Disaster Recovery**  \n  – Basic backup/restore → add **+3 raw_days**  \n  – RPO ≤ 15 min OR multi-region failover → add **+7 raw_days**  \n  – Active-active setup → add **+10 raw_days**\n\n#### BUSINESS LOGIC COMPLEXITY\n• **Complex Domain Logic**  \n  – Rule engines → add **+10 raw_days**  \n  – Pricing calculators → add **+8 raw_days**  \n  – Workflow engines → add **+12 raw_days**  \n  – State machines → add **+6 raw_days**\n• **Scheduled Jobs / Batch Processing**  \n  – Simple cron jobs → add **+3 raw_days**  \n  – Complex batch processing → add **+6 raw_days**  \n  – Job orchestration/dependencies → add **+4 raw_days**\n• **Background Job Processing**  \n  – Simple job queue (Bull, Celery) → add **+4 raw_days**  \n  – Complex workflows with retries → add **+6 raw_days**  \n  – Compensation/rollback logic → add **+3 raw_days** more\n• **Reporting & Analytics**  \n  – Basic reporting endpoints → add **+3 raw_days**  \n  – Complex aggregations/OLAP → add **+6 raw_days**  \n  – Real-time analytics → add **+5 raw_days**\n\n#### COMPLIANCE & REGULATORY\n• **Highly Regulated Projects**  \n  – If regulatory_classification.level = \"Highly Regulated\" → add **+10 raw_days**  \n  – Mandatory security audits → add **+5 raw_days**  \n  – Compliance documentation → add **+3 raw_days**\n• **Audit & Logging**  \n  – Complete audit trails → add **+5 raw_days**  \n  – Field-level change capture → add **+3 raw_days**  \n  – Immutable audit logs → add **+2 raw_days**\n• **Data Retention Policies**  \n  – Automated data retention → add **+3 raw_days**  \n  – Complex archival strategies → add **+4 raw_days**\n\n#### SPECIAL CONSIDERATIONS\n• **Internationalization (i18n)**  \n  – Backend i18n (locale, currency, timezone) → add **+3 raw_days**  \n  – Multi-language content management → add **+4 raw_days**\n• **API Documentation**  \n  – OpenAPI/Swagger setup → add **+2 raw_days**  \n  – Interactive documentation → add **+1 raw_day**\n• **Testing Infrastructure**  \n  – Unit test setup (if not included) → add **+3 raw_days**  \n  – Integration test framework → add **+4 raw_days**  \n  – E2E test automation → add **+5 raw_days**\n\n#### COMPLEXITY MULTIPLIERS\n• **Team Experience Adjustments**  \n  – If no senior backend devs in team → multiply total by **1.3x**  \n  – If tech stack new to team → multiply total by **1.2x**  \n  – If distributed team across > 3 timezones → multiply total by **1.15x**\n• **Requirements Uncertainty**  \n  – If requirements contain > 5 \"TBD\" items → multiply total by **1.15x**  \n  – If no technical specifications → multiply total by **1.25x**\n• **Risk-Based Adjustments**  \n  – For each \"High\" risk in risk register → add **+2 raw_days**  \n  – For each \"Critical\" risk → add **+5 raw_days**\n\n#### INDUSTRY-STANDARD CONSIDERATIONS\n• **Code Quality & Technical Debt**  \n  – Greenfield project → base estimate  \n  – Brownfield/legacy refactoring → multiply by **1.5x**  \n  – Tech debt paydown required → add **+20% to total**  \n  – Code quality tools setup (SonarQube, etc.) → add **+3 raw_days**\n• **Development Methodology Impact**  \n  – Agile with 2-week sprints → base estimate  \n  – Waterfall with fixed phases → multiply by **1.2x**  \n  – DevOps/continuous deployment → reduce by **-5%** (efficiency gain)  \n  – Pair programming mandated → multiply by **1.4x**\n• **Documentation Standards**  \n  – API documentation only → add **+5% to total**  \n  – Full technical documentation → add **+15% to total**  \n  – Architecture Decision Records (ADRs) → add **+3 raw_days**  \n  – Runbooks and ops guides → add **+5 raw_days**\n• **Communication Overhead**  \n  – Single stakeholder → base estimate  \n  – 2-5 stakeholders → add **+10% to total**  \n  – > 5 stakeholders or steering committee → add **+20% to total**  \n  – External vendor coordination → add **+5 raw_days** per vendor\n• **Deployment Complexity**  \n  – Single environment → base estimate  \n  – Dev + Staging + Prod → add **+5 raw_days**  \n  – Multiple prod regions → add **+8 raw_days**  \n  – Blue-green or canary deployments → add **+4 raw_days**\n• **Service Level Agreements**  \n  – No formal SLA → base estimate  \n  – 99.9% uptime SLA → add **+5 raw_days**  \n  – 99.99% uptime SLA → add **+10 raw_days**  \n  – Financial penalties for downtime → add **+5 raw_days** more\n• **Change Management**  \n  – Informal change process → base estimate  \n  – CAB approval required → add **+5% to total**  \n  – ITIL compliance → add **+10% to total**\n• **Knowledge Transfer**  \n  – No handover required → base estimate  \n  – Documentation handover → add **+3 raw_days**  \n  – Training sessions required → add **+5 raw_days**  \n  – Shadow period required → add **+10 raw_days**\n• **Contract & Commercial**  \n  – Time & materials → base estimate  \n  – Fixed price contract → add **+15% buffer**  \n  – Penalty clauses → add **+10% buffer**  \n  – Staged delivery with milestones → add **+5 raw_days** for coordination\n\n#### ESTIMATION FORMULA FACTORS\n• **Cone of Uncertainty Adjustments**  \n  – Requirements phase estimate → multiply by range **0.5x to 2.0x**  \n  – Design phase estimate → multiply by range **0.75x to 1.5x**  \n  – Implementation phase estimate → multiply by range **0.9x to 1.1x**\n• **Project Size Scaling** (non-linear complexity)  \n  – < 50 raw_days → multiply by **1.0x**  \n  – 50-100 raw_days → multiply by **1.1x**  \n  – 100-200 raw_days → multiply by **1.2x**  \n  – > 200 raw_days → multiply by **1.3x**\n• **Integration Complexity Scaling**  \n  – 1-2 integrations → base estimate  \n  – 3-5 integrations → add **+15% to integration days**  \n  – > 5 integrations → add **+30% to integration days**\n• **Parallel Work Inefficiency**  \n  – 1-2 developers → base estimate  \n  – 3-4 developers → add **+10% coordination overhead**  \n  – > 4 developers → add **+20% coordination overhead**\n\n#### RISK BUFFERS (INDUSTRY STANDARD)\n• **Standard Risk Contingency**  \n  – Low risk project → add **+10% buffer**  \n  – Medium risk project → add **+20% buffer**  \n  – High risk project → add **+30% buffer**\n• **Specific Risk Factors**  \n  – First time with tech stack → add **+15% buffer**  \n  – Unclear requirements → add **+25% buffer**  \n  – Dependencies on other teams → add **+5% per dependency**  \n  – Regulatory approval gates → add **+10% per gate**\n\n#### CALCULATION RULES\n• **Minimum Thresholds**  \n  – No backend project < **20 raw_days** regardless of simplicity  \n  – If calculated < 20, set to 20 with note: \"Minimum threshold applied\"\n• **Maximum Sanity Checks**  \n  – If total > **250 raw_days** → add warning: \"Consider phased delivery\"  \n  – If single integration > **15 raw_days** → flag for review\n• **Rounding**  \n  – Always round final raw_days to nearest whole number  \n  – Document all additions in calc_note field\n• **Confidence Levels**  \n  – High confidence: All requirements clear, proven tech, experienced team  \n  – Medium confidence: Some unknowns, mostly proven approach  \n  – Low confidence: Many unknowns, new tech, unclear requirements\n; `\n\nreturn [\n  {\n    json: { refinementRules }\n  }\n];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -2620,
        6420
      ],
      "id": "e5c8a965-9611-423c-ad5c-e0c890e1bf89",
      "name": "Backend Estimation Rules"
    }
  ],
  "pinData": {},
  "repo_name": "n8n-backup-zm",
  "repo_owner": "zlatkomq",
  "repo_path": "",
  "settings": {
    "executionOrder": "v1"
  },
  "shared": [
    {
      "createdAt": "2025-06-17T07:02:40.778Z",
      "updatedAt": "2025-06-17T07:02:40.778Z",
      "role": "workflow:owner",
      "workflowId": "ZbHMKsiavwFA5iD6",
      "projectId": "NM7VZoSXkcKo262s"
    }
  ],
  "staticData": null,
  "tags": [
    {
      "createdAt": "2025-04-24T10:59:44.979Z",
      "updatedAt": "2025-04-24T10:59:44.979Z",
      "id": "qEREEA2JvunvA9Nv",
      "name": "Estimation Tool"
    }
  ],
  "triggerCount": 1,
  "updatedAt": "2025-07-10T10:09:04.587Z",
  "versionId": "0f96eed8-e816-4a88-bc9a-3a2140d92f10"
}