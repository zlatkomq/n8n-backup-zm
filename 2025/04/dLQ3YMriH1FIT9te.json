{
  "active": true,
  "connections": {
    "When clicking ‘Test workflow’": {
      "main": [
        []
      ]
    },
    "Queries": {
      "main": [
        [
          {
            "node": "Embed Query - ollama",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Embed Query - ollama": {
      "main": [
        [
          {
            "node": "Wait",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Map Response": {
      "main": [
        [
          {
            "node": "Deduplicate and Best Score",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "PreparePrompts": {
      "main": [
        [
          {
            "node": "Get Platforms",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Claude 3.7": {
      "ai_languageModel": [
        []
      ]
    },
    "Platforms + Rationale": {
      "ai_outputParser": [
        [
          {
            "node": "Get Platforms",
            "type": "ai_outputParser",
            "index": 0
          }
        ]
      ]
    },
    "Merge Chunks": {
      "main": [
        [
          {
            "node": "Token Budgeting",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Deduplicate and Best Score": {
      "main": [
        [
          {
            "node": "Merge Chunks",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Token Budgeting": {
      "main": [
        [
          {
            "node": "Prepare Context3",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Chat Model1": {
      "ai_languageModel": [
        [
          {
            "node": "Get Platforms",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Prepare Context3": {
      "main": [
        [
          {
            "node": "PreparePrompts",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Queries2": {
      "main": [
        [
          {
            "node": "Embed Query - ollama2",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Embed Query - ollama2": {
      "main": [
        [
          {
            "node": "Wait1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Map Response2": {
      "main": [
        [
          {
            "node": "Deduplicate and Best Score6",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "PreparePrompts4": {
      "main": [
        [
          {
            "node": "Functional requirements",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Query - Full9": {
      "main": [
        [
          {
            "node": "Has Hits?1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Merge Chunks5": {
      "main": [
        [
          {
            "node": "Token Budgeting2",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Deduplicate and Best Score6": {
      "main": [
        [
          {
            "node": "Merge Chunks5",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Token Budgeting2": {
      "main": [
        [
          {
            "node": "Prepare Context4",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Chat Model3": {
      "ai_languageModel": [
        [
          {
            "node": "Functional requirements",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Prepare Context4": {
      "main": [
        [
          {
            "node": "PreparePrompts4",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Claude 3.": {
      "ai_languageModel": [
        []
      ]
    },
    "Functional requirements": {
      "main": [
        [
          {
            "node": "Functional Requirements Output",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Stop and Error1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Think": {
      "ai_tool": [
        [
          {
            "node": "Functional requirements",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Platforms Output": {
      "main": [
        [
          {
            "node": "Prepare for frontend8",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "GPT 4.1 Mini2": {
      "ai_languageModel": [
        []
      ]
    },
    "Code": {
      "main": [
        [
          {
            "node": "Team Composition",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Anthropic Chat Model": {
      "ai_languageModel": [
        [
          {
            "node": "Team Composition",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Functional Requirements Output": {
      "main": [
        [
          {
            "node": "Queries8",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Queries8": {
      "main": [
        [
          {
            "node": "Embed Query - ollama8",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Embed Query - ollama8": {
      "main": [
        [
          {
            "node": "Wait2",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "PreparePrompts7": {
      "main": [
        [
          {
            "node": "NonFunctional Requirements",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Query - Full11": {
      "main": [
        [
          {
            "node": "Has Hits?2",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Merge Chunks8": {
      "main": [
        [
          {
            "node": "Token Budgeting7",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Deduplicate and Best Score8": {
      "main": [
        [
          {
            "node": "Merge Chunks8",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Token Budgeting7": {
      "main": [
        [
          {
            "node": "Prepare Context6",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Chat Model": {
      "ai_languageModel": [
        [
          {
            "node": "NonFunctional Requirements",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Prepare Context6": {
      "main": [
        [
          {
            "node": "PreparePrompts7",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Think1": {
      "ai_tool": [
        [
          {
            "node": "NonFunctional Requirements",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Map Response8": {
      "main": [
        [
          {
            "node": "Deduplicate and Best Score8",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "NonFunctional Requirements": {
      "main": [
        [
          {
            "node": "NonFunctional Requirements Output",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Stop and Error2",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "NonFunctional Requirements Output": {
      "main": [
        [
          {
            "node": "Combine Requirements",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Queries7": {
      "main": [
        [
          {
            "node": "Embed Query - ollama7",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Embed Query - ollama7": {
      "main": [
        [
          {
            "node": "Wait3",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Map Response3": {
      "main": [
        [
          {
            "node": "Deduplicate and Best Score7",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "PreparePrompts6": {
      "main": [
        [
          {
            "node": "Get Techstack",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Claude 3.8": {
      "ai_languageModel": [
        [
          {
            "node": "Get Techstack",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Platforms + Rationale2": {
      "ai_outputParser": [
        [
          {
            "node": "Get Techstack",
            "type": "ai_outputParser",
            "index": 0
          }
        ]
      ]
    },
    "Query - Full10": {
      "main": [
        [
          {
            "node": "Has Hits?3",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Merge Chunks7": {
      "main": [
        [
          {
            "node": "Token Budgeting5",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Deduplicate and Best Score7": {
      "main": [
        [
          {
            "node": "Merge Chunks7",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Token Budgeting5": {
      "main": [
        [
          {
            "node": "Prepare Context5",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare Context5": {
      "main": [
        [
          {
            "node": "PreparePrompts6",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Get Techstack": {
      "main": [
        [
          {
            "node": "Techstack Output",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Stop and Error4",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Chat Model5": {
      "ai_languageModel": [
        []
      ]
    },
    "Title + Desc + Section": {
      "ai_outputParser": [
        []
      ]
    },
    "Description": {
      "ai_outputParser": [
        [
          {
            "node": "Functional requirements",
            "type": "ai_outputParser",
            "index": 0
          }
        ]
      ]
    },
    "Full": {
      "ai_outputParser": [
        []
      ]
    },
    "Description + Category": {
      "ai_outputParser": [
        [
          {
            "node": "NonFunctional Requirements",
            "type": "ai_outputParser",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Chat Model6": {
      "ai_languageModel": [
        [
          {
            "node": "Combine Requirements",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Structured Output Parser": {
      "ai_outputParser": [
        [
          {
            "node": "Combine Requirements",
            "type": "ai_outputParser",
            "index": 0
          }
        ]
      ]
    },
    "Combine Requirements": {
      "main": [
        [
          {
            "node": "Combined Requirements Output",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Stop and Error3",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Combined Requirements Output": {
      "main": [
        [
          {
            "node": "Dependencies1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Dependencies1": {
      "main": [
        [
          {
            "node": "Prepare for frontend9",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Techstack Output": {
      "main": [
        [
          {
            "node": "Prepare for frontend10",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Team Composition1": {
      "ai_outputParser": [
        [
          {
            "node": "Team Composition",
            "type": "ai_outputParser",
            "index": 0
          }
        ]
      ]
    },
    "Team Composition": {
      "main": [
        [
          {
            "node": "Team Composition Output",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Stop and Error5",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Team Composition Output": {
      "main": [
        [
          {
            "node": "Prepare for frontend11",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Greenfield + Rationale": {
      "ai_outputParser": [
        [
          {
            "node": "Effort Estimation",
            "type": "ai_outputParser",
            "index": 0
          }
        ]
      ]
    },
    "GPT 4.1 Mini4": {
      "ai_languageModel": [
        [
          {
            "node": "Effort Estimation",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Code2": {
      "main": [
        [
          {
            "node": "Effort Estimation",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Calculator": {
      "ai_tool": [
        [
          {
            "node": "Effort Estimation",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Anthropic Chat Model2": {
      "ai_languageModel": [
        []
      ]
    },
    "Greenfield + Rationale3": {
      "ai_outputParser": [
        [
          {
            "node": "Development Plan",
            "type": "ai_outputParser",
            "index": 0
          }
        ]
      ]
    },
    "Code3": {
      "main": [
        [
          {
            "node": "Development Plan",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Anthropic Chat Model3": {
      "ai_languageModel": [
        [
          {
            "node": "Development Plan",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Calculator1": {
      "ai_tool": [
        [
          {
            "node": "Development Plan",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Effort Estimation": {
      "main": [
        [
          {
            "node": "Effort Estimate Output",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Stop and Error6",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Effort Estimate Output": {
      "main": [
        [
          {
            "node": "Prepare for frontend12",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Create index - Elastic Search": {
      "main": [
        [
          {
            "node": "Download File",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Delete Index": {
      "main": [
        [
          {
            "node": "Create ES Url",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Create ES Url",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Embed Chunks": {
      "main": [
        [
          {
            "node": "Embedding Isolated",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Remove TOC": {
      "main": [
        [
          {
            "node": "Filter Empty & Duplicate Chunks",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Final Escaping": {
      "main": [
        [
          {
            "node": "Embed Chunks",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Add To Index": {
      "main": [
        [
          {
            "node": "Prepare for frontend",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Filter Empty & Duplicate Chunks": {
      "main": [
        [
          {
            "node": "Split Chunks",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Split Chunks": {
      "main": [
        [
          {
            "node": "Final Escaping",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Edit Fields": {
      "main": [
        [
          {
            "node": "Add To Index",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Embedding Isolated": {
      "main": [
        [
          {
            "node": "Edit Fields",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Chunker Full": {
      "main": [
        [
          {
            "node": "Format Output",
            "type": "main",
            "index": 0
          }
        ],
        []
      ]
    },
    "Format Output": {
      "main": [
        [
          {
            "node": "Remove TOC",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Start RFP Analysis": {
      "main": [
        [
          {
            "node": "Get Session ID and prepare file data",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Create ES Url": {
      "main": [
        [
          {
            "node": "Create index - Elastic Search",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Extract FileId": {
      "main": [
        [
          {
            "node": "Delete Index",
            "type": "main",
            "index": 0
          }
        ],
        []
      ]
    },
    "Prepare for frontend": {
      "main": [
        [
          {
            "node": "SSE - Document Preparation",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "SSE - Document Preparation": {
      "main": [
        [
          {
            "node": "Queries",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare for frontend8": {
      "main": [
        [
          {
            "node": "SSE - Platforms",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare for frontend9": {
      "main": [
        [
          {
            "node": "SSE - Requirements",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "SSE - Platforms": {
      "main": [
        [
          {
            "node": "Queries2",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "SSE - Requirements": {
      "main": [
        [
          {
            "node": "Queries7",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare for frontend10": {
      "main": [
        [
          {
            "node": "SSE - Techstack",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "SSE - Techstack": {
      "main": [
        [
          {
            "node": "Code",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare for frontend11": {
      "main": [
        [
          {
            "node": "SSE - Team Composition",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "SSE - Team Composition": {
      "main": [
        [
          {
            "node": "Code2",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare for frontend12": {
      "main": [
        [
          {
            "node": "SSE - Effort Estimation",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "SSE - Effort Estimation": {
      "main": [
        [
          {
            "node": "Code3",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare for frontend13": {
      "main": [
        [
          {
            "node": "SSE - Development Plan",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Development Plan": {
      "main": [
        [
          {
            "node": "Development Plan Output",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Stop and Error7",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Anthropic Chat Model5": {
      "ai_languageModel": [
        [
          {
            "node": "Reporter",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Reporter": {
      "main": [
        [
          {
            "node": "Prepare for frontend7",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Stop and Error8",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare for frontend7": {
      "main": [
        [
          {
            "node": "SSE - Final Report",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "SSE - Development Plan": {
      "main": [
        [
          {
            "node": "Prompt",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prompt": {
      "main": [
        [
          {
            "node": "Reporter",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Development Plan Output": {
      "main": [
        [
          {
            "node": "Prepare for frontend13",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Calculator2": {
      "ai_tool": [
        [
          {
            "node": "Reporter",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Think2": {
      "ai_tool": [
        [
          {
            "node": "Reporter",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "mock": {
      "main": [
        []
      ]
    },
    "Send PDF to Email": {
      "main": [
        [
          {
            "node": "Code6",
            "type": "main",
            "index": 0
          },
          {
            "node": "Merge",
            "type": "main",
            "index": 0
          },
          {
            "node": "Respond to Webhook",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Merge": {
      "main": [
        [
          {
            "node": "Gmail",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Code6": {
      "main": [
        [
          {
            "node": "Merge",
            "type": "main",
            "index": 1
          }
        ]
      ]
    },
    "Query - Full1": {
      "main": [
        [
          {
            "node": "Has Hits?",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Has Hits?": {
      "main": [
        [
          {
            "node": "Map Response",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Stop and Error",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Wait": {
      "main": [
        [
          {
            "node": "Query - Full1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Wait1": {
      "main": [
        [
          {
            "node": "Query - Full9",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Wait2": {
      "main": [
        [
          {
            "node": "Query - Full11",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Wait3": {
      "main": [
        [
          {
            "node": "Query - Full10",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Get Session ID and prepare file data": {
      "main": [
        [
          {
            "node": "Save To FileSystem",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Save To FileSystem": {
      "main": [
        [
          {
            "node": "Extract FileId",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Download File": {
      "main": [
        [
          {
            "node": "Chunker Full",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Has Hits?1": {
      "main": [
        [
          {
            "node": "Map Response2",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Stop and Error1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Has Hits?2": {
      "main": [
        [
          {
            "node": "Map Response8",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Stop and Error2",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Has Hits?3": {
      "main": [
        [
          {
            "node": "Map Response3",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "PreparePrompts6",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "SSE - Final Report": {
      "main": [
        [
          {
            "node": "Delete tmp file",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "LLama4Scout": {
      "ai_languageModel": [
        []
      ]
    },
    "Get Platforms": {
      "main": [
        [
          {
            "node": "Platforms Output",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "createdAt": "2025-04-19T16:17:47.392Z",
  "id": "dLQ3YMriH1FIT9te",
  "isArchived": false,
  "meta": {
    "templateCredsSetupCompleted": true
  },
  "name": "RFP Analysis Public",
  "nodes": [
    {
      "parameters": {},
      "id": "d5a341f3-b02d-4eb3-b159-56c7f825befc",
      "name": "When clicking ‘Test workflow’",
      "type": "n8n-nodes-base.manualTrigger",
      "typeVersion": 1,
      "position": [
        -3488,
        1664
      ],
      "disabled": true
    },
    {
      "parameters": {
        "jsCode": "return [\n  {\n    json: {\n      platform: \"web\",\n      query: \"What web technologies or platforms are mentioned in the RFP?\",\n      keywords: \"web technology, technologies, platform, platforms, website, webapp, web application, HTML, CSS, JavaScript, TypeScript, React, Angular, Vue, Svelte, Next.js, Nuxt.js, PHP, Python, Django, Flask, Ruby, Rails, Node.js, Express, .NET, ASP.NET, Java, Spring, Laravel, Drupal, WordPress, CMS, frontend, backend, server-side, client-side, SaaS, PaaS, cloud hosting\",\n      phrase: \"web technology platform web application\",\n      rescore_query: \"web application OR React OR Angular OR Vue OR HTML OR CSS\"\n    }\n  },\n  {\n    json: {\n      platform: \"mobile\",\n      query: \"Is a mobile app required or mentioned in the RFP? Android, iOS or Flutter?\",\n      keywords: \"mobile app, application, Android, iOS, Flutter, React Native, Swift, Kotlin, cross-platform, smartphone, tablet, mobile device, iPhone, iPad, Play Store, App Store\",\n      phrase: \"mobile application mobile app\",\n      rescore_query: \"mobile app OR Android OR iOS OR Flutter OR React Native\"\n    }\n  },\n  {\n    json: {\n      platform: \"backend\",\n      query: \"Are there backend services or APIs involved in the RFP?\",\n      keywords: \"backend service, services, API, APIs, REST, RESTful, GraphQL, server, database, microservice, microservices, endpoint, endpoints, integration, integration layer, middleware, backend system, data storage, authentication, authorization, business logic\",\n      phrase: \"backend service API integration\",\n      rescore_query: \"REST API OR GraphQL OR microservice OR backend service\"\n    }\n  },\n  {\n    json: {\n      platform: \"admin\",\n      query: \"Does the RFP include an admin portal or dashboard?\",\n      keywords: \"admin portal, dashboard, administration, control panel, admin interface, management console, backend portal, admin dashboard, reporting, analytics, monitoring, configuration settings, user management\",\n      phrase: \"admin portal admin dashboard\",\n      rescore_query: \"admin portal OR admin dashboard OR management console\"\n    }\n  },\n  {\n    json: {\n      platform: \"desktop\",\n      query: \"Is desktop software or a desktop client part of the RFP scope?\",\n      keywords: \"desktop software, client application, Windows, MacOS, Linux, desktop app, Electron, desktop client, installable application, native desktop, cross-platform desktop, program, executable\",\n      phrase: \"desktop software desktop client\",\n      rescore_query: \"desktop app OR Electron OR native desktop\"\n    }\n  },\n  {\n    json: {\n      platform: \"kiosk\",\n      query: \"Are kiosk systems or interfaces required in the RFP?\",\n      keywords: \"kiosk system, systems, interface, interfaces, self-service terminal, touch screen, touchscreen, kiosk application, kiosk mode, interactive kiosk, public kiosk, digital kiosk, POS, point of sale\",\n      phrase: \"kiosk system kiosk interface\",\n      rescore_query: \"kiosk interface OR touchscreen OR point of sale\"\n    }\n  },\n  {\n    json: {\n      platform: \"system-architecture\",\n      query: \"Describe the overall system structure and functionality mentioned in the RFP.\",\n      keywords: \"system structure, architecture, functionality, components, modules, workflow, process, integration, overview, system design, system diagram, technical architecture, high-level design, system overview\",\n      phrase: \"system structure system functionality\",\n      rescore_query: \"system architecture OR technical architecture OR system design\"\n    }\n  },\n  {\n    json: {\n      platform: \"technical-components\",\n      query: \"What are the main technical or system components described in the RFP?\",\n      keywords: \"technical component, components, system element, elements, module, modules, subsystem, subsystems, architecture, infrastructure, technology stack, platform, integration, interface, API, backend, frontend, database, server, client\",\n      phrase: \"technical component system component\",\n      rescore_query: \"technical component OR system module OR technology stack\"\n    }\n  }\n];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -4064,
        3344
      ],
      "id": "9a8fabe5-aafc-4005-bf19-b2d90ab1b084",
      "name": "Queries"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "http://192.168.20.70:11434/api/embed",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"model\": \"nomic-embed-text:latest\",\n  \"input\": [\"{{ $json.query }}\"]\n}",
        "options": {}
      },
      "id": "0c0d33da-005c-4885-a24c-672726df6acd",
      "name": "Embed Query - ollama",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -3888,
        3344
      ]
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "17f9e7d3-307e-4d60-92ef-e32285cbec29",
              "name": "_score",
              "value": "={{ $json._score }}",
              "type": "number"
            },
            {
              "id": "618f58cd-27c7-4ab4-8612-899f048afb6c",
              "name": "_id",
              "value": "={{ $json._id }}",
              "type": "string"
            },
            {
              "id": "a8cfb079-48c6-4ce2-a54c-251304107206",
              "name": "chunk_id",
              "value": "={{ $json._source.chunk_id }}",
              "type": "string"
            },
            {
              "id": "22e6e029-7ff1-4870-a1c2-d3b025a2748b",
              "name": "section_title",
              "value": "={{ $json._source.section_title }}",
              "type": "string"
            },
            {
              "id": "27e9a9ac-b6ed-4320-bb21-027f8659e7c5",
              "name": "text",
              "value": "={{ $json._source.text }}",
              "type": "string"
            },
            {
              "id": "6830a868-6492-405b-b8fb-1ae36ea184b2",
              "name": "metadata",
              "value": "={{ $json._source.metadata }}",
              "type": "object"
            },
            {
              "id": "e5dce93c-eb16-42be-8b42-47ca5cfacc52",
              "name": "platform",
              "value": "={{ $('Queries').item.json.platform }}",
              "type": "string"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        -3648,
        3360
      ],
      "id": "c377e0b0-0518-4fc3-818a-49bb9651bb6b",
      "name": "Map Response"
    },
    {
      "parameters": {
        "jsCode": "const contextForPrompt = $input.first().json.context;\nconst systemPrompt = \"You are a precise assistant that extracts structured insights from project documents, such as RFPs or technical scopes. Your primary goal is to identify platform requirements based on the content provided. Focus on what is clearly described, but use practical software development reasoning when appropriate: - If a frontend (web or mobile) is described in detail, and no backend is mentioned, assume a backend is required unless the RFP explicitly states otherwise.- If user-facing workflows imply system control or role management, you may reasonably infer that an admin interface is needed. Never invent features or platforms not supported by the text or standard architectural logic. If something is unclear or missing, say so clearly. Be structured, realistic, and accurate in all your conclusions.\";\n\n// 3. Define the user prompt\nconst userPrompt = `You are reviewing excerpts from an RFP document to determine which technology platforms are explicitly required.\n\\n\\n### excerpts:\\n\\n${contextForPrompt}\nInstructions:\n- Only list platforms that are clearly described or required in the text.\n- For each platform you list, provide a **short rationale** explaining what in the text led you to include it.\n- If no platforms are clearly required, say: \"No platform requirements explicitly stated.\"\n\nOnly identify platforms from the list below and use EXACTLY these enum values and text formats:\n- {\"enum\": \"WEB\", \"text\": \"Web application\"}\n- {\"enum\": \"MOBILE\", \"text\": \"Mobile app\"} (mention iOS/Android in rationale if stated)\n- {\"enum\": \"BACKEND_API\", \"text\": \"Backend/API services\"}\n- {\"enum\": \"ADMIN_PORTAL\", \"text\": \"Admin portal/dashboard\"}\n- {\"enum\": \"DESKTOP\", \"text\": \"Desktop application\"}\n- {\"enum\": \"IOT\", \"text\": \"IoT/Embedded system\"}\n- {\"enum\": \"KIOSK\", \"text\": \"Kiosk system\"}\n\n**Additional notes**:\n- If a web or mobile frontend is clearly described but no backend is mentioned, **assume a backend is needed** and include {\"enum\": \"BACKEND_API\", \"text\": \"Backend/API services\"} unless explicitly stated otherwise.\n- If the RFP includes user-facing features that typically require admin management (e.g., content moderation, approval workflows, user roles), you may infer that an **admin portal** is required even if not explicitly named - use {\"enum\": \"ADMIN_PORTAL\", \"text\": \"Admin portal/dashboard\"}.\n- Use Think tool to help you with reasoning.\n\nRemember: Base your answers strictly on the provided Context.  \nYou may make minimal inferences only when explicitly allowed in the instructions above (e.g., assuming a backend for a described frontend).  \nDo not invent platform requirements beyond that.\n\n**IMPORTANT: Format the rationale field using markdown markup for better readability:**\n- Use **bold text** for key points and important terms\n- Use ## headers for main sections\n- Use ### subheaders for subsections  \n- Use bullet points (- item) for lists\n- Use numbered lists (1. item) for sequential steps\n- Use \"code\" formatting for technical terms\n- Structure the rationale with clear sections and hierarchy\n`;\n\nreturn {\n  json: {\n    userPrompt,\n    systemPrompt: systemPrompt\n  }\n};"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -3504,
        3568
      ],
      "id": "1aa8962f-de1b-44fe-82f8-43d5b6ac91db",
      "name": "PreparePrompts"
    },
    {
      "parameters": {
        "content": "## Inference PLATFORMS\nYou are reviewing excerpts \nfrom an RFP document \nto determine which technology \nplatforms are explicitly required.\n\nUse only the following categories:\n- Web applications\n- Mobile apps (mention iOS/Android if stated)\n- Backend/API services\n- Admin portals or dashboards\n- Desktop applications\n- Specialized systems (e.g., kiosks, IoT)\n\nFor each platform you identify, \nexplain briefly what in the text\n led you to that conclusion.\nOnly include platforms that are\n clearly required or described.\n\nIf nothing is clear, say \n“No platform requirements explicitly stated.”",
        "height": 860,
        "width": 2360
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        -4480,
        3152
      ],
      "id": "3208fa34-dd58-42ab-94b9-27d57c87aa44",
      "name": "Sticky Note4"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "claude-sonnet-4-20250514",
          "mode": "list",
          "cachedResultName": "Claude Sonnet 4"
        },
        "options": {
          "temperature": 0.2,
          "thinking": false
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatAnthropic",
      "typeVersion": 1.3,
      "position": [
        -3392,
        3760
      ],
      "id": "860cecd1-317b-411f-9966-f94e3ffe1561",
      "name": "Claude 3.7",
      "credentials": {
        "anthropicApi": {
          "id": "qzCm5Ds2qD9ZY1W5",
          "name": "Anthropic account"
        }
      }
    },
    {
      "parameters": {
        "jsonSchemaExample": "{\n\t\"platforms\": [\n    {\n      \"enum\": \"ENUM_VALUE\",\n      \"text\": \"Platform text\"\n    }\n  ],\n  \"rationale\": \"Brief explanation for each platform identified\"\n}"
      },
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "typeVersion": 1.2,
      "position": [
        -3056,
        3760
      ],
      "id": "46da9feb-d13e-42f6-ac1c-ae6ebd7dd2dd",
      "name": "Platforms + Rationale"
    },
    {
      "parameters": {
        "jsCode": "// n8n Function Node: Corrected Merge Split-Chunk Groups\n\nconst grouped = {};\n\n// 1. Group all items by the “true” chunk identifier\nfor (const item of $input.all()) {\n  const data = item.json;\n  // Use parent_chunk_id if it exists, else chunk_id\n  const parentId = data.metadata?.is_split_chunk\n    ? data.metadata.parent_chunk_id\n    : data.chunk_id;\n\n  if (!grouped[parentId]) grouped[parentId] = [];\n  grouped[parentId].push(data);\n}\n\nconst merged = [];\n\n// 2. For each group, produce exactly one merged record\nfor (const [parentId, parts] of Object.entries(grouped)) {\n  // Sort by the split_part if present (else leave order)\n  parts.sort((a, b) => \n    (a.metadata?.split_part ?? 0) - (b.metadata?.split_part ?? 0)\n  );\n\n  // Stitch text together\n  const text = parts.map(p => p.text).join(\"\\n\\n\");\n\n  // Merge platform_origins arrays from all parts (dedupe by platform)\n  const allOrigins = parts.flatMap(p => p.platform_origins || []);\n  const platform_origins = [];\n  for (const o of allOrigins) {\n    if (!platform_origins.some(existing => existing.platform === o.platform)) {\n      platform_origins.push(o);\n    }\n  }\n\n  // Pick the highest-scoring part to inherit section_title, filename, pages, and score\n  const bestPart = parts.reduce((best, p) => \n    p._score > best._score ? p : best\n  , parts[0]);\n\n  // Build the single merged record\n  const record = {\n    chunk_id: parentId,\n    _score: bestPart._score,\n    section_title: bestPart.section_title,\n    text,\n    metadata: {\n      ...bestPart.metadata,\n      is_split_chunk: false,\n      parent_chunk_id: undefined,\n      split_part: undefined,\n      total_parts: undefined\n    },\n    platform_origins\n  };\n\n  merged.push({ json: record });\n}\nmerged.sort((a, b) => b.json._score - a.json._score);\nreturn merged;\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -4064,
        3568
      ],
      "id": "f0209968-927c-4d5b-b9c8-6bb651622162",
      "name": "Merge Chunks"
    },
    {
      "parameters": {
        "jsCode": "// n8n Function Node: Dedupe → Merge Origins → Filter → Sort → Fallback\n\nconst MIN_SCORE = 3.0;\nconst DESIRED_COUNT = 10;\n\n// Step 1: Deduplicate & merge platform origins, keep highest‐score record\nconst seen = {};\nfor (const item of $input.all()) {\n  const { chunk_id, platform, _score, ...rest } = item.json;\n  \n  if (!seen[chunk_id]) {\n    // First time seeing this chunk\n    seen[chunk_id] = {\n      chunk_id,\n      _score,\n      ...rest,\n      platform_origins: [{ platform, score: _score }],\n    };\n  } else {\n    // Merge new platform origin\n    const record = seen[chunk_id];\n    if (!record.platform_origins.some(p => p.platform === platform)) {\n      record.platform_origins.push({ platform, score: _score });\n    }\n    // If this hit has a higher score, overwrite core fields\n    if (_score > record._score) {\n      record._score = _score;\n      Object.assign(record, rest);\n    }\n  }\n}\n\n// Convert deduped map back to array of items\nlet deduped = Object.values(seen).map(r => ({ json: r }));\n\n// Step 2: Filter by score and sort descending\nlet filtered = deduped\n  .filter(item => item.json._score >= MIN_SCORE)\n  .sort((a, b) => b.json._score - a.json._score);\n\n// Step 3: Fallback if too few hits\nif (filtered.length < DESIRED_COUNT) {\n  // Return top DESIRED_COUNT from deduped (regardless of score)\n  filtered = deduped\n    .sort((a, b) => b.json._score - a.json._score)\n    .slice(0, DESIRED_COUNT);\n}\n\n// Step 4: Ensure we only return up to DESIRED_COUNT\nfiltered = filtered.slice(0, DESIRED_COUNT);\n\n// Return in n8n-compatible format\nreturn filtered;\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -3504,
        3360
      ],
      "id": "351e286d-1aa4-48f0-90b1-a0ad82f2b3de",
      "name": "Deduplicate and Best Score"
    },
    {
      "parameters": {
        "jsCode": "// Configuration\nconst TOKEN_LIMIT = 5000;\nconst MIN_STRONG_SCORE = 7.0;\n\n// Rough token estimator (1 token ~ 4 characters)\nfunction estimateTokenCount(text) {\n  if (!text) return 0;\n  return Math.ceil(text.length / 4);\n}\n\n// Input already filtered and sorted!\nconst chunks = $input.all().map(item => item.json);\n\n// Build the final list\nconst selectedChunks = [];\nlet tokenCount = 0;\n\nfor (const chunk of chunks) {\n  const tokens = estimateTokenCount(chunk.text);\n\n  if ((tokenCount + tokens) <= TOKEN_LIMIT) {\n    selectedChunks.push(chunk);\n    tokenCount += tokens;\n  } else if (chunk._score >= MIN_STRONG_SCORE) {\n    // Allow overflow for very strong chunks\n    selectedChunks.push(chunk);\n    tokenCount += tokens;\n  } else {\n    break; // Stop adding\n  }\n}\n\n// Prepare output\nconst output = selectedChunks.map(chunk => ({ json: chunk }));\n\n// Add token usage metadata (attach to first item for simplicity)\nif (output.length > 0) {\n  output[0].json._token_summary = {\n    total_tokens_estimated: tokenCount,\n    total_chunks_selected: selectedChunks.length,\n  };\n}\n\nreturn output;\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -3888,
        3568
      ],
      "id": "a3911767-fb3f-47f2-8d48-cbd407ef4936",
      "name": "Token Budgeting"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "gpt-5",
          "mode": "list",
          "cachedResultName": "gpt-5"
        },
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        -3264,
        3760
      ],
      "id": "83f9911c-193f-4200-9e4f-7dbe7e0fcd3c",
      "name": "OpenAI Chat Model1",
      "credentials": {
        "openAiApi": {
          "id": "M8xqWvEC6mH6LNuk",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "/**\n * Prepare ES chunks for Claude, without chunk‐length limiting.\n */\nfunction prepareSecurityRegulatoryContextForClaude(esResults) {\n  if (!Array.isArray(esResults)) {\n    throw new Error(\"Input must be an array of Elasticsearch results\");\n  }\n\n  // simple Markdown escaper\n  function mdEscape(str) {\n    return str.replace(/(`|\\*|_|~|>|\\[|\\])/g, \"\\\\$1\");\n  }\n\n  // normalize bullets and split into lines\n  function cleanText(raw) {\n    return raw\n      .replace(/^\\s*-\\s+/gm, \"\\n- \")\n      .replace(/^\\s*\\*\\s+/gm, \"\\n- \")\n      .replace(/[ \\t]+/g, \" \")\n      .replace(/\\. ([A-Z])/g, \".\\n$1\")\n      .replace(/\\n{3,}/g, \"\\n\\n\")\n      .trim();\n  }\n\n  const blocks = esResults.map(chunk => {\n    const { chunk_id, section_title, text = \"\", metadata = {}, _score, regScore, locScore } = chunk;\n\n    // Heading\n    const title = section_title\n      ? mdEscape(section_title)\n      : `Untitled Section (${chunk_id})`;\n\n    // Build YAML metadata\n    const pages = Array.isArray(metadata.page_numbers)\n      ? metadata.page_numbers.join(\", \")\n      : metadata.page_numbers || \"Unknown\";\n\n    const metaLines = [\n      `filename: ${metadata.filename || \"Unknown Document\"}`,\n      `pages: ${pages}`,\n      `score: ${_score.toFixed(2)}`,\n    ];\n    if (typeof regScore === \"number\") metaLines.push(`regScore: ${regScore.toFixed(2)}`);\n    if (typeof locScore === \"number\") metaLines.push(`locScore: ${locScore.toFixed(2)}`);\n    if (metadata.document_type) metaLines.push(`type: ${metadata.document_type}`);\n    if (metadata.languages) metaLines.push(`language: ${metadata.languages.join(\", \")}`);\n\n    const metaBlock = metaLines.join(\"\\n\");\n\n    // Clean and escape body\n    const body = mdEscape(cleanText(text));\n\n    return [\n      `### ${title}`,\n      \"```yaml\",\n      metaBlock,\n      \"```\",\n      \"\",\n      body\n    ].join(\"\\n\");\n  });\n\n  // Join with clear separators\n  return blocks.join(\"\\n\\n---\\n\\n\");\n}\n\n// Usage in n8n Function node:\nconst esResults = $input.all().map(i => i.json);\nconst contextForPrompt = prepareSecurityRegulatoryContextForClaude(esResults);\n\nreturn [{ json: { context: contextForPrompt } }];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -3680,
        3568
      ],
      "id": "4ea054e6-8fd9-42c6-9f09-8d45971c2a54",
      "name": "Prepare Context3"
    },
    {
      "parameters": {
        "jsCode": "return [\n{\n  json: {\n    query_type: \"feature_backlog\",\n    query:\n      \"Extract every user-facing feature, workflow, module, and use-case described in the RFP that will drive development effort.\",\n    /* Core verbs + backlog vocabulary (no compliance or legal terms) */\n    keywords: [\n      /* imperative verbs that usually start requirements */\n      \"shall\", \"must\", \"will\", \"should\", \"enable\", \"allow\", \"support\",\n\n      /* backlog & requirements terminology */\n      \"feature\", \"features\", \"functionality\", \"functional\", \"user story\",\n      \"user stories\", \"story\", \"stories\", \"epic\", \"use case\", \"use cases\",\n      \"acceptance criterion\", \"acceptance criteria\", \"requirement\",\n      \"requirements\", \"deliverable\", \"deliverables\",\n\n      /* common software capabilities */\n      \"dashboard\", \"report\", \"reporting\", \"search\", \"filter\", \"export\",\n      \"import\", \"authentication\", \"authorization\", \"login\", \"registration\",\n      \"profile\", \"notification\", \"messaging\", \"chat\", \"payment\", \"checkout\",\n      \"file upload\", \"download\", \"analytics\", \"admin panel\", \"cms\", \"api\",\n\n      /* workflow & domain phrases */\n      \"workflow\", \"process\", \"approval\", \"review\", \"comment\", \"feedback\",\n\n      /* MVP / release language */\n      \"MVP\", \"minimum viable product\", \"phase 1\", \"phase one\",\n      \"initial release\", \"pilot\", \"beta\"\n    ],\n\n    /* Phrase to give extra boost to clearly written requirements */\n    phrase: \"shall must will should feature user story use case\",\n\n    /* Tightest phrase for rescoring */\n    rescore_query: \"user story OR feature OR use case\",\n\n    description:\n      \"Surface all functional features and backlog items that drive development effort; ignore regulatory or contractual statements.\"\n  }\n}\n];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1728,
        3344
      ],
      "id": "f0bcd13a-8c8d-4e20-b207-79622a32e9c9",
      "name": "Queries2"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "http://192.168.20.70:11434/api/embed",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"model\": \"nomic-embed-text:latest\",\n  \"input\": [\"{{ $json.query }}\"]\n}",
        "options": {}
      },
      "id": "1baf316b-6769-438d-a189-c093a7e03c0e",
      "name": "Embed Query - ollama2",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -1504,
        3344
      ]
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "17f9e7d3-307e-4d60-92ef-e32285cbec29",
              "name": "_score",
              "value": "={{ $json._score }}",
              "type": "number"
            },
            {
              "id": "618f58cd-27c7-4ab4-8612-899f048afb6c",
              "name": "_id",
              "value": "={{ $json._id }}",
              "type": "string"
            },
            {
              "id": "a8cfb079-48c6-4ce2-a54c-251304107206",
              "name": "chunk_id",
              "value": "={{ $json._source.chunk_id }}",
              "type": "string"
            },
            {
              "id": "22e6e029-7ff1-4870-a1c2-d3b025a2748b",
              "name": "section_title",
              "value": "={{ $json._source.section_title }}",
              "type": "string"
            },
            {
              "id": "27e9a9ac-b6ed-4320-bb21-027f8659e7c5",
              "name": "text",
              "value": "={{ $json._source.text }}",
              "type": "string"
            },
            {
              "id": "6830a868-6492-405b-b8fb-1ae36ea184b2",
              "name": "metadata",
              "value": "={{ $json._source.metadata }}",
              "type": "object"
            },
            {
              "id": "e5dce93c-eb16-42be-8b42-47ca5cfacc52",
              "name": "platform",
              "value": "={{ $('Queries2').item.json.platform }}",
              "type": "string"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        -736,
        3344
      ],
      "id": "d48bd3ca-20bd-432e-b09d-222aef6e0adb",
      "name": "Map Response2"
    },
    {
      "parameters": {
        "jsCode": "// 2. Format the context\nconst contextForPrompt = $input.first().json.context;\nconst systemPrompt = \"You are a strict JSON extractor.The user will supply raw excerpts from a software RFP that describe project scope and backlog. Identify every distinct Functional Requirement (what the system must do). Do NOT invent, merge, or omit anything.Return **only** a valid JSON array—no headings, no markdown, no extra text.\";\n// 3. Define the user prompt\nconst userPrompt = `Below are excerpts from an RFP that describe the project scope, backlog items, and milestones.\n\n\\n\\n### excerpts:\\n\\n${contextForPrompt}\n\nYour task is to extract all meaningful features and expectations and assign them to one of the following categories:\n\n- Functional Requirement (FR): What the system must do.\n\nInstructions:\n- Do not skip, combine, or summarize any features.\n- Do not refer to “the document” or mention formatting.\n- Do not include commentary, labels, headings, or markdown blocks.\n- Sort results using section numbers, ascending.\n- Do not include documentation, \n`;\n\nreturn {\n  json: {\n    userPrompt,\n    systemPrompt: systemPrompt\n  }\n};\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -976,
        3568
      ],
      "id": "7f1c336e-1c85-4387-bf31-796e880cf16d",
      "name": "PreparePrompts4"
    },
    {
      "parameters": {
        "content": "## Inference Functional Requirements\n",
        "height": 860,
        "width": 1740,
        "color": 6
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        -1968,
        3152
      ],
      "id": "80becf25-11e1-4e73-9530-e6697020143e",
      "name": "Sticky Note10"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "mode": "list",
          "value": "claude-3-7-sonnet-20250219",
          "cachedResultName": "Claude 3.7 Sonnet"
        },
        "options": {
          "thinking": true
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatAnthropic",
      "typeVersion": 1.3,
      "position": [
        -896,
        3760
      ],
      "id": "769e8cee-c89b-462c-aaae-80e26bd06530",
      "name": "Claude 3.",
      "credentials": {
        "anthropicApi": {
          "id": "qzCm5Ds2qD9ZY1W5",
          "name": "Anthropic account"
        }
      }
    },
    {
      "parameters": {
        "operation": "getAll",
        "indexId": "={{ $('Start RFP Analysis').first().json.body.indexName }}",
        "limit": 30,
        "simple": false,
        "options": {
          "query": "={\n  \"size\": 30,\n  \"min_score\": 1.5,\n  \"_source\": [\n    \"chunk_id\",\"section_title\",\"text\",\n    \"metadata.filename\",\"metadata.page_numbers\",\n    \"metadata.parent_chunk_id\",\"metadata.is_split_chunk\",\n    \"metadata.split_part\",\"metadata.total_parts\"\n  ],\n  \"knn\": {\n    \"field\": \"embeddings\",\n    \"query_vector\":[ {{ $json.embeddings }} ],\n    \"k\": 60,\n    \"num_candidates\": 300\n  },\n  \"query\": {\n    \"bool\": {\n      \"should\": [\n        {\n          \"match_phrase\": {\n            \"text\": {\n              \"query\": \"shall must require\",\n              \"slop\":      2,\n              \"boost\":     2.0\n            }\n          }\n        },\n        {\n          \"multi_match\": {\n            \"query\": \"{{$('Queries2').item.json.keywords.join(' ') }}\",\n            \"fields\": [\"text^2\",\"section_title^3\"],\n            \"type\": \"most_fields\",\n            \"minimum_should_match\":   1,\n            \"boost\":                  1.2\n          }\n        },\n        {\n          \"terms_set\": {\n            \"text.keyword\": {\n              \"terms\": {{ JSON.stringify($('Queries2').item.json.keywords) }},\n              \"minimum_should_match_script\": {\n                \"source\": \"1\"\n              }\n            }\n          }\n        }\n      ],\n      \"minimum_should_match\": 1\n    }\n  },\n  \"rescore\": {\n    \"window_size\": 100,\n    \"query\": {\n      \"rescore_query\": {\n        \"match_phrase\": {\n          \"text\": {\n            \"query\": \"shall must require\",\n            \"slop\": 2\n          }\n        }\n      },\n      \"query_weight\":        0.5,\n      \"rescore_query_weight\":0.5\n    }\n  },\n  \"highlight\": {\n    \"type\": \"unified\",\n    \"fields\": { \"text\": {}, \"section_title\": {} }\n  }\n}\n"
        }
      },
      "type": "n8n-nodes-base.elasticsearch",
      "typeVersion": 1,
      "position": [
        -1088,
        3344
      ],
      "id": "de3926d0-e6ca-40a7-9e92-375c8a56c1c5",
      "name": "Query - Full9",
      "alwaysOutputData": true,
      "credentials": {
        "elasticsearchApi": {
          "id": "wwaILZtoajWrVXwt",
          "name": "Elasticsearch account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// n8n Function Node: Corrected Merge Split-Chunk Groups\n\nconst grouped = {};\n\n// 1. Group all items by the “true” chunk identifier\nfor (const item of $input.all()) {\n  const data = item.json;\n  // Use parent_chunk_id if it exists, else chunk_id\n  const parentId = data.metadata?.is_split_chunk\n    ? data.metadata.parent_chunk_id\n    : data.chunk_id;\n\n  if (!grouped[parentId]) grouped[parentId] = [];\n  grouped[parentId].push(data);\n}\n\nconst merged = [];\n\n// 2. For each group, produce exactly one merged record\nfor (const [parentId, parts] of Object.entries(grouped)) {\n  // Sort by the split_part if present (else leave order)\n  parts.sort((a, b) => \n    (a.metadata?.split_part ?? 0) - (b.metadata?.split_part ?? 0)\n  );\n\n  // Stitch text together\n  const text = parts.map(p => p.text).join(\"\\n\\n\");\n\n  // Merge platform_origins arrays from all parts (dedupe by platform)\n  const allOrigins = parts.flatMap(p => p.platform_origins || []);\n  const platform_origins = [];\n  for (const o of allOrigins) {\n    if (!platform_origins.some(existing => existing.platform === o.platform)) {\n      platform_origins.push(o);\n    }\n  }\n\n  // Pick the highest-scoring part to inherit section_title, filename, pages, and score\n  const bestPart = parts.reduce((best, p) => \n    p._score > best._score ? p : best\n  , parts[0]);\n\n  // Build the single merged record\n  const record = {\n    chunk_id: parentId,\n    _score: bestPart._score,\n    section_title: bestPart.section_title,\n    text,\n    metadata: {\n      ...bestPart.metadata,\n      is_split_chunk: false,\n      parent_chunk_id: undefined,\n      split_part: undefined,\n      total_parts: undefined\n    },\n    platform_origins\n  };\n\n  merged.push({ json: record });\n}\nmerged.sort((a, b) => b.json._score - a.json._score);\nreturn merged;\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1536,
        3568
      ],
      "id": "6adcdee4-e549-477a-8368-ff7a4927c477",
      "name": "Merge Chunks5"
    },
    {
      "parameters": {
        "jsCode": "// n8n Function Node: Dedupe → Merge Origins → Filter → Sort → Fallback\n\nconst MIN_SCORE = 1.0;\nconst DESIRED_COUNT = 20;\n\n// Step 1: Deduplicate & merge platform origins, keep highest‐score record\nconst seen = {};\nfor (const item of $input.all()) {\n  const { chunk_id, platform, _score, ...rest } = item.json;\n  \n  if (!seen[chunk_id]) {\n    // First time seeing this chunk\n    seen[chunk_id] = {\n      chunk_id,\n      _score,\n      ...rest,\n      platform_origins: [{ platform, score: _score }],\n    };\n  } else {\n    // Merge new platform origin\n    const record = seen[chunk_id];\n    if (!record.platform_origins.some(p => p.platform === platform)) {\n      record.platform_origins.push({ platform, score: _score });\n    }\n    // If this hit has a higher score, overwrite core fields\n    if (_score > record._score) {\n      record._score = _score;\n      Object.assign(record, rest);\n    }\n  }\n}\n\n// Convert deduped map back to array of items\nlet deduped = Object.values(seen).map(r => ({ json: r }));\n\n// Step 2: Filter by score and sort descending\nlet filtered = deduped\n  .filter(item => item.json._score >= MIN_SCORE)\n  .sort((a, b) => b.json._score - a.json._score);\n\n// Step 3: Fallback if too few hits\nif (filtered.length < DESIRED_COUNT) {\n  // Return top DESIRED_COUNT from deduped (regardless of score)\n  filtered = deduped\n    .sort((a, b) => b.json._score - a.json._score)\n    .slice(0, DESIRED_COUNT);\n}\n\n// Step 4: Ensure we only return up to DESIRED_COUNT\nfiltered = filtered.slice(0, DESIRED_COUNT);\n\n// Return in n8n-compatible format\nreturn filtered;\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -560,
        3344
      ],
      "id": "4f3f8c58-d3bb-464c-b4de-177dec6ee9fd",
      "name": "Deduplicate and Best Score6"
    },
    {
      "parameters": {
        "jsCode": "// Configuration\nconst TOKEN_LIMIT = 7000;\nconst MIN_STRONG_SCORE = 16.0;\n\n// Rough token estimator (1 token ~ 4 characters)\nfunction estimateTokenCount(text) {\n  if (!text) return 0;\n  return Math.ceil(text.length / 4);\n}\n\n// Input already filtered and sorted!\nconst chunks = $input.all().map(item => item.json);\n\n// Build the final list\nconst selectedChunks = [];\nlet tokenCount = 0;\n\nfor (const chunk of chunks) {\n  const tokens = estimateTokenCount(chunk.text);\n\n  if ((tokenCount + tokens) <= TOKEN_LIMIT) {\n    selectedChunks.push(chunk);\n    tokenCount += tokens;\n  } else if (chunk._score >= MIN_STRONG_SCORE) {\n    // Allow overflow for very strong chunks\n    selectedChunks.push(chunk);\n    tokenCount += tokens;\n  } else {\n    break; // Stop adding\n  }\n}\n\n// Prepare output\nconst output = selectedChunks.map(chunk => ({ json: chunk }));\n\n// Add token usage metadata (attach to first item for simplicity)\nif (output.length > 0) {\n  output[0].json._token_summary = {\n    total_tokens_estimated: tokenCount,\n    total_chunks_selected: selectedChunks.length,\n  };\n}\n\nreturn output;\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1360,
        3568
      ],
      "id": "2ee3b373-15ee-4f03-817f-07b9b96ab28e",
      "name": "Token Budgeting2"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "gpt-4.1-mini",
          "mode": "list",
          "cachedResultName": "gpt-4.1-mini"
        },
        "options": {
          "temperature": 0.1
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        -768,
        3760
      ],
      "id": "720e9b3a-46c2-40fd-a58c-8de277c9cfd8",
      "name": "OpenAI Chat Model3",
      "credentials": {
        "openAiApi": {
          "id": "M8xqWvEC6mH6LNuk",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "/**\n * Prepare ES chunks for Claude, without chunk‐length limiting.\n */\nfunction prepareSecurityRegulatoryContextForClaude(esResults) {\n  if (!Array.isArray(esResults)) {\n    throw new Error(\"Input must be an array of Elasticsearch results\");\n  }\n\n  // simple Markdown escaper\n  function mdEscape(str) {\n    return str.replace(/(`|\\*|_|~|>|\\[|\\])/g, \"\\\\$1\");\n  }\n\n  // normalize bullets and split into lines\n  function cleanText(raw) {\n    return raw\n      .replace(/^\\s*-\\s+/gm, \"\\n- \")\n      .replace(/^\\s*\\*\\s+/gm, \"\\n- \")\n      .replace(/[ \\t]+/g, \" \")\n      .replace(/\\. ([A-Z])/g, \".\\n$1\")\n      .replace(/\\n{3,}/g, \"\\n\\n\")\n      .trim();\n  }\n\n  const blocks = esResults.map(chunk => {\n    const { chunk_id, section_title, text = \"\", metadata = {}, _score, regScore, locScore } = chunk;\n\n    // Heading\n    const title = section_title\n      ? mdEscape(section_title)\n      : `Untitled Section (${chunk_id})`;\n\n    // Build YAML metadata\n    const pages = Array.isArray(metadata.page_numbers)\n      ? metadata.page_numbers.join(\", \")\n      : metadata.page_numbers || \"Unknown\";\n\n    const metaLines = [\n      `filename: ${metadata.filename || \"Unknown Document\"}`,\n      `pages: ${pages}`,\n      `score: ${_score.toFixed(2)}`,\n    ];\n    if (typeof regScore === \"number\") metaLines.push(`regScore: ${regScore.toFixed(2)}`);\n    if (typeof locScore === \"number\") metaLines.push(`locScore: ${locScore.toFixed(2)}`);\n    if (metadata.document_type) metaLines.push(`type: ${metadata.document_type}`);\n    if (metadata.languages) metaLines.push(`language: ${metadata.languages.join(\", \")}`);\n\n    const metaBlock = metaLines.join(\"\\n\");\n\n    // Clean and escape body\n    const body = mdEscape(cleanText(text));\n\n    return [\n      `### ${title}`,\n      \"```yaml\",\n      metaBlock,\n      \"```\",\n      \"\",\n      body\n    ].join(\"\\n\");\n  });\n\n  // Join with clear separators\n  return blocks.join(\"\\n\\n---\\n\\n\");\n}\n\n// Usage in n8n Function node:\nconst esResults = $input.all().map(i => i.json);\nconst contextForPrompt = prepareSecurityRegulatoryContextForClaude(esResults);\n\nreturn [{ json: { context: contextForPrompt } }];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1168,
        3568
      ],
      "id": "8f2776c8-cd4f-45ad-b727-628f17ee03c1",
      "name": "Prepare Context4"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ $json.userPrompt }}",
        "hasOutputParser": true,
        "options": {
          "systemMessage": "={{ $json.systemPrompt }}"
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.9,
      "position": [
        -736,
        3568
      ],
      "id": "d2940ebf-7145-40af-9fad-6371efb035ba",
      "name": "Functional requirements",
      "onError": "continueErrorOutput"
    },
    {
      "parameters": {},
      "type": "@n8n/n8n-nodes-langchain.toolThink",
      "typeVersion": 1,
      "position": [
        -624,
        3760
      ],
      "id": "9888ffee-9211-47eb-bf8d-d8a134b6433a",
      "name": "Think"
    },
    {
      "parameters": {
        "jsCode": "/**\n * n8n Function node\n * Input  : first item from the previous “platform extraction” node\n *          {\n *            output: {\n *              platforms: [ ... ],\n *              rationale: \"...\"\n *            }\n *          }\n * Output : { detectedPlatformsSnippet: '### DETECTED_PLATFORMS …' }\n */\n\nconst { output } = $input.first().json;\n// --- Basic sanity check ----------------------------------------------------\nif (!output?.platforms || !Array.isArray(output.platforms)) {\n  throw new Error('Expected output.platforms array from previous step.');\n}\n\n// --- Build the snippet -----------------------------------------------------\nconst detectedPlatformsSnippet = [\n  '### DETECTED_PLATFORMS (authoritative, extracted in a prior step)',\n  JSON.stringify(\n    {\n      platforms: output.platforms,\n      rationale: output.rationale,\n    },\n    null,\n    2 // pretty-print indent\n  ),\n  '',\n  'You must treat the array in \"platforms\" as ground truth when selecting or defaulting technologies.',\n].join('\\n');\n\n// --- Return for the next node ---------------------------------------------\nreturn [\n  {\n    json: {\n      detectedPlatformsSnippet,\n    },\n  },\n];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -2784,
        3568
      ],
      "id": "a364b975-be3a-4add-bf8f-b0da6804492d",
      "name": "Platforms Output"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "gpt-4.1",
          "mode": "list",
          "cachedResultName": "gpt-4.1"
        },
        "options": {
          "temperature": 0.1
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        -2000,
        4720
      ],
      "id": "0cb2da5e-8c47-4312-8aff-d38cae4b39a7",
      "name": "GPT 4.1 Mini2",
      "credentials": {
        "openAiApi": {
          "id": "M8xqWvEC6mH6LNuk",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ $json.userPrompt }}",
        "hasOutputParser": true,
        "options": {
          "systemMessage": "={{ $json.systemPrompt }}"
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.9,
      "position": [
        -1680,
        4464
      ],
      "id": "5a8ca7e1-3a56-4e73-a417-4583dc1ebd9f",
      "name": "Team Composition",
      "onError": "continueErrorOutput"
    },
    {
      "parameters": {
        "jsCode": "/* n8n Function node\n   Builds the prompt for the “Team-Composition” LLM step.\n   ➜  Output JSON: { systemPrompt, userPrompt }\n*/\n\n// ---------------------------------------------------------------------------\n// 1. Collect fixed snippets prepared in earlier steps\n// ---------------------------------------------------------------------------\nconst {\n   detectedPlatformsSnippet,\n} = $('Dependencies1').first().json;\n\n// Optional extra RAG context (not mandatory)\nconst techstack = $('Techstack Output').first().json.detectedTechStackSnippet;\n\n// ---------------------------------------------------------------------------\n// 2. Static system prompt (sent once per LLM call)\n// ---------------------------------------------------------------------------\nconst systemPrompt =\n  'You are a senior delivery manager who produces concise team-composition plans ' +\n  'for software projects. Merge the fixed project constraints below with standard ' +\n  'Agile delivery practice. Output **only** a valid JSON object under the key \"team_plan\".';\n\n// ---------------------------------------------------------------------------\n// 3. Dynamic user prompt assembled from all snippets plus rules\n// ---------------------------------------------------------------------------\nconst userPrompt = `\nONLY output the JSON object—no other text.\n\n### CONTEXT_SNIPPETS\n\n${techstack}\n\n${detectedPlatformsSnippet}\n\n### TASK\nDefine the delivery roles needed to execute this project in line with the timeline and constraints.\nDo **not** estimate sprints, person-days, rates, or buffers—those will be calculated later.\nJust list each role, its seniority (e.g. Mid, Senior, Principal), and the average full-time-equivalent (FTE) allocation over the core delivery period.\n\n### DEFAULT & FALLBACK RULES\n\n-  Platform-driven roles:\n  • \"Web applications\" ⇒ Frontend Developer (React, Next.js)\n  • \"Mobile apps\" ⇒ Mobile Developer (Flutter by default; Swift/Kotlin if native)\n  • \"Admin portal\" ⇒ Frontend Developer with design system experience (Shadcn, Material UI)\n  • \"Backend/API services\" ⇒ Backend Developer (PHP Symfony, Node.js, or inferred)\n  • \"CMS\" or content-heavy site ⇒ CMS Developer or Content Specialist\n\nBy default add 1 Solution Arhitect at 30% -  depending on the complexity.\n\nBy default we have 1 project manager and 1 business analyst.\nIf the project is not too complex, use one Hybrid role (50% Project Manager and 50% Business Analyst) - Called: Product Manager.\n\n-  If compliance is \"Moderately Regulated\" or stricter:\n  • Add 1 QA Engineer minimum but in 30%\n  • Mention security-aware development practices in rationale\n  If compliance is \"Highly Regulated\":\n  add 1 QA at 50%\n\n-  If deployment seems classic (implicit or explicit):\n  • Add DevOps Engineer at 25% - if its complicated then add it at 50%\n\n-  If mobile apps required:\n  • Prefer Flutter unless RFP clearly prefers native (then Swift/Kotlin)\nIf Flutter, use 1 Flutter developer.\nIf iOS & Android, user 1 for each.\n\n-  If analytics, SEO, or tracking required:\n  • Include Analytics Specialist or Web Analyst at 30%\n\n-  If project includes “training”, “handover”, or “documentation”:\n  • Add Knowledge Transfer Lead or Documentation Specialist\n\n-  If delivery_model is “Full launch”:\n  • Treat it as a single delivery phase\n\n-  If MVP, phased delivery, or iterations mentioned:\n  • Scale team accordingly across delivery periods if needed\n\n-  If functional scope is large or complex (based on feature count or diversity):\n  • Increase number of developers or FTE allocation\n\n  -  If time line is tight:\n  • Increase number of developers or FTE allocation\n\n-  If 3rd party integrations like CRM, ERP, SSO, Stripe, etc. are required:\n  • Add some percentage to Solution Arhitect \n\n  If development aproach would be Heavily AI Generated code with Shadcn:\n  Don't add Designers. Add just one 100% NodeJS developer for development.\n  If Design is custom or if the project needs it, put 1 Designer at about 30%.\n\n  If the project needs AI, add 1 AI Engineer and, if data preparation is needed, add 1 Data Engineer.\n\n  If any requirement mentions login, authentication, payments, user roles, or GDPR, consider adding 10% to QA Engineer or Solution Architect FTE for security tasks.\n\n-  Rationale must:\n  • Start with **Extracted:**, **Inferred:**, or **Defaulted:**\n  • Be ≤ 200 words\n  • Mention platform/stack mapping to skills\n  • Justify any specialized roles added\n  **IMPORTANT: Format the rationale field using markdown markup for better readability:**\n- Use **bold text** for key points and important terms\n- Use ## headers for main sections\n- Use ### subheaders for subsections  \n- Use bullet points (- item) for lists\n- Use numbered lists (1. item) for sequential steps\n- Use \"code\" formatting for technical terms\n- Structure the rationale with clear sections and hierarchy\n\nONLY output the JSON object—no other text.\n`;\n\nreturn {\n  json: {\n    systemPrompt,\n    userPrompt,\n  },\n};\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1984,
        4464
      ],
      "id": "5f1e5867-a324-4ae7-90c9-b686df6f1c4f",
      "name": "Code"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "claude-sonnet-4-20250514",
          "mode": "list",
          "cachedResultName": "Claude Sonnet 4"
        },
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatAnthropic",
      "typeVersion": 1.3,
      "position": [
        -1776,
        4752
      ],
      "id": "ee7b03c7-9724-412a-b452-9ca14e2306ce",
      "name": "Anthropic Chat Model",
      "credentials": {
        "anthropicApi": {
          "id": "qzCm5Ds2qD9ZY1W5",
          "name": "Anthropic account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "/**\n * n8n Function node\n * Input (first item):\n * {\n *   \"output\": {\n *     \"features\": [\n *       { \"title\": \"...\", \"description\": \"...\", \"reference_section\": \"...\" },\n *       ...\n *     ]\n *   }\n * }\n *\n * Output:\n * { featureListSnippet: '### KEY_FEATURES …' }\n */\n\nconst feat = $input.first().json.output || {};\n\n// --- Basic validation ------------------------------------------------------\nif (!Array.isArray(feat.features) || feat.features.length === 0) {\n  throw new Error('Expected non-empty output.features array from previous step.');\n}\n\n// --- Build the snippet -----------------------------------------------------\nconst featureListSnippet = [\n  '### KEY_FEATURES (authoritative, extracted in a prior step)',\n  JSON.stringify(feat.features, null, 2), // pretty-printed JSON array\n  '',\n  'Treat this feature list as fixed functional scope for downstream sizing, sequencing, and cost estimation.',\n].join('\\n');\n\n// --- Return for downstream use --------------------------------------------\nreturn [\n  {\n    json: {\n      featureListSnippet,\n    },\n  },\n];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -128,
        3568
      ],
      "id": "6ef021ca-e2b4-48eb-b186-4e6ba90c5c15",
      "name": "Functional Requirements Output"
    },
    {
      "parameters": {
        "jsCode": "/**\n * n8n Function  ➜  “Build NFR query-pack”\n * Returns a single array item (same shape as your feature pack)\n */\nreturn [\n  {\n    json: {\n      query_type: \"non_functional_requirements\",\n      query:\n        \"Extract every non-functional requirement (performance, security, availability, scalability, accessibility, SEO, DevOps, monitoring, localization) described in the RFP that will influence architecture, DevOps, or QA effort.\",\n      /* NFR vocabulary */\n      keywords: [\n        /* performance & scale */\n        \"performance\", \"latency\", \"response time\", \"rps\", \"tps\",\n        \"load time\", \"web vitals\", \"core web vitals\", \"lighthouse\",\n        \"concurrency\", \"throughput\", \"scalability\", \"autoscale\",\n\n        /* availability & reliability */\n        \"uptime\", \"availability\", \"sla\", \"99.9%\", \"ha\", \"redundancy\",\n        \"failover\", \"disaster recovery\", \"rto\", \"rpo\",\n\n        /* security & privacy */\n        \"encryption\", \"tls\", \"ssl\", \"https\", \"owasp\", \"penetration test\",\n        \"vulnerability scan\", \"sso\", \"oauth\", \"saml\", \"jwt\", \"waf\",\n        \"access control\", \"role based access\", \"audit log\",\n\n        /* accessibility & seo */\n        \"wcag\", \"accessibility\", \"screen reader\", \"seo\", \"page speed\",\n        \"structured data\", \"sitemap.xml\",\n\n        /* DevOps & monitoring */\n        \"ci/cd\", \"pipeline\", \"deployment\", \"kubernetes\", \"docker\",\n        \"infrastructure as code\", \"terraform\", \"ansible\",\n        \"monitoring\", \"alerting\", \"logging\", \"grafana\", \"prometheus\",\n        \"observability\", \"sli\", \"slo\",\n\n        /* maintenance & support */\n        \"maintainability\", \"upgrade\", \"patching\", \"rollback\",\n        \"support window\", \"support hours\",\n\n          /* localisation & content scope */\n  \"localisation\", \"localization\", \"multilingual\", \"multi-language\",\n  \"translation\", \"i18n\", \"l10n\", \"languages\", \"locale\", \"page count\",\n  \"templates\", \"content migration\"\n      ],\n\n      /* Phrase boost for classic NFR language */\n      phrase: \"performance latency uptime availability security scalability localization\",\n\n      /* Rescore phrase for tight relevance */\n      rescore_query: \"performance OR uptime OR security OR scalability\",\n\n      description:\n        \"Surface all non-functional requirements that impact architecture, DevOps, security, performance, monitoring, or support.\"\n    }\n  }\n];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        448,
        3360
      ],
      "id": "5f85f83b-b9ec-4db8-b875-acd37975ee02",
      "name": "Queries8"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "http://192.168.20.70:11434/api/embed",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"model\": \"nomic-embed-text:latest\",\n  \"input\": [\"{{ $json.query }}\"]\n}",
        "options": {}
      },
      "id": "2bf341b4-403b-4101-9366-9f59b99d0c1c",
      "name": "Embed Query - ollama8",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        624,
        3360
      ]
    },
    {
      "parameters": {
        "jsCode": "// 1. Gather ES-RAG context\nconst contextForPrompt = $input.first().json.context;\n\n// 2. System prompt (static)\nconst systemPrompt = `\nYou are a strict JSON extractor. The user will supply raw excerpts from a software RFP.\nIdentify every distinct Non-Functional Requirement (how the system must perform or be operated).\nDo NOT invent, merge, or omit anything.\nDo NOT extract functional requirements.\nReturn **only** a valid JSON array—no headings, no markdown, no extra text.\n`;\n\n// 3. User prompt (dynamic)\nconst userPrompt = `\nBelow are RFP excerpts related to performance, security, scalability, uptime, DevOps, accessibility, or other non-functional expectations.\n\n### excerpts:\n\n${contextForPrompt}\n\nInstructions:\n- Extract each non-functional requirement (NFR) as its own object.\n- Make sure that there are no functional requirements\n- Categories to use: Performance, Availability, Security, Scalability, Accessibility, SEO, Localization/Languages, DevOps/Deployment, Monitoring/Logging, Maintainability, Compliance.\n- Do not summarise or combine items.\n- Provide a short \"rationale\" if the category is inferred.\n- Sort by section number ascending.\n- I Localization / Languages are nonexistent, choose English.\n- Return **only** the JSON\n— no extra text.\n`;\n\nreturn {\n  json: {\n    userPrompt,\n    systemPrompt\n  }\n};\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1008,
        3584
      ],
      "id": "9f300114-513e-4017-9e9f-28f02f446316",
      "name": "PreparePrompts7"
    },
    {
      "parameters": {
        "content": "## Inference NonFunctional Requirements\n",
        "height": 860,
        "width": 1740,
        "color": 2
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        32,
        3168
      ],
      "id": "37ca3bcf-617f-4dea-aa7b-ee775106e2e5",
      "name": "Sticky Note"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "mode": "list",
          "value": "claude-3-7-sonnet-20250219",
          "cachedResultName": "Claude 3.7 Sonnet"
        },
        "options": {
          "thinking": true
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatAnthropic",
      "typeVersion": 1.3,
      "position": [
        1088,
        3792
      ],
      "id": "674e399f-4597-4db0-9c54-e4e8b8f1be54",
      "name": "Claude 3.1",
      "credentials": {
        "anthropicApi": {
          "id": "qzCm5Ds2qD9ZY1W5",
          "name": "Anthropic account"
        }
      }
    },
    {
      "parameters": {
        "operation": "getAll",
        "indexId": "={{ $('Start RFP Analysis').first().json.body.indexName }}",
        "limit": 30,
        "simple": false,
        "options": {
          "query": "={\n  \"size\": 30,\n  \"min_score\": 1.5,\n  \"_source\": [\n    \"chunk_id\",\"section_title\",\"text\",\n    \"metadata.filename\",\"metadata.page_numbers\",\n    \"metadata.parent_chunk_id\",\"metadata.is_split_chunk\",\n    \"metadata.split_part\",\"metadata.total_parts\"\n  ],\n  \"knn\": {\n    \"field\": \"embeddings\",\n    \"query_vector\": [ {{ $json.embeddings }} ],\n    \"k\": 60,\n    \"num_candidates\": 300\n  },\n  \"query\": {\n    \"bool\": {\n      \"should\": [\n        {\n          \"match_phrase\": {\n            \"text\": {\n              \"query\": \"performance latency uptime availability\",\n              \"slop\": 3,\n              \"boost\": 2.0\n            }\n          }\n        },\n        {\n          \"multi_match\": {\n            \"query\": \"{{ $('Queries8').item.json.keywords.join(' ') }}\",\n            \"fields\": [\"text^2\",\"section_title^3\"],\n            \"type\": \"most_fields\",\n            \"minimum_should_match\": 1,\n            \"boost\": 1.2\n          }\n        },\n        {\n          \"terms_set\": {\n            \"text.keyword\": {\n              \"terms\": {{ JSON.stringify($('Queries8').item.json.keywords) }},\n              \"minimum_should_match_script\": { \"source\": \"1\" }\n            }\n          }\n        }\n      ],\n      \"minimum_should_match\": 1\n    }\n  },\n  \"rescore\": {\n    \"window_size\": 100,\n    \"query\": {\n      \"rescore_query\": {\n        \"match_phrase\": {\n          \"text\": {\n            \"query\": \"{{ $('Queries8').item.json.rescore_query }}\",\n            \"slop\": 2\n          }\n        }\n      },\n      \"query_weight\": 0.5,\n      \"rescore_query_weight\": 0.5\n    }\n  },\n  \"highlight\": {\n    \"type\": \"unified\",\n    \"fields\": { \"text\": {}, \"section_title\": {} }\n  }\n}\n"
        }
      },
      "type": "n8n-nodes-base.elasticsearch",
      "typeVersion": 1,
      "position": [
        992,
        3360
      ],
      "id": "c837310d-21e0-4c7d-b69e-ccf4d99acfef",
      "name": "Query - Full11",
      "alwaysOutputData": true,
      "credentials": {
        "elasticsearchApi": {
          "id": "wwaILZtoajWrVXwt",
          "name": "Elasticsearch account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// n8n Function Node: Corrected Merge Split-Chunk Groups\n\nconst grouped = {};\n\n// 1. Group all items by the “true” chunk identifier\nfor (const item of $input.all()) {\n  const data = item.json;\n  // Use parent_chunk_id if it exists, else chunk_id\n  const parentId = data.metadata?.is_split_chunk\n    ? data.metadata.parent_chunk_id\n    : data.chunk_id;\n\n  if (!grouped[parentId]) grouped[parentId] = [];\n  grouped[parentId].push(data);\n}\n\nconst merged = [];\n\n// 2. For each group, produce exactly one merged record\nfor (const [parentId, parts] of Object.entries(grouped)) {\n  // Sort by the split_part if present (else leave order)\n  parts.sort((a, b) => \n    (a.metadata?.split_part ?? 0) - (b.metadata?.split_part ?? 0)\n  );\n\n  // Stitch text together\n  const text = parts.map(p => p.text).join(\"\\n\\n\");\n\n  // Merge platform_origins arrays from all parts (dedupe by platform)\n  const allOrigins = parts.flatMap(p => p.platform_origins || []);\n  const platform_origins = [];\n  for (const o of allOrigins) {\n    if (!platform_origins.some(existing => existing.platform === o.platform)) {\n      platform_origins.push(o);\n    }\n  }\n\n  // Pick the highest-scoring part to inherit section_title, filename, pages, and score\n  const bestPart = parts.reduce((best, p) => \n    p._score > best._score ? p : best\n  , parts[0]);\n\n  // Build the single merged record\n  const record = {\n    chunk_id: parentId,\n    _score: bestPart._score,\n    section_title: bestPart.section_title,\n    text,\n    metadata: {\n      ...bestPart.metadata,\n      is_split_chunk: false,\n      parent_chunk_id: undefined,\n      split_part: undefined,\n      total_parts: undefined\n    },\n    platform_origins\n  };\n\n  merged.push({ json: record });\n}\nmerged.sort((a, b) => b.json._score - a.json._score);\nreturn merged;\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        448,
        3584
      ],
      "id": "38d24a7d-5619-40db-aa71-cff8fd118925",
      "name": "Merge Chunks8"
    },
    {
      "parameters": {
        "jsCode": "// n8n Function Node: Dedupe → Merge Origins → Filter → Sort → Fallback\n\nconst MIN_SCORE = 1.0;\nconst DESIRED_COUNT = 20;\n\n// Step 1: Deduplicate & merge platform origins, keep highest‐score record\nconst seen = {};\nfor (const item of $input.all()) {\n  const { chunk_id, platform, _score, ...rest } = item.json;\n  \n  if (!seen[chunk_id]) {\n    // First time seeing this chunk\n    seen[chunk_id] = {\n      chunk_id,\n      _score,\n      ...rest,\n      platform_origins: [{ platform, score: _score }],\n    };\n  } else {\n    // Merge new platform origin\n    const record = seen[chunk_id];\n    if (!record.platform_origins.some(p => p.platform === platform)) {\n      record.platform_origins.push({ platform, score: _score });\n    }\n    // If this hit has a higher score, overwrite core fields\n    if (_score > record._score) {\n      record._score = _score;\n      Object.assign(record, rest);\n    }\n  }\n}\n\n// Convert deduped map back to array of items\nlet deduped = Object.values(seen).map(r => ({ json: r }));\n\n// Step 2: Filter by score and sort descending\nlet filtered = deduped\n  .filter(item => item.json._score >= MIN_SCORE)\n  .sort((a, b) => b.json._score - a.json._score);\n\n// Step 3: Fallback if too few hits\nif (filtered.length < DESIRED_COUNT) {\n  // Return top DESIRED_COUNT from deduped (regardless of score)\n  filtered = deduped\n    .sort((a, b) => b.json._score - a.json._score)\n    .slice(0, DESIRED_COUNT);\n}\n\n// Step 4: Ensure we only return up to DESIRED_COUNT\nfiltered = filtered.slice(0, DESIRED_COUNT);\n\n// Return in n8n-compatible format\nreturn filtered;\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1392,
        3360
      ],
      "id": "89301eae-0884-44c1-aac6-778b5f10b1c1",
      "name": "Deduplicate and Best Score8"
    },
    {
      "parameters": {
        "jsCode": "// Configuration\nconst TOKEN_LIMIT = 7000;\nconst MIN_STRONG_SCORE = 16.0;\n\n// Rough token estimator (1 token ~ 4 characters)\nfunction estimateTokenCount(text) {\n  if (!text) return 0;\n  return Math.ceil(text.length / 4);\n}\n\n// Input already filtered and sorted!\nconst chunks = $input.all().map(item => item.json);\n\n// Build the final list\nconst selectedChunks = [];\nlet tokenCount = 0;\n\nfor (const chunk of chunks) {\n  const tokens = estimateTokenCount(chunk.text);\n\n  if ((tokenCount + tokens) <= TOKEN_LIMIT) {\n    selectedChunks.push(chunk);\n    tokenCount += tokens;\n  } else if (chunk._score >= MIN_STRONG_SCORE) {\n    // Allow overflow for very strong chunks\n    selectedChunks.push(chunk);\n    tokenCount += tokens;\n  } else {\n    break; // Stop adding\n  }\n}\n\n// Prepare output\nconst output = selectedChunks.map(chunk => ({ json: chunk }));\n\n// Add token usage metadata (attach to first item for simplicity)\nif (output.length > 0) {\n  output[0].json._token_summary = {\n    total_tokens_estimated: tokenCount,\n    total_chunks_selected: selectedChunks.length,\n  };\n}\n\nreturn output;\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        624,
        3584
      ],
      "id": "ddcdec73-d1d6-4d45-96ce-1586499893f9",
      "name": "Token Budgeting7"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "gpt-4.1-mini",
          "mode": "list",
          "cachedResultName": "gpt-4.1-mini"
        },
        "options": {
          "maxTokens": 10000,
          "temperature": 0.1
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        1232,
        3792
      ],
      "id": "6c3a7238-70b1-49bb-a7df-5de84ee2dfd4",
      "name": "OpenAI Chat Model",
      "credentials": {
        "openAiApi": {
          "id": "M8xqWvEC6mH6LNuk",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "/**\n * Prepare ES chunks for Claude, without chunk‐length limiting.\n */\nfunction prepareSecurityRegulatoryContextForClaude(esResults) {\n  if (!Array.isArray(esResults)) {\n    throw new Error(\"Input must be an array of Elasticsearch results\");\n  }\n\n  // simple Markdown escaper\n  function mdEscape(str) {\n    return str.replace(/(`|\\*|_|~|>|\\[|\\])/g, \"\\\\$1\");\n  }\n\n  // normalize bullets and split into lines\n  function cleanText(raw) {\n    return raw\n      .replace(/^\\s*-\\s+/gm, \"\\n- \")\n      .replace(/^\\s*\\*\\s+/gm, \"\\n- \")\n      .replace(/[ \\t]+/g, \" \")\n      .replace(/\\. ([A-Z])/g, \".\\n$1\")\n      .replace(/\\n{3,}/g, \"\\n\\n\")\n      .trim();\n  }\n\n  const blocks = esResults.map(chunk => {\n    const { chunk_id, section_title, text = \"\", metadata = {}, _score, regScore, locScore } = chunk;\n\n    // Heading\n    const title = section_title\n      ? mdEscape(section_title)\n      : `Untitled Section (${chunk_id})`;\n\n    // Build YAML metadata\n    const pages = Array.isArray(metadata.page_numbers)\n      ? metadata.page_numbers.join(\", \")\n      : metadata.page_numbers || \"Unknown\";\n\n    const metaLines = [\n      `filename: ${metadata.filename || \"Unknown Document\"}`,\n      `pages: ${pages}`,\n      `score: ${_score.toFixed(2)}`,\n    ];\n    if (typeof regScore === \"number\") metaLines.push(`regScore: ${regScore.toFixed(2)}`);\n    if (typeof locScore === \"number\") metaLines.push(`locScore: ${locScore.toFixed(2)}`);\n    if (metadata.document_type) metaLines.push(`type: ${metadata.document_type}`);\n    if (metadata.languages) metaLines.push(`language: ${metadata.languages.join(\", \")}`);\n\n    const metaBlock = metaLines.join(\"\\n\");\n\n    // Clean and escape body\n    const body = mdEscape(cleanText(text));\n\n    return [\n      `### ${title}`,\n      \"```yaml\",\n      metaBlock,\n      \"```\",\n      \"\",\n      body\n    ].join(\"\\n\");\n  });\n\n  // Join with clear separators\n  return blocks.join(\"\\n\\n---\\n\\n\");\n}\n\n// Usage in n8n Function node:\nconst esResults = $input.all().map(i => i.json);\nconst contextForPrompt = prepareSecurityRegulatoryContextForClaude(esResults);\n\nreturn [{ json: { context: contextForPrompt } }];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        832,
        3584
      ],
      "id": "555c9959-444d-4680-a311-c08d2428b082",
      "name": "Prepare Context6"
    },
    {
      "parameters": {},
      "type": "@n8n/n8n-nodes-langchain.toolThink",
      "typeVersion": 1,
      "position": [
        1360,
        3792
      ],
      "id": "097753ac-2374-4e7d-937b-8f1697f08344",
      "name": "Think1"
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "17f9e7d3-307e-4d60-92ef-e32285cbec29",
              "name": "_score",
              "value": "={{ $json._score }}",
              "type": "number"
            },
            {
              "id": "618f58cd-27c7-4ab4-8612-899f048afb6c",
              "name": "_id",
              "value": "={{ $json._id }}",
              "type": "string"
            },
            {
              "id": "a8cfb079-48c6-4ce2-a54c-251304107206",
              "name": "chunk_id",
              "value": "={{ $json._source.chunk_id }}",
              "type": "string"
            },
            {
              "id": "22e6e029-7ff1-4870-a1c2-d3b025a2748b",
              "name": "section_title",
              "value": "={{ $json._source.section_title }}",
              "type": "string"
            },
            {
              "id": "27e9a9ac-b6ed-4320-bb21-027f8659e7c5",
              "name": "text",
              "value": "={{ $json._source.text }}",
              "type": "string"
            },
            {
              "id": "6830a868-6492-405b-b8fb-1ae36ea184b2",
              "name": "metadata",
              "value": "={{ $json._source.metadata }}",
              "type": "object"
            },
            {
              "id": "e5dce93c-eb16-42be-8b42-47ca5cfacc52",
              "name": "platform",
              "value": "={{ $('Queries8').item.json.platform }}",
              "type": "string"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        1200,
        3360
      ],
      "id": "a3a3eed7-c986-4ac0-a11c-1467be9f6496",
      "name": "Map Response8"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ $json.userPrompt }}",
        "hasOutputParser": true,
        "options": {
          "systemMessage": "={{ $json.systemPrompt }}"
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.9,
      "position": [
        1248,
        3584
      ],
      "id": "5ea25e7d-73db-4a5d-82ab-c557eb864d67",
      "name": "NonFunctional Requirements",
      "onError": "continueErrorOutput"
    },
    {
      "parameters": {
        "jsCode": "/**\n * n8n Function node ─ “Build NFR snippet”\n *\n * Input shape (first item):\n * [\n *   {\n *     output: [\n *       { title, description, category, rationale, reference_section },\n *       ...\n *     ]\n *   }\n * ]\n *\n * Output (for the next node):\n * { nonFunctionalRequirementsSnippet: '### NON_FUNCTIONAL_REQUIREMENTS …' }\n */\n\n// --- Grab first item -------------------------------------------------------\nconst nfrArray = $input.first().json.output || [];\n\n// --- Basic validation ------------------------------------------------------\nif (!Array.isArray(nfrArray) || nfrArray.length === 0) {\n  throw new Error('Expected non-empty output array of NFR objects from previous step.');\n}\n\n// --- Build the snippet -----------------------------------------------------\nconst nonFunctionalRequirementsSnippet = [\n  '### NON_FUNCTIONAL_REQUIREMENTS (authoritative, extracted in a prior step)',\n  JSON.stringify(nfrArray, null, 2),  // pretty-printed JSON array\n  '',\n  'Treat this NFR list as fixed scope impacting architecture, DevOps, performance, and QA in downstream estimation.',\n].join('\\n');\n\n// --- Return for downstream use --------------------------------------------\nreturn [\n  {\n    json: {\n      nonFunctionalRequirementsSnippet,\n    },\n  },\n];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1808,
        3584
      ],
      "id": "290236eb-cbd9-400a-913a-e28201a670e3",
      "name": "NonFunctional Requirements Output"
    },
    {
      "parameters": {
        "jsCode": "return [\n  {\n    json: {\n      key: \"web_stack\",\n      query: \"What frontend or web frameworks are mentioned?\",\n      keywords: \"React, Angular, Vue, Svelte, Next.js, Nuxt.js, web framework, frontend, front-end, web app, web application, JavaScript, TypeScript, HTML, CSS\",\n      phrase: \"frontend web application\",\n      rescore_query: \"React OR Angular OR Vue OR Next.js\"\n    }\n  },\n  {\n    json: {\n      key: \"design\",\n      query: \"What design system or UI components are referenced?\",\n      keywords: \"Shadcn, Tailwind, Bootstrap, Material UI, design system, UI kit, style guide, branding, UX, Figma, wireframes, visual design, WCAG, Radix, Ant Design\",\n      phrase: \"design system UI kit\",\n      rescore_query: \"Shadcn OR Material UI OR Tailwind\"\n    }\n  },\n  {\n    json: {\n      key: \"mobile_stack\",\n      query: \"What mobile development technologies are mentioned?\",\n      keywords: \"Flutter, React Native, Swift, Kotlin, iOS, Android, mobile app, mobile development, native mobile, cupertino\",\n      phrase: \"mobile development mobile app\",\n      rescore_query: \"Flutter OR React Native OR Kotlin OR Swift\"\n    }\n  },\n  {\n    json: {\n      key: \"backend_stack\",\n      query: \"What backend technologies or server frameworks are used?\",\n      keywords: \"Node.js, Python, Django, Java, Spring, PHP, Laravel, Ruby, Rails, Express, .NET, API, backend server, server-side, Go, Rust, FastAPI, NestJS\",\n      phrase: \"backend server backend technology\",\n      rescore_query: \"Node.js OR Django OR Laravel OR Java OR Spring\"\n    }\n  },\n  {\n    json: {\n      key: \"ai_needed\",\n      query: \"Does the project involve AI, ML, or data processing?\",\n      keywords: \"AI, artificial intelligence, machine learning, ML, chatbot, NLP, LLM, model training, predictive analytics, smart assistant, automation, algorithm, TensorFlow, PyTorch, OpenAI, Azure AI\",\n      phrase: \"AI functionality ML features\",\n      rescore_query: \"AI OR ML OR LLM OR chatbot\"\n    }\n  },\n  {\n    json: {\n      key: \"database\",\n      query: \"What kind of database or data storage is required?\",\n      keywords: \"PostgreSQL, MySQL, MongoDB, Redis, database, data storage, data layer, NoSQL, SQL, relational database, DBMS, backend storage, SQL Server, Oracle, DynamoDB, Firebase\",\n      phrase: \"data storage database\",\n      rescore_query: \"PostgreSQL OR MongoDB OR database system\"\n    }\n  },\n  {\n    json: {\n      key: \"deployment\",\n      query: \"Where is the system hosted or deployed?\",\n      keywords: \"AWS, Azure, GCP, cloud hosting, on-premises, hybrid, deployment, infrastructure, Kubernetes, Docker, container, server, on-premise, self-hosted, serverless, Kubernetes\",\n      phrase: \"deployment infrastructure hosting\",\n      rescore_query: \"AWS OR Azure OR cloud hosting\"\n    }\n  },\n  {\n    json: {\n      key: \"integrations\",\n      query: \"What external systems, APIs, or services need to be integrated?\",\n      keywords: \"integration, OAuth, SAML, API, APIs, third-party service, external system, SSO, payment gateway, Stripe, REST API, GraphQL, CRM, ERP\",\n      phrase: \"integration third-party system\",\n      rescore_query: \"OAuth OR API OR SSO OR Stripe\"\n    }\n  }\n];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -4384,
        4432
      ],
      "id": "9120879e-1794-42ea-b29a-c9a8e0508057",
      "name": "Queries7"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "http://192.168.20.70:11434/api/embed",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"model\": \"nomic-embed-text:latest\",\n  \"input\": [\"{{ $json.query }}\"]\n}",
        "options": {}
      },
      "id": "4fe17488-09c3-4829-81ed-8b890f622ca3",
      "name": "Embed Query - ollama7",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -4208,
        4432
      ]
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "17f9e7d3-307e-4d60-92ef-e32285cbec29",
              "name": "_score",
              "value": "={{ $json._score }}",
              "type": "number"
            },
            {
              "id": "618f58cd-27c7-4ab4-8612-899f048afb6c",
              "name": "_id",
              "value": "={{ $json._id }}",
              "type": "string"
            },
            {
              "id": "a8cfb079-48c6-4ce2-a54c-251304107206",
              "name": "chunk_id",
              "value": "={{ $json._source.chunk_id }}",
              "type": "string"
            },
            {
              "id": "22e6e029-7ff1-4870-a1c2-d3b025a2748b",
              "name": "section_title",
              "value": "={{ $json._source.section_title }}",
              "type": "string"
            },
            {
              "id": "27e9a9ac-b6ed-4320-bb21-027f8659e7c5",
              "name": "text",
              "value": "={{ $json._source.text }}",
              "type": "string"
            },
            {
              "id": "6830a868-6492-405b-b8fb-1ae36ea184b2",
              "name": "metadata",
              "value": "={{ $json._source.metadata }}",
              "type": "object"
            },
            {
              "id": "e5dce93c-eb16-42be-8b42-47ca5cfacc52",
              "name": "platform",
              "value": "={{ $('Queries7').item.json.platform }}",
              "type": "string"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        -4496,
        4672
      ],
      "id": "46f781c6-2343-4429-89b4-dcf54270fe3e",
      "name": "Map Response3"
    },
    {
      "parameters": {
        "jsCode": "// ---------------------------------------------------------------------------\n// gather snippets\n// ---------------------------------------------------------------------------\nconst ctxChunks = $input.first().json.context || \"\";;\nconst platforms = $('Platforms Output').first().json.detectedPlatformsSnippet;\nconst requirements  = $('Combined Requirements Output').first().json.combinedRequirementsSnippet;\n\n// ---------------------------------------------------------------------------\n// system prompt\n// ---------------------------------------------------------------------------\nconst systemPrompt = `\nYou are a senior solution-architect.\nReturn ONLY a valid JSON object under the key \"tech_stack\".\nDo NOT output headings, markdown, or commentary.\n`;\n\n// ---------------------------------------------------------------------------\n// user prompt\n// ---------------------------------------------------------------------------\nconst userPrompt = `\nYou are analysing RFP excerpts to define the optimal technology stack.\n\n### CONTEXT\n${ctxChunks}\n\n${platforms}\n\n${requirements}\n\n### TASK\nSelect **one** primary technology (or an empty list) for each dimension and build the JSON object below.\nIMPORTANT: Only define platforms that are explicitly listed in the “platforms” excerpt.\nIf a platform is not included in the list, leave its corresponding value empty (e.g., if web is not listed in “platforms”, then set webstack: \"\"). Do not assume or invent platforms outside the provided list.\n\n1. **Selection priority**  \n   a. Use tech the RFP **explicitly** names.  \n   b. Else use tech the RFP **implicitly** requires (e.g., WordPress ⇒ PHP + MySQL).  \n   c. Else apply our **house defaults**:  \n      • web_stack = \"React\"  \n      • backend_stack = \"PHP Symfony\"  \n      • mobile_stack = \"Flutter\"  \n      • design = \"Shadcn\"  \n      • database = \"PostgreSQL\"  \n      • deployment = \"AWS\"\n\n2. **Heavily AI-generated shortcut**  \n   If BOTH conditions hold:  \n   • Design is not Custom or demanding.  \n   • Functional Requirements describe mainly CRUD tables & simple admin UI.\n   • Techstack is not explicitly defined in RFP.  \n   → Override rule 1 and set:  \n     • web_stack = \"Next.js\"  \n     • backend_stack = \"Supabase\"  \n     • database = \"Supabase\"  \n     • design = \"Shadcn\"  \n     • stack_model = \"fullstack\"  \n     • Begin rationale with **\"Heavily AI-generated:\"**.\n\n3. **Additional industry heuristics** (activate only if rule 1 or 2 hasn’t decided the dimension):\n\n   • *Marketing / Blog CMS*: React + Next.js front, Node JS back, Postgres, headless CMS (“Strapi”, “Sanity”, etc.), stack_model = separated.  \n   • *Finance / high-compliance with no tech named*: backend_stack = \"Java Spring Boot\" **or** \".NET\"; note compliance in rationale.  \n   • *Real-time / microservice wording*: add Node JS **or** Go plus Redis cache.  \n   • *EU data residency, cloud unnamed*: deployment = \"AWS (eu-central-1)\" **or** \"Azure (West Europe)\".  \n   • *Elastic traffic spikes*: append \"serverless\" or \"containerized (Docker/K8s)\".  \n   • *Native device features (camera, AR)*: mobile_stack = \"Swift\" **or** \"Kotlin\".  \n   • *WCAG / strict design*: design = \"Material UI\".  \n   • *Analytics / BI tooling*: add \"Snowflake\" **or** \"BigQuery\".  \n\n   **Domain-specific triggers**  \n   – *E-commerce / checkout*: ensure integrations include \"Stripe\"; backend maybe \"Node.js\" or \"PHP Laravel\"; add \"Cloudflare CDN\" to deployment.  \n   – *Government / FedRAMP*: deployment = \"AWS GovCloud\" or \"Azure Government\"; backend = \".NET\" or \"Java Spring Boot\".  \n   – *Heavy video streaming*: integrations include \"AWS MediaConvert\" or \"Cloudflare Stream\"; add \"Redis\" cache.  \n   – *Multi-language localisation*: add \"i18next\" or \"next-intl\" integration.  \n   – *Strict CI/CD named*: mention chosen CI tool in rationale; deployment includes Docker/K8s.  \n   – *Legacy .NET stack referenced*: backend_stack = \".NET Core\".  \n   – *Open-source mandate*: avoid commercial DBs; enforce PostgreSQL and Linux hosting.  \n   – *99.9 % SLA / observability*: integrations include \"Prometheus\", \"Grafana\".\n  \n\n4. **ai_needed**  \n   true if RFP **mentions OR implies** AI/ML, chatbot, predictive, NLP, recommendation, smart search, forecasting, etc.; else false.\n\n5. **integrations**  \n   List only systems explicitly mentioned or strongly implied (CRM, ERP, SSO, payment, etc.).  \n   – Always include \"REST APIs\" when CRM/ERP/SSO appears.  \n   – If SAML, OAuth, Okta, Keycloak appear, list them.\n\n6. **stack_model**  \n   \"fullstack\" if FE & BE share one runtime (React + Supabase, React + Node, etc.); otherwise \"separated\".\n\n7. **Output constraints**  \n   • Provide **exactly one** entry per tech list (except integrations, where you should only put one solution choise - for example, in Inregrations, If we can use Stripe or Paypal, choose one thats best, dont return both of them).  \n   • Remove duplicates.  \n   • Rationale ≤ 700 words and must start with **Extracted:**, **Inferred:**, or **Heavily AI-generated:** indicating the rule used.  \n   • Mention how DETECTED_PLATFORMS informed defaults when defaults are chosen.\n   • Extract the techstack only for platforms that you got in DETECTED_PLATFORMS, leave the others one empty\n   . If you can choose bitween React Native and Flutter, choose Flutter\n   IMPORTANT: Only define platforms that are explicitly listed in the “platforms” excerpt.\nIf a platform is not included in the list, leave its corresponding value empty (e.g., if web is not listed in “platforms”, then set webstack: \"\"). Do not assume or invent platforms outside the provided list.\n\n**IMPORTANT: Format the rationale field using markdown markup for better readability:**\n- Use **bold text** for key points and important terms\n- Use ## headers for main sections\n- Use ### subheaders for subsections  \n- Use bullet points (- item) for lists\n- Use numbered lists (1. item) for sequential steps\n- Use \"code\" formatting for technical terms\n- Structure the rationale with clear sections and hierarchy\n- Keep Rationale < 300 words\n`;\n\nreturn { json: { systemPrompt, userPrompt } };\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -3648,
        4672
      ],
      "id": "99fd50b1-dcc1-4dd5-aafe-7e0d0aef7f3d",
      "name": "PreparePrompts6"
    },
    {
      "parameters": {
        "content": "## Inference Techstack\n",
        "height": 860,
        "width": 1480,
        "color": 3
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        -4608,
        4224
      ],
      "id": "62778d0b-27f0-413c-ab71-07fa4b432a58",
      "name": "Sticky Note11"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "claude-sonnet-4-20250514",
          "mode": "list",
          "cachedResultName": "Claude Sonnet 4"
        },
        "options": {
          "maxTokensToSample": 6096,
          "temperature": 0.3,
          "thinking": false
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatAnthropic",
      "typeVersion": 1.3,
      "position": [
        -3664,
        4864
      ],
      "id": "b5838771-fc0b-45e5-abc1-62e4a29e5109",
      "name": "Claude 3.8",
      "credentials": {
        "anthropicApi": {
          "id": "qzCm5Ds2qD9ZY1W5",
          "name": "Anthropic account"
        }
      }
    },
    {
      "parameters": {
        "jsonSchemaExample": "{\n  \"tech_stack\": {\n    \"stack_model\": \"fullstack\",\n    \"backend_stack\": [\"Node.js\", \"Java\", \"Python\"],\n    \"web_stack\": [\"React\", \"Vue\", \"Angular\"],\n    \"mobile_stack\": [\"Flutter\", \"Swift\", \"Kotlin\"],\n    \"design\": [\"Shadcn\", \"Material UI\", \"Custom\"],\n    \"ai_needed\": true,\n    \"database\": \"PostgreSQL\",\n    \"deployment\": \"cloud\",\n    \"integrations\": [\"OAuth\", \"SAML\", \"third-party APIs\"],\n    \"rationale\": \"Why this tech stack is appropriate for this project\"\n  }\n}"
      },
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "typeVersion": 1.2,
      "position": [
        -3296,
        4864
      ],
      "id": "7c7fbe08-a0e1-47fa-b819-be5be0b32ba5",
      "name": "Platforms + Rationale2"
    },
    {
      "parameters": {
        "operation": "getAll",
        "indexId": "={{ $('Start RFP Analysis').first().json.body.indexName }}",
        "limit": 10,
        "simple": false,
        "options": {
          "query": "={\n  \"size\": 10,\n  \"min_score\": 1.5,\n  \"_source\": [\n    \"chunk_id\",\"section_title\",\"text\",\n    \"metadata.filename\",\"metadata.page_numbers\",\n    \"metadata.parent_chunk_id\",\"metadata.is_split_chunk\",\n    \"metadata.split_part\",\"metadata.total_parts\",\n    \"vector_metadata.token_count\",\"vector_metadata.is_split\",\n    \"vector_metadata.chunk_index\"\n  ],\n  \"knn\": {\n    \"field\": \"embeddings\",\n    \"query_vector\": [ {{ $json.embeddings }} ],\n    \"k\": 20,\n    \"num_candidates\": 50\n  },\n  \"query\": {\n    \"bool\": {\n      \"should\": [\n        {\n          \"match_phrase\": {\n            \"text\": {\n              \"query\": \"{{ $('Queries7').item.json.phrase }}\",\n              \"slop\": 4,\n              \"boost\": 2.0\n            }\n          }\n        },\n        {\n          \"multi_match\": {\n            \"query\": \"{{ $('Queries7').item.json.keywords }}\",\n            \"fields\": [\"text^2\",\"section_title^3\"],\n            \"type\": \"most_fields\",\n            \"minimum_should_match\": 2,\n            \"boost\": 1.2\n          }\n        },\n        {\n          \"terms_set\": {\n            \"text.keyword\": {\n              \"terms\": {{ JSON.stringify($('Queries7').item.json.keywords.split(',').map(k => k.trim())) }},\n\n              \"minimum_should_match_script\": {\n                \"source\": \"Math.min(params.num_terms, 2)\"\n              }\n            }\n          }\n        }\n      ],\n      \"minimum_should_match\": 1\n    }\n  },\n  \"rescore\": {\n    \"window_size\": 20,\n    \"query\": {\n      \"rescore_query\": {\n        \"match_phrase\": {\n          \"text\": {\n            \"query\": \"{{ $('Queries7').item.json.rescore_query }}\",\n            \"slop\": 8\n          }\n        }\n      },\n      \"query_weight\": 0.7,\n      \"rescore_query_weight\": 0.3\n    }\n  },\n  \"highlight\": {\n    \"type\": \"unified\",\n    \"fields\": { \"text\": {}, \"section_title\": {} }\n  }\n}\n"
        }
      },
      "type": "n8n-nodes-base.elasticsearch",
      "typeVersion": 1,
      "position": [
        -3888,
        4432
      ],
      "id": "b1fda326-4a69-4244-a9fc-8f9656c25bca",
      "name": "Query - Full10",
      "alwaysOutputData": true,
      "credentials": {
        "elasticsearchApi": {
          "id": "wwaILZtoajWrVXwt",
          "name": "Elasticsearch account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// n8n Function Node: Corrected Merge Split-Chunk Groups\n\nconst grouped = {};\n\n// 1. Group all items by the “true” chunk identifier\nfor (const item of $input.all()) {\n  const data = item.json;\n  // Use parent_chunk_id if it exists, else chunk_id\n  const parentId = data.metadata?.is_split_chunk\n    ? data.metadata.parent_chunk_id\n    : data.chunk_id;\n\n  if (!grouped[parentId]) grouped[parentId] = [];\n  grouped[parentId].push(data);\n}\n\nconst merged = [];\n\n// 2. For each group, produce exactly one merged record\nfor (const [parentId, parts] of Object.entries(grouped)) {\n  // Sort by the split_part if present (else leave order)\n  parts.sort((a, b) => \n    (a.metadata?.split_part ?? 0) - (b.metadata?.split_part ?? 0)\n  );\n\n  // Stitch text together\n  const text = parts.map(p => p.text).join(\"\\n\\n\");\n\n  // Merge platform_origins arrays from all parts (dedupe by platform)\n  const allOrigins = parts.flatMap(p => p.platform_origins || []);\n  const platform_origins = [];\n  for (const o of allOrigins) {\n    if (!platform_origins.some(existing => existing.platform === o.platform)) {\n      platform_origins.push(o);\n    }\n  }\n\n  // Pick the highest-scoring part to inherit section_title, filename, pages, and score\n  const bestPart = parts.reduce((best, p) => \n    p._score > best._score ? p : best\n  , parts[0]);\n\n  // Build the single merged record\n  const record = {\n    chunk_id: parentId,\n    _score: bestPart._score,\n    section_title: bestPart.section_title,\n    text,\n    metadata: {\n      ...bestPart.metadata,\n      is_split_chunk: false,\n      parent_chunk_id: undefined,\n      split_part: undefined,\n      total_parts: undefined\n    },\n    platform_origins\n  };\n\n  merged.push({ json: record });\n}\nmerged.sort((a, b) => b.json._score - a.json._score);\nreturn merged;\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -4144,
        4672
      ],
      "id": "3bd5af3a-3e4c-4909-80a0-6814c4d51f13",
      "name": "Merge Chunks7"
    },
    {
      "parameters": {
        "jsCode": "// n8n Function Node: Dedupe → Merge Origins → Filter → Sort → Fallback\n\nconst MIN_SCORE = 3.0;\nconst DESIRED_COUNT = 10;\n\n// Step 1: Deduplicate & merge platform origins, keep highest‐score record\nconst seen = {};\nfor (const item of $input.all()) {\n  const { chunk_id, platform, _score, ...rest } = item.json;\n  \n  if (!seen[chunk_id]) {\n    // First time seeing this chunk\n    seen[chunk_id] = {\n      chunk_id,\n      _score,\n      ...rest,\n      platform_origins: [{ platform, score: _score }],\n    };\n  } else {\n    // Merge new platform origin\n    const record = seen[chunk_id];\n    if (!record.platform_origins.some(p => p.platform === platform)) {\n      record.platform_origins.push({ platform, score: _score });\n    }\n    // If this hit has a higher score, overwrite core fields\n    if (_score > record._score) {\n      record._score = _score;\n      Object.assign(record, rest);\n    }\n  }\n}\n\n// Convert deduped map back to array of items\nlet deduped = Object.values(seen).map(r => ({ json: r }));\n\n// Step 2: Filter by score and sort descending\nlet filtered = deduped\n  .filter(item => item.json._score >= MIN_SCORE)\n  .sort((a, b) => b.json._score - a.json._score);\n\n// Step 3: Fallback if too few hits\nif (filtered.length < DESIRED_COUNT) {\n  // Return top DESIRED_COUNT from deduped (regardless of score)\n  filtered = deduped\n    .sort((a, b) => b.json._score - a.json._score)\n    .slice(0, DESIRED_COUNT);\n}\n\n// Step 4: Ensure we only return up to DESIRED_COUNT\nfiltered = filtered.slice(0, DESIRED_COUNT);\n\n// Return in n8n-compatible format\nreturn filtered;\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -4320,
        4672
      ],
      "id": "1b6767f9-6b5e-4e2b-bfe6-39d93773f985",
      "name": "Deduplicate and Best Score7"
    },
    {
      "parameters": {
        "jsCode": "// Configuration\nconst TOKEN_LIMIT = 5000;\nconst MIN_STRONG_SCORE = 7.0;\n\n// Rough token estimator (1 token ~ 4 characters)\nfunction estimateTokenCount(text) {\n  if (!text) return 0;\n  return Math.ceil(text.length / 4);\n}\n\n// Input already filtered and sorted!\nconst chunks = $input.all().map(item => item.json);\n\n// Build the final list\nconst selectedChunks = [];\nlet tokenCount = 0;\n\nfor (const chunk of chunks) {\n  const tokens = estimateTokenCount(chunk.text);\n\n  if ((tokenCount + tokens) <= TOKEN_LIMIT) {\n    selectedChunks.push(chunk);\n    tokenCount += tokens;\n  } else if (chunk._score >= MIN_STRONG_SCORE) {\n    // Allow overflow for very strong chunks\n    selectedChunks.push(chunk);\n    tokenCount += tokens;\n  } else {\n    break; // Stop adding\n  }\n}\n\n// Prepare output\nconst output = selectedChunks.map(chunk => ({ json: chunk }));\n\n// Add token usage metadata (attach to first item for simplicity)\nif (output.length > 0) {\n  output[0].json._token_summary = {\n    total_tokens_estimated: tokenCount,\n    total_chunks_selected: selectedChunks.length,\n  };\n}\n\nreturn output;\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -3984,
        4672
      ],
      "id": "177b23b0-9080-42ec-b357-0e61467c509a",
      "name": "Token Budgeting5"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "gpt-4.1",
          "mode": "list",
          "cachedResultName": "gpt-4.1"
        },
        "options": {
          "temperature": 0.4
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        -3504,
        4944
      ],
      "id": "d79f2a5a-5e94-44dc-8c21-200c0d0ce9dc",
      "name": "OpenAI Chat Model5",
      "credentials": {
        "openAiApi": {
          "id": "M8xqWvEC6mH6LNuk",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "/**\n * Prepare ES chunks for Claude, without chunk‐length limiting.\n */\nfunction prepareSecurityRegulatoryContextForClaude(esResults) {\n  if (!Array.isArray(esResults)) {\n    throw new Error(\"Input must be an array of Elasticsearch results\");\n  }\n\n  // simple Markdown escaper\n  function mdEscape(str) {\n    return str.replace(/(`|\\*|_|~|>|\\[|\\])/g, \"\\\\$1\");\n  }\n\n  // normalize bullets and split into lines\n  function cleanText(raw) {\n    return raw\n      .replace(/^\\s*-\\s+/gm, \"\\n- \")\n      .replace(/^\\s*\\*\\s+/gm, \"\\n- \")\n      .replace(/[ \\t]+/g, \" \")\n      .replace(/\\. ([A-Z])/g, \".\\n$1\")\n      .replace(/\\n{3,}/g, \"\\n\\n\")\n      .trim();\n  }\n\n  const blocks = esResults.map(chunk => {\n    const { chunk_id, section_title, text = \"\", metadata = {}, _score, regScore, locScore } = chunk;\n\n    // Heading\n    const title = section_title\n      ? mdEscape(section_title)\n      : `Untitled Section (${chunk_id})`;\n\n    // Build YAML metadata\n    const pages = Array.isArray(metadata.page_numbers)\n      ? metadata.page_numbers.join(\", \")\n      : metadata.page_numbers || \"Unknown\";\n\n    const metaLines = [\n      `filename: ${metadata.filename || \"Unknown Document\"}`,\n      `pages: ${pages}`,\n      `score: ${_score.toFixed(2)}`,\n    ];\n    if (typeof regScore === \"number\") metaLines.push(`regScore: ${regScore.toFixed(2)}`);\n    if (typeof locScore === \"number\") metaLines.push(`locScore: ${locScore.toFixed(2)}`);\n    if (metadata.document_type) metaLines.push(`type: ${metadata.document_type}`);\n    if (metadata.languages) metaLines.push(`language: ${metadata.languages.join(\", \")}`);\n\n    const metaBlock = metaLines.join(\"\\n\");\n\n    // Clean and escape body\n    const body = mdEscape(cleanText(text));\n\n    return [\n      `### ${title}`,\n      \"```yaml\",\n      metaBlock,\n      \"```\",\n      \"\",\n      body\n    ].join(\"\\n\");\n  });\n\n  // Join with clear separators\n  return blocks.join(\"\\n\\n---\\n\\n\");\n}\n\n// Usage in n8n Function node:\nconst esResults = $input.all().map(i => i.json);\nconst contextForPrompt = prepareSecurityRegulatoryContextForClaude(esResults);\n\nreturn [{ json: { context: contextForPrompt } }];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -3824,
        4672
      ],
      "id": "61451e2e-c2e2-4375-b632-4eea16077b07",
      "name": "Prepare Context5"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ $json.userPrompt }}",
        "hasOutputParser": true,
        "options": {
          "systemMessage": "={{ $json.systemPrompt }}"
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.9,
      "position": [
        -3504,
        4672
      ],
      "id": "908e6da3-adca-4bdf-ac2b-7e436e28f010",
      "name": "Get Techstack",
      "onError": "continueErrorOutput"
    },
    {
      "parameters": {
        "jsCode": "/**\n * n8n Function node\n * Input  : first item from the previous “tech-stack agent” node\n *          {\n *            output: {\n *              tech_stack: { ... }\n *            }\n *          }\n * Output : { detectedTechStackSnippet: '### DETECTED_TECH_STACK …' }\n */\n\nconst { tech_stack } = $input.first().json.output || {};\n\n// --- Sanity check ----------------------------------------------------------\nif (!tech_stack || typeof tech_stack !== 'object') {\n  throw new Error('Expected output.tech_stack object from previous step.');\n}\n\n// --- Build the snippet -----------------------------------------------------\nconst detectedTechStackSnippet = [\n  '### DETECTED_TECH_STACK (authoritative, extracted in a prior step)',\n  JSON.stringify(tech_stack, null, 2),  // pretty-printed JSON\n  '',\n  'Treat this \"tech_stack\" as the baseline when refining or merging technology recommendations in the next step.',\n].join('\\n');\n\n// --- Return for the next node ---------------------------------------------\nreturn [\n  {\n    json: {\n      detectedTechStackSnippet,\n    },\n  },\n];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -3056,
        4672
      ],
      "id": "be21fbf3-b3d0-4977-a797-46dac3da90e5",
      "name": "Techstack Output"
    },
    {
      "parameters": {
        "jsonSchemaExample": "{\n  \"features\": \n\t\t[\n  {\n    \"title\": \"Title\",\n    \"description\": \"Clear and specific requirement\",\n    \"reference_section\":\"\"\n  }\n]\n}"
      },
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "typeVersion": 1.2,
      "position": [
        -464,
        3760
      ],
      "id": "191b9a1c-333d-4981-b184-3a66b65b4459",
      "name": "Title + Desc + Section"
    },
    {
      "parameters": {
        "jsonSchemaExample": "{\n  \"features\": \n\t\t[\n  {\n    \"title\": \"Title\",\n    \"description\": \"Clear and specific requirement\"\n  }\n]\n}"
      },
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "typeVersion": 1.2,
      "position": [
        -320,
        3760
      ],
      "id": "f616210a-35ff-4f8a-bc6f-3051846b1f25",
      "name": "Description"
    },
    {
      "parameters": {
        "jsonSchemaExample": "[\n  {\n    \"title\": \"Brief requirement title\",\n    \"description\": \"Exact or paraphrased requirement statement\",\n    \"category\": \"Performance | Availability | Security | ...\",\n    \"rationale\": \"Why this is an NFR and chosen category\",\n    \"reference_section\": \"2.3\"\n  }\n]"
      },
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "typeVersion": 1.2,
      "position": [
        1504,
        3792
      ],
      "id": "406b1948-8ee6-4a22-8fb2-561b02f1133a",
      "name": "Full"
    },
    {
      "parameters": {
        "jsonSchemaExample": "[\n  {\n    \"title\": \"Title\",\n    \"description\": \"Exact or paraphrased requirement statement\",\n    \"category\": \"Performance | Availability | Security | ...\"\n  }\n]"
      },
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "typeVersion": 1.2,
      "position": [
        1600,
        3792
      ],
      "id": "cbfc573f-e1a6-42a7-b635-1b1e954704f6",
      "name": "Description + Category"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "gpt-4.1-mini",
          "mode": "list",
          "cachedResultName": "gpt-4.1-mini"
        },
        "options": {
          "temperature": 0.1
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        2064,
        3744
      ],
      "id": "1820410f-f252-4aa3-a35e-3753447a702b",
      "name": "OpenAI Chat Model6",
      "credentials": {
        "openAiApi": {
          "id": "M8xqWvEC6mH6LNuk",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=You are analyzing two sets of extracted software project requirements from an RFP.\n\n{{ $('Functional Requirements Output').first().json.featureListSnippet }}\n\n{{ $json.nonFunctionalRequirementsSnippet }}\n\nInstructions:\n- Preserve the Functional Requirements exactly as they are.\n- From the Non-Functional list, remove any item that overlaps in meaning with the Functional list.\n- Deduplicate by meaning, not exact wording.\n- Reclassify each item as either:\n  - \"Functional\"\n  - \"Non-Functional\"\n\nDo not include commentary, markdown, or headings — return only the raw JSON.\n",
        "hasOutputParser": true,
        "options": {
          "systemMessage": "=You are a precise and structured assistant that consolidates software project requirements.\n\nYou will receive two sets of input:\n- Functional Requirements: what the system must do (e.g., user features, system behaviors)\n- Non-Functional Requirements: how the system must behave (e.g., performance, security, usability)\n\nYour task is to:\n- Preserve all Functional Requirements exactly as given.\n- From the Non-Functional Requirements, exclude anything that overlaps with the Functional list (based on intent).\n- Classify each requirement under \"Functional\" or \"Non-Functional\".\n- Ensure phrasing is specific, unambiguous, and clean.\n- Return a single valid JSON object with this structure:\n\nEach item must include:\ntitle: Short summary\ndescription: Specific requirement\n\nDo not omit meaningful content. Do not return explanations."
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.9,
      "position": [
        2128,
        3552
      ],
      "id": "63f88669-d876-4a4f-80e5-883b0ba8d80f",
      "name": "Combine Requirements",
      "onError": "continueErrorOutput"
    },
    {
      "parameters": {
        "jsonSchemaExample": "[\n  {\n    \"functional\": [\n      {\n        \"title\": \"Short title\",\n        \"description\": \"Detailed and unambiguous requirement\"\n      }\n    ],\n    \"non_functional\": [\n      {\n        \"title\": \"Security Captcha on Admin Login\",\n        \"description\": \"Login to admin panel must include CAPTCHA and CSRF protection.\"\n      }\n    ]\n  }\n]\n"
      },
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "typeVersion": 1.2,
      "position": [
        2288,
        3760
      ],
      "id": "d7292b22-f615-493b-a2d1-3ce2f7e16b34",
      "name": "Structured Output Parser"
    },
    {
      "parameters": {
        "jsCode": "/**\n * n8n Function Node — \"Build Combined Requirements Snippet\"\n *\n * Input shape:\n * [\n *   {\n *     output: [\n *       {\n *         functional: [ { title, description }, ... ],\n *         non_functional: [ { title, description }, ... ]\n *       }\n *     ]\n *   }\n * ]\n *\n * Output shape:\n * {\n *   combinedRequirementsSnippet: '### COMBINED_REQUIREMENTS …'\n * }\n */\n\n// --- Grab input safely -----------------------------------------------------\nconst input = $input.first().json.output?.[0] || {};\nconst functional = input.functional || [];\nconst nonFunctional = input.non_functional || [];\n\n// --- Basic validation ------------------------------------------------------\nif (!Array.isArray(functional) || !Array.isArray(nonFunctional)) {\n  throw new Error('Expected arrays for functional and non_functional requirements.');\n}\n\n// --- Build the snippet -----------------------------------------------------\nconst combinedRequirementsSnippet = [\n  '### FUNCTIONAL AND NON-FUNCTIONAL REQUIREMENTS (authoritative, merged functional and non-functional set)',\n  JSON.stringify({ functional, non_functional: nonFunctional }, null, 2),\n  '',\n  'Treat this merged list as the unified scope for all downstream steps including tech stack reasoning, risk estimation, and delivery planning.'\n].join('\\n');\n\n// --- Return for downstream use --------------------------------------------\nreturn [\n  {\n    json: {\n      combinedRequirementsSnippet\n    }\n  }\n];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        2528,
        3552
      ],
      "id": "4bce036b-17d2-40fb-a0d5-df15fb2f1147",
      "name": "Combined Requirements Output"
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "2eb926dc-6f8b-4145-a627-2a699038399a",
              "name": "detectedPlatformsSnippet",
              "value": "={{ $('Platforms Output').first().json.detectedPlatformsSnippet }}",
              "type": "string"
            },
            {
              "id": "224cb69c-4a9f-4228-a215-25531d77b261",
              "name": "combinedRequirementsSnippet",
              "value": "={{ $json.combinedRequirementsSnippet }}",
              "type": "string"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        2752,
        3552
      ],
      "id": "9dcbee47-cad8-495b-b6f3-f4c6aa84440b",
      "name": "Dependencies1"
    },
    {
      "parameters": {
        "content": "## Combined Requirements\n",
        "height": 900,
        "width": 900
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        1968,
        3120
      ],
      "id": "814ad958-5e3c-48d3-ad47-f87123e20786",
      "name": "Sticky Note1"
    },
    {
      "parameters": {
        "jsonSchemaExample": "{\n  \"team_plan\": {\n    \"roles\": [\n      { \"role\": \"Product Owner\", \"fte\": 1.0, \"rationale\": \"≤ 200 words explaining the decisions.\" },\n      { \"role\": \"Scrum Master\", \"fte\": 0.5, \"rationale\": \"≤ 200 words explaining the decisions.\" }\n    ],\n    \"rationale\": \"≤ 500 words explaining the decisions.\"\n  }\n}"
      },
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "typeVersion": 1.2,
      "position": [
        -1456,
        4784
      ],
      "id": "da4fdd54-fc5d-4cdd-b176-5aa3d24d7ed1",
      "name": "Team Composition1"
    },
    {
      "parameters": {
        "content": "## Team Compositon\n",
        "height": 860,
        "width": 1140,
        "color": 4
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        -2288,
        4224
      ],
      "id": "60fb5376-76e8-4372-bdc9-f748af6b75bc",
      "name": "Sticky Note3"
    },
    {
      "parameters": {
        "jsCode": "/**\n * n8n Function node\n * Input  : first item from the previous “Team-Composition” LLM step\n * Output : { teamCompositionSnippet: '### TEAM_COMPOSITION …' }\n */\n\nconst team_plan = $input.first().json.output?.team_plan;\n\nif (!team_plan || typeof team_plan !== 'object') {\n  throw new Error('Expected output.team_plan object from previous step.');\n}\n\nconst teamCompositionSnippet = [\n  '### TEAM_COMPOSITION (authoritative, extracted in a prior step)',\n  JSON.stringify(team_plan, null, 2),\n  '',\n  'Treat this team structure as a baseline for effort, duration, and cost calculations downstream.'\n].join('\\n');\n\nreturn [\n  {\n    json: {\n      teamCompositionSnippet,\n    },\n  },\n];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1056,
        4464
      ],
      "id": "4af26086-bbd8-4790-b3e6-f0b6d8a61f2f",
      "name": "Team Composition Output"
    },
    {
      "parameters": {
        "jsonSchemaExample": "{\n\t\"min_sprints\": 0,\n\t\"max_sprints\": 0,\n    \"rationale\":\"\"\n}"
      },
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "typeVersion": 1.2,
      "position": [
        640,
        4512
      ],
      "id": "38361726-356b-4fe1-98f2-700b5de7995b",
      "name": "Greenfield + Rationale"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "gpt-4.1",
          "mode": "list",
          "cachedResultName": "gpt-4.1"
        },
        "options": {
          "temperature": 0.1
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        448,
        4528
      ],
      "id": "10c34a8f-3409-47b2-b504-93db0d219c4c",
      "name": "GPT 4.1 Mini4",
      "credentials": {
        "openAiApi": {
          "id": "M8xqWvEC6mH6LNuk",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "const snippets = [\n  $('Dependencies1').first().json.combinedRequirementsSnippet,\n].join('\\n\\n');\n\nconst techstack = $('Techstack Output').first().json.detectedTechStackSnippet;\nconst team = $('Team Composition Output').first().json.teamCompositionSnippet;\n\n\nconst systemPrompt = `\nYou are a senior delivery strategist estimating agile effort for software projects.\nYour goal is to output a realistic 2-week sprint range (min to max) based on high-level scope and delivery context.\nAlways assume:\n• Optimal AI-assisted development using modern tooling (AI pair programming, codegen, automated testing)\n• A capable cross-functional team with each developer delivering 15 story points per sprint\n• High delivery velocity without unnecessary padding\nYour output must be a valid JSON object under the key \"sprint_estimate\". Do not include any other text or formatting.\n`;\n\nconst userPrompt = `\nBelow are structured excerpts that describe the project context:\n\n${snippets}\n${team}\n${techstack}\n\nTASK:\n1. Estimate the number of 2-week sprints needed to implement the full scope (MVP).\n2. Return:\n   - \"min_sprints\": lower-bound estimate\n   - \"max_sprints\": upper-bound estimate\n   - \"rationale\": a short explanation (< 700 characters)\n\nESTIMATION RULES:\n• Narrow the sprint range if the scope is well-defined and straightforward.\n• Consider the number of developers, assuming they can work in parallel on the same tech stack or domain area.\n• Use a broader range when there are significant risks (e.g. vague NFRs, unclear integrations, or regulatory complexity).\n• Exclude wide buffers, discovery work, and post-launch support.\n• Only estimate the implementation phase (from kick-off to MVP launch).\n• Do NOT break down or estimate features individually.\n• Output must be in JSON only—no markdown, bullet points, or additional text.\n• The \"rationale\" field must clearly explain how scope, risk, and delivery dynamics affect the sprint estimate.\n\nPROJECT DURATION PRINCIPLE:\nAssume that developers and supporting roles work in parallel across their own domains.  \nHowever, the **total project duration should be anchored to the development stream that carries the most effort** (e.g., frontend-heavy projects should span as long as frontend implementation takes).  \nOther roles (e.g., backend, QA, PM) should be proportional in effort and capacity (FTE), but not dictate overall duration if they finish earlier.  \nDo not artificially serialize tasks, but reflect the true critical path of the most effort-heavy track.\n\n• For projects using a \"Heavily AI Generated\" tech stack, assume high delivery velocity and minimal risk overhead—this should reduce the lower-bound estimate.\n• If the RFP includes a fixed deadline or time budget:\n  - Suggest team composition adjustments (e.g., adding developers) to meet the timeline.\n  - Propose requirement descoping strategies (e.g., removing non-critical, high-risk features) to help fit the scope within constraints.\n  - Use this reasoning to support the “note” field in the JSON output.\n\n  **IMPORTANT: Format the rationale field using markdown markup for better readability:**\n- Use **bold text** for key points and important terms\n- Use ## headers for main sections\n- Use ### subheaders for subsections  \n- Use bullet points (- item) for lists\n- Use numbered lists (1. item) for sequential steps\n- Use \"code\" formatting for technical terms\n- Structure the rationale with clear sections and hierarchy\n`;\n\nreturn {\n  json: {\n    systemPrompt,\n    userPrompt\n  }\n};\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        112,
        4288
      ],
      "id": "5a7c0c6b-e3ba-4565-be8d-57663d9980f8",
      "name": "Code2"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "claude-sonnet-4-20250514",
          "mode": "list",
          "cachedResultName": "Claude Sonnet 4"
        },
        "options": {
          "maxTokensToSample": 6000,
          "temperature": 0.1,
          "thinking": false
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatAnthropic",
      "typeVersion": 1.3,
      "position": [
        304,
        4528
      ],
      "id": "9889cff8-8b9a-4de7-a7d4-9b990d65bd31",
      "name": "Anthropic Chat Model2",
      "credentials": {
        "anthropicApi": {
          "id": "qzCm5Ds2qD9ZY1W5",
          "name": "Anthropic account"
        }
      }
    },
    {
      "parameters": {
        "content": "## Effort Estimation\n",
        "height": 740,
        "width": 2000,
        "color": 5
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        -304,
        4208
      ],
      "id": "2d8ee339-8936-4b17-b5e7-841dff893722",
      "name": "Sticky Note13"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ $json.userPrompt }}",
        "hasOutputParser": true,
        "options": {
          "systemMessage": "={{ $json.systemPrompt }}"
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.9,
      "position": [
        400,
        4288
      ],
      "id": "d21f086f-eee4-4dcd-aa76-5a040d651cfa",
      "name": "Effort Estimation",
      "onError": "continueErrorOutput"
    },
    {
      "parameters": {},
      "type": "@n8n/n8n-nodes-langchain.toolCalculator",
      "typeVersion": 1,
      "position": [
        544,
        4528
      ],
      "id": "ecc4c9d9-87a2-445c-b7d6-6f9b06f489ab",
      "name": "Calculator"
    },
    {
      "parameters": {
        "jsonSchemaExample": "{\n  \"phases\": [\n    {\n      \"name\": \"Planning and Foundation\",\n      \"sprints\": { \"start\": 1, \"end\": 2 },\n      \"items\": [\n        \"Set up environments and CI/CD pipeline\",\n        \"Define architecture and technical frameworks\",\n        \"Implement user authentication and role system\"\n      ]\n    },\n    {\n      \"name\": \"Core Development\",\n      \"sprints\": { \"start\": 3, \"end\": 6 },\n      \"items\": [\n        \"Develop mission system and rewards engine\",\n        \"Integrate forest visualization and topic feed\"\n      ]\n    }\n  ],\n  \"cross_cutting\": {\n    \"infrastructure\": [ \"CI/CD setup\", \"VPN access configuration\" ],\n    \"security\": [ \"Access control\", \"Penetration testing\" ],\n    \"testing\": [ \"Unit testing\", \"UAT\" ],\n    \"documentation\": [ \"API documentation\", \"User guides\" ],\n    \"deployment\": [ \"Staging environment\", \"Production rollout\" ]\n  }\n}"
      },
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "typeVersion": 1.2,
      "position": [
        2448,
        4672
      ],
      "id": "3ec9951a-e3b2-4ff8-a342-8d61731095e3",
      "name": "Greenfield + Rationale3"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "gpt-4.1",
          "mode": "list",
          "cachedResultName": "gpt-4.1"
        },
        "options": {
          "temperature": 0.3
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        2208,
        4672
      ],
      "id": "6173fd5d-1fb5-4d72-8c3f-d03af34ca249",
      "name": "GPT 4.1 Mini5",
      "credentials": {
        "openAiApi": {
          "id": "M8xqWvEC6mH6LNuk",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "const snippets = [\n  $('Dependencies1').first().json.combinedRequirementsSnippet,\n].join('\\n\\n');\n\nconst team = $('Team Composition Output').first().json.teamCompositionSnippet;\nconst estimation = $('Effort Estimate Output').first().json.effortEstimationSnippet;\n\nconst systemPrompt = `\nYou are a senior technical project planner and agile delivery strategist. You design high-level sprint-based development plans for software projects based on known scope and estimated duration.\nYou always:\n- Organize the plan into clear sprint phases\n- Include key delivery activities per phase\n- Address cross-cutting themes like infrastructure, testing, and security\n- Avoid repeating or re-estimating effort\n`;\n\nconst userPrompt = `\nBelow are structured excerpts that describe the project context:\n\n${snippets}\n${team}\n${estimation}\n\nYour task:\n- Do not include discovery phase\n- Take into consideration the optimal AI Assisted Development and setup for that\n- Consider the number of developers, assuming they can work in parallel on the same tech stack or domain area.\n- Use the \"min_sprints\" and \"max_sprints\" from the effort estimation as the timeline range.\n- Assume Agile 2-week sprints.\n1. Create a high-level **sprint-based development plan** that aligns with the estimated duration.\n2. Organize the plan into **semantically labeled phases** based on common delivery flow, such as:\n   - \"Setup and Foundation\"\n   - \"Core Development\"\n   - \"Feature Completion and Polishing\"\n   - \"Finalization and Handover\"\n3. For each phase, include:\n   - A \"name\" (semantic label as described)\n   - A \"sprints\" object with \"start\" and \"end\" sprint numbers\n   - A list of \"items\" representing deliverables, feature groups, or technical milestones\n\n4. Also provide a \"cross_cutting\" section with grouped items under:\n   - \"infrastructure\"\n   - \"security\"\n   - \"testing\"\n   - \"documentation\"\n   - \"deployment\"\nAvoid generic items. Make cross-cutting work as concrete and contextualized as possible (e.g. “Configure Firebase Analytics for event tracking” under analytics).\nYou must not re-estimate effort. Use the sprint range provided.\n\n`;\n\nreturn {\n  json: {\n    systemPrompt,\n    userPrompt\n  }\n};\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1920,
        4448
      ],
      "id": "8017c7bf-9e08-4725-9d5b-897314d91040",
      "name": "Code3"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "claude-sonnet-4-20250514",
          "mode": "list",
          "cachedResultName": "Claude Sonnet 4"
        },
        "options": {
          "maxTokensToSample": 8000,
          "temperature": 0.3,
          "thinking": false
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatAnthropic",
      "typeVersion": 1.3,
      "position": [
        2080,
        4672
      ],
      "id": "5afde0a7-401c-4b8a-996b-d189dccd87ac",
      "name": "Anthropic Chat Model3",
      "credentials": {
        "anthropicApi": {
          "id": "qzCm5Ds2qD9ZY1W5",
          "name": "Anthropic account"
        }
      }
    },
    {
      "parameters": {
        "content": "## Development Plan\n",
        "height": 740,
        "width": 1340,
        "color": 6
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        1888,
        4224
      ],
      "id": "3b85c9c2-d9c7-4cc0-8aea-d76d90d36cec",
      "name": "Sticky Note14"
    },
    {
      "parameters": {},
      "type": "@n8n/n8n-nodes-langchain.toolCalculator",
      "typeVersion": 1,
      "position": [
        2320,
        4672
      ],
      "id": "a1b22d91-60c1-45cf-9760-e00cd6090e5d",
      "name": "Calculator1"
    },
    {
      "parameters": {
        "jsCode": "/**\n * n8n Function node\n * Input  : first item from the previous “Effort Estimation” LLM step\n * Output : { effortEstimationSnippet: '### EFFORT_ESTIMATION …' }\n */\n\nconst effort = $input.first().json.output;\n\nif (!effort || typeof effort !== 'object') {\n  throw new Error('Expected output object with min_sprints, max_sprints, rationale, and discovery_steps.');\n}\n\nconst effortEstimationSnippet = [\n  '### EFFORT_ESTIMATION (authoritative, generated in prior step)',\n  JSON.stringify(effort, null, 2),\n  '',\n  'Treat this sprint range and rationale as the base reference for downstream cost, buffer, and delivery planning.'\n].join('\\n');\n\nreturn [\n  {\n    json: {\n      effortEstimationSnippet,\n    },\n  },\n];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        848,
        4288
      ],
      "id": "716c6d25-7cad-458c-9067-80da188e1238",
      "name": "Effort Estimate Output"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ $json.userPrompt }}",
        "hasOutputParser": true,
        "options": {
          "systemMessage": "={{ $json.systemPrompt }}"
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.9,
      "position": [
        2144,
        4400
      ],
      "id": "acb9def9-7fc1-4d3a-b2ee-d2f73b6153ea",
      "name": "Development Plan",
      "onError": "continueErrorOutput"
    },
    {
      "parameters": {
        "jsCode": "const snippets = [\n  $('Dependencies').first().json.regulatoryComplianceSnippet,\n  $('Dependencies').first().json.combinedRequirementsSnippet,\n  $('Dependencies').first().json.projectClassificationSnippet,\n  $('Dependencies').first().json.deliveryRequirementsSnippet,\n  $('Dependencies').first().json.detectedTechStackSnippet,\n  $('Dependencies').first().json.teamCompositionSnippet,\n  $input.first().json.riskRegisterSnippet\n].join('\\n\\n');\n\nconst systemPrompt = `\nYou are a senior delivery strategist estimating agile effort for software projects.\nYour goal is to output a realistic 2-week sprint range (min to max) based on high-level scope and delivery context.\nAlways assume:\n• Optimal AI-assisted development using modern tooling (AI pair programming, codegen, automated testing)\n• A capable cross-functional team with each developer delivering 15 story points per sprint\n• High delivery velocity without unnecessary padding\nYour output must be a valid JSON object under the key \"sprint_estimate\". Do not include any other text or formatting.\n`;\n\nconst userPrompt = `\nBelow are structured excerpts that describe the project context:\n\n${snippets}\n\nTASK:\n1. Estimate the number of 2-week sprints needed to implement the full scope (MVP).\n2. Return:\n   - \"min_sprints\": lower-bound estimate\n   - \"max_sprints\": upper-bound estimate\n   - \"rationale\": a short explanation < 700 characters\n   - \"discovery steps\": steps that should be done in discovery to mitigate risks and reduce the buffer\n\nESTIMATION RULES:\nDiscovery is excluded from the sprint count, but provide discovery steps to reduce uncertainty\n• Narrow the sprint range if the scope is well-defined and straightforward.\n• Consider the number of developers, assuming they can work in parallel on the same tech stack or domain area.\n• Use a broader range when there are significant risks (e.g. vague NFRs, unclear integrations, or regulatory complexity).\n• Exclude wide buffers, discovery work, and post-launch support.\n• Only estimate the implementation phase (from kick-off to MVP launch).\n• Do NOT break down or estimate features individually.\n• Output must be in JSON only—no markdown, bullet points, or additional text.\n• The \"rationale\" field must clearly explain how scope, risk, and delivery dynamics affect the sprint estimate.\n• Anchor the timeline to the developer role bearing the most implementation load (e.g., frontend-heavy projects should reflect frontend effort primarily, with others scaled accordingly).\n• For projects using a \"Heavily AI Generated\" tech stack, assume high delivery velocity and minimal risk overhead—this should reduce the lower-bound estimate.\n• If the RFP includes a fixed deadline or time budget:\n  - Suggest team composition adjustments (e.g., adding developers) to meet the timeline.\n  - Propose requirement descoping strategies (e.g., removing non-critical, high-risk features) to help fit the scope within constraints.\n  - Use this reasoning to support the “note” field in the JSON output.\n`;\n\nreturn {\n  json: {\n    systemPrompt,\n    userPrompt\n  }\n};\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        112,
        4448
      ],
      "id": "8a9f85b6-1cf1-4beb-b6d4-35f84244614a",
      "name": "Code4"
    },
    {
      "parameters": {
        "jsCode": "/**\n * n8n Function node\n * Input  : first item from the previous domain-specific “Effort Estimation” LLM step\n * Output : { frontendEffortSnippet: '### FRONTEND_EFFORT_ESTIMATION …' }\n */\n\nconst effort = $input.first().json.output;\n\nif (\n  !effort ||\n  typeof effort !== 'object' ||\n  !('min_days' in effort) ||\n  !('max_days' in effort)\n) {\n  throw new Error('Expected output object with min_days, max_days, rationale, and acceleration_basis.');\n}\n\nconst frontendEffortSnippet = [\n  '### FRONTEND_EFFORT_ESTIMATION (authoritative, domain-specific)',\n  JSON.stringify(effort, null, 2),\n  '',\n  'This is the effort estimation for frontend development only. Use it as a partial input for aggregating total duration or converting to sprint-based planning downstream.'\n].join('\\n');\n\nreturn [\n  {\n    json: {\n      frontendEffortSnippet,\n    },\n  },\n];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -5008,
        6912
      ],
      "id": "03697efd-b2f8-4b03-bd95-4b50fee6fb76",
      "name": "Total Effort Estimate Output"
    },
    {
      "parameters": {
        "formTitle": "RFP",
        "formFields": {
          "values": [
            {
              "fieldLabel": "file",
              "fieldType": "file",
              "multipleFiles": false,
              "acceptFileTypes": ".pdf"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.formTrigger",
      "typeVersion": 2.2,
      "position": [
        -3488,
        1872
      ],
      "id": "e1321666-9bde-435e-a3c1-a7589a7a0a71",
      "name": "RFP Upload",
      "webhookId": "c13ee4fc-516b-4741-ad7c-121c51c3f594",
      "disabled": true
    },
    {
      "parameters": {
        "method": "PUT",
        "url": "={{ $json.elasticsearchUrl }}",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "elasticsearchApi",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "{\n  \"mappings\": {\n    \"dynamic\": \"strict\",\n    \"properties\": {\n      \"chunk_id\": {\n        \"type\": \"keyword\"\n      },\n      \"section_title\": {\n        \"type\": \"text\",\n        \"fields\": {\n          \"keyword\": { \"type\": \"keyword\" }\n        }\n      },\n      \"text\": {\n        \"type\": \"text\",\n        \"analyzer\": \"standard\"\n      },\n      \"metadata\": {\n        \"type\": \"object\",\n        \"dynamic\": \"strict\",\n        \"properties\": {\n          \"content_type\": { \"type\": \"keyword\" },\n          \"pages\":        { \"type\": \"integer\" },\n          \"chunk_index\":  { \"type\": \"integer\" }\n        }\n      },\n      \"embeddings\": {\n        \"type\":       \"dense_vector\",\n        \"dims\":       768,\n        \"index\":      true,\n        \"similarity\": \"cosine\"\n      }\n    }\n  }\n}\n",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -2416,
        2272
      ],
      "id": "f692d4e9-b6c1-41da-b216-c0bbbbb87490",
      "name": "Create index - Elastic Search",
      "credentials": {
        "elasticsearchApi": {
          "id": "wwaILZtoajWrVXwt",
          "name": "Elasticsearch account"
        }
      }
    },
    {
      "parameters": {
        "resource": "index",
        "operation": "delete",
        "indexId": "={{ $('Start RFP Analysis').item.json.body.indexName }}"
      },
      "type": "n8n-nodes-base.elasticsearch",
      "typeVersion": 1,
      "position": [
        -2416,
        2064
      ],
      "id": "a3cbef9a-0228-4346-ad56-9d5c98a02e8b",
      "name": "Delete Index",
      "alwaysOutputData": false,
      "credentials": {
        "elasticsearchApi": {
          "id": "wwaILZtoajWrVXwt",
          "name": "Elasticsearch account"
        }
      },
      "onError": "continueErrorOutput"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "http://192.168.20.70:11434/api/embed",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"model\": \"nomic-embed-text:latest\",\n  \"input\": [\"{{ $input.item.json.text}}\"]\n}",
        "options": {}
      },
      "id": "c19117b5-c974-4704-97cc-12b5619c2f32",
      "name": "Embed Chunks",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -816,
        2224
      ]
    },
    {
      "parameters": {
        "jsCode": "const input = $input.all().map(item => item.json);\n\n// Normalize and test against known patterns\nfunction isTOC(title) {\n  if (!title || typeof title !== 'string') return false;\n\n  const normalized = title\n    .toLowerCase()\n    .replace(/[^a-z0-9]/g, ' ') // replace punctuation with space\n    .replace(/\\s+/g, ' ')       // collapse spaces\n    .trim();\n\n  const tocKeywords = [\n    'table of contents',\n    'table of content',\n    'contents',\n    'toc'\n  ];\n\n  return tocKeywords.some(keyword => normalized.includes(keyword));\n}\n\n// Filter out chunks where the title suggests it's TOC\nconst filtered = input.filter(chunk => {\n  const title = chunk.section_title || chunk.text || '';\n  return !isTOC(title);\n});\n\nreturn filtered.map(chunk => ({ json: chunk }));\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1264,
        2064
      ],
      "id": "57852fd1-8597-40f5-b2cf-a79df9a75e39",
      "name": "Remove TOC",
      "alwaysOutputData": true
    },
    {
      "parameters": {
        "jsCode": "/**\n * Sanitizes chunk text to ensure compatibility with Nomic embedding API\n * This function deals with \"smart\" characters, quotes, and other problematic elements\n * Preserves existing chunk_index values\n * \n * @returns {Array} - The processed items\n */\nfunction sanitizeChunksForEmbedding() {\n  // Get input data\n  const items = $input.all();\n  const outputItems = [];\n  \n  // Process each item\n  for (const item of items) {\n    // Handle different possible input formats\n    let chunks;\n    \n    if (Array.isArray(item.json)) {\n      // If item.json is already an array of chunks\n      chunks = item.json;\n    } else if (item.json.chunks && Array.isArray(item.json.chunks)) {\n      // If chunks are in a property called 'chunks'\n      chunks = item.json.chunks;\n    } else {\n      // If the item itself is a single chunk\n      chunks = [item.json];\n    }\n    \n    // Track chunk indices per section for chunks without existing chunk_index\n    const sectionIndices = {};\n    \n    // Sanitize each chunk\n    const sanitizedChunks = chunks.map(chunk => {\n      // Create a new object to avoid modifying the original\n      const sanitizedChunk = { ...chunk };\n      \n      // Sanitize the main text field if it exists\n      if (sanitizedChunk.text) {\n        sanitizedChunk.text = sanitizeText(sanitizedChunk.text);\n      }\n      \n      // Sanitize the embedding text field if it exists\n      if (sanitizedChunk.text_to_embed) {\n        sanitizedChunk.text_to_embed = sanitizeText(sanitizedChunk.text_to_embed);\n      }\n      \n      // Sanitize section title if it exists\n      if (sanitizedChunk.section_title) {\n        sanitizedChunk.section_title = sanitizeText(sanitizedChunk.section_title);\n      }\n      \n      // Ensure vector_metadata exists\n      if (!sanitizedChunk.vector_metadata) {\n        sanitizedChunk.vector_metadata = {};\n      }\n      \n      // IMPORTANT CHANGE: Only set chunk_index if it doesn't already exist\n      if (sanitizedChunk.vector_metadata.chunk_index === undefined) {\n        // Initialize or get the current section's index tracker\n        const sectionKey = sanitizedChunk.section_title || 'default';\n        if (sectionIndices[sectionKey] === undefined) {\n          sectionIndices[sectionKey] = 0;\n        }\n        \n        // Populate chunk_index in vector_metadata\n        sanitizedChunk.vector_metadata.chunk_index = sectionIndices[sectionKey];\n        \n        // If this is a split chunk and already has part_index, don't increment the section index\n        // Otherwise, increment for the next chunk with the same section\n        if (!sanitizedChunk.vector_metadata.is_split || \n            (sanitizedChunk.vector_metadata.is_split && sanitizedChunk.vector_metadata.part_index === 0)) {\n          sectionIndices[sectionKey]++;\n        }\n      }\n      \n      return sanitizedChunk;\n    });\n    \n    // Return in the same format as received\n    if (Array.isArray(item.json)) {\n      outputItems.push({ json: sanitizedChunks });\n    } else if (item.json.chunks && Array.isArray(item.json.chunks)) {\n      outputItems.push({\n        json: {\n          ...item.json,\n          chunks: sanitizedChunks\n        }\n      });\n    } else {\n      // Return processed single chunk\n      outputItems.push({ json: sanitizedChunks[0] });\n    }\n  }\n  \n  return outputItems;\n}\n\n/**\n * Sanitizes text by replacing special characters and ensuring JSON compatibility\n * @param {string} text - Text to sanitize\n * @returns {string} - Sanitized text\n */\nfunction sanitizeText(text) {\n  if (!text) return '';\n  \n  // Remove wrapping quotes if present\n  let sanitized = text;\n  if ((text.startsWith('\"') && text.endsWith('\"')) || \n      (text.startsWith('\"') && text.endsWith('\"'))) {\n    sanitized = text.substring(1, text.length - 1);\n  }\n  \n // Replace smart/curly quotes with straight quotes\n  sanitized = sanitized\n    .replace(/[\\u2018\\u2019]/g, \"'\") // Replace single smart quotes\n    .replace(/[\\u201C\\u201D]/g, '\"') // Replace double smart quotes\n    \n    // Remove invisible control characters\n    .replace(/[\\u0000-\\u001F\\u007F-\\u009F\\u2000-\\u200F\\u2028-\\u202F]/g, ' ')\n    \n    // Replace other problematic characters\n    .replace(/[\\u2013\\u2014]/g, '-') // Replace em dash and en dash\n    .replace(/\\u2026/g, '...') // Replace ellipsis\n    .replace(/\\u00A0/g, ' ') // Replace non-breaking space\n    \n    // Special handling for bullet points and other list markers\n    .replace(/[\\u2022\\u2023\\u25E6\\u2043\\u2219]/g, '*') // Convert bullets to asterisks\n    \n    // Normalize whitespace (remove multiple spaces, tabs, etc.)\n    .replace(/\\s+/g, ' ')\n    // Trim leading and trailing whitespace\n    .replace(/\"/g, '\\\\\"')\n    // Handle other special characters that might cause issues in JSON\n    //.replace(/\\\\/g, '\\\\\\\\')\n    .replace(/\\f/g, '\\\\f')\n    .replace(/\\n/g, '\\\\n')\n    .replace(/\\r/g, '\\\\r')\n    .replace(/\\t/g, '\\\\t')\n    .trim();\n  \n  return sanitized;\n}\n\n// Execute the function and return the result\nreturn sanitizeChunksForEmbedding();"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1264,
        2224
      ],
      "id": "5c3c3ea7-5e4c-4ca7-bdb4-572b7460775e",
      "name": "Final Escaping"
    },
    {
      "parameters": {
        "operation": "create",
        "indexId": "={{ $('Start RFP Analysis').first().json.body.indexName }}",
        "dataToSend": "autoMapInputData",
        "inputsToIgnore": "=",
        "additionalFields": {},
        "options": {}
      },
      "type": "n8n-nodes-base.elasticsearch",
      "typeVersion": 1,
      "position": [
        -816,
        2464
      ],
      "id": "3268dfbc-218a-4266-ba10-b56183383db4",
      "name": "Add To Index",
      "credentials": {
        "elasticsearchApi": {
          "id": "wwaILZtoajWrVXwt",
          "name": "Elasticsearch account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// n8n Function node\n// Filters out empty / duplicate chunks and adds an incremental `index` starting at 0.\n\nfunction filterEmptyAndDuplicateChunks() {\n  const inputItems   = $input.all();\n  const seenContent  = new Set();\n  const validChunks  = [];\n\n  for (const item of inputItems) {\n    const chunk = item.json;\n\n    /* 1 ── skip empty rows */\n    if (!chunk || !chunk.text || chunk.text.trim() === \"\") continue;\n\n    const titleText   = (chunk.section_title || \"\").trim();\n    const contentText = chunk.text.trim();\n\n    /* 2 ── drop title-only rows */\n    if (contentText === titleText) continue;\n\n    /* 3 ── duplicate detection (normalise whitespace + leading numbers) */\n    const normalized = contentText\n      .replace(/^\\d+(\\.\\d+)*\\s+/gm, \"\")  // remove numbered prefixes\n      .replace(/\\s+/g, \" \")              // collapse whitespace\n      .trim();\n\n    if (seenContent.has(normalized)) continue;\n    seenContent.add(normalized);\n\n    validChunks.push(chunk);\n  }\n\n  /* 4 ── return with incremental index */\n  return validChunks.map((chunk, idx) => ({\n    json: {\n      ...chunk\n    }\n  }));\n}\n\nreturn filterEmptyAndDuplicateChunks();\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1088,
        2064
      ],
      "id": "947d7869-a17a-43d7-a610-22201a54ef6e",
      "name": "Filter Empty & Duplicate Chunks"
    },
    {
      "parameters": {
        "jsCode": "/**\n * N8n Function node to split document chunks for optimized Elasticsearch vector search\n * Takes chunks like those extracted from PDF documents and splits them if they exceed token limits\n * while preserving context and section structure\n * \n * @param {Object} items - The input items coming from n8n workflow\n * @returns {Object} - The processed items with optimized chunks for vector search\n */\n\n// Main processing function for n8n Function node\nfunction processDocumentChunks() {\n  // Get input data\n  const items = $input.all();\n  \n  // Configuration (could be made into node parameters in a custom n8n node)\n  const maxTokens = 7000;        // Maximum tokens per chunk\n  const overlapTokens = 50;     // Tokens to overlap between chunks\n  const embeddingField = 'text_to_embed'; // Field for the text to be embedded\n  \n  let outputItems = [];\n  let globalChunkIndex = 0;  // Global counter for chunk indexing\n  \n  // Process each item\n  for (const item of items) {\n    let inputChunks;\n    \n    // Determine input format\n    if (Array.isArray(item.json)) {\n      // If input is already an array of chunks\n      inputChunks = item.json;\n    } else if (item.json.chunks && Array.isArray(item.json.chunks)) {\n      // If chunks are in a property called 'chunks'\n      inputChunks = item.json.chunks;\n    } else {\n      // If the item itself is a single chunk\n      inputChunks = [item.json];\n    }\n    \n    // Process the chunks\n    const processedChunks = splitChunks(inputChunks, maxTokens, overlapTokens, embeddingField, globalChunkIndex);\n    \n    // Update the counter\n    globalChunkIndex += inputChunks.length;\n    \n    // Return in the same format as received\n    if (Array.isArray(item.json)) {\n      outputItems.push({ json: processedChunks });\n    } else if (item.json.chunks) {\n      outputItems.push({\n        json: {\n          ...item.json,\n          chunks: processedChunks\n        }\n      });\n    } else {\n      // Return processed chunks as separate items\n      processedChunks.forEach(chunk => {\n        outputItems.push({ json: chunk });\n      });\n    }\n  }\n  \n  return outputItems;\n}\n\n/**\n * Split chunks if they exceed the token limit\n * @param {Array} chunks - Array of document chunks\n * @param {number} maxTokens - Maximum tokens per chunk\n * @param {number} overlapTokens - Tokens to overlap between chunks\n * @param {string} embeddingField - Field name for embeddings\n * @param {number} startIndex - Starting index for global chunk indexing\n * @returns {Array} - Processed chunks\n */\nfunction splitChunks(chunks, maxTokens, overlapTokens, embeddingField, startIndex = 0) {\n  const result = [];\n  \n  // Process each chunk\n  chunks.forEach((chunk, index) => {\n    const tokenCount = estimateTokens(chunk.text);\n    const actualIndex = startIndex + index;\n    \n    // If chunk is within token limit, add vector fields and keep it as is\n    if (tokenCount <= maxTokens) {\n      result.push({\n        ...chunk,\n        //[embeddingField]: chunk.text, // Add embedding field\n        // vector_metadata: {\n        //   token_count: tokenCount,\n        //   is_split: false,\n        // }\n      });\n      return;\n    }\n    \n    // Need to split the chunk - first try by paragraphs\n    const paragraphs = splitIntoParagraphs(chunk.text);\n    let chunkParts = [];\n    \n    if (paragraphs.length > 1) {\n      // If we have multiple paragraphs, try to group them into chunks\n      chunkParts = groupContentUnits(paragraphs, maxTokens, chunk.section_title);\n    } else {\n      // Otherwise split by sentences\n      const sentences = splitIntoSentences(chunk.text);\n      chunkParts = groupContentUnits(sentences, maxTokens, chunk.section_title);\n    }\n    \n    // Create chunk objects for each part\n    chunkParts.forEach((part, partIndex) => {\n      // Add section title to beginning of parts after the first one\n      const textWithContext = partIndex === 0 \n        ? part\n        : `${chunk.section_title || ''} (continued) ${part}`;\n      \n      result.push({\n        chunk_id: `${chunk.chunk_id}_part${partIndex + 1}`,\n        section_title: chunk.section_title,\n        text: textWithContext,\n        //[embeddingField]: textWithContext, // Field for embedding\n        metadata: {\n          ...chunk.metadata,\n          parent_chunk_id: chunk.chunk_id,\n          is_split_chunk: true,\n          split_part: partIndex + 1,\n          total_parts: chunkParts.length\n        },\n        //vector_metadata: {\n         // token_count: estimateTokens(textWithContext),\n         // is_split: true,\n         // part_index: partIndex\n       // }\n      });\n    });\n  });\n  \n  return result;\n}\n\n/**\n * Group content units (paragraphs or sentences) into chunks of appropriate size\n * @param {Array} units - Content units to group\n * @param {number} maxTokens - Maximum tokens per chunk\n * @param {string} sectionTitle - Section title for context\n * @returns {Array} - Grouped content as chunks\n */\nfunction groupContentUnits(units, maxTokens, sectionTitle) {\n  const chunks = [];\n  let currentChunk = '';\n  let currentTokens = 0;\n  const contextPrefix = sectionTitle ? sectionTitle + ' ' : '';\n  const contextTokens = estimateTokens(contextPrefix);\n  \n  // Account for context in parts after the first\n  const effectiveMaxTokens = maxTokens - contextTokens;\n  \n  units.forEach((unit, index) => {\n    const unitTokens = estimateTokens(unit);\n    \n    // If this unit alone exceeds limits, split it further by words\n    if (unitTokens > effectiveMaxTokens) {\n      if (currentChunk) {\n        chunks.push(currentChunk);\n        currentChunk = '';\n        currentTokens = 0;\n      }\n      \n      // Split large unit by words\n      const words = unit.split(/\\s+/);\n      let tempChunk = '';\n      \n      words.forEach(word => {\n        const wordTokens = estimateTokens(word + ' ');\n        \n        if (currentTokens + wordTokens > effectiveMaxTokens) {\n          if (tempChunk) {\n            chunks.push(tempChunk);\n            tempChunk = word;\n            currentTokens = wordTokens;\n          } else {\n            // Word itself is too big, have to include it anyway\n            tempChunk = word;\n            currentTokens = wordTokens;\n          }\n        } else {\n          tempChunk += (tempChunk ? ' ' : '') + word;\n          currentTokens += wordTokens;\n        }\n      });\n      \n      if (tempChunk) {\n        chunks.push(tempChunk);\n      }\n    }\n    // If adding this unit would exceed max tokens, start a new chunk\n    else if (currentTokens + unitTokens > effectiveMaxTokens) {\n      if (currentChunk) {\n        chunks.push(currentChunk);\n      }\n      currentChunk = unit;\n      currentTokens = unitTokens;\n    } \n    // Add to current chunk\n    else {\n      currentChunk += (currentChunk ? ' ' : '') + unit;\n      currentTokens += unitTokens;\n    }\n  });\n  \n  // Add any remaining content\n  if (currentChunk) {\n    chunks.push(currentChunk);\n  }\n  \n  return chunks;\n}\n\n/**\n * Split text into paragraphs\n * @param {string} text - Input text\n * @returns {Array} - Array of paragraphs\n */\nfunction splitIntoParagraphs(text) {\n  // Split on double newlines or equivalent\n  return text.split(/\\n\\s*\\n|\\r\\n\\s*\\r\\n/).filter(p => p.trim());\n}\n\n/**\n * Split text into sentences\n * @param {string} text - Input text\n * @returns {Array} - Array of sentences\n */\nfunction splitIntoSentences(text) {\n  // Split on sentence-ending punctuation followed by space or end of string\n  return text.split(/(?<=[.!?])\\s+|(?<=[.!?])$/).filter(s => s.trim());\n}\n\n/**\n * Estimate token count for a text string\n * @param {string} text - Text to estimate tokens for\n * @returns {number} - Estimated token count\n */\nfunction estimateTokens(text) {\n  if (!text) return 0;\n  \n  // Simple estimation: roughly 4 characters per token for English\n  // For production, replace with a proper tokenizer matching your embedding model\n  return Math.ceil(text.length / 4);\n}\n\n// Execute the function and return results\nreturn processDocumentChunks();"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1424,
        2224
      ],
      "id": "bc34ddc6-0187-4c78-ac60-deaff5cd8ad6",
      "name": "Split Chunks"
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "ab2bedcf-f824-47dd-9e51-00888ee470fa",
              "name": "chunk_id",
              "value": "={{ $('Final Escaping').item.json.chunk_id }}",
              "type": "string"
            },
            {
              "id": "3ad9ad67-06cb-4490-b5c0-d87362a48128",
              "name": "section_title",
              "value": "={{ $('Final Escaping').item.json.section_title }}",
              "type": "string"
            },
            {
              "id": "16c251d1-42c5-45a4-978e-ce91f0e295bb",
              "name": "text",
              "value": "={{ $('Final Escaping').item.json.text }}",
              "type": "string"
            },
            {
              "id": "53121648-9acf-46fb-9027-7898e85865d5",
              "name": "metadata",
              "value": "={{ $('Final Escaping').item.json.metadata }}",
              "type": "object"
            },
            {
              "id": "4f420c43-5c17-474f-b524-9f7a98f9873a",
              "name": "embeddings",
              "value": "={{ $json.embedding }}",
              "type": "array"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        -464,
        2224
      ],
      "id": "e40fd51a-8dca-4897-93e8-4b3dbe001c6b",
      "name": "Edit Fields"
    },
    {
      "parameters": {
        "mode": "runOnceForEachItem",
        "jsCode": "const input = $json;\nreturn {\n  json: {\n    embedding: input.embeddings[0]\n  }\n};"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -640,
        2224
      ],
      "id": "55d9e07c-db62-4679-97f0-62b84c0c655a",
      "name": "Embedding Isolated"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "http://192.168.20.70:8878/parse/file",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "accept",
              "value": "application/json"
            },
            {
              "name": "Authorization",
              "value": "Bearer dev-key"
            }
          ]
        },
        "sendBody": true,
        "contentType": "multipart-form-data",
        "bodyParameters": {
          "parameters": [
            {
              "name": "data",
              "value": "{\"chunk_document\":true,\"max_tokens_per_chunk\":7000,\"optimize_pdf\":true}"
            },
            {
              "parameterType": "formBinaryData",
              "name": "file",
              "inputDataFieldName": "data"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -1728,
        2160
      ],
      "id": "f3ebfc8f-ce23-4a9b-bcaa-d7c912d6723a",
      "name": "Chunker Full"
    },
    {
      "parameters": {
        "jsCode": "const slug = s => (s ?? \"\").toLowerCase()\n  .replace(/[^a-z0-9]+/g, '_')\n  .replace(/^_|_$/g, '')\n  .slice(0, 50);\n\nconst final = ($input.first()?.json?.data?.chunks ?? []).map((c, i) => {\n  const sectionTitle = c?.section_title ?? \"\";\n  const text = c?.text ?? \"\";\n  const chunkIndex = c?.chunk_index ?? \"\";\n\n  const chunkId = `${slug(sectionTitle)}_${i}`;\n  const metadata = {\n    ...(c?.metadata ?? {}),\n    chunk_index: chunkIndex\n  };\n\n  // Remove heading_path if it exists\n  if (\"heading_path\" in metadata) {\n    delete metadata.heading_path;\n  }\n\n  return {\n    section_title: sectionTitle,\n    chunk_id: chunkId,\n    text: text,\n    metadata: metadata\n  };\n});\n\nreturn final.map(j => ({ json: j }));\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1424,
        2064
      ],
      "id": "48f8d152-339e-4e29-9202-cb7d8966bb8a",
      "name": "Format Output"
    },
    {
      "parameters": {
        "content": "## Generating JSON with chunks from raw PDF\n\n### Using Chunker on docker.",
        "height": 380,
        "width": 300,
        "color": 3
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        -1808,
        1984
      ],
      "id": "7a7d8485-7213-407d-a686-f808512a9171",
      "name": "Sticky Note6"
    },
    {
      "parameters": {
        "content": "## JSON Cleanup & Splitting",
        "height": 380,
        "width": 620
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        -1504,
        1984
      ],
      "id": "5b504955-e3fb-4358-8f05-f90908d803e3",
      "name": "Sticky Note17"
    },
    {
      "parameters": {
        "content": "## Remove and recreate the index\n",
        "height": 460,
        "width": 680,
        "color": 2
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        -2480,
        1984
      ],
      "id": "0a30fc21-7323-45b7-81a0-aa3d31ea6bd3",
      "name": "Sticky Note18"
    },
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "rfp-analyse",
        "options": {}
      },
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 2,
      "position": [
        -3488,
        2064
      ],
      "id": "850f8345-d0a6-4382-b066-a037e15bce48",
      "name": "Start RFP Analysis",
      "webhookId": "663a2e7d-35dd-4241-8890-97393732bb42"
    },
    {
      "parameters": {
        "jsCode": "const indexName = $('Start RFP Analysis').first().json.body.indexName;\nif (!indexName) {\n  throw new Error('indexName not found in previous step');\n}\n\nconst elasticUrl = `http://192.168.20.70:9204/${indexName}`;\n\nreturn [{\n  json: {\n    ...items[0].json,\n    elasticsearchUrl: elasticUrl,\n    elasticEndpoint: `${elasticUrl}/_doc`  // For document operations\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -2064,
        2064
      ],
      "id": "f3594aad-01cf-42e1-85ff-68beee4e2f85",
      "name": "Create ES Url"
    },
    {
      "parameters": {
        "jsCode": "// Extract file ID from the link\nconst link = $('Start RFP Analysis').first().json.body.link;\n\n// This regex handles multiple Google Drive URL formats:\n// - https://drive.google.com/uc?id=FILE_ID&export=download\n// - https://drive.google.com/file/d/FILE_ID/view\n// - https://drive.google.com/open?id=FILE_ID\nconst match = link.match(/[?&]id=([a-zA-Z0-9_-]+)|\\/d\\/([a-zA-Z0-9_-]+)/);\nconst fileId = match ? (match[1] || match[2]) : null;\n\nif (!fileId) {\n  throw new Error('Could not extract file ID from link');\n}\n\nreturn [{\n  json: {\n    ...items[0].json.body,\n    googleFileId: fileId  // Will be: 1zkYxLnRpA-NeMAWeT-vzTO6rkl6G4ae7\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -2720,
        2064
      ],
      "id": "314ebd94-e555-4e7d-a398-e2dd421b08f4",
      "name": "Extract FileId"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://sse-estimation-tool.onrender.com/progress",
        "sendBody": true,
        "contentType": "raw",
        "rawContentType": "application/json",
        "body": "={{ $json.body }}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -464,
        2464
      ],
      "id": "59f77291-68d2-42f1-874f-aad0dde5f6e1",
      "name": "SSE - Document Preparation"
    },
    {
      "parameters": {
        "jsCode": "// Get sessionId from the RFP Upload node\nconst sessionId = $('Start RFP Analysis').first().json.body.sessionId || \"no-session\";\n\n// Transform into the desired format\n// return [{\n//   json: {\n//     step: \"document_preparation\",\n//     title: \"Step 1: Document Preparation\", \n//     sessionId: sessionId,\n//     output: JSON.stringify(outputData || {})\n//   }\n// }];\n\nconst payload = {\n    step: \"document_preparation\",\n    title: \"Step 1: Document Preparation\", \n    sessionId: sessionId,\n    output: \"Document parsed\"\n};\n\nreturn [\n  {\n    json: {\n      body: JSON.stringify(payload)\n    }\n  }\n];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -640,
        2464
      ],
      "id": "a1e3aa07-996a-4693-9918-bbd88a16a13a",
      "name": "Prepare for frontend"
    },
    {
      "parameters": {
        "jsCode": "\nconst outputs = $('Get Platforms').all().map(item => item.json.output);\nconst sessionId = $('Start RFP Analysis').first().json.body.sessionId || \"no-session\";\n\nconst payload = {\n  step: \"platforms\",\n  title: \"Step 2. Platforms Info\",\n  sessionId:sessionId,\n  output: JSON.stringify(outputs ?? {}),\n};\n\nreturn [\n  {\n    json: {\n      platforms: JSON.stringify(payload)\n    }\n  }\n];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -2608,
        3568
      ],
      "id": "cedcde81-7eb3-4073-b62d-01dcec787ab0",
      "name": "Prepare for frontend8"
    },
    {
      "parameters": {
        "jsCode": "// Get the output from the Combined Requirements Output node\nconst combinedOutput = $('Combine Requirements').first().json.output;\nconst sessionId = $('Start RFP Analysis').first().json.body.sessionId || \"no-session\";\n\n// Extract only titles from both functional and non-functional requirements\nconst titlesOnly = combinedOutput.map(section => {\n  const processedSection = {};\n  \n  // Process each category (functional, non-functional, etc.)\n  Object.keys(section).forEach(category => {\n    if (Array.isArray(section[category])) {\n      processedSection[category] = section[category].map(req => req.title);\n    }\n  });\n  \n  return processedSection;\n});\n\nconst payload = {\n  step: \"requirements\",\n  title: \"Step 3. Requirements\",\n  sessionId: sessionId,\n  output: JSON.stringify(titlesOnly)\n};\n\nreturn [{\n  json: payload\n}];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        3008,
        3552
      ],
      "id": "53ada245-67fb-4f72-9fa1-05a15b568340",
      "name": "Prepare for frontend9"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://sse-estimation-tool.onrender.com/progress",
        "sendBody": true,
        "contentType": "raw",
        "rawContentType": "application/json",
        "body": "={{ $json}}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        3008,
        3984
      ],
      "id": "ef7c0d95-0a95-46f9-9c18-8c24f8af4676",
      "name": "SSE - Requirements"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://sse-estimation-tool.onrender.com/progress",
        "sendBody": true,
        "contentType": "raw",
        "rawContentType": "application/json",
        "body": "={{ $json.platforms }}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -2448,
        3568
      ],
      "id": "798f51ec-39e3-4c6b-bb8f-e6bbaa615257",
      "name": "SSE - Platforms"
    },
    {
      "parameters": {
        "jsCode": "// Get the output from the Combined Requirements Output node\nconst techstack = $('Get Techstack').first().json.output;\nconst sessionId = $('Start RFP Analysis').first().json.body.sessionId || \"no-session\";\n\nconst payload = {\n  step: \"techstack\",\n  title: \"Step 4. Techstack\",\n  sessionId: sessionId,\n  output: JSON.stringify(techstack)\n};\n\nreturn [{\n  json: payload\n}];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -2816,
        4672
      ],
      "id": "f527fac7-3d08-45fa-b724-b94a8b109841",
      "name": "Prepare for frontend10"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://sse-estimation-tool.onrender.com/progress",
        "sendBody": true,
        "contentType": "raw",
        "rawContentType": "application/json",
        "body": "={{ $json}}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -2560,
        4672
      ],
      "id": "4f711341-d697-410a-9d08-42ba54e638fb",
      "name": "SSE - Techstack"
    },
    {
      "parameters": {
        "jsCode": "// Get the output from the Combined Requirements Output node\nconst team = $('Team Composition').first().json.output;\nconst sessionId = $('Start RFP Analysis').first().json.body.sessionId || \"no-session\";\n\nconst payload = {\n  step: \"team_composition\",\n  title: \"Step 5. Team Composition\",\n  sessionId: sessionId,\n  output: JSON.stringify(team)\n};\n\nreturn [{\n  json: payload\n}];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -800,
        4464
      ],
      "id": "a2b6b81c-0894-40d3-b2a6-c50615b92a74",
      "name": "Prepare for frontend11"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://sse-estimation-tool.onrender.com/progress",
        "sendBody": true,
        "contentType": "raw",
        "rawContentType": "application/json",
        "body": "={{ $json}}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -528,
        4464
      ],
      "id": "a4f7e230-6124-47c4-846f-8340b2bf9e8f",
      "name": "SSE - Team Composition"
    },
    {
      "parameters": {
        "jsCode": "// Get the output from the Combined Requirements Output node\nconst effort = $('Effort Estimation').first().json.output;\nconst sessionId = $('Start RFP Analysis').first().json.body.sessionId || \"no-session\";\n\nconst payload = {\n  step: \"effort_estimation\",\n  title: \"Step 6. Effort Estimation\",\n  sessionId: sessionId,\n  output: JSON.stringify(effort)\n};\n\nreturn [{\n  json: payload\n}];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1088,
        4288
      ],
      "id": "04a6dd31-c352-42c0-af23-6315c462e96c",
      "name": "Prepare for frontend12"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://sse-estimation-tool.onrender.com/progress",
        "sendBody": true,
        "contentType": "raw",
        "rawContentType": "application/json",
        "body": "={{ $json}}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        1328,
        4272
      ],
      "id": "a7cf8ca3-30d1-4bf9-98d0-c814528845a1",
      "name": "SSE - Effort Estimation"
    },
    {
      "parameters": {
        "jsCode": "// Get the output from the Combined Requirements Output node\nconst plan = $('Development Plan').first().json.output;\nconst sessionId = $('Start RFP Analysis').first().json.body.sessionId || \"no-session\";\n\nconst payload = {\n  step: \"development_plan\",\n  title: \"Step 7. Development Plan\",\n  sessionId: sessionId,\n  output: JSON.stringify(plan)\n};\n\nreturn [{\n  json: payload\n}];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        2784,
        4400
      ],
      "id": "403f4dd5-cb3a-4525-ab1c-3d7ea99db8b1",
      "name": "Prepare for frontend13"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://sse-estimation-tool.onrender.com/progress",
        "sendBody": true,
        "contentType": "raw",
        "rawContentType": "application/json",
        "body": "={{ $json}}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        3008,
        4400
      ],
      "id": "f75443f5-d44d-45bd-92a6-dac1d4e37041",
      "name": "SSE - Development Plan"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "claude-sonnet-4-20250514",
          "mode": "list",
          "cachedResultName": "Claude Sonnet 4"
        },
        "options": {
          "maxTokensToSample": 6096,
          "thinking": true
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatAnthropic",
      "typeVersion": 1.3,
      "position": [
        3584,
        4608
      ],
      "id": "890abe39-390e-4cf5-9492-8573d262149f",
      "name": "Anthropic Chat Model5",
      "credentials": {
        "anthropicApi": {
          "id": "qzCm5Ds2qD9ZY1W5",
          "name": "Anthropic account"
        }
      }
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ $json.userPrompt }}",
        "options": {
          "systemMessage": "={{ $json.systemPrompt }}"
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.8,
      "position": [
        3584,
        4432
      ],
      "id": "deed8200-dd26-45bd-b6b8-1ce171f3f43c",
      "name": "Reporter",
      "onError": "continueErrorOutput"
    },
    {
      "parameters": {
        "jsCode": "const input = $input.first().json.output;\nconst sessionId = $('Start RFP Analysis').first().json.body.sessionId || \"no-session\";\n\nconst payload = {\n  step: \"final_report\",\n  title: \"Step 8. Final Report\",\n  sessionId: sessionId,\n  output: input\n};\n\nreturn [{\n  json: payload\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        3984,
        4432
      ],
      "id": "878d9336-db9f-4836-8c39-8e2023e679c3",
      "name": "Prepare for frontend7"
    },
    {
      "parameters": {
        "jsCode": "\n//const requirements = $('Dependencies1').first().json.combinedRequirementsSnippet;\nconst team = $('Team Composition Output').first().json.teamCompositionSnippet;\nconst estimation = $('Effort Estimate Output').first().json.effortEstimationSnippet;\nconst dev = $('Development Plan Output').first().json.developmentPlanOutput;\nconst techstack = $('Techstack Output').first().json.detectedTechStackSnippet\nconst platforms = $('Platforms Output').first().json.detectedPlatformsSnippet\n\nconst systemPrompt = `\nYou are a professional document formatter specialized in creating executive-grade PDF reports. Your role is to take structured project data and present it in a clean, professional format optimized for PDF rendering.\n\nCRITICAL REQUIREMENTS:\n- Present existing data in professional PDF format - DO NOT add new analysis\n- Use clean markdown formatting with proper line breaks\n- Format existing information into professional tables and sections\n- Use executive summary styling and highlight boxes for key information\n- Keep content high-level and focused on presenting the provided data clearly\n`;\n\nconst userPrompt = `\nFormat the provided project analysis data into a professional executive summary document optimized for PDF export.\n\nFORMATTING REQUIREMENTS:\n- Use proper markdown syntax (not escaped characters)\n- Present data in professional tables and sections\n- Use **RECOMMENDATION**, **RISK**, **SUCCESS** for any existing insights\n- Structure with clear headers using # ## ### syntax\n- Include executive summary with key metrics from provided data\n\n**DATA TO FORMAT:**\n\n**PLATFORMS:** ${platforms}\n**TECHNOLOGY STACK:** ${techstack}  \n**TEAM COMPOSITION:** ${team}\n**EFFORT ESTIMATION:** ${estimation}\n**DEVELOPMENT PLAN:** ${dev}\n\nGenerate a professional document with this structure:\n\n# PROJECT DELIVERY SUMMARY\n## [Extract project name/type from data]\n\n<div class=\"executive-summary\">\n\n**PROJECT INVESTMENT SUMMARY**\n\n[Create 150-200 word summary using ONLY the provided data, highlighting:\n- Platform scope (from platforms data)\n- Technology approach (from techstack data) \n- Team size and timeline (from team/estimation data)\n- Key deliverables (from dev plan data)]\n\n**Key Investment Metrics:**\n- **Timeline:** [Extract from estimation data] sprints ([calculate weeks])\n- **Team Size:** [Sum FTE from team data] FTE resources\n- **Platforms:** [List from platforms data]\n- **Technology Stack:** [Summary from techstack data]\n\n</div>\n\n## Platform and Technology Overview\n\n### Target Platforms\n[Create table from platforms data showing platform types and descriptions]\n\n### Technology Architecture  \n[Format techstack data into clear sections:\n- Backend: [from backend_stack]\n- Frontend: [from web_stack] \n- Mobile: [from mobile_stack]\n- Database: [from database]\n- Deployment: [from deployment]\n- Key Integrations: [from integrations]]\n\n## Team Structure and Resource Allocation\n\n[Create professional table from team data with columns:]\n| **Role** | **FTE Allocation** | **Key Responsibilities** |\n|----------|-------------------|--------------------------|\n[Format each role from team composition data]\n| **Total Team** | **[Sum all FTE]** | **Complete project delivery** |\n\n## Development Timeline and Phases\n\n### Project Timeline\n- **Sprint Range:** [min_sprints] - [max_sprints] sprints\n- **Estimated Duration:** [calculate weeks/months from sprint data]\n- **Methodology:** Agile with 2-week sprints\n\n### Development Phases\n[For each phase in development plan, create structured overview:]\n\n**Phase [X]: [phase name]** (Sprints [start]-[end])\n- **Duration:** [calculate sprint count] sprints  \n- **Key Focus:** [summarize 2-3 main items from phase items]\n\n[Continue for all phases in dev plan...]\n\n\n## Executive Summary\n\n<div class=\"highlight-box\">\n\n**PROJECT DELIVERY OVERVIEW**\n\n**Total Investment:** [Sum team FTE] FTE resources over [estimation range] sprints\n\n**Technology Approach:** [Brief summary of separated/unified architecture from techstack]\n\n**Delivery Confidence:** Based on [estimation rationale summary]\n\n**Key Success Factors:**\n- [Extract 2-3 points from team/estimation rationale]\n\n\n</div>\n\nIMPORTANT INSTRUCTIONS:\n- Use ONLY the data provided - do not add new analysis or conclusions\n- Format existing information into professional presentation\n- Keep requirements section as overview/summary only (do not list all requirements)\n- Present data clearly without adding interpretation beyond what's already provided\n- Use professional formatting that works well with PDF generation\n`;\n\nreturn {\n  json: {\n    systemPrompt,\n    userPrompt\n  }\n};"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        3360,
        4400
      ],
      "id": "8bc320c2-c016-4446-aed5-74ecbac1d053",
      "name": "Prompt"
    },
    {
      "parameters": {
        "jsCode": "/**\n * n8n Function node\n * Input  : first item from the previous “Effort Estimation” LLM step\n * Output : { effortEstimationSnippet: '### EFFORT_ESTIMATION …' }\n */\n\nconst effort = $input.first().json.output;\n\nif (!effort || typeof effort !== 'object') {\n  throw new Error('Expected output object with development plan.');\n}\n\nconst developmentPlanOutput = [\n  '### DEVELOPMENT_PLAN (authoritative, generated in prior step)',\n  JSON.stringify(effort, null, 2),\n  '',\n  'Treat this development plan as the base reference.'\n].join('\\n');\n\nreturn [\n  {\n    json: {\n      developmentPlanOutput,\n    },\n  },\n];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        2592,
        4400
      ],
      "id": "e6654dcc-5eb2-419d-be38-ba2cd397aad7",
      "name": "Development Plan Output"
    },
    {
      "parameters": {},
      "type": "@n8n/n8n-nodes-langchain.toolCalculator",
      "typeVersion": 1,
      "position": [
        3840,
        4640
      ],
      "id": "6d321fb9-b38a-46d5-8b59-7e09599c1023",
      "name": "Calculator2"
    },
    {
      "parameters": {},
      "type": "@n8n/n8n-nodes-langchain.toolThink",
      "typeVersion": 1,
      "position": [
        3744,
        4640
      ],
      "id": "1a64f503-feff-4973-8241-c06380f48e0b",
      "name": "Think2"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://sse-estimation-tool.onrender.com/progress",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ $json }}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        4240,
        4432
      ],
      "id": "387c4e6a-f8ae-4511-876d-e70f8b78ea5a",
      "name": "SSE - Final Report"
    },
    {
      "parameters": {
        "jsCode": "// Get sessionId from previous step\nconst sessionId = $('Start RFP Analysis').first().json.body.sessionId || \"no-session\";\n\n// Professional PDF content example\nconst professionalContent = `# PROJECT2 DELIVERY SUMMARY\n## Enterprise CRM & Customer Management Platform\n\n<div class=\"executive-summary\">\n\n**PROJECT INVESTMENT SUMMARY**\n\nThis comprehensive enterprise CRM platform represents a strategic digital transformation initiative requiring 18-24 months and 12.5 FTE resources. The solution encompasses web applications, mobile platforms (iOS/Android), and robust backend services with extensive third-party integrations including Microsoft 365, Salesforce, and QuickBooks Online.\n\nThe project scope includes 45 functional requirements spanning user management, advanced analytics, customer journey mapping, automated marketing workflows, and comprehensive reporting capabilities. Additionally, 28 non-functional requirements mandate enterprise-grade security, GDPR compliance, scalability to support 1000+ concurrent users, and 99.9% uptime SLA.\n\n**Key Investment Metrics:**\n- **Estimated Timeline:** 18-24 months\n- **Required Team Size:** 12.5 FTE resources  \n- **Total Investment:** 300-450 person-months\n- **Confidence Level:** High (88%)\n- **Overall Risk Level:** Medium\n\n**Strategic Recommendation:** Proceed with phased implementation approach to minimize risk and deliver incremental business value.\n\n</div>\n\n## Project Scope and Requirements Analysis\n\n**Project Complexity Rating:** Highly Complex\n\nThe comprehensive requirements analysis reveals a sophisticated enterprise-level platform with multiple integration points and advanced functionality requirements.\n\n### Requirements Quality Assessment\n\n- **Completeness Rating:** Excellent (92%) - Well-defined functional and technical specifications\n- **Technical Clarity:** High - Clear architectural requirements and integration specifications  \n- **Implementation Feasibility:** High - Technically achievable with recommended team structure\n\n**RECOMMENDATION**: Requirements are well-defined and ready for implementation. Recommend conducting technical discovery workshops for Microsoft 365 and Salesforce integration specifics.\n\n**RISK**: Complex third-party integrations may introduce timeline dependencies on external vendor support and API limitations.\n\n## Investment Analysis and Resource Planning\n\n### Development Effort Estimation\n\n| **Investment Metric** | **Minimum Scenario** | **Most Likely** | **Maximum Scenario** | **Recommended Planning** |\n|----------------------|---------------------|-----------------|---------------------|-------------------------|\n| **Development Duration** | 16 months | 20 months | 24 months | 20 months |\n| **Sprint Count** | 32 sprints | 40 sprints | 48 sprints | 40 sprints |\n| **Team Size (FTE)** | 10.0 FTE | 12.5 FTE | 15.0 FTE | 12.5 FTE |\n| **Confidence Level** | 75% | 88% | 95% | 88% |\n| **Total Investment** | 267 person-months | 333 person-months | 450 person-months | 333 person-months |\n\n### Timeline and Risk Analysis\n\n**Estimation Methodology:** Three-point estimation using industry benchmarks for enterprise CRM implementations, adjusted for project complexity and team experience.\n\n**Critical Timeline Factors:**\n- Third-party API integration complexity and documentation quality\n- Customer data migration from legacy systems (estimated 2.5M records)\n- Enterprise security compliance and penetration testing requirements\n- User acceptance testing across multiple business units (250+ users)\n\n**RISK**: Microsoft 365 integration timeline dependent on tenant configuration complexity and may require additional 2-4 weeks if custom permissions are needed.\n\n**SUCCESS**: Strong technical leadership availability and clear business requirements will accelerate development velocity by an estimated 15-20%.\n\n## Team Composition and Resource Strategy\n\n### Recommended Team Structure\n\n| **Role** | **FTE Allocation** | **Duration (months)** | **Key Responsibilities** | **Seniority Required** |\n|----------|-------------------|-----------------------|-------------------------|----------------------|\n| **Technical Lead** | 1.0 FTE | 20 months | Architecture, code reviews, technical decisions | Senior (8+ years) |\n| **Backend Developers** | 3.0 FTE | 18 months | API development, database design, integrations | Mid-Senior (5+ years) |\n| **Frontend Developers** | 2.5 FTE | 16 months | React web app, responsive design, UX implementation | Mid-Level (3+ years) |\n| **Mobile Developers** | 2.0 FTE | 14 months | iOS/Android native apps, mobile UX optimization | Mid-Senior (4+ years) |\n| **DevOps Engineer** | 1.0 FTE | 20 months | CI/CD, infrastructure, monitoring, security | Senior (6+ years) |\n| **QA Engineers** | 2.0 FTE | 18 months | Test automation, manual testing, UAT coordination | Mid-Level (3+ years) |\n| **UI/UX Designer** | 1.0 FTE | 12 months | Design system, prototypes, user research | Mid-Senior (4+ years) |\n| **Total Team** | **12.5 FTE** | **20 months** | **Complete enterprise platform delivery** | **Mixed experience levels** |\n\n### Resource Strategy\n\n**Team Composition Rationale:** Balanced team structure emphasizing backend expertise for complex integrations while ensuring strong frontend capabilities for user experience excellence.\n\n**Critical Skills and Expertise:**\n- Microsoft 365 API integration experience (Graph API, SharePoint)\n- Enterprise security implementation (OAuth 2.0, SAML, encryption)\n- High-volume data processing and optimization\n- Mobile application development with offline capabilities\n\n**RECOMMENDATION**: Prioritize hiring technical lead and senior backend developers first to establish architecture foundation. Consider Microsoft-certified developers for Graph API integration.\n\n**SUCCESS**: Cross-functional team with previous enterprise CRM experience will reduce learning curve and improve delivery predictability by 25-30%.\n\n## Development Methodology and Delivery Phases\n\n### Development Approach\n\nAgile methodology with 2-week sprints, emphasizing continuous integration, automated testing, and regular stakeholder feedback loops. Parallel development tracks for web, mobile, and backend components with clearly defined integration milestones.\n\n### Delivery Phase Breakdown\n\n**Phase 1: Foundation & Core Platform** (Sprints 1-12)\n- **Duration:** 12 sprints (24 weeks)\n- **Key Deliverables:** \n  - Core authentication and user management system\n  - Basic CRM functionality (contacts, accounts, opportunities)\n  - Database schema and API foundation\n  - Development infrastructure and CI/CD pipeline\n- **Success Criteria:** User authentication, basic CRUD operations, automated testing framework\n- **Dependencies:** Infrastructure setup, third-party service accounts provisioning\n\n**Phase 2: Advanced Features & Integrations** (Sprints 13-28)\n- **Duration:** 16 sprints (32 weeks)\n- **Key Deliverables:** \n  - Microsoft 365 integration (Calendar, Email, SharePoint)\n  - Advanced analytics and reporting engine\n  - Mobile applications (iOS and Android)\n  - Automated workflow engine\n- **Success Criteria:** Full integration functionality, mobile app store deployment, analytics dashboard\n- **Dependencies:** Microsoft 365 tenant configuration, mobile developer account setup\n\n**Phase 3: Enterprise Features & Optimization** (Sprints 29-40)\n- **Duration:** 12 sprints (24 weeks)\n- **Key Deliverables:** \n  - Advanced security features and compliance\n  - Performance optimization and scalability testing\n  - Data migration tools and legacy system integration\n  - User training materials and documentation\n- **Success Criteria:** Security certification, performance benchmarks met, successful data migration\n- **Dependencies:** Legacy system access, security audit scheduling\n\n### Project Success Framework\n\n**SUCCESS**: Key factors ensuring project success include dedicated product owner engagement, regular stakeholder reviews, and phased user acceptance testing with business units.\n\n**RISK**: Primary project risks include third-party API changes, scope creep from additional integration requests, and resource availability during peak development phases. Mitigation includes API versioning strategy, formal change control process, and backup resource planning.\n\n## Executive Summary and Investment Recommendation\n\n<div class=\"highlight-box\">\n\n**FINAL INVESTMENT RECOMMENDATION**\n\n**Total Project Investment:** 333 person-months over 20 months\n\n**Strategic Recommendation:** **PROCEED** with phased implementation approach\n\n**Confidence Assessment:** High confidence (88%) in delivery estimates based on detailed technical analysis and industry benchmarks\n\n**Critical Success Dependencies:**\n- Dedicated technical leadership and senior backend development expertise\n- Early Microsoft 365 integration planning and tenant configuration\n- Committed product owner with decision-making authority for requirement clarifications\n- Phased user acceptance testing approach with business unit representatives\n\n**Immediate Next Steps:**\n1. **Technical Discovery Phase** (2-4 weeks) - Microsoft 365 integration assessment and architecture design\n2. **Team Assembly** (4-6 weeks) - Recruit technical lead and core backend development team\n3. **Infrastructure Setup** (2-3 weeks) - Development environment, CI/CD pipeline, and monitoring tools\n\n**ROI Projection:** Expected 300% ROI within 18 months post-deployment through improved sales efficiency, automated workflows, and enhanced customer insights.\n\n</div>\n\n**RECOMMENDATION**: This enterprise CRM platform represents a strategic investment with clear business value and technical feasibility. The phased approach minimizes risk while delivering incremental value. Recommend proceeding with immediate technical discovery and team assembly.\n\n## Risk Assessment and Mitigation Strategy\n\n**RISK**: **Third-Party Integration Complexity** - Microsoft 365 and Salesforce API limitations may impact timeline\n- *Mitigation:* Conduct technical proof-of-concept during discovery phase\n- *Contingency:* 2-week buffer built into Phase 2 timeline\n\n**RISK**: **Team Scaling Challenges** - Difficulty finding experienced enterprise developers\n- *Mitigation:* Engage technical recruiting partner, consider remote team members\n- *Contingency:* Adjust timeline by 10-15% if key positions remain unfilled after 6 weeks\n\n**SUCCESS**: **Strong Business Sponsorship** - Executive commitment ensures resource availability and decision-making speed\n- *Advantage:* Reduces requirement clarification delays, accelerates UAT cycles\n- *Impact:* Potential 15-20% timeline improvement with dedicated product ownership\n\nThis comprehensive analysis demonstrates high confidence in successful delivery of an enterprise-grade CRM platform that will transform customer relationship management capabilities and drive significant business value.`;\n\nconst payload = {\n  step: \"final_report\",\n  title: \"Step 8. Final Report\",\n  sessionId: sessionId,\n  output: professionalContent\n};\n\nreturn [{\n  json: payload\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        3360,
        4624
      ],
      "id": "5ff68bf8-6340-482c-970a-e1d9ca5866aa",
      "name": "mock"
    },
    {
      "parameters": {
        "operation": "getAll",
        "indexId": "={{ $('Start RFP Analysis').first().json.body.indexName }}",
        "limit": 10,
        "simple": false,
        "options": {
          "query": "={\n  \"size\": 10,\n  \"min_score\": 1.0,\n  \"_source\": [\n    \"chunk_id\",\"section_title\",\"text\",\n    \"metadata.filename\",\"metadata.page_numbers\",\n    \"metadata.parent_chunk_id\",\"metadata.is_split_chunk\",\n    \"metadata.split_part\",\"metadata.total_parts\",\n    \"vector_metadata.token_count\",\"vector_metadata.is_split\",\n    \"vector_metadata.chunk_index\"\n  ],\n  \"knn\": {\n    \"field\": \"embeddings\",\n    \"query_vector\": [ {{ $json.embeddings }} ],\n    \"k\": 20,\n    \"num_candidates\": 50\n  },\n  \"query\": {\n    \"bool\": {\n      \"should\": [\n        {\n          \"match_phrase\": {\n            \"text\": {\n              \"query\": \"{{ $('Queries').item.json.phrase }}\",\n              \"slop\": 4,\n              \"boost\": 2.0\n            }\n          }\n        },\n        {\n          \"multi_match\": {\n            \"query\": \"{{ $('Queries').item.json.keywords }}\",\n            \"fields\": [\"text^2\",\"section_title^3\"],\n            \"type\": \"most_fields\",\n            \"minimum_should_match\": 2,\n            \"boost\": 1.2\n          }\n        },\n        {\n          \"terms_set\": {\n            \"text.keyword\": {\n              \"terms\": {{ JSON.stringify($('Queries').item.json.keywords.split(',').map(k => k.trim())) }},\n\n              \"minimum_should_match_script\": {\n                \"source\": \"Math.min(params.num_terms, 2)\"\n              }\n            }\n          }\n        }\n      ],\n      \"minimum_should_match\": 1\n    }\n  },\n  \"rescore\": {\n    \"window_size\": 20,\n    \"query\": {\n      \"rescore_query\": {\n        \"match_phrase\": {\n          \"text\": {\n            \"query\": \"{{ $('Queries').item.json.rescore_query }}\",\n            \"slop\": 8\n          }\n        }\n      },\n      \"query_weight\": 0.7,\n      \"rescore_query_weight\": 0.3\n    }\n  },\n  \"highlight\": {\n    \"type\": \"unified\",\n    \"fields\": { \"text\": {}, \"section_title\": {} }\n  }\n}\n"
        }
      },
      "type": "n8n-nodes-base.elasticsearch",
      "typeVersion": 1,
      "position": [
        -3456,
        3152
      ],
      "id": "b898cac6-ea34-4dcc-8a2b-df14bf84ad5a",
      "name": "Query - Full1",
      "alwaysOutputData": true,
      "credentials": {
        "elasticsearchApi": {
          "id": "wwaILZtoajWrVXwt",
          "name": "Elasticsearch account"
        }
      }
    },
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "sendToEmail",
        "responseMode": "responseNode",
        "options": {}
      },
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 2,
      "position": [
        -4384,
        5744
      ],
      "id": "b241b7df-3263-499f-aa10-4d9b82038892",
      "name": "Send PDF to Email",
      "webhookId": "663a2e7d-35dd-4241-8890-97393732bb42"
    },
    {
      "parameters": {
        "sendTo": "={{ $json.email }}",
        "subject": "=Your Q AI RFP Analysis Report is Ready for {{ $json.body.fileName }}",
        "message": "=<!DOCTYPE html>\n<html>\n  <head>\n    <meta charset=\"UTF-8\" />\n    <title>Q AI RFP Analysis Report</title>\n  </head>\n  <body style=\"font-family: Arial, sans-serif; background-color: #f5f5f5; padding: 20px; margin: 0;\">\n    <table width=\"100%\" cellpadding=\"0\" cellspacing=\"0\" border=\"0\" style=\"max-width: 600px; margin: auto; background-color: #ffffff; border-radius: 8px; overflow: hidden;\">\n      <tr>\n        <td style=\"padding: 30px 40px;\">\n          <h2 style=\"color: #333333;\">Dear {{ $json.name }},</h2>\n          <p style=\"font-size: 16px; color: #555555; line-height: 1.6;\">\n            Thank you for using the <strong>Q AI RFP Analysis Tool</strong>.\n          </p>\n          <p style=\"font-size: 16px; color: #555555; line-height: 1.6;\">\n            Attached to this email, you will find the informative analysis report generated based on the RFP you uploaded.\n            The report includes insights related to <strong>estimated effort</strong>, <strong>key requirements</strong>, <strong>potential risks</strong>, and other relevant aspects of the document.\n          </p>\n          <p style=\"font-size: 16px; color: #555555; line-height: 1.6;\">\n            We hope this helps you streamline your decision-making process and improve planning efficiency.\n          </p>\n          <p style=\"font-size: 16px; color: #555555; line-height: 1.6;\">\n            <strong>Please note:</strong> This report was generated using the <strong>limited free version</strong> of our Q Estimation Tool.\n          </p>\n          <p style=\"font-size: 16px; color: #555555; line-height: 1.6;\">\n            To explore the full range of features, visit <a href=\"https://q.agency/products/q-estimation-tool/\" style=\"color: #1a73e8; text-decoration: none;\"><strong>Q Estimation Tool</strong></a>.\n          </p>\n          <p style=\"font-size: 16px; color: #555555; line-height: 1.6;\">\n            If you have any questions or would like further support, feel free to reach us at <a href=\"mailto:hello@q.agency\" style=\"color: #1a73e8; text-decoration: none;\"><strong>hello@q.agency</strong></a>.\n          </p>\n          <p style=\"font-size: 16px; color: #333333; margin-top: 30px;\">\n            Best regards,<br/>\n            <strong>AI Team at Q Agency</strong>\n          </p>\n        </td>\n      </tr>\n      <tr>\n        <td style=\"background-color: #eeeeee; padding: 20px; text-align: center; font-size: 12px; color: #888888;\">\n          © 2025 Q Agency. All rights reserved.\n        </td>\n      </tr>\n    </table>\n  </body>\n</html>",
        "options": {
          "appendAttribution": false,
          "attachmentsUi": {
            "attachmentsBinary": [
              {
                "property": "pdf"
              }
            ]
          },
          "bccList": "zlatko.matokanovic@q.agency"
        }
      },
      "type": "n8n-nodes-base.gmail",
      "typeVersion": 2.1,
      "position": [
        -3664,
        5744
      ],
      "id": "23f18901-e69e-403b-8ee7-5f39956afce8",
      "name": "Gmail",
      "webhookId": "e71d01f0-8d29-4bad-8b6a-25062a67369e",
      "credentials": {
        "gmailOAuth2": {
          "id": "AnMIdKkQ5ToxkLrh",
          "name": "Gmail account"
        }
      }
    },
    {
      "parameters": {
        "mode": "combine",
        "combineBy": "combineAll",
        "options": {}
      },
      "type": "n8n-nodes-base.merge",
      "typeVersion": 3,
      "position": [
        -3920,
        5744
      ],
      "id": "3c38a586-e32a-4977-885f-135efd3bc193",
      "name": "Merge"
    },
    {
      "parameters": {
        "jsCode": "function extractNameFromEmail(email) {\n  if (!email || typeof email !== 'string') return '';\n\n  const localPart = email.split('@')[0];\n\n  // Replace separators with spaces\n  const raw = localPart.replace(/[\\._\\-]+/g, ' ').trim();\n\n  // Split and capitalize\n  const nameParts = raw\n    .split(' ')\n    .filter(Boolean)\n    .map(w => w.charAt(0).toUpperCase() + w.slice(1).toLowerCase());\n\n  return nameParts.join(' ');\n}\n\nconst input = $input.first().json;\n\nconst email = input.body?.email || '';\nconst sessionId = input.body?.sessionId || '';\nconst name = extractNameFromEmail(email);\nconst fileName = $input.first().json.body.originalFilename\n\n\nreturn [\n  {\n    json: {\n      email,\n      name,\n      sessionId,\n      fileName,\n      binary: input.binary\n    }\n  }\n];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -4144,
        5872
      ],
      "id": "3a1d3c8f-5aae-4cee-ba02-a0a51313877f",
      "name": "Code6"
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 2
          },
          "conditions": [
            {
              "id": "9a436325-f8ac-491f-99aa-c66f916b471d",
              "leftValue": "={{$json._index === undefined}}",
              "rightValue": "",
              "operator": {
                "type": "boolean",
                "operation": "false",
                "singleValue": true
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [
        -3248,
        3152
      ],
      "id": "29541b0e-091e-4d8c-8fe0-b7a56a1b1fc4",
      "name": "Has Hits?"
    },
    {
      "parameters": {
        "content": "## Email Trigger - Client\n",
        "height": 860,
        "width": 1320,
        "color": 4
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        -4464,
        5504
      ],
      "id": "f2cdf605-1e7a-4a67-bb35-57413ba46985",
      "name": "Sticky Note5"
    },
    {
      "parameters": {
        "content": "## Final Report\n",
        "height": 520,
        "width": 1080
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        3328,
        4320
      ],
      "id": "18728a32-7f65-4a2a-ba4f-79fbbb01d4e9",
      "name": "Sticky Note2"
    },
    {
      "parameters": {
        "amount": 0.7
      },
      "type": "n8n-nodes-base.wait",
      "typeVersion": 1.1,
      "position": [
        -3680,
        3152
      ],
      "id": "4b073436-1496-4c40-b6e8-79e6c7d346ec",
      "name": "Wait",
      "webhookId": "39e4fb26-2d96-4dd9-a44a-ca00c6b72d67"
    },
    {
      "parameters": {
        "amount": 0.7
      },
      "type": "n8n-nodes-base.wait",
      "typeVersion": 1.1,
      "position": [
        -1296,
        3344
      ],
      "id": "d476c362-b25b-4e00-8455-186bedfabe4f",
      "name": "Wait1",
      "webhookId": "39e4fb26-2d96-4dd9-a44a-ca00c6b72d67"
    },
    {
      "parameters": {
        "amount": 0.7
      },
      "type": "n8n-nodes-base.wait",
      "typeVersion": 1.1,
      "position": [
        800,
        3360
      ],
      "id": "8c43b3ff-d4da-43c2-b454-b57e3a1b75c0",
      "name": "Wait2",
      "webhookId": "39e4fb26-2d96-4dd9-a44a-ca00c6b72d67"
    },
    {
      "parameters": {
        "amount": 0.7
      },
      "type": "n8n-nodes-base.wait",
      "typeVersion": 1.1,
      "position": [
        -4048,
        4432
      ],
      "id": "69d8c343-161b-4954-9e93-87141f6b777c",
      "name": "Wait3",
      "webhookId": "39e4fb26-2d96-4dd9-a44a-ca00c6b72d67"
    },
    {
      "parameters": {
        "errorType": "errorObject",
        "errorObject": "{\n  \"title\": \"Platforms\",\n  \"message\": \"Unfortunately, we couldn’t identify the target platforms from your RFP. Since this information is essential for the analysis, the process has been halted.\"\n}"
      },
      "type": "n8n-nodes-base.stopAndError",
      "typeVersion": 1,
      "position": [
        -2944,
        3024
      ],
      "id": "95aa3917-db4b-4701-ac03-ae8f4927cb0c",
      "name": "Stop and Error"
    },
    {
      "parameters": {
        "operation": "download",
        "fileId": {
          "__rl": true,
          "value": "={{ $('Extract FileId').item.json.googleFileId }}",
          "mode": "id"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.googleDrive",
      "typeVersion": 3,
      "position": [
        -2064,
        2272
      ],
      "id": "45a8cc9b-7434-41e3-8a32-199c6ac68050",
      "name": "Download File",
      "credentials": {
        "googleDriveOAuth2Api": {
          "id": "OYJ2pu0fWBya0IA6",
          "name": "Google Drive account 3"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "const sessionId = $input.first().json.body.sessionId;\n\nconst executionId = $execution.id;\nconst workflowId = $workflow.id;\nconst startTime = new Date().toISOString();\n\n// Create session data object\nconst sessionData = {\n  sessionId: sessionId,\n  executionId: executionId,\n  workflowId: workflowId,\n  workflowName: $workflow.name,\n  startTime: startTime,\n  status: 'active',\n  nodeCount: 1\n};\n\n// Prepare file content\nconst fileName = `session_${executionId}.json`;\nconst fileContent = JSON.stringify(sessionData, null, 2);\nconst filePath = `/tmp/${fileName}`;\n\nconsole.log(`📁 Creating session file: ${filePath}`);\nconsole.log(`🆔 Session ID: ${sessionId}`);\n\nreturn {\n  json: {\n    sessionId: sessionId,\n    executionId: executionId,\n    fileName: fileName,\n    filePath: filePath,\n    fileContent: fileContent,\n    sessionData: sessionData,\n    \n    // Include original input data\n    ...$input.first()?.json\n  }\n};"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -3216,
        2064
      ],
      "id": "172cea53-c3c0-4f0f-8ee4-95861a733b3c",
      "name": "Get Session ID and prepare file data"
    },
    {
      "parameters": {
        "command": "=printf '%s\\n' '{{ $json.fileContent }}' > /tmp/session_{{ $execution.id }}.json && echo \"Session file created\"\n"
      },
      "type": "n8n-nodes-base.executeCommand",
      "typeVersion": 1,
      "position": [
        -2960,
        2064
      ],
      "id": "bcc12cdb-482d-43ad-9250-d5d9fa0b4ede",
      "name": "Save To FileSystem"
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 2
          },
          "conditions": [
            {
              "id": "9a436325-f8ac-491f-99aa-c66f916b471d",
              "leftValue": "={{$json._index === undefined}}",
              "rightValue": "",
              "operator": {
                "type": "boolean",
                "operation": "false",
                "singleValue": true
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [
        -896,
        3200
      ],
      "id": "b38d7869-a063-4bce-a560-17a5e966c0b5",
      "name": "Has Hits?1"
    },
    {
      "parameters": {
        "errorType": "errorObject",
        "errorObject": "{\n  \"title\": \"Functional Requirements\",\n  \"message\": \"Unfortunately, we couldn’t identify the functional requirements from your RFP. Since this information is essential for the analysis, the process has been halted.\"\n}"
      },
      "type": "n8n-nodes-base.stopAndError",
      "typeVersion": 1,
      "position": [
        -304,
        3008
      ],
      "id": "583a6bd1-6c4d-4fba-a78a-8bc453cdf5ae",
      "name": "Stop and Error1"
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 2
          },
          "conditions": [
            {
              "id": "9a436325-f8ac-491f-99aa-c66f916b471d",
              "leftValue": "={{$json._index === undefined}}",
              "rightValue": "",
              "operator": {
                "type": "boolean",
                "operation": "false",
                "singleValue": true
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [
        1088,
        3200
      ],
      "id": "db87a48e-3c8e-41b3-9718-6cdb17abc575",
      "name": "Has Hits?2"
    },
    {
      "parameters": {
        "errorType": "errorObject",
        "errorObject": "{\n  \"title\": \"Non-Functional Requirements\",\n  \"message\": \"Unfortunately, we couldn’t identify the non-functional requirements from your RFP. Since this information is essential for the analysis, the process has been halted.\"\n}"
      },
      "type": "n8n-nodes-base.stopAndError",
      "typeVersion": 1,
      "position": [
        1648,
        3024
      ],
      "id": "b0f78901-fa93-4992-85f2-88645543345e",
      "name": "Stop and Error2"
    },
    {
      "parameters": {
        "errorType": "errorObject",
        "errorObject": "{\n  \"title\": \"Functional Requirements\",\n  \"message\": \"Unfortunately, we couldn’t identify the functional requirements from your RFP. Since this information is essential for the analysis, the process has been halted.\"\n}"
      },
      "type": "n8n-nodes-base.stopAndError",
      "typeVersion": 1,
      "position": [
        2480,
        2992
      ],
      "id": "8c6f12f5-e6da-4144-b600-2fca010de626",
      "name": "Stop and Error3"
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 2
          },
          "conditions": [
            {
              "id": "9a436325-f8ac-491f-99aa-c66f916b471d",
              "leftValue": "={{$json._index === undefined}}",
              "rightValue": "",
              "operator": {
                "type": "boolean",
                "operation": "false",
                "singleValue": true
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [
        -3728,
        4432
      ],
      "id": "ebe41519-27cb-4c10-8aff-96c0b629bc74",
      "name": "Has Hits?3"
    },
    {
      "parameters": {
        "errorType": "errorObject",
        "errorObject": "{\n  \"title\": \"Techstack\",\n  \"message\": \"Unfortunately, we couldn’t identify the techstack from your RFP. Since this information is essential for the analysis, the process has been halted.\"\n}"
      },
      "type": "n8n-nodes-base.stopAndError",
      "typeVersion": 1,
      "position": [
        -3056,
        4848
      ],
      "id": "de12b0bf-e047-40aa-8845-5a38725a0dd9",
      "name": "Stop and Error4"
    },
    {
      "parameters": {
        "errorType": "errorObject",
        "errorObject": "{\n  \"title\": \"Team Composition\",\n  \"message\": \"Unfortunately, we couldn’t identify the team composition from your RFP. Since this information is essential for the analysis, the process has been halted.\"\n}"
      },
      "type": "n8n-nodes-base.stopAndError",
      "typeVersion": 1,
      "position": [
        -1248,
        4080
      ],
      "id": "489692cb-fe75-44ce-9643-8e1d2bc2c889",
      "name": "Stop and Error5"
    },
    {
      "parameters": {
        "errorType": "errorObject",
        "errorObject": "{\n  \"title\": \"Effort Estimation\",\n  \"message\": \"Unfortunately, something went wrong while generating the effort estimation. Please try again or upload a revised RFP if the issue persists.\"\n}"
      },
      "type": "n8n-nodes-base.stopAndError",
      "typeVersion": 1,
      "position": [
        768,
        4080
      ],
      "id": "b950945f-2a95-4cb5-952b-5d02a4cf772d",
      "name": "Stop and Error6"
    },
    {
      "parameters": {
        "errorType": "errorObject",
        "errorObject": "{\n  \"title\": \"Roadmap\",\n  \"message\": \"Unfortunately, something went wrong while generating the roadmap. Please try again or upload a revised RFP if the issue persists.\"\n}"
      },
      "type": "n8n-nodes-base.stopAndError",
      "typeVersion": 1,
      "position": [
        2480,
        4080
      ],
      "id": "32930a94-bc3a-4cc2-88a2-216c692943a1",
      "name": "Stop and Error7"
    },
    {
      "parameters": {
        "errorType": "errorObject",
        "errorObject": "{\n  \"title\": \"Final Report\",\n  \"message\": \"Unfortunately, something went wrong while generating the final report. Please try again or upload a revised RFP if the issue persists.\"\n}"
      },
      "type": "n8n-nodes-base.stopAndError",
      "typeVersion": 1,
      "position": [
        3888,
        4160
      ],
      "id": "92b855cd-2c17-4ae1-a317-2691c46c13bf",
      "name": "Stop and Error8"
    },
    {
      "parameters": {
        "command": "=rm -f /tmp/session_{{ $('Get Session ID and prepare file data').first().json.execution.id }}.json && echo \"Session file cleaned up\"\n"
      },
      "type": "n8n-nodes-base.executeCommand",
      "typeVersion": 1,
      "position": [
        4512,
        4432
      ],
      "id": "316cacd2-7a58-47d5-9d0f-a0c11832d325",
      "name": "Delete tmp file"
    },
    {
      "parameters": {
        "options": {
          "responseCode": 200
        }
      },
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1.4,
      "position": [
        -3424,
        5744
      ],
      "id": "acabc517-2273-4e98-9896-3669b400e8b4",
      "name": "Respond to Webhook"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "/models/qwen3_coder_30b_a3b",
          "mode": "list",
          "cachedResultName": "/models/qwen3_coder_30b_a3b"
        },
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        -3520,
        3760
      ],
      "id": "a226710b-7d1e-40ed-99c5-8107add08775",
      "name": "LLama4Scout",
      "credentials": {
        "openAiApi": {
          "id": "09tIxrZPXx1gwPgx",
          "name": "vllm"
        }
      }
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ $json.userPrompt }}",
        "hasOutputParser": true,
        "options": {
          "systemMessage": "={{ $json.systemPrompt }}"
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.9,
      "position": [
        -3264,
        3552
      ],
      "id": "108b3e0e-01fd-4e3f-b9c4-1558662badf8",
      "name": "Get Platforms"
    }
  ],
  "pinData": {},
  "repo_name": "n8n-backup-zm",
  "repo_owner": "zlatkomq",
  "repo_path": "",
  "settings": {
    "executionOrder": "v1",
    "callerPolicy": "workflowsFromSameOwner",
    "errorWorkflow": "052VdzVIz9bFK2dw"
  },
  "staticData": null,
  "tags": [
    {
      "createdAt": "2025-04-24T10:59:44.979Z",
      "updatedAt": "2025-04-24T10:59:44.979Z",
      "id": "qEREEA2JvunvA9Nv",
      "name": "Estimation Tool"
    }
  ],
  "triggerCount": 2,
  "updatedAt": "2025-08-11T16:44:48.900Z",
  "versionId": "16bf7017-7a43-4f71-af43-f2320ffc112b"
}